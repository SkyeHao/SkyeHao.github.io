{"pages":[{"title":"书单","date":"2022-02-04T09:42:28.028Z","updated":"2022-02-04T09:42:28.028Z","comments":false,"path":"books/index.html","permalink":"http://example.com/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2022-02-04T11:23:34.438Z","updated":"2022-02-04T09:42:28.028Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2022-02-04T12:45:10.310Z","updated":"2022-02-04T12:45:10.310Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"擅长Java后端开发。喜欢通过编程解决生活中遇到的问题，关注后端动态，对新的技术有追求，喜欢有逻辑的事物，喜欢coding。 1234567891011121314151617181920212223242526&#123; name: &#x27;Skye&#x27; age: 21, gender: &#x27;男&#x27;, profession: &#x27;大四就业狗 &amp; 后端开发&#x27;, experience: &#x27;2年&#x27;, address: &#x27;河南省新乡市&#x27;, education: &#x27;本科&#x27;, github: &#x27;https://github.com/SkyeHao&#x27;, email: &#x27;xxhsk0618@163.com&#x27;, description: &#x27;喜欢通过编程解决生活中遇到的问题&#x27;, skills: [ [&#x27;Java&#x27;, &#x27;Ajax&#x27;, &#x27;Python&#x27;], [&#x27;SpringBoot&#x27;, &#x27;Mybatis&#x27;, &#x27;SpringMVC&#x27;], [&#x27;MySQL&#x27;,&#x27;Tomcat&#x27;,&#x27;Git&#x27;], [&#x27;Vue&#x27;, &#x27;HTML&#x27;, &#x27;CSS&#x27;, &#x27;Node&#x27;], [&#x27;Android&#x27;, &#x27;Linux&#x27;, &#x27;docker&#x27;], ], devTools: [ [&#x27;IDEA&#x27;,&#x27;Eclipse&#x27;,&#x27;Android Studio&#x27;,&#x27;Pycharm&#x27;], [&#x27;Sublime Text&#x27;, &#x27;Visual Studio Code&#x27;, &#x27;Notepad++&#x27;], [&#x27;Navicat&#x27;, &#x27;VMware&#x27;] ] &#125;"},{"title":"友情链接","date":"2022-02-04T11:00:08.259Z","updated":"2022-02-04T09:42:28.029Z","comments":true,"path":"links/index.html","permalink":"http://example.com/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2022-02-04T09:42:28.029Z","updated":"2022-02-04T09:42:28.029Z","comments":false,"path":"repository/index.html","permalink":"http://example.com/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-02-04T09:42:28.030Z","updated":"2022-02-04T09:42:28.030Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"404 Not Found：该页无法显示","date":"2022-02-15T15:35:09.986Z","updated":"2022-02-04T09:42:28.025Z","comments":false,"path":"/404.html","permalink":"http://example.com/404.html","excerpt":"","text":""}],"posts":[{"title":"数字序列中某一位的数字","slug":"19、数字序列中某一位的数字","date":"2022-02-18T14:16:35.000Z","updated":"2022-02-18T14:22:56.214Z","comments":true,"path":"2022/02/18/19、数字序列中某一位的数字/","link":"","permalink":"http://example.com/2022/02/18/19%E3%80%81%E6%95%B0%E5%AD%97%E5%BA%8F%E5%88%97%E4%B8%AD%E6%9F%90%E4%B8%80%E4%BD%8D%E7%9A%84%E6%95%B0%E5%AD%97/","excerpt":"","text":"问题描述 主要问题 暴力解导致堆内存溢出 解决办法找规律 123456789101112131415161718192021222324public int findNthDigit(int n) &#123; if(n==0) return 0; //由于是n=0时对应开始的0，这里不需要进行减操作n--;，但是如果n=1对应开始的0则需要减操作 //排除n=0后，后面n从1开始。 int digit = 1; int start = 1; long count = 9; //count的值有可能会超出int的范围，所以变量类型取为long while(n&gt;count)&#123;//不能带=号，此时n从1开始，n=count时，属于上一个循环的最后一个数字 n=(int)(n-count);//这里(int)不能省略 digit++; start = start*10; count = (long)start*9*digit; //这里的long不能省略，否则，会先按照int类型进行计算，然后赋值给long型的count，超过int大小限制时，会出现负数 &#125; int num = start + (n-1)/digit; int index = (n-1)%digit;//index最大取digit-1,即此时num坐标从左到右为0,1,...,digit-1,共digit位 while(index&lt;(digit-1))&#123; //最后的结果是num中的第index个数字，index从左到右从0开始递增，考虑到踢出右侧末尾的数字比较简单，我们从右侧开始依次踢出数字 num = num/10; digit--; &#125; return num%10;//此时num的右侧末尾数字即为结果 &#125; 复杂度分析 时间复杂度：O(logn) 空间复杂度：O(logn)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"搜索算法","slug":"算法/剑指offer/搜索算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"搜索算法","slug":"算法/剑指offer/搜索算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/"}]},{"title":"字符串的排列","slug":"18、字符串的排列","date":"2022-02-18T13:34:35.000Z","updated":"2022-02-18T13:40:19.729Z","comments":true,"path":"2022/02/18/18、字符串的排列/","link":"","permalink":"http://example.com/2022/02/18/18%E3%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%8E%92%E5%88%97/","excerpt":"","text":"问题描述 主要问题 对于拥有重复字符的字符串，在递归调用时不能只是简单的判断是否含有相同字符，否则会出错。 解决办法回溯算法在递归调用时，不是每次都要传入当前字符串，而是将 char[] 数组设为成员变量，通过交换 char[] 数组中元素的位置来起到连接不同字符的作用，在最终跳出递归时将数组转为字符串加入集合即可。 12345678910111213141516171819202122232425262728class Solution &#123; List&lt;String&gt; res = new LinkedList&lt;&gt;(); char[] c; public String[] permutation(String s) &#123; c = s.toCharArray(); dfs(0); return res.toArray(new String[res.size()]); &#125; void dfs(int x) &#123; if(x == c.length - 1) &#123; res.add(String.valueOf(c)); // 添加排列方案 return; &#125; HashSet&lt;Character&gt; set = new HashSet&lt;&gt;(); for(int i = x; i &lt; c.length; i++) &#123; if(set.contains(c[i])) continue; // 重复，因此剪枝 set.add(c[i]); swap(i, x); // 交换，将 c[i] 固定在第 x 位 dfs(x + 1); // 开启固定第 x + 1 位字符 swap(i, x); // 恢复交换 &#125; &#125; void swap(int a, int b) &#123; char tmp = c[a]; c[a] = c[b]; c[b] = tmp; &#125;&#125; 复杂度分析 时间复杂度：O(n!n) 空间复杂度：O(n^2)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"回溯算法","slug":"算法/剑指offer/回溯算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"回溯算法","slug":"算法/剑指offer/回溯算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/"}]},{"title":"旋转数组的最小数字","slug":"16、旋转数组的最小数字","date":"2022-02-18T12:34:35.000Z","updated":"2022-02-18T12:53:56.847Z","comments":true,"path":"2022/02/18/16、旋转数组的最小数字/","link":"","permalink":"http://example.com/2022/02/18/16%E3%80%81%E6%97%8B%E8%BD%AC%E6%95%B0%E7%BB%84%E7%9A%84%E6%9C%80%E5%B0%8F%E6%95%B0%E5%AD%97/","excerpt":"","text":"问题描述 主要问题 使用二分法时，对于 arr[mid] 和谁比较产生疑问 解决办法二分法 对于 num[m] = num[j] 的情况而言，因为题目只要求找到最小值而不要求旋转节点索引值，所以在有相等的值的时候，进行 j = j -1 并不会导致最小值丢失。 实际上，当出现 nums[m] = nums[j] 时，一定有区间 [i,m] 内所有元素相等 或 区间 [m,j] 内所有元素相等（或两者皆满足）。对于寻找此类数组的最小值问题，可直接放弃二分查找，而使用线性查找替代。 123456789101112131415161718class Solution &#123; public int minArray(int[] numbers) &#123; int i = 0, j = numbers.length - 1; while (i &lt; j) &#123; int m = (i + j) / 2; if (numbers[m] &gt; numbers[j]) i = m + 1; else if (numbers[m] &lt; numbers[j]) j = m; else &#123; int x = i; for(int k = i + 1; k &lt; j; k++) &#123; if(numbers[k] &lt; numbers[x]) x = k; &#125; return numbers[x]; &#125; &#125; return numbers[i]; &#125;&#125; 复杂度分析 时间复杂度：O(logN) 空间复杂度：O(1)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"搜索算法","slug":"算法/剑指offer/搜索算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"搜索算法","slug":"算法/剑指offer/搜索算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/"}]},{"title":"二维数组中查找","slug":"15、二维数组中查找","date":"2022-02-18T10:30:35.000Z","updated":"2022-02-18T10:35:57.136Z","comments":true,"path":"2022/02/18/15、二维数组中查找/","link":"","permalink":"http://example.com/2022/02/18/15%E3%80%81%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E4%B8%AD%E6%9F%A5%E6%89%BE/","excerpt":"","text":"问题描述 我的代码1234567891011121314151617181920public class Solution &#123; public boolean Find(int target, int [][] array) &#123; if(array.length == 0 || array[0].length == 0) return false; if(target &lt; array[0][0] || target &gt; array[array.length-1][array[0].length-1])&#123; return false; &#125; int num = array[0].length; for(int i = 0;i &lt; array.length;i++)&#123; for(int j = 0;j &lt; num;j++)&#123; if(array[i][j] == target) return true; else&#123; if(array[i][j] &gt; target)&#123; num = j; &#125; &#125; &#125; &#125; return false; &#125;&#125; 主要问题 难以达到O(n+m)的时间复杂度 解决办法二分查找 123456789101112class Solution &#123; public boolean findNumberIn2DArray(int[][] matrix, int target) &#123; int i = matrix.length - 1, j = 0; while(i &gt;= 0 &amp;&amp; j &lt; matrix[0].length) &#123; if(matrix[i][j] &gt; target) i--; else if(matrix[i][j] &lt; target) j++; else return true; &#125; return false; &#125;&#125; 复杂度分析 时间复杂度：O(n+m) 空间复杂度：O(1)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"搜索算法","slug":"算法/剑指offer/搜索算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"搜索算法","slug":"算法/剑指offer/搜索算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/"}]},{"title":"在排序数组中查找数字","slug":"17、在排序数组中查找数字","date":"2022-02-17T04:12:35.000Z","updated":"2022-02-18T12:54:13.069Z","comments":true,"path":"2022/02/17/17、在排序数组中查找数字/","link":"","permalink":"http://example.com/2022/02/17/17%E3%80%81%E5%9C%A8%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E6%9F%A5%E6%89%BE%E6%95%B0%E5%AD%97/","excerpt":"","text":"问题描述 主要问题 对于二分查找的左右端点的数组下标不确定 解决办法二分法 1234567891011121314151617181920212223class Solution &#123; public int search(int[] nums, int target) &#123; // 搜索右边界 right int i = 0, j = nums.length - 1; while(i &lt;= j) &#123; int m = (i + j) / 2; if(nums[m] &lt;= target) i = m + 1; else j = m - 1; &#125; int right = i; // 若数组中无 target ，则提前返回 if(j &gt;= 0 &amp;&amp; nums[j] != target) return 0; // 搜索左边界 right i = 0; j = nums.length - 1; while(i &lt;= j) &#123; int m = (i + j) / 2; if(nums[m] &lt; target) i = m + 1; else j = m - 1; &#125; int left = j; return right - left - 1; &#125;&#125; 复杂度分析 时间复杂度：O(logN) 空间复杂度：O(1)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"搜索算法","slug":"算法/剑指offer/搜索算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"搜索算法","slug":"算法/剑指offer/搜索算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/"}]},{"title":"数的子结构","slug":"14、树的子结构","date":"2022-02-15T14:33:02.000Z","updated":"2022-02-15T14:55:56.911Z","comments":true,"path":"2022/02/15/14、树的子结构/","link":"","permalink":"http://example.com/2022/02/15/14%E3%80%81%E6%A0%91%E7%9A%84%E5%AD%90%E7%BB%93%E6%9E%84/","excerpt":"","text":"问题描述 主要问题 对于遍历叶节点后是否将叶节点的左右空结点写入集合产生疑问，写入则先序遍历可能受到影响 解决办法先序遍历+包含判断若树 B 是树 A 的子结构，则子结构的根节点可能为树 A 的任意一个节点。因此，判断树 B 是否是树 A 的子结构，需完成以下两步工作： 先序遍历树A中的每个结点nA；（对应函数 isSubstructrue(A,B) ） 判断树A中以 nA 为根节点的子树是否包含树 B 。（对应函数recur(A,B)） 算法流程： 名词规定：树 A 的根节点记作节点 A ，树 B 的根节点称为节点 B recur(A, B) 函数： 终止条件： 当节点 B 为空：说明树 B 已匹配完成（越过叶子节点），因此返回 true ； 当节点 A 为空：说明已经越过树 A 叶子节点，即匹配失败，返回 false； 当节点 A 和 B 的值不同：说明匹配失败，返回 false ； 返回值： 判断 A 和 B 的左子节点是否相等，即 recur(A.left, B.left) ； 判断 A 和 B 的右子节点是否相等，即 recur(A.right, B.right) ； isSubStructure(A, B) 函数： 特例处理： 当 树 A 为空 或 树 B 为空时，直接返回 false ； 返回值： 若树 B 是树 A 的子结构，则必满足以下三种情况之一，因此用或 || 连接； 以 节点 A 为根节点的子树 包含树 B ，对应 recur(A, B)； 树 B 是 树 A 左子树 的子结构，对应 isSubStructure(A.left, B)； 树 B 是 树 A 右子树 的子结构，对应 isSubStructure(A.right, B)； 12345678910class Solution &#123; public boolean isSubStructure(TreeNode A, TreeNode B) &#123; return (A != null &amp;&amp; B != null) &amp;&amp; (recur(A, B) || isSubStructure(A.left, B) || isSubStructure(A.right, B)); &#125; boolean recur(TreeNode A, TreeNode B) &#123; if(B == null) return true; if(A == null || A.val != B.val) return false; return recur(A.left, B.left) &amp;&amp; recur(A.right, B.right); &#125;&#125; 复杂度分析： 时间复杂度：O(MN) M,N分别为树 pRoot1和 树 pRoot2的节点数量 空间复杂度：O(M)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"树","slug":"算法/剑指offer/树","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%A0%91/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"树","slug":"算法/剑指offer/树","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%A0%91/"}]},{"title":"重建二叉树","slug":"13、重建二叉树","date":"2022-02-14T11:22:02.000Z","updated":"2022-02-14T11:43:08.315Z","comments":true,"path":"2022/02/14/13、重建二叉树/","link":"","permalink":"http://example.com/2022/02/14/13%E3%80%81%E9%87%8D%E5%BB%BA%E4%BA%8C%E5%8F%89%E6%A0%91/","excerpt":"","text":"问题描述 主要问题 对于给定的前序遍历和中序遍历，没有找到普适的方法确定二叉树的排列方式 解决办法分治算法 前序遍历性质： 节点按照 [ 根节点 | 左子树 | 右子树 ] 排序。 中序遍历性质： 节点按照 [ 左子树 | 根节点 | 右子树 ] 排序。 根据以上性质，可得出以下推论： 前序遍历的首元素 为 树的根节点 node 的值。 在中序遍历中搜索根节点 node 的索引 ，可将 中序遍历 划分为 [ 左子树 | 根节点 | 右子树 ] 。 根据中序遍历中的左（右）子树的节点数量，可将 前序遍历 划分为 [ 根节点 | 左子树 | 右子树 ] 。 通过以上三步，可确定 三个节点 ：1.树的根节点、2.左子树根节点、3.右子树根节点。 根据「分治算法」思想，对于树的左、右子树，仍可复用以上方法划分子树的左右子树。 分治算法解析： 递推参数： 根节点在前序遍历的索引 root 、子树在中序遍历的左边界 left 、子树在中序遍历的右边界 right ； 终止条件： 当 left &gt; right ，代表已经越过叶节点，此时返回 null ； 递推工作： 建立根节点 node ： 节点值为 preorder[root] ； 划分左右子树： 查找根节点在中序遍历 inorder 中的索引 i ； 为了提升效率，本文使用哈希表 dic 存储中序遍历的值与索引的映射，查找操作的时间复杂度为 O(1)； 构建左右子树： 开启左右子树递归； 根节点索引 中序遍历左边界 中序遍历右边界 左子树 root + 1 left i - 1 右子树 i - left + root + 1 i + 1 right TIPS： i - left + root + 1含义为 根节点索引 + 左子树长度 + 1 返回值： 回溯返回 node ，作为上一层递归中根节点的左 &#x2F; 右子节点； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;();//标记中序遍历 int[] preorder;//保留的先序遍历，方便递归时依据索引查看先序遍历的值 public TreeNode buildTree(int[] preorder, int[] inorder) &#123; this.preorder = preorder; //将中序遍历的值及索引放在map中，方便递归时获取左子树与右子树的数量及其根的索引 for (int i = 0; i &lt; inorder.length; i++) &#123; map.put(inorder[i], i); &#125; //三个索引分别为 //当前根的的索引 //递归树的左边界，即数组左边界 //递归树的右边界，即数组右边界 return recur(0,0,inorder.length-1); &#125; //递归遍历所有子树，pre_root是根据先序遍历找到的根节点在中序遍历中的位置 //in_left是中序遍历中索要遍历的子树的左边界 //in_right是中序遍历中索要遍历的子树的右边界 TreeNode recur(int pre_root, int in_left, int in_right)&#123; if(in_left &gt; in_right) return null;// 相等的话就是自己 TreeNode root = new TreeNode(preorder[pre_root]);//获取root节点 int idx = map.get(preorder[pre_root]);//获取在中序遍历中根节点所在索引，以方便获取左子树的数量 //左子树的根的索引为先序中的根节点+1 //递归左子树的左边界为原来的中序in_left //递归左子树的右边界为中序中的根节点索引-1 root.left = recur(pre_root+1, in_left, idx-1); //右子树的根的索引为先序中的 当前根位置 + 左子树的数量 + 1 //递归右子树的左边界为中序中当前根节点+1 //递归右子树的右边界为中序中原来右子树的边界 root.right = recur(pre_root + (idx - in_left) + 1, idx+1, in_right); return root; &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(n)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"树","slug":"算法/剑指offer/树","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%A0%91/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"树","slug":"算法/剑指offer/树","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%A0%91/"}]},{"title":"二叉搜索树的第k个结点","slug":"12、二叉搜索树的第k个结点","date":"2022-02-14T10:41:02.000Z","updated":"2022-02-14T10:44:57.180Z","comments":true,"path":"2022/02/14/12、二叉搜索树的第k个结点/","link":"","permalink":"http://example.com/2022/02/14/12%E3%80%81%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E7%9A%84%E7%AC%ACk%E4%B8%AA%E7%BB%93%E7%82%B9/","excerpt":"","text":"问题描述 我的代码12345678910111213141516171819202122232425262728293031323334353637383940import java.util.*;/* * public class TreeNode &#123; * int val = 0; * TreeNode left = null; * TreeNode right = null; * public TreeNode(int val) &#123; * this.val = val; * &#125; * &#125; */public class Solution &#123; /** * 代码中的类名、方法名、参数名已经指定，请勿修改，直接返回方法规定的值即可 * * * @param proot TreeNode类 * @param k int整型 * @return int整型 */ public int KthNode (TreeNode proot, int k) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); recursion(proot,list); if(k &gt; list.size() || proot == null || k &lt;= 0) return -1; return list.get(k-1); &#125; public void recursion(TreeNode node,ArrayList&lt;Integer&gt; list)&#123; if(node == null) return; if(node.left == null)&#123; list.add(node.val); &#125;else&#123; recursion(node.left,list); list.add(node.val); &#125; if(node.right != null) recursion(node.right,list); &#125;&#125; 主要问题 对于中序遍历，前序遍历，后序遍历一棵树的递归算法思路不够清晰 解决办法中序遍历1234567// 打印中序遍历void dfs(TreeNode root) &#123; if(root == null) return; dfs(root.left); // 左 System.out.println(root.val); // 根 dfs(root.right); // 右&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"树","slug":"算法/剑指offer/树","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%A0%91/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"树","slug":"算法/剑指offer/树","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%A0%91/"}]},{"title":"从上到下打印二叉树(ⅠⅡⅢ)","slug":"11、从上到下打印二叉树（1，2，3）","date":"2022-02-14T03:05:02.000Z","updated":"2022-02-14T10:41:36.915Z","comments":true,"path":"2022/02/14/11、从上到下打印二叉树（1，2，3）/","link":"","permalink":"http://example.com/2022/02/14/11%E3%80%81%E4%BB%8E%E4%B8%8A%E5%88%B0%E4%B8%8B%E6%89%93%E5%8D%B0%E4%BA%8C%E5%8F%89%E6%A0%91%EF%BC%881%EF%BC%8C2%EF%BC%8C3%EF%BC%89/","excerpt":"","text":"问题描述从上到下打印二叉树Ⅰ 从上到下打印二叉树Ⅱ 从上到下打印二叉树Ⅲ 主要问题 使用层序遍历时，对于要使用什么数据类型去存储结点产生疑问 对于第Ⅲ个问题，奇数层与偶数层的区别没有好的实现办法 解决办法 题目要求的二叉树的 从上至下 打印（即按层打印），又称为二叉树的 广度优先搜索（BFS）。 BFS 通常借助 队列 的先入先出特性来实现。 从上到下打印二叉树Ⅰ算法流程： 特例处理： 当树的根节点为空，则直接返回空列表 [] ； 初始化： 打印结果列表 res = [] ，包含根节点的队列 queue = [root] ； BFS 循环： 当队列 queue 为空时跳出； 出队： 队首元素出队，记为 node； 打印： 将 node.val 添加至列表 tmp 尾部； 添加子节点： 若 node 的左（右）子节点不为空，则将左（右）子节点加入队列 queue ； 返回值： 返回打印结果列表 res 即可。 1234567891011121314151617class Solution &#123; public int[] levelOrder(TreeNode root) &#123; if(root == null) return new int[0]; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;()&#123;&#123; add(root); &#125;&#125;; ArrayList&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); while(!queue.isEmpty()) &#123; TreeNode node = queue.poll(); ans.add(node.val); if(node.left != null) queue.add(node.left); if(node.right != null) queue.add(node.right); &#125; int[] res = new int[ans.size()]; for(int i = 0; i &lt; ans.size(); i++) res[i] = ans.get(i); return res; &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(n) 从上到下打印二叉树Ⅱ算法流程： 特例处理： 当根节点为空，则返回空列表 [] ； 初始化： 打印结果列表 res = [] ，包含根节点的队列 queue = [root] ； BFS 循环： 当队列 queue 为空时跳出； 新建一个临时列表 tmp ，用于存储当前层打印结果； 当前层打印循环： 循环次数为当前层节点数（即队列 queue 长度）； 出队： 队首元素出队，记为 node； 打印： 将 node.val 添加至 tmp 尾部； 添加子节点： 若 node 的左（右）子节点不为空，则将左（右）子节点加入队列 queue ； 将当前层结果 tmp 添加入 res 。 返回值： 返回打印结果列表 res 即可。 123456789101112131415161718class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); if(root != null) queue.add(root); while(!queue.isEmpty()) &#123; List&lt;Integer&gt; tmp = new ArrayList&lt;&gt;(); for(int i = queue.size(); i &gt; 0; i--) &#123; TreeNode node = queue.poll(); tmp.add(node.val); if(node.left != null) queue.add(node.left); if(node.right != null) queue.add(node.right); &#125; res.add(tmp); &#125; return res; &#125;&#125; 利用for循环从高到低进行循环解决分层问题 从上到下打印二叉树Ⅲ层序遍历+双端队列 利用双端队列的两端皆可添加元素的特性，设打印列表（双端队列）tmp ，并规定： 奇数层 则添加至 tmp 尾部 ， 偶数层 则添加至 tmp 头部 。 算法流程： 特例处理： 当树的根节点为空，则直接返回空列表 [] ； 初始化： 打印结果空列表 res ，包含根节点的双端队列 deque ； BFS 循环： 当 deque 为空时跳出； 新建列表 tmp ，用于临时存储当前层打印结果； 当前层打印循环： 循环次数为当前层节点数（即 deque 长度）； 出队： 队首元素出队，记为 node； 打印： 若为奇数层，将 node.val 添加至 tmp 尾部；否则，添加至 tmp 头部； 添加子节点： 若 node 的左（右）子节点不为空，则加入 deque ； 将当前层结果 tmp 转化为 list 并添加入 res ； 返回值：返回打印结果列表 res 即可。 12345678910111213141516171819class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); if(root != null) queue.add(root); while(!queue.isEmpty()) &#123; LinkedList&lt;Integer&gt; tmp = new LinkedList&lt;&gt;(); for(int i = queue.size(); i &gt; 0; i--) &#123; TreeNode node = queue.poll(); if(res.size() % 2 == 0) tmp.addLast(node.val); // 偶数层 -&gt; 队列头部 else tmp.addFirst(node.val); // 奇数层 -&gt; 队列尾部 if(node.left != null) queue.add(node.left); if(node.right != null) queue.add(node.right); &#125; res.add(tmp); &#125; return res; &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(n) 层序遍历+双端队列（奇偶层逻辑分离） 方法一代码简短、容易实现；但需要判断每个节点的所在层奇偶性，即冗余了 NN 次判断。 通过将奇偶层逻辑拆分，可以消除冗余的判断。 算法流程： 与方法一对比，仅 BFS 循环不同。 BFS 循环： 循环打印奇 &#x2F; 偶数层，当 deque 为空时跳出； 打印奇数层： 从左向右 打印，先左后右 加入下层节点； 若 deque 为空，说明向下无偶数层，则跳出； 打印偶数层： 从右向左 打印，先右后左 加入下层节点； 123456789101112131415161718192021222324252627282930313233class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; Deque&lt;TreeNode&gt; deque = new LinkedList&lt;&gt;(); List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); if(root != null) deque.add(root); while(!deque.isEmpty()) &#123; // 打印奇数层 List&lt;Integer&gt; tmp = new ArrayList&lt;&gt;(); for(int i = deque.size(); i &gt; 0; i--) &#123; // 从左向右打印 TreeNode node = deque.removeFirst(); tmp.add(node.val); // 先左后右加入下层节点 if(node.left != null) deque.addLast(node.left); if(node.right != null) deque.addLast(node.right); &#125; res.add(tmp); if(deque.isEmpty()) break; // 若为空则提前跳出 // 打印偶数层 tmp = new ArrayList&lt;&gt;(); for(int i = deque.size(); i &gt; 0; i--) &#123; // 从右向左打印 TreeNode node = deque.removeLast(); tmp.add(node.val); // 先右后左加入下层节点 if(node.right != null) deque.addFirst(node.right); if(node.left != null) deque.addFirst(node.left); &#125; res.add(tmp); &#125; return res; &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(n) 层序遍历+倒序 此方法的优点是只用列表即可，无需其他数据结构。 偶数层倒序： 若 res 的长度为 奇数 ，说明当前是偶数层，则对 tmp 执行 倒序 操作。 12345678910111213141516171819class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); if(root != null) queue.add(root); while(!queue.isEmpty()) &#123; List&lt;Integer&gt; tmp = new ArrayList&lt;&gt;(); for(int i = queue.size(); i &gt; 0; i--) &#123; TreeNode node = queue.poll(); tmp.add(node.val); if(node.left != null) queue.add(node.left); if(node.right != null) queue.add(node.right); &#125; if(res.size() % 2 == 1) Collections.reverse(tmp); res.add(tmp); &#125; return res; &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(n)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"树","slug":"算法/剑指offer/树","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%A0%91/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"树","slug":"算法/剑指offer/树","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%A0%91/"}]},{"title":"Nacos配置中心","slug":"Nacos配置中心","date":"2022-02-13T15:55:14.000Z","updated":"2022-02-15T08:33:32.918Z","comments":true,"path":"2022/02/13/Nacos配置中心/","link":"","permalink":"http://example.com/2022/02/13/Nacos%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/","excerpt":"","text":"1、使用Nacos作为配置中心统一管理配置 导入 Nacos 配置中心依赖 12345&lt;!-- 版本由SpringCloudAlibab统一管理 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建 bootstrap.properties 配置文件来配置 Nacos Server 地址 123456# DataId 默认使用 `spring.application.name` 配置跟文件扩展名结合(配置格式默认使用 properties), GROUP 不配置默认使用 DEFAULT_GROUP。因此该配置文件对应的 Nacos Config 配置的 DataId 为 nacos-config.properties, GROUP 为 DEFAULT_GROUPspring.application.name=nacos-configspring.cloud.nacos.config.server-addr=127.0.0.1:8848#注意当你使用域名的方式来访问 Nacos 时，spring.cloud.nacos.config.server-addr 配置的方式为 域名:port。 例如 Nacos 的域名为abc.com.nacos，监听的端口为 80，则 spring.cloud.nacos.config.server-addr=abc.com.nacos:80。 注意 80 端口不能省略 在 Nacos 配置中心创建配置文件，命名为nacos-config.properties ,与 bootstrap.properties 配置文件中的名称一致，选择格式为 properties 在对应 controller 中添加 @RefreshScope 注解动态刷新配置，在对应变量添加 @Value 注解获取某个配置的值 &#x3D;&#x3D;注：创建 Nacos 配置中心的配置文件后，即使本地文件中的 application.properties 中没有配置 user.age 也不会报错，如果 Nacos 配置文件无法获取，则会报错&#x3D;&#x3D; 2、细节 命名空间：配置隔离 默认：public；默认新增的所有配置都在public空间 注：需要使用哪个命名空间下的配置，要在bootstrap.properties配置 1spring.cloud.nacos.config.namespace=prop 开发、测试、生产环境隔离 各个微服务之间根据不同的命名空间互相隔离配置 配置集：所有配置的集合 配置集ID：类似文件名 Data ID：类似文件名 配置分组： 默认所有配置分组为： DEFAULT_GROUP 1spring.cloud.nacos.config.group=prod 每个微服务创建自己的命名空间，使用配置分组区分环境。 3、加载多个数据集1234567891011spring.cloud.nacos.config.ext.config[0].data-id=datasource.ymlspring.cloud.nacos.config.ext.config[0].group=devspring.cloud.nacos.config.ext.config[0].refresh=truespring.cloud.nacos.config.ext.config[1].data-id=datasource.ymlspring.cloud.nacos.config.ext.config[1].group=devspring.cloud.nacos.config.ext.config[1].refresh=truespring.cloud.nacos.config.ext.config[2].data-id=datasource.ymlspring.cloud.nacos.config.ext.config[2].group=devspring.cloud.nacos.config.ext.config[2].refresh=true 4、总结 微服务任何配置信息，任何配置文件都可以放在配置中心中 只需要在bootstrap.properties说明加载配置中心中的哪些配置文件即可 配置中心有的，优先使用配置中心的配置","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}]},{"title":"Nacos注册中心","slug":"Nacos注册中心","date":"2022-02-12T13:33:14.000Z","updated":"2022-02-14T13:40:57.423Z","comments":true,"path":"2022/02/12/Nacos注册中心/","link":"","permalink":"http://example.com/2022/02/12/Nacos%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83/","excerpt":"","text":"引入 spring-cloud-alibaba 依赖管理 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 下载Nacos Server 下载地址：Github Releaseco 运行bin目录下 startup.cmd 运行Nacos Server 导入Nacos Discovery Starter 1234&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt; 在微服务的 application.yml 配置文件中配置Nacos Server的地址和微服务名称 1234567spring: cloud: nacos: discovery: server-addr: 127.0.0.1:8848 application: name: emall-coupon 使用 @EnableDiscoveryClient 注解开启服务注册与发现功能","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}]},{"title":"MySQL连接","slug":"MySQL连接","date":"2022-02-10T13:29:14.000Z","updated":"2022-02-14T13:33:45.667Z","comments":true,"path":"2022/02/10/MySQL连接/","link":"","permalink":"http://example.com/2022/02/10/MySQL%E8%BF%9E%E6%8E%A5/","excerpt":"","text":"导入MySQL依赖 1234567&lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt;&lt;!--mysql驱动--&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.17&lt;/version&gt;&lt;/dependency&gt; 在配置文件中配置用户名密码以及数据库名等 123456spring: datasource: username: root password: 123456 url: jdbc:mysql://192.168.40.100:3306/emall_sms driver-class-name: com.mysql.cj.jdbc.Driver","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}]},{"title":"二叉树的深度","slug":"10、二叉树的深度","date":"2022-02-10T04:14:35.000Z","updated":"2022-02-10T12:07:46.137Z","comments":true,"path":"2022/02/10/10、二叉树的深度/","link":"","permalink":"http://example.com/2022/02/10/10%E3%80%81%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%B7%B1%E5%BA%A6/","excerpt":"","text":"问题描述 我的代码12345678910111213141516171819202122232425262728/**public class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; int depth = 0,temp = 0; public int TreeDepth(TreeNode root) &#123; if(root == null)&#123; return 0; &#125;else&#123; temp++; &#125; if(TreeDepth(root.left)==0 &amp; TreeDepth(root.right)==0)&#123; depth = temp &gt; depth ? temp : depth; &#125; temp--; return depth; &#125;&#125; 主要问题 递归算法不够熟悉，对于递归的终止条件，每次递归执行的内容不够明确 解决办法后序遍历（DFS） 数的后序遍历往往使用递归或栈实现，下面使用递归实现。 关键点： 此树的深度和其左（右）子树的深度之间的关系。显然，此树的深度 等于 左子树的深度 与 右子树的深度 中的 最大值 +1+1 。 算法解析： 终止条件：当root结点为空时，说明已经越过叶节点，因此返回深度0。 递推工作：本质上是对树做后序遍历。 计算结点root的左子树深度，即调用 TreeDepth(root.left) 计算结点root的右子树深度，即调用 TreeDepth(root.right) 返回值：返回此树的深度，即max(TreeDepth(root.left), TreeDepth(root.right)) + 1 12345public class Solution &#123; public int TreeDepth(TreeNode root) &#123; return root == null ? 0 : Math.max(TreeDepth(root.left), TreeDepth(root.right)) + 1; &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(n) 层序遍历（BFS） 树的层序遍历 &#x2F; 广度优先搜索往往利用 队列 实现。 关键点： 每遍历一层，则计数器 +1，直到遍历完成，则可得到树的深度。 算法解析： 特例处理： 当 root 为空，直接返回 深度 0 。 初始化： 队列queue （加入根节点root），计数器 res &#x3D; 0。 循环遍历： 当 queue 为空时跳出。 初始化一个空列表 tmp ，用于临时存储下一层节点； 遍历队列： 遍历 queue 中的各节点 node ，并将其左子节点和右子节点加入 tmp； 更新队列： 执行 queue = tmp ，将下一层节点赋值给 queue； 统计层数： 执行 res += 1 ，代表层数加 1； 返回值：返回res即可。 1234567891011121314151617class Solution &#123; public int maxDepth(TreeNode root) &#123; if(root == null) return 0; List&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;() &#123;&#123; add(root); &#125;&#125;, tmp; int res = 0; while(!queue.isEmpty()) &#123; tmp = new LinkedList&lt;&gt;(); for(TreeNode node : queue) &#123; if(node.left != null) tmp.add(node.left); if(node.right != null) tmp.add(node.right); &#125; queue = tmp; res++; &#125; return res; &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(n)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"树","slug":"算法/剑指offer/树","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%A0%91/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"树","slug":"算法/剑指offer/树","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%A0%91/"}]},{"title":"删除链表的结点","slug":"9、删除链表的结点","date":"2022-02-09T11:27:17.000Z","updated":"2022-02-09T11:30:49.772Z","comments":true,"path":"2022/02/09/9、删除链表的结点/","link":"","permalink":"http://example.com/2022/02/09/9%E3%80%81%E5%88%A0%E9%99%A4%E9%93%BE%E8%A1%A8%E7%9A%84%E7%BB%93%E7%82%B9/","excerpt":"","text":"问题描述 我的代码123456789101112131415161718192021222324252627282930313233343536import java.util.*;/* * public class ListNode &#123; * int val; * ListNode next = null; * public ListNode(int val) &#123; * this.val = val; * &#125; * &#125; */public class Solution &#123; /** * 代码中的类名、方法名、参数名已经指定，请勿修改，直接返回方法规定的值即可 * * * @param head ListNode类 * @param val int整型 * @return ListNode类 */ public ListNode deleteNode (ListNode head, int val) &#123; ListNode dummy = new ListNode(0); dummy.next = head; ListNode temp = head,pre = dummy; while(temp != null)&#123; if(temp.val == val)&#123; pre.next = temp.next; return dummy.next; &#125; pre = temp; temp = temp.next; &#125; return dummy.next; &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(1) 主要问题 利用创建的虚拟头结点dummy实现对于头部的复杂判断的简化","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}]},{"title":"删除链表中的重复结点","slug":"8、删除链表中的重复结点","date":"2022-02-09T02:31:46.000Z","updated":"2022-02-09T11:27:32.037Z","comments":true,"path":"2022/02/09/8、删除链表中的重复结点/","link":"","permalink":"http://example.com/2022/02/09/8%E3%80%81%E5%88%A0%E9%99%A4%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E7%BB%93%E7%82%B9/","excerpt":"","text":"问题描述 我的代码1234567891011121314151617181920212223242526272829303132333435363738394041/* public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode deleteDuplication(ListNode pHead) &#123; //创建哨兵结点作为头结点，便于头结点的处理 ListNode head = new ListNode(0); head.next = pHead; ListNode temp = pHead; while(temp != null &amp;&amp; temp.next != null)&#123; if(temp.val == temp.next.val)&#123; temp = check(temp); &#125;else&#123; temp = temp.next; &#125; &#125; return head.next; &#125; //递归寻找不与该结点重复的第一个结点 public ListNode check(ListNode node)&#123; //由于传入的是第一个重复的结点，所以如果为空则直接返回空即可 if(node == null || node.next == null)&#123; return null; &#125; //返回第一个不重复的结点 if(node.val != node.next.val)&#123; return node.next; &#125;else&#123; //重复则继续递归 return check(node.next); &#125; &#125;&#125; 主要问题 实现递归算法时头结点与尾结点位置的情况出现问题。 利用HashMap实现时，由于HashMap的key值最好设为不变的类型，而ListNode类型会更改next属性，所以无法使用ListNode作为key值。而使用ListNode数组时只能进行判空操作，对于重复奇数次的结点无法判断。 判断条件的“&amp;”、“&amp;&amp;”、“|”、“||”要分清楚。 解决办法迭代解法 建立虚拟头结点dummy可以有效减少边界判断的情况，降低复杂程度 123456789101112131415161718class Solution &#123; public ListNode deleteDuplication(ListNode pHead) &#123; ListNode dummy = new ListNode(-1); ListNode tail = dummy; while (pHead != null) &#123; // 进入循环时，确保了 pHead 不会与上一节点相同 if (pHead.next == null || pHead.next.val != pHead.val) &#123; tail.next = pHead; tail = pHead; &#125; // 如果 pHead 与下一节点相同，跳过相同节点（到达「连续相同一段」的最后一位） while (pHead.next != null &amp;&amp; pHead.val == pHead.next.val) pHead = pHead.next; pHead = pHead.next; &#125; tail.next = null; return dummy.next; &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(1) 递归解法 1234567891011121314151617public class Solution &#123; public ListNode deleteDuplication(ListNode pHead) &#123; // 递归出口：当「输入节点为空」或者「不存在下一节点」，直接返回 if (pHead == null || pHead.next == null) return pHead; if (pHead.val != pHead.next.val) &#123; // 若「当前节点」与「下一节点」值不同，则当前节点可以被保留 pHead.next = deleteDuplication(pHead.next); return pHead; &#125; else &#123; // 若「当前节点」与「下一节点」相同，需要跳过「值相同的连续一段」 ListNode tmp = pHead; while (tmp != null &amp;&amp; tmp.val == pHead.val) tmp = tmp.next; return deleteDuplication(tmp); &#125; &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(1) 忽略递归带来的额外空间开销","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}]},{"title":"复杂链表的复制","slug":"7、复杂链表的复制","date":"2022-02-08T11:11:54.000Z","updated":"2022-02-08T11:25:26.406Z","comments":true,"path":"2022/02/08/7、复杂链表的复制/","link":"","permalink":"http://example.com/2022/02/08/7%E3%80%81%E5%A4%8D%E6%9D%82%E9%93%BE%E8%A1%A8%E7%9A%84%E5%A4%8D%E5%88%B6/","excerpt":"","text":"问题描述 我的代码123456789101112131415161718192021222324252627282930313233343536373839404142/*public class RandomListNode &#123; int label; RandomListNode next = null; RandomListNode random = null; RandomListNode(int label) &#123; this.label = label; &#125;&#125;*/import java.util.HashMap;public class Solution &#123; public RandomListNode Clone(RandomListNode pHead) &#123; //判断链表是否为空 if(pHead == null) return null; //创建HashMap HashMap&lt;RandomListNode,RandomListNode&gt; map = new HashMap(); //在内存中克隆每个结点并与原结点对应存入HashMap RandomListNode temp = pHead; while(temp != null)&#123; RandomListNode node = new RandomListNode(temp.label); map.put(temp,node); temp = temp.next; &#125; for(RandomListNode node : map.keySet())&#123; //克隆每个结点的next属性 if(node.next != null)&#123; map.get(node).next = map.get(node.next); &#125;else&#123; map.get(node).next = null; &#125; //克隆每个结点的random属性 if(node.random != null)&#123; map.get(node).random = map.get(node.random); &#125;else&#123; map.get(node).random = null; &#125; &#125; return map.get(pHead); &#125;&#125; 主要问题 使用哈希表，空间复杂度较大 解决办法链表拼接和拆分 12345678910111213141516171819202122232425262728293031class Solution &#123; public Node copyRandomList(Node head) &#123; if(head == null) return null; Node cur = head; // 1. 复制各节点，并构建拼接链表 while(cur != null) &#123; Node tmp = new Node(cur.val); tmp.next = cur.next; cur.next = tmp; cur = tmp.next; &#125; // 2. 构建各新节点的 random 指向 cur = head; while(cur != null) &#123; if(cur.random != null) cur.next.random = cur.random.next; cur = cur.next.next; &#125; // 3. 拆分两链表 cur = head.next; Node pre = head, res = head.next; while(cur.next != null) &#123; pre.next = pre.next.next; cur.next = cur.next.next; pre = pre.next; cur = cur.next; &#125; pre.next = null; // 单独处理原链表尾节点 return res; // 返回新链表头节点 &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(1)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}]},{"title":"两个链表的第一个公共结点","slug":"4、两个链表的第一个公共结点","date":"2022-02-08T09:05:02.000Z","updated":"2022-02-08T10:17:11.716Z","comments":true,"path":"2022/02/08/4、两个链表的第一个公共结点/","link":"","permalink":"http://example.com/2022/02/08/4%E3%80%81%E4%B8%A4%E4%B8%AA%E9%93%BE%E8%A1%A8%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%85%AC%E5%85%B1%E7%BB%93%E7%82%B9/","excerpt":"","text":"问题描述 我的代码123456789101112131415161718192021222324/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode FindFirstCommonNode(ListNode pHead1, ListNode pHead2) &#123; while(pHead1!=null)&#123; ListNode node = pHead2; while(node!=null)&#123; if(pHead1 == node)&#123; return node; &#125; node = node.next; &#125; pHead1 = pHead1.next; &#125; return null; &#125;&#125; 主要问题 双层循环遍历的暴力解法，及其低级，不够优美。 未考虑链表为空的情况。 解决办法长度差法若两链表存在公共结点，则从公共结点开始，到链表尾部的所有结点都相同。则可视为两个链表&#x3D;&#x3D;尾对齐&#x3D;&#x3D;。 &#x3D;&#x3D;由于两链表尾对齐，链表的长度差就与公共结点前的链表的长度差一致。&#x3D;&#x3D; 故可先计算出长度差，将两链表同步到同一起点时再进行齐头并进的比较。 1234567891011121314151617181920212223import java.util.*;public class Solution &#123; public ListNode FindFirstCommonNode(ListNode a, ListNode b) &#123; int c1 = 0, c2 = 0; ListNode ta = a, tb = b; //计算两链表长度 while (ta != null &amp;&amp; c1++ &gt;= 0) ta = ta.next; while (tb != null &amp;&amp; c2++ &gt;= 0) tb = tb.next; //长度差 int d = c1 - c2; if (d &gt; 0) &#123; while (d-- &gt; 0) a = a.next; &#125; else if (d &lt; 0) &#123; d = -d; while (d-- &gt; 0) b = b.next; &#125; while (a != b) &#123; a = a.next; b = b.next; &#125; return a; &#125;&#125; 复杂度分析 时间复杂度：O(n + m)O(n+m) 空间复杂度：O(1)O(1)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}]},{"title":"链表中环的入口结点","slug":"5、链表中环的入口结点","date":"2022-02-08T09:05:02.000Z","updated":"2022-02-08T10:14:34.722Z","comments":true,"path":"2022/02/08/5、链表中环的入口结点/","link":"","permalink":"http://example.com/2022/02/08/5%E3%80%81%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%8E%AF%E7%9A%84%E5%85%A5%E5%8F%A3%E7%BB%93%E7%82%B9/","excerpt":"","text":"问题描述 我的代码123456789101112131415161718192021222324/* public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode EntryNodeOfLoop(ListNode pHead) &#123; //创建数组根据下标记录每个结点的访问次数 int[] num = new int[10001]; //当结点为空或访问两次后跳出循环 //使用短路与&quot;&amp;&amp;&quot;保证当结点为空时直接跳出循环，不进行后续判断，避免出现空指针异常 //++i使数组元素先自增再比较，简化代码 while(pHead != null &amp;&amp; ++num[pHead.val] &lt; 2)&#123; pHead = pHead.next; &#125; return pHead; &#125;&#125; 主要问题 创建数组时不能确定链表的长度，只能使用最大数量进行创建，浪费大量存储空间（牛客网无法自动导包，原本想使用HashMap） while跳出条件”与或“判断和”等号还是不等号“写的就像一坨臭狗屎！！！ 解决办法哈希表一个非常直观的思路是：我们遍历链表中的每个节点，并将它记录下来；一旦遇到了此前遍历过的节点，就可以判定链表中存在环。借助哈希表可以很方便地实现。 &#x3D;&#x3D;将数组换成哈希表。&#x3D;&#x3D; 123456789101112131415public class Solution &#123; public ListNode detectCycle(ListNode head) &#123; ListNode pos = head; Set&lt;ListNode&gt; visited = new HashSet&lt;ListNode&gt;(); while (pos != null) &#123; if (visited.contains(pos)) &#123; return pos; &#125; else &#123; visited.add(pos); &#125; pos = pos.next; &#125; return null; &#125;&#125; 快慢指针 问题：为什么快慢指针必定在慢指针入环第一圈内相遇？ 第一步，快指针先进入环 第二步：当慢指针刚到达环的入口时，快指针此时在环中的某个位置(也可能此时相遇) 第三步：设此时快指针和慢指针距离为x，若在第二步相遇，则x &#x3D; 0； 第四步：设环的周长为n，那么看成快指针追赶慢指针，需要追赶n-x； 第五步：快指针每次都追赶慢指针1个单位，设慢指针速度1&#x2F;s，快指针2&#x2F;s，那么追赶需要(n-x)s 第六步：在n-x秒内，慢指针走了n-x单位，因为x&gt;&#x3D;0，则慢指针走的路程小于等于n，即走不完一圈就和快指针相遇 1234567891011121314151617181920212223242526public class Solution &#123; public ListNode detectCycle(ListNode head) &#123; if (head == null) &#123; return null; &#125; ListNode slow = head, fast = head; while (fast != null) &#123; slow = slow.next; if (fast.next != null) &#123; fast = fast.next.next; &#125; else &#123; return null; &#125; if (fast == slow) &#123; ListNode ptr = head; //因为a = c + (n-1)环长，故两指针毕相遇在入环点 while (ptr != slow) &#123; ptr = ptr.next; slow = slow.next; &#125; return ptr; &#125; &#125; return null; &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(1)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}]},{"title":"链表中倒数最后k个结点","slug":"6、链表中倒数最后k个结点","date":"2022-02-08T08:28:07.000Z","updated":"2022-02-08T10:40:53.986Z","comments":true,"path":"2022/02/08/6、链表中倒数最后k个结点/","link":"","permalink":"http://example.com/2022/02/08/6%E3%80%81%E9%93%BE%E8%A1%A8%E4%B8%AD%E5%80%92%E6%95%B0%E6%9C%80%E5%90%8Ek%E4%B8%AA%E7%BB%93%E7%82%B9/","excerpt":"","text":"问题描述 我的代码123456789101112131415161718192021222324252627282930import java.util.*;/* * public class ListNode &#123; * int val; * ListNode next = null; * public ListNode(int val) &#123; * this.val = val; * &#125; * &#125; */public class Solution &#123; public ListNode FindKthToTail (ListNode pHead, int k) &#123; //链表长度 int len = 0; ListNode node = pHead; while(node != null)&#123; len++; node = node.next; &#125; //如果k超出链表长度，返回null if(k &gt; len)&#123; return null; &#125; node = pHead; while(len-- &gt;k)&#123; node = node.next; &#125; return node; &#125;&#125; 主要问题 使用两次循环，代码看起来较为繁琐 没有考虑链表为空的情况 解决办法双指针法使用双指针则可以不用统计链表长度。 初始化： 前指针 former 、后指针 latter ，双指针都指向头节点 head 。 构建双指针距离： 前指针 former 先向后走 kk步（结束后，双指针 former 和 latter 间相距 k 步）。 双指针共同移动： 循环中，双指针 former 和 latter 每轮都向后走一步，直至 former 走过链表&#x3D;&#x3D;尾节点&#x3D;&#x3D;时跳出（跳出后， latter 与尾节点距离为 k-1，即 latter 指向倒数第 k 个节点）。 返回值： 返回 latter 即可。 1234567891011121314151617class Solution &#123; public ListNode getKthFromEnd(ListNode head, int k) &#123; ListNode former = head, latter = head; for(int i = 0; i &lt; k; i++)&#123; if(former == null)&#123; return null; &#125; former = former.next; &#125; while(former != null) &#123; former = former.next; latter = latter.next; &#125; return latter; &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(1)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}]},{"title":"JVM","slug":"JVM","date":"2022-02-07T12:56:19.000Z","updated":"2022-02-07T14:42:44.776Z","comments":true,"path":"2022/02/07/JVM/","link":"","permalink":"http://example.com/2022/02/07/JVM/","excerpt":"","text":"尚硅谷复习视频GC Roots 什么是垃圾？ 内存中不再被使用的空间 如何判断一个对象是否被回收？ 1、引用计数算法 2、可达性分析算法 可达性分析算法过程？ 通过一系列GC Roots的对象作为起始点，从这个被称为GCRoots的对象开始向下搜索，如果一个对象到GC Roots没有任何引用链相连时，则说明对象不可用。 哪些对象是GC Roots对象？ 1、虚拟机栈（局部变量表）中引用的对象 2、本地方法栈中引用的对象 3、方法区中类静态属性引用的对象（1.7之后在堆中） 4、方法区中常量引用的对象 5、被synchronized持有的对象 6、虚拟机内部的引用 JVM参数 JVM参数类型 1、标配参数：java -version、java -help、java -showversion 2、X参数 -Xint：解释执行 -Xcomp：第一次使用就编译成本地代码 -Xmixed：混合模式，先编译再执行 3、XX参数 Boolean类型 公式：-XX:+或者-某个属性值，+表示打开，-表示关闭 KV设值类型 公式：-XX:属性key=属性值value 例子：-XX:MetaspaceSize=20180888 如何查看一个正在运行中的java程序，他的某个参数是否开启？参数信息？ 1、jps：查看进程ID jps -l 2、jinfo：查看参数信息 jinfo -flag 参数 ID jinfo -flags ID JVM默认值 1、-XX:PrintFlagsInitial：查看初始默认值 公式：java -XX:+PrintFlagsInitial 2、-XX:PrintFlagsFinal：查看修改更新 公式：java -XX:+PrintFlagsFinal -version 常用基本配置参数1、-Xms等价于-XX:InitialHeapSize 2、-Xmx等价于-XX:MaxHeapSize 3、-Xss：设置单个线程栈的大小，等价于-XX:ThreadStackSize 默认值依赖于平台 1024KB（MAC系统、Linux） 依赖于虚拟内存（Windows系统） 4、-Xmn：设置年轻代的大小 5、-XX:MetaspaceSize：设置元空间大小，使用本地内存（jdk8之后） 6、-XX:+PrintGCDetails：输出GC详细日志信息 1[Full GC (Allocation Failure) [PSYoungGen: 496K-&gt;0K(2560K)] [ParOldGen: 16K-&gt;372K(7168K)] 512K-&gt;372K(9728K), [Metaspace: 3014K-&gt;3014K(1056768K)], 0.0059257 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 7、-XX:SurivorRatio：Eden区、幸存区0、幸存区1的比例（设置为8，则是8:1:1） 8、-XX:NewRatio：年轻代、老年代比例（默认2，新生代1，老年代2） 9、-XX:MaxTenuringThrehold：对象年龄的阈值（默认15，设置为0就直接进入老年代），必须小于15（jdk8） 引用类型 整体架构 强引用 12Object obj1 = new Object();//这样定义默认是强引用Object obj2 = obj1;//obj2引用赋值 1、强引用可以直接访问目标对象 2、强引用所指向的对象在任何时候都不会被系统回收，虚拟机宁愿抛出OOM异常，也不会回收强引用所指向对象 3、强引用可能导致内存泄漏 软引用 GC回收后，内存不足就进行回收 123Object obj = new Object（）； //声明强引用SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;（obj）；//创建软引用obj = null； //销毁强引用，这样就只有一个软引用了 通常用在对内存敏感的程序中，比如高速缓存 弱引用 GC一律回收 123Object obj = new Object（）； //声明强引用WeakReference&lt;Object&gt; sf = new WeakReference&lt;Object&gt;（obj）；obj = null； //销毁强引用 软引用和弱引用的使用场景？ 假如要读取大量的本地图片 如果每次读取图片都从本地读取会严重影响性能 如果一次性读取可能会造成内存溢出 此时使用软引用可以解决这个问题：用一个hashmap存储图片的路径和图片对象关联的软引用之间的映射关系，内存不足就自动回收这些缓存图片对象所占用的空间，从而避免OOM 1Map&lt;String SoftReference&lt;Bitmap&gt;&gt; imageCache = new HashMap&lt;&gt;(); 你使用过WeakHashMap吗？ 12345678910111213141516171819HashMap&lt;Integer,String&gt; map = new HashMap&lt;&gt;();Integer key = new Integer(1);String value = &quot;hashMap&quot;;map.put(key,value);System.out.println(map);//&#123;1=hashMap&#125;key=null;System.out.println(map);//&#123;1=hashMap&#125;System.gc();System.out.println(map);//&#123;1=hashMap&#125;WeakHashMap&lt;Integer,String&gt; weakHashMap = new WeakHashMap&lt;&gt;();Integer key1 = new Integer(1);String value1 = &quot;hashMap&quot;;weakHashMap.put(key1,value1);System.out.println(weakHashMap);//&#123;1=hashMap&#125;key1=null;System.out.println(weakHashMap);//&#123;1=hashMap&#125;System.gc();System.out.println(weakHashMap);//&#123;&#125; 引用队列 被回收前需要被引用队列保存 1234567891011121314Object o1 = new Object();ReferenceQueue&lt;Object&gt; referenceQueue = new ReferenceQueue&lt;&gt;();WeakReference&lt;Object&gt; weak = new WeakReference&lt;&gt;(o1,referenceQueue);System.out.println(o1);//java.lang.Object@5cad8086System.out.println(weak.get());//java.lang.Object@5cad8086System.out.println(referenceQueue.poll());//nullSystem.out.println(&quot;==========&quot;);o1=null;System.gc();TimeUnit.SECONDS.sleep(1);System.out.println(weak.get());//nullSystem.out.println(referenceQueue.poll());//java.lang.ref.WeakReference@6e0be858 虚引用 如果一个对象只有虚引用，那么就和没有引用一样 虚引用必须和引用队列一起使用 作用：跟踪对象被垃圾回收的状态，说明一个对象已经进入finalization阶段，可以被gc回收，用来实现比finalization机制更灵活的回收操作 Java技术允许使用finalize()方法在gc前做一些必要的清理工作 1234object obj = new object();ReferenceQueuephantomQueue = new ReferenceQueue( ) ;PhantomReference&lt;object&gt; pf = new PhantomReference&lt;object&gt;(obj, phantomQueue); obj = null; 1234567891011121314Object o1 = new Object();ReferenceQueue&lt;Object&gt; referenceQueue = new ReferenceQueue&lt;&gt;();PhantomReference&lt;Object&gt; weak = new PhantomReference&lt;&gt;(o1,referenceQueue);System.out.println(o1);//java.lang.Object@5cad8086System.out.println(weak.get());//nullSystem.out.println(referenceQueue.poll());//nullSystem.out.println(&quot;==========&quot;);o1=null;System.gc();TimeUnit.SECONDS.sleep(1);System.out.println(weak.get());//nullSystem.out.println(referenceQueue.poll());//java.lang.ref.PhantomReference@6e0be858 总结：虚引用必须加入引用队列，可以在对象被销毁后做一些想做的事情 OOM java.lang.StackOverflowError 栈溢出，递归 Java.lang.OutOfMemoryError：Java heap Space 堆内存溢出 Java.lang.OutOfMemoryError：GC overhead limit exceeded GC回收时间过长，超过98%的时间用来GC并且回收了不到2%的堆内存 Java.lang.OutOfMemoryError：Direct buffer memory 写NIO程序经常使用ByteBuffer来读取或者写入数据，这是一种基于通道与缓冲区的IO方式 它可以使用native函数直接分配堆外内存，然后通过一个存储在java堆内的DirectByteBuffer对象作为这块内存的引用进行操作 ByteBuffer.allocate(capability)：分配JVM堆内存，属于GC管辖范围，由于需要拷贝所以速度较慢 ByteBuffer.allocateDirect（capability）：分配本地内存，不属于GC管辖范围，速度较快 如果不断分配本地内存，堆内存很少使用，那么JVM就不需要执行GC，DirectByteBuffer对象就不会回收，这个时候堆内存充足但是本地内存已经使用光了，再次尝试分配就会报错 Java.lang.OutOfMemoryError：unable to create new native thread 1、创建了太多线程，一个应用进程创建了多个线程，超过了系统的承载极限 2、服务器不允许创建太多线程，linux线程默认最多1024个 Java.lang.OutOfMemoryError：Metaspace 元空间内存溢出 垃圾回收 垃圾回收算法和垃圾回收器的关系？ 垃圾回收算法是内存回收的方法论，垃圾回收器是算法的具体实现 四种主要的垃圾回收器？ 1、串行回收：Serial、Serial Old 2、并行回收：ParNew、Parallel、Parallel Old 多个垃圾收集线程并行工作，STW，适合后台运算场景 3、并发回收：CMS、G1 如何查看服务器默认的垃圾收集器？ java -XX:+PrintCommandLineFlags 17329 垃圾回收器 部分参数预先说明 DefNew：默认新生代 Tenured：老年代 ParNew：在新生代并行 PSYoungGen：在新生代Parallel ParOldGen：Parallel老年代 串行Serial STW、复制算法、标记-整理算法 Client模式下默认的新生代垃圾收集器 参数：-XX:+UseSerialGC 并行ParNew STW、复制算法 很多java虚拟机运行在Server模式下新生代的默认垃圾收集器 -XX:ParallelGCThreads：限制线程数量，默认开启和CPU相同的数量 并行Parallel Parallel Scavenge：新生代、复制算法、吞吐量优先收集器 重点关注： 可控制的吞吐量：高效利用CPU，多用于后台运算 自适应调节策略：虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供合适的停顿时间（-XX:MaxGCPauseMillis）或最大吞吐量 常用JVM参数： -XX:+UseAdaptiveSizePolicy：设置Parallel Scavenge收集器具有自适应调节策略 CMS 老年区 标记-清理算法 低延迟 适合堆内存大、CPU核数多的服务端应用 1、过程： 初始标记：STW，标记GC Roots直接关联对象，速度快 并发标记：并发，遍历对象树，标记全部对象 重新标记：STW，修正 并发清理：并发，清理对象 2、优点：并发收集、低延迟 3、缺点： 内存碎片，最后不得不通过担保机制对堆内存进行压缩，进行一次fullGC 对cpu资源压力大：Serial Old收集器后备策略 浮动垃圾 4、参数： -XX:+UseConcMarkSweepGC：开启CMS，自动开启ParNew 以前收集器的特点 1、年轻代、老年代各自独立 2、年轻代使用复制算法 3、老年代收集必须扫描整个老年代区域 4、都是以尽可能少而快速的GC为设计原则 G1的特点 服务端，多处理器和大容量内存，在实现高吞吐量的同时尽可能满足垃圾收集暂停时间的要求 1、特性： 像CMS一样，能与应用程序线程并发执行 整理空闲空间更快 需要更多的时间来预测GC停顿时间 不希望牺牲大量的吞吐性能 不需要更大的Java Heap 2、目标：取代CMS收集器，在以下方面表现的更出色： 不会产生很多的内存碎片 STW更可控，在停顿时间上添加了预测机制，用户可以指定期望的停顿时间 3、优点 充分利用CPU、多核环境的硬件优势，缩短STW 整体上采用标记-整理算法，局部通过复制算法，没有内存碎片 将内存划分为多个region（逻辑上的分代概念） 4、缺点 G1无论是为了垃圾收集产生的内存占用还是程序运行时的额外执行负载都要比CMS要高。 在小内存应用上CMS的表现大概率会优于G1，而G1在大内存应用，上则发挥其优势，平衡点在6一8GB之间。 G1的底层原理 1、Region -XX:G1HeapRegionSize=n指定分区大小，默认2048个分区（64G） 分区：E、S、O、H 新生代的垃圾收集依然采用STW的方式将存活对象拷贝到老年代或者S区 老年代，G1通过将对象从一个区域复制到另外一个区域，完成了清理工作，这就意味着在正常处理过程中G1完成了堆的压缩，就不会有碎片产生了 H区：如果一个对象大于50%的region，就是大对象，放入H区，如果一个H区放不下就寻找连续的H区，为了找到连续的H区有时候需要Full GC 2、回收步骤 针对Eden区的收集，Eden区耗尽后会被触发，主要是小区域+形成连续的内存块 Eden区数据移动到S区，假如S区空间不够，E区晋升到Old区 S区移动到新的S区，部分数据晋升Old区 最后Eden区收拾干净了，GC结束 步骤： 初始标记 并发标记 最终标记 筛选回收 和CMS相比的优势？ 1、不会产生内存碎片 2、可以精确控制停顿 并发标记算法三色标记白色：表示对象尚未被垃圾回收器访问过 灰色：表示对象已经被垃圾回收器访问过，但这个对象至少存在一个引用还没有被扫描过 黑色：表示对象已经被垃圾回收器访问过，且这个对象的所有引用都已经扫描过 浮动垃圾问题垃圾回收器在对象图上面标记颜色，而同时用户线程在修改引用关系，引用关系修改了，那么对象图就变化了，这样就有可能出现两种后果： 一种是把原本消亡的对象错误的标记为存活，这不是好事，但是其实是可以容忍的，只不过产生了一点逃过本次回收的浮动垃圾而已，下次清理就可以。 一种是把原本存活的对象错误的标记为已消亡，这就是非常严重的后果了，一个程序还需要使用的对象被回收了，那程序肯定会因此发生错误。 如何解决？当且仅当以下两个条件同时满足时，会产生”对象消失”的问题，原来应该是黑色的对象被误标为了白色： 条件一：赋值器插入了一条或者多条从黑色对象到白色对象的新引用 条件二：赋值器删除了全部从灰色对象到该白色对象的直接或间接引用 结合图捋一捋上面的这两个条件，是不是当且仅当的关系： 黑色对象5到白色对象9之间的引用是新建的，对应条件一。 黑色对象6到白色对象9之间的引用被删除了，对应条件二。 由于两个条件之间是当且仅当的关系。所以，我们要解决并发标记时对象消失的问题，只需要破坏两个条件中的任意一个就行。 于是产生了两种解决方案：增量更新（Incremental Update）和原始快照（Snapshot At The Beginning，SATB）。 在HotSpot虚拟机中，CMS是基于增量更新来做并发标记的，G1则采用的是原始快照的方式。 增量更新1、破坏的是第一个条件 2、当黑色对象插入新的指向白色对象的引用关系时，就将这个新插入的引用记录下来，等并发扫描结束之后，再将这些记录过的引用关系中的黑色对象为根，重新扫描一次 3、写屏障：写后屏障(Post-Write Barrier)，记录了所有新增的引用关系 4、但是存在问题，所以CMS的重新扫描阶段需要重新扫描一遍 原始快照（SATB）破坏第二个条件 关注引用的删除，记录下删除的引用，下次扫描保证还能被GC到 说一下 JVM 调优的命令 jps：JVM Process Status Tool,显示指定系统内所有的HotSpot虚拟机进程。 jstat：jstat(JVM statistics Monitoring)是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。 jmap：jmap(JVM Memory Map)命令用于生成heap dump文件，如果不使用这个命令，还阔以使用-XX:+HeapDumpOnOutOfMemoryError参数来让虚拟机出现OOM的时候·自动生成dump文件。 jmap不仅能生成dump文件，还阔以查询finalize执行队列、Java堆和永久代的详细信息，如当前使用率、当前使用的是哪种收集器等。 jhat：jhat(JVM Heap Analysis Tool)命令是与jmap搭配使用，用来分析jmap生成的dump，jhat内置了一个微型的HTTP&#x2F;HTML服务器，生成dump的分析结果后，可以在浏览器中查看。在此要注意，一般不会直接在服务器上进行分析，因为jhat是一个耗时并且耗费硬件资源的过程，一般把服务器生成的dump文件复制到本地或其他机器上进行分析。 jstack：jstack用于生成java虚拟机当前时刻的线程快照。jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。 如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。 介绍下空间分配担保原则如果YougGC时新生代有大量对象存活下来，而 survivor 区放不下了，这时必须转移到老年代中，但这时发现老年代也放不下这些对象了，那怎么处理呢？其实JVM有一个老年代空间分配担保机制来保证对象能够进入老年代。 在执行每次 YoungGC 之前，JVM会先检查老年代最大可用连续空间是否大于新生代所有对象的总大小。因为在极端情况下，可能新生代 YoungGC 后，所有对象都存活下来了，而 survivor 区又放不下，那可能所有对象都要进入老年代了。这个时候如果老年代的可用连续空间是大于新生代所有对象的总大小的，那就可以放心进行 YoungGC。但如果老年代的内存大小是小于新生代对象总大小的，那就有可能老年代空间不够放入新生代所有存活对象，这个时候JVM就会先检查 -XX:HandlePromotionFailure 参数是否允许担保失败，如果允许，就会判断老年代最大可用连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试进行一次YoungGC，尽快这次YoungGC是有风险的。如果小于，或者 -XX:HandlePromotionFailure 参数不允许担保失败，这时就会进行一次 Full GC。 在允许担保失败并尝试进行YoungGC后，可能会出现三种情况： ① YoungGC后，存活对象小于survivor大小，此时存活对象进入survivor区中 ② YoungGC后，存活对象大于survivor大小，但是小于老年大可用空间大小，此时直接进入老年代。 ③ YoungGC后，存活对象大于survivor大小，也大于老年大可用空间大小，老年代也放不下这些对象了，此时就会发生“Handle Promotion Failure”，就触发了 Full GC。如果 Full GC后，老年代还是没有足够的空间，此时就会发生OOM内存溢出了。 通过下图来了解空间分配担保原则： JVM和Java体系结构虚拟机与Java虚拟机1、所谓虚拟机，就是一台虚拟的计算机，大体上分为系统虚拟机和程序虚拟机 2、Java虚拟机是一台执行Java字节码的虚拟计算机，拥有独立的运行机制，其运行的Java字节码也未必由java语言编译而成 3、Java技术的核心就是Java虚拟机，所有的Java程序都运行在Java虚拟机内部 4、特点： 一次编译，到处运行 自动内存管理 自动垃圾回收功能 JVM是运行在操作系统之上的，与硬件没有直接交互 JVM整体结构HotSpot VM是高性能虚拟机的代表作之一 1、类装载器子系统：将字节码文件加载到内存中，生成class对象（加载、链接、初始化） 2、运行时数据区：方法区、Java栈、本地方法栈、堆、程序计数器 3、执行引擎：高级语言翻译成机器语言 Java代码执行流程 JVM的架构模型Java编译器输入的指令流基本上是一种基于栈的指令集架构 特点： 设计和实现更简单，适用于资源受限的系统 避开了寄存器的分配难题，使用零地址指令方式分配 指令流中的指令大部分是零地址指令，其执行过程依赖于操作栈 不需要硬件的支持，可移植性更好，更好实现跨平台 跨平台、指令集小、指令多、执行性能比寄存器差 JVM的生命周期启动 通过引导类加载器创建一个初始类来完成，这个类由虚拟机的具体实现指定 执行 一个运行中的java虚拟机有一个清晰的任务：执行Java程序 程序开始执行他才开始运行，程序结束就停止 执行一个Java程序的时候，真正执行的是Java虚拟机的进程 退出 如下几种情况： 程序正常执行结束 异常终止 由于操作系统导致终止 线程调用Runtime类或System类的exit方法等 类加载子系统类加载器和类加载过程1、类加载器子系统的作用 类加载子系统负责从文件系统或者网络中加载Class文件，class文件在文件开头有特定的文件标识； ClassLoader只负责class文件的加载，至于它是否可以运行，则由Execution Engine（执行引擎）决定 加载的类信息存放于一块成为方法区的内存空间。除了类信息之外，方法区还会存放运行时常量池信息，可能还包括字符串字面量和数字常量（这部分常量信息是Class文件中常量池部分的内存映射） 2、类加载器ClassLoader角色 3、阶段一：加载阶段 通过一个类的全限定名获取定义此类的二进制字节流 将这个字节流代表的静态存储结构转化为方法区的运行时数据结构 在内存中生出一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口 4、阶段二：链接阶段 验证 目的在于确保Class文件的字节流中包含信息符合当前虚拟机要求，保证被加载类的正确性，不会危害虚拟机自身安全 主要包括四种验证：文件格式验证，源数据验证，字节码验证，符号引用验证 准备 为类变量分配内存并且设置该类变量（即静态变量、被static修饰的变量）的默认初始值，即零值； 这里不包含用final修饰的static，因为final在编译的时候就会分配了，准备阶段会显式初始化 不会为实例变量分配初始化，类变量会分配在方法区中，而实例变量是会随着对象一起分配到java堆中 解析 将常量池内的符号引用转换为直接引用的过程。 事实上，解析操作往往会伴随着jvm在执行完初始化之后再执行 符号引用就是一组符号来描述所引用的目标。符号应用的字面量形式明确定义在《java虚拟机规范》的class文件格式中。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型等。对应常量池中的CONSTANT_Class_info&#x2F;CONSTANT_Fieldref_info、CONSTANT_Methodref_info等。 5、阶段三：初始化 初始化阶段就是执行类构造器方法clinit（）的过程（静态变量） 此方法不需要定义，是javac编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并而来。 我们注意到如果没有静态变量c，那么字节码文件中就不会有clinit方法 构造器方法中指令按语句在源文件中出现的顺序执行 clinit()不同于类的构造器。（关联：构造器是虚拟机视角下的init()） 若该类具有父类，jvm会保证子类的clinit()执行前，父类的clinit()已经执行完毕 虚拟机必须保证一个类的clinit方法在多线程下被同步加锁 （静态变量、静态初始化块：决于它们在类中出现的先后顺序）&gt;（变量、初始化块：决于它们在类中出现的先后顺序）&gt; 构造器 有父类的加载顺序： 父类–静态变量 父类–静态初始化块 子类–静态变量 子类–静态初始化块 子类main方法 父类–变量 父类–初始化块 父类–构造器 子类–变量 子类–初始化块 子类–构造器 类加载器分类1、JVM支持两种类型的加载器，分别为引导类加载器（BootStrap ClassLoader）和自定义类加载器（User-Defined ClassLoader） 从概念上来讲，自定义类加载器一般指的是程序中由开发人员自定义的一类类加载器 但是java虚拟机规范却没有这么定义，而是将所有派生于抽象类ClassLoader的类加载器都划分为自定义类加载器。 2、加载器： 引导类加载器（非java语言实现），加载java的核心类库 扩展类加载器 系统类加载器，用户自定义类使用这个加载器 自定义加载器 123456789101112131415161718192021public static void main(String[] args)&#123; //获取系统类加载器 ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader(); System.out.println(systemClassLoader);//sun.misc.Launcher$AppClassLoader@18b4aac2 //获取上层：扩展类加载器 ClassLoader e = systemClassLoader.getParent(); System.out.println(e);//sun.misc.Launcher$ExtClassLoader@5cad8086 //获取上层：引导类加载器 ClassLoader b = e.getParent(); System.out.println(b);//null //对于用户自定义类来说：默认使用系统类加载器进行加载 ClassLoader add = add.class.getClassLoader(); System.out.println(add);//sun.misc.Launcher$AppClassLoader@18b4aac2 //String类：使用引导类加载器进行加载，系统核心类库都是使用引导类加载器进行加载的 ClassLoader s = String.class.getClassLoader(); System.out.println(s);//null&#125; 引导类加载器1、使用C&#x2F;C++语言实现，嵌套在JVM内部 2、加载Java的核心库，用于提供JVM自身需要的类 3、并不继承自java.lang.ClassLoader，没有父加载器 4、加载扩展类和应用程序类加载器，并指定为他们的父类加载器 扩展类加载器1、Java语言编写 2、派生于ClassLoader类 3、父类加载器为引导类加载器 4、从jdk的安装目录的jre/lib/ext子目录下加载类库，如果用户把jar包放在这个目录下就自动使用扩展类加载器加载 系统类加载器1、Java语言编写 2、派生于ClassLoader类 3、父类加载器为引导类加载器 4、负责加载classpath或者系统属性java.class.path下的类库 5、该类加载器是程序默认使用的类加载器 6、通过ClassLoader.getSystemClassLoader()可以获取该类的加载器 用户自定义类加载器使用场景： 1、从任意位置加载类。JVM 预定义的三个类加载器都被限定了自己的类路径，我们可以通过自定义类加载器去加载其他任意位置的类。 2、解密类文件。比如我们可以对编译后的类文件进行加密，然后通过自定义类加载器进行解密。当然这种方法实际并没有太大的用处，因为自定义的类加载器也可以被反编译。 3、支持更灵活的内存管理。我们可以使用自定义类加载器在运行时卸载已加载的类，从而更高效的利用内存。 实现步骤 1、继承class.lang.ClassLoader类，实现自己的类加载器 2、将自定义的类加载逻辑写在findClass方法中 类加载器的启动顺序BootStrapClassLoader 是一个使用 C&#x2F;C++ 编写的类加载器，它已经嵌入到了 JVM 的内核之中。 当 JVM 启动时，BootStrapClassLoader 也会随之启动并加载核心类库。 当核心类库加载完成后，BootStrapClassLoader 会创建 ExtClassLoader 和 AppClassLoader 的实例，两个 Java 实现的类加载器将会加载自己负责路径下的类库，这个过程我们可以在 sun.misc.Launcher 中窥见。 ClassLoader类ClassLoader类是一个抽象类，类的加载器继承自这个类（不包括引导类加载器） 获取ClassLoader的途径 双亲委派机制 Java虚拟机对class文件采用的是按需加载的方式，也就是说当需要使用该类时才会将她的class文件加载到内存生成的class对象。而且加载某个类的class文件时，java虚拟机采用的是双亲委派模式，即把请求交由父类处理，它是一种任务委派模式 工作原理 先委托给父类加载器，递归到顶层的引导类加载器 如果父类加载器可以完成加载任务就成功返回，如果不能子加载器才会自己加载 优势 避免类的重复加载 保护程序安全，防止核心API被随意篡改 自定义类：java.lang.String 自定义类：java.lang.test（java.lang包需要访问权限，阻止我们用包名自定义类） 「双亲委派」机制用来保证类的唯一性，只要两个类的全路径名称一致，且都是同一个类加载器加载，那么就判断这两个类是相同的 沙箱安全机制自定义String类，但是在加载自定义String类的时候会率先使用引导类加载器加载，而引导类加载器在加载过程中会先加载jdk自带的文件（rt.jar包中的java\\lang\\String.class）,报错信息说没有main方法就是因为加载的是rt.jar包中的String类。 这样可以保证对java核心源代码的保护，这就是沙箱安全机制。 运行时数据区（一）内存和线程内存内存是非常重要的系统资源，是硬盘和cpu的中间仓库及桥梁，承载着操作系统和应用程序的实时运行。JVM内存布局规定了JAVA在运行过程中内存申请、分配、管理的策略，保证了JVM的高效稳定运行。 不同的jvm对于内存的划分方式和管理机制存在着部分差异（对于Hotspot主要指：方法区） JDK8的元数据区+JIT编译产物 就是JDK8以前的方法区 分区 红色：一个进程一份 灰色：一个线程一份 每个线程：程序计数器、虚拟机栈、本地栈 线程间共享：堆、堆外内存（永久代或元空间、代码缓存） 一般来说，jvm优化（比如垃圾回收）95%是优化堆区，5%优化的是方法区 Runtime相当于运行时数据区，每个虚拟机只有一个Runtime实例 线程1、线程是一个程序里的运行单元，JVM允许一个程序有多个线程并行的执行 2、在HotSpot JVM，每个线程都与操作系统的本地线程直接映射 当一个java线程准备好执行以后，此时一个操作系统的本地线程也同时创建。java线程执行终止后。本地线程也会回收 3、操作系统负责所有线程的安排调度到任何一个可用的CPU上。一旦本地线程初始化成功，它就会调用java线程中的run（）方法 程序计数器（PC寄存器）JVM中的程序计数寄存器（Program Counter Register）中，Register的命名源于CPU的寄存器，寄存器存储指令相关的现场信息。 CPU只有把数据装载到寄存器才能够运行。 JVM中的PC寄存器是对物理PC寄存器的一种抽象模拟 作用PC寄存器是用来存储指向下一条指令的地址，即将要执行的指令代码，由执行引擎读取下一条指令。 它是一块很小的内存空间，几乎可以忽略不计，也是运行速度最快的存储区域 在jvm规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期保持一致 任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。程序计数器会存储当前线程正在执行的java方法的JVM指令地址； 如果是在执行native方法，则是未指定值（undefined）（因为这个是java层面的寄存器，无法调用c的方法）。 它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成 字节码解释器工作时就是通过改变这个计数器的值来选取吓一跳需要执行的字节码指令 它是唯一一个在java虚拟机规范中没有规定任何OOM情况的区域 常见面试问题1、使用PC寄存器存储字节码指令地址有什么用？ 因为CPU在不停切换不同的线程，切换回来之后需要知道接下来从哪里开始继续执行 2、PC寄存器为什么被设定为线程私有？ **为了能够准确地记录各个线程正在执行的当前字节码指令地址，最好的办法自然是为每一个线程都分配一个PC寄存器,**这样一来各个线程之间便可以进行独立计算，从而不会出现相互干扰的情况。 由于CPU时间片轮限制，众多线程在并发执行过程中，任何一个确定的时刻，一个处理器或者多核处理器中的一个内核，只会执行某个线程中的一条指令。 这样必然导致经常中断或恢复，如何保证分毫无差呢？每个线程在创建后，都会产生自己的程序计数器和栈帧，程序计数器在各个线程之间互不影响。 CPU时间片CPU时间片即CPU分配各各个程序的时间，每个线程被分配一个时间段。称作它的时间片。 在宏观上：我们可以同时打开多个应用程序，每个程序并行不悖，同时运行。 但在微观上：由于只有一个CPU，一次只能处理程序要求的一部分，如何处理公平，一种方法就是引入时间片，每个程序轮流执行。 并行与并发的区别 并行：同一时间多个线程同时执行； 并发：一个核快速切换多个线程，让它们依次执行，看起来像并行，实际上是并发 虚拟机栈概述1、栈和堆 栈是运行时的单位，堆是存储的单位 栈解决程序的运行问题，即程序如何执行、如何处理数据 堆解决数据的存储问题，即数据怎么放，放在哪儿 2、Java虚拟机栈是什么？ 每个线程在创建时都会创建一个虚拟机栈，其内部保存一个个的栈帧，对应一次次的Java方法调用（一个栈帧对应一个方法） 3、生命周期与线程一致 4、作用：主管Java程序的运行，保存方法的局部变量（8种基本数据类型、对象的引用地址）、部分结果、并参与方法的调用和返回 局部变量 vs 成员变量（属性） 基本数据类型变量 vs 引用类型变量（类、数组、接口） 5、优点 栈是一种快速有效的分配存储方式，访问速度仅次于PC寄存器（程序计数器） JVM直接对java栈的操作只有两个 每个方法执行，伴随着进栈（入栈，压栈） 执行结束后的出栈工作 对于栈来说不存在垃圾回收问题 栈的存储单位（栈帧）1、每个线程都有自己的栈，栈中的数据都是以栈帧的格式存在的 2、方法和栈帧是一对一的关系 3、栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息 4、一条活动线程中，一个时间点上，只有一个活动栈帧 只有当前正在执行的栈帧才是有效的，被称为当前栈帧 对应的方法叫做当前方法 定义这个方法的类就是当前类 5、不同的线程所包含的栈帧是不允许存在相互引用的，即不可能在一个栈帧中引用另外一个栈帧 6、Java方法有两种返回函数的方式 return 抛出异常（没有处理这个异常） 内部结构每个栈帧中存储着： 局部变量表（Local Variables） 操作数栈（Operand Stack）(或表达式栈) 动态链接（Dynamic Linking）(或执行运行时常量池的方法引用) 方法返回地址（Return Adress）（或方法正常退出或者异常退出的定义） 一些附加信息 局部变量表1、定义为一个数字数组，主要用于存储方法参数和定义在方法体内的局部变量 数据类型：8种基本数据类型、对象引用、returnAdress类型 2、局部变量表需要的容量大小在编译期确定，并保存在方法的Code属性的Maximum local variables数据项中 3、局部变量表中的变量只在当前方法调用中有效，方法调用结束后自动销毁 Slot1、参数值的存放总是在局部变量数组的index0开始，到数组长度-1的索引结束（数组） 2、局部变量表，最基本的存储单元是Slot(变量槽) 3、局部变量表中存放编译期可知的各种基本数据类型（8种），引用类型（reference），returnAddress类型的变量。 4、在局部变量表里，32位以内的类型只占用一个slot（包括returnAddress类型），64位的类型（long和double）占用两个slot。 byte、short、char、float在存储前被转换为int，boolean也被转换为int，0表示false，非0表示true； long和double则占据两个slot。 5、JVM会为局部变量表中的每一个slot都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值 6、当一个实例方法被调用的时候，它的方法参数和方法体内部定义的局部变量将会按照顺序被复制到局部变量表中的每一个slot上 7、如果需要访问局部变量表中一个64bit的局部变量值时，只需要使用前一个索引即可。（比如：访问long或者double类型变量） 8、如果当前帧是由构造方法或者实例方法（非静态代码）创建的，那么该对象引用this将会存放在index为0的slot处,其余的参数按照参数表顺序排列。 总结： double和long占两位索引，取前一位 非静态方法index为0的位置为this 无参构造器只有this slot的重复利用栈帧中的局部变量表中的槽位是可以重复利用的，如果一个局部变量过了其作用域，那么在其作用域之后申明的新的局部变量就很有可能会复用过期局部变量的槽位，从而达到节省资源的目的。 123456789private void test2() &#123; int a = 0; &#123; int b = 0; b = a+1; &#125; //变量c使用之前以及经销毁的变量b占据的slot位置 int c = a+1;&#125; 静态变量与局部变量变量分类： 按照数据类型：基本数据类型、引用数据类型 按照类中声明的位置： 成员变量：在使用前都经历过默认初始化赋值（类加载的第二阶段中的准备） 类变量（静态变量） 链接的准备阶段：给类变量赋值 初始化阶段：给类变量显式赋值即静态代码块赋值 实例变量 随着对象的创建，会在堆空间中分配实例变量空间，并有默认赋值 局部变量：使用前必须进行显式赋值，不然编译无法通过 补充在栈帧中，与性能调优关系最密切的部分就是局部变量表，在方法执行时，虚拟机使用局部变量表完成方法的传递 局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收 操作数栈1、操作数栈，在方法执行过程中根据字节码指令，往栈中写入数据或者提取数据，即入栈&#x2F;出栈 2、操作数栈，主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间。 3、操作数栈就是jvm执行引擎的一个工作区，当一个方法开始执行的时候，一个新的栈帧也会随之被创建出来，这个方法的操作数栈是空的 4、每一个操作数栈都会拥有一个明确的栈深度用于存储数值，其所需的最大深度在编译器就定义好了，保存在方法的code属性中，为max_stack的值（数组的长度是固定的） 5、栈中的任何一个元素都是可以任意的java数据类型 32bit的类型占用一个栈单位深度 64bit的类型占用两个栈深度单位（long、double） 6、操作数栈并非采用访问索引的方式来进行数据访问的，而是只能通过标准的入栈push和出栈pop操作来完成一次数据访问 7、如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中，并更新PC寄存器中下一条需要执行的字节码指令。 8、操作数栈中的元素的数据类型必须与字节码指令的序列严格匹配，这由编译器在编译期间进行验证，同时在类加载过程中的类验证阶段的数据流分析阶段要再次验证。 9、另外，我们说Java虚拟机的解释引擎是基于栈的执行引擎,其中的栈指的就是操作数栈。 结合下面的图来看一下一个方法（栈帧）的执行过程 ①15入栈；②存储15，15进入局部变量表 ③压入8；④存储8，8进入局部变量表； ⑤从局部变量表中把索引为1和2的是数据取出来，放到操作数栈；⑥iadd相加操作，8和15出栈 ⑦iadd操作结果23入栈；⑧将23存储在局部变量表索引为3的位置上 i++和++i的区别 栈顶缓存技术基于栈式架构的虚拟机所使用的零地址指令更加紧凑，但完成一项操作的时候必然需要使用更多的入栈和出栈指令，这同时也就意味着将需要更多的指令分派（instruction dispatch）次数和内存读&#x2F;写次数 由于操作数是存储在内存中的，因此频繁地执行内存读&#x2F;写操作必然会影响执行速度。为了解决这个问题，HotSpot JVM的设计者们提出了栈顶缓存技术，将栈顶元素全部缓存在物理CPU的寄存器中，以此降低对内存的读&#x2F;写次数，提升执行疫情的执行效率 动态链接1、帧数据区：附加信息+动态链接+方法返回地址 2、每一个栈帧内部都包含一个指向运行时常量池中该栈帧所属方法的引用。这个引用的目的就是为了支持当前方法的代码能够实现动态链接，比如invokedynamic指令 3、在Java源文件被编译成字节码文件中时，所有的变量和方法引用都作为符号引用（symbolic Refenrence）保存在class文件的常量池里。 比如：描述一个方法调用了另外的其他方法时，就是通过常量池中指向方法的符号引用来表示的，那么动态链接的作用就是为了将这些符号引用转换为调用方法的直接引用。 为什么需要常量池？ 提供符号和常量，便于指令的识别 方法的调用在JVM中，将符号引用转换为调用方法的直接引用与方法的绑定机制相关 1、静态链接 当一个 字节码文件被装载进JVM内部时，如果被调用的目标方法在编译期可知，且运行期保持不变时。这种情况下将调用方法的符号引用转换为直接引用的过程称之为静态链接。 2、动态链接 如果被调用的方法在编译期无法被确定下来，也就是说，只能够在程序运行期将调用方法的符号引用转换为直接引用，由于这种引用转换过程具备动态性，因此也就被称之为动态链接。 对应的方法的绑定机制为：早起绑定（Early Binding）和晚期绑定（Late Bingding）。绑定是一个字段、方法或者类在符号引用被替换为直接引用的过程，这仅仅发生一次。 1、早期绑定 早期绑定就是指被调用的目标方法如果在编译期可知，且运行期保持不变时，即可将这个方法与所属的类型进行绑定，这样一来，由于明确了被调用的目标方法究竟是哪一个，因此也就可以使用静态链接的方式将符号引用转换为直接引用。 2、晚期绑定 如果被调用的方法在编译期无法被确定下来，只能够在程序运行期根据实际的类型绑定相关的方法，这种绑定方式也就被称之为晚期绑定。 随着高级语言的横空出世，类似于java一样的基于面向对象的编程语言如今越来越多，尽管这类编程语言在语法风格上存在一定的差别，但是它们彼此之间始终保持着一个共性，那就是都支持封装，集成和多态等面向对象特性，既然这一类的编程语言具备多态特性，那么自然也就具备早期绑定和晚期绑定两种绑定方式。 Java中任何一个普通的方法其实都具备虚函数的特征，它们相当于C++语言中的虚函数（C++中则需要使用关键字virtual来显式定义）。如果在Java程序中不希望某个方法拥有虚函数的特征时，则可以使用关键字final来标记这个方法。 虚方法和非虚方法 非虚方法 如果方法在编译器就确定了具体的调用版本，这个版本在运行时是不可变的。这样的方法称为非虚方法 静态方法、私有方法、final方法、实例构造器、父类方法都是非虚方法 其他方法称为虚方法 虚拟机中提供了以下几条方法调用指令：普通调用指令：1.invokestatic：调用静态方法，解析阶段确定唯一方法版本；2.invokespecial：调用方法、私有及弗雷方法，解析阶段确定唯一方法版本；3.invokevirtual：调用所有虚方法；4.invokeinterface：调用接口方法； 动态调用指令：5.invokedynamic：动态解析出需要调用的方法，然后执行 . 前四条指令固化在虚拟机内部，方法的调用执行不可人为干预，而invokedynamic指令则支持由用户确定方法版本。其中invokestatic指令和invokespecial指令调用的方法称为非虚方法，其余的（final修饰的除外）称为虚方法。 虚方法表 在面向对象编程中，会很频繁期使用到动态分派，如果在每次动态分派的过程中都要重新在累的方法元数据中搜索合适的目标的话就可能影响到执行效率。因此，为了提高性能，jvm采用在类的方法区建立一个虚方法表（virtual method table）（非虚方法不会出现在表中）来实现。使用索引表来代替查找。 每个类中都有一个虚方法表，表中存放着各个方法的实际入口。 那么虚方法表什么时候被创建？ 虚方法表会在类加载的链接阶段被创建并开始初始化，类的变量初始值准备完成之后，jvm会把该类的方法表也初始化完毕。 方法返回地址1、存放调用该方法的pc寄存器的值 一个方法的结束，有两种方式： 正常执行完成 出现未处理的异常，非正常退出 无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置。 方法正常退出时，被调用者的pc计数器的值作为返回地址，即调用该方法的指令的下一条指令的地址。 而通过异常退出时，返回地址是要通过异常表来确定，栈帧中一般不会保存这部分信息。 3、本质上，方法的退出就是当前栈帧出栈的过程。此时，需要恢复上层方法的局部变量表、操作数栈、将返回值也如调用者栈帧的操作数栈、设置PC寄存器值等，让调用者方法继续执行下去。 正常完成出口和异常完成出口的区别在于：通过异常完成出口退出的不会给他的上层调用者产生任何的返回值。 面试题1、举例栈溢出的情况？（StackOverflowError） 递归调用、无限循环等 通过-Xss设置栈的大小 2、调整栈大小，就能保证不出现溢出吗？ 不能保证， 比如：递归无限次数肯定会溢出，调整栈大小只能保证溢出的时间晚一些 3、分配的栈内存越大越好么？ 不是，会挤占其他线程的空间 4、垃圾回收是否会涉及到虚拟机栈？ 不会 5、方法中定义的局部变量是否线程安全？ 根据情况分析 在方法中创建，在方法中消亡是安全的 有返回值，return出去是不安全的 不是在内部产生（形参）的是不安全的 本地方法接口本地方法简单来讲，一个Native Method就是一个java调用非java代码的接口， 一个Native Method是这样一个java方法：该方法的实现由非Java语言实现，比如C。 本地接口的作用是融合不同的编程语言为java所用，它的初衷是融合C&#x2F;C++程序。 为什么使用本地方法1、与java环境外交互 有时java应用需要与java外面的环境交互，这是本地方法存在的主要原因。 你可以想想java需要与一些底层系统，如擦偶偶系统或某些硬件交换信息时的情况。本地方法正式这样的一种交流机制：它为我们提供了一个非常简洁的接口，而且我们无需去了解java应用之外的繁琐细节。 2、与操作系统交互 JVM支持着java语言本身和运行库，它是java程序赖以生存的平台，它由一个解释器（解释字节码）和一些连接到本地代码的库组成。然而不管怎样，它毕竟不是一个完整的系统，它经常依赖于一些底层系统的支持。这些底层系统常常是强大的操作系统。通过使用本地方法，我们得以用java实现了jre的与底层系统的交互，甚至jvm的一些部分就是用C写的。还有，如果我们要使用一些java语言本身没有提供封装的操作系统特性时，我们也需要使用本地方法。 3、Sun’s Java Sun的解释器是用C实现的，这使得它能像一些普通的C一样与外部交互。jre大部分是用java实现的，它也通过一些本地方法与外界交互。例如：类java.lang.Thread的setPriority()方法是用Java实现的，但是它实现调用的事该类里的本地方法setPriority0（）。这个本地方法是用C实现的，并被植入JVM内部，在Windows 95的平台上，这个本地方法最终将调用Win32 SetProority（）API。这是一个本地方法的具体实现由JVM直接提供，更多的情况是本地方法由外部的动态链接库（external dynamic link library）提供，然后被JVM调用。 本地方法栈1、Java虚拟机栈用于管理Java方法的调用，而本地方法栈用于管理本地方法的调用 2、本地方法栈是线程私有的 3、允许被实现成固定或者是可动态拓展的内存大小（和虚拟机栈在内存溢出方面是相同的） 如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java虚拟机将会抛出一个StackOverFlowError异常。 如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么java虚拟机将会抛出一个OutOfMemoryError异常。 4、它的具体做法是Native Method Stack中登记native方法，在Execution Engine执行时加载本地方法库 5、当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界，它和虚拟机拥有同样的权限 本地方法可以通过本地方法接口来 访问虚拟机内部的运行时数据区 它甚至可以直接使用本地处理器中的寄存器 直接从本地内存的堆中分配任意数量的内存 运行时数据区（二）堆核心概述1、一个进程对应一个JVM实例，一个JVM实例对应一个运行时数据区，一个JVM实例只存在一个堆内存 线程共享方法区、堆，在堆还可以划分线程私有的缓冲区 每个线程独立拥有虚拟机栈、本地方法栈、程序计数器 2、Java堆区在JVM启动的时候即被创建，其空间大小也就确定了，是JVM最大的内存空间 堆内存的大小是可以调节的 3、“几乎”所有的对象实例以及数组都应该在运行时分配在堆上 4、数组和对象可能永远不会存储在栈上，因为栈帧中保存引用，这个引用指向对象或者数组在堆中的位置 5、方法结束以后，堆中的对象不会被马上移除 内存细分现代垃圾收集器大部分都基于分代收集理论设计，堆空间细分为： Java 7及以前逻辑上分为：新生区 + 养老区 + 永久区 Java 8及之后逻辑上分为：新生区 + 养老区 + 元空间 新生区（年轻代）：Young Generation Space Eden Survivor 养老区（老年代）：Tenure generation space 元空间：Meta Space 设置堆空间大小1、Java堆区用于存储java对象实例，堆的大小在jvm启动时就已经设定好了，可以通过 “-Xmx”和 “-Xms”来进行设置 -Xms 用于表示堆的起始内存，等价于 -XX:InitialHeapSize -Xms 用来设置堆空间（年轻代+老年代）的初始内存大小 -X 是jvm的运行参数 ms 是memory start -Xmx 用于设置堆的最大内存，等价于 -XX:MaxHeapSize 2、一旦堆区中的内存大小超过 -Xmx所指定的最大内存时，将会抛出OOM异常 年轻代和老年代1、存储在JVM中的Java对象可以被划分为两类： 一类是生命周期较短的对象，这类对象创建和消亡都非常迅速 一类对象生命周期较长，在某些极端情况下还能够与JVM的生命周期保持一致 2、Java堆可以划分为年轻代和老年代 3、年轻代分为Eden空间、survivor0空间（from区）、survivor1空间（to区） 8:1:1 几乎所有Java对象都在Eden空间被new出来 绝大部分Java对象的销毁在新生代进行 对象分配过程 1、new的对象先放伊甸园区。此区有大小限制。 2、当伊甸园的空间填满时，程序又需要创建对象，JVM的垃圾回收器将对伊甸园区进行垃圾回收（Minor GC)， 将伊甸园区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到伊甸园区 3、然后将伊甸园中的剩余对象移动到幸存者0区。 4、如果再次触发垃圾回收，此时上次幸存下来的放到幸存者0区的，如果没有回收，就会放到幸存者1区。 5、如果再次经历垃圾回收，此时会重新放回幸存者0区，接着再去幸存者1区。 6、啥时候能去养老区呢？可以设置次数。默认是15次。可以设置参数：-XX:MaxTenuringThreshold&#x3D;进行设置。 7、在养老区，相对悠闲。当老年区内存不足时，再次触发GC：Major GC，进行养老区的内存清理。 8、若养老区执行了Major GC之后发现依然无法进行对象的保存，就会产生OOM异常。 总结： 针对幸存者s0,s1区：谁空谁是to 关于垃圾回收：频繁在新生区收集，很少在养老区收集，几乎不在永久区&#x2F;元空间收集。 什么时候触发YGC？Eden区满，幸存者区满了不会触发（只有在Eden区满了触发YGC的时候被动触发） 对象分配特殊情况 超大对象—&gt;老年代 YGC时幸存者区放不下—&gt;老年代 Minor GC、Major GC、Full GC JVM在进行GC时，并非每次都针对上面三个内存区域（新生代、老年代；方法区）一起回收的，大部分时候回收都是指新生代 1、GC按照回收区域分为两大类： 部分收集（Partial GC）：不是完整的收集整个Java堆的垃圾收集 新生代收集（Minor GC &#x2F; Yong GC）：只是新生代的垃圾收集 老年代收集（Major GC &#x2F; Old GC）：只是老年代的垃圾收集 混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集 整堆收集（full GC）：收集整个java堆和方法区的垃圾收集 2、Minor GC的触发机制 年轻代空间不足，触发Minor GC，这里的年轻代满指的是Eden区域，幸存者区满不会触发 因为Java对象大多都朝生夕灭，所以Minor GC频率很高，速度也很快 Minor GC会引发STW，暂停其他用户的线程，等垃圾回收结束，用户线程才恢复运行 3、Major GC的触发机制 发生在老年代的GC，对象从老年代消失时，我们说“Major GC”发生了 出现了Major GC，经常伴随至少一次的Minor GC（不是绝对的） 也就是老年代空间不足时，会先尝试触发Minor GC，如果之后空间还不足就触发Major GC Major GC速度一般更慢，STW时间更长 如果Major GC之后，内存还不足，就报OOM 4、Full GC的触发机制 五种触发情况： 调用system.gc()时，系统执行Full GC 老年代空间不足 通过Minor GC进入老年代的平均大小大于老年代的可用内存 由Eden区，Survivor S0（from）区向S1（to）区复制时，对象大小由于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小 方法区空间不足 尽量避免 堆空间分代思想 为什么要把Java堆分代？不分代就不能正常工作了么 经研究，不同对象的生命周期不同。70%-99%的对象都是临时对象。 新生代：有Eden、Survivor构成（s0,s1 又称为from to），to总为空 老年代：存放新生代中经历多次依然存活的对象 其实不分代完全可以，分代的唯一理由就是优化GC性能。如果没有分代，那所有的对象都在一块，就如同把一个学校的人都关在一个教室。GC的时候要找到哪些对象没用，这样就会对堆的所有区域进行扫描，而很多对象都是朝生夕死的，如果分代的话，把新创建的对象放到某一地方，当GC的时候先把这块存储“朝生夕死”对象的区域进行回收，这样就会腾出很大的空间出来。 总结：内存分配策略1、如果对象在Eden出生并经过第一次Minor GC后依然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，把那个将对象年龄设为1.对象在Survivor区中每熬过一次MinorGC，年龄就增加一岁，当它的年龄增加到一定程度（默认15岁，其实每个JVM、每个GC都有所不同）时，就会被晋升到老年代中。 2、针对不同年龄段的对象分配原则如下： 优先分配到Eden 大对象直接分配到老年代 尽量避免程序中出现过多的大对象 长期存活的对象分配到老年代（大于阈值） 动态对象年龄判断 如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入到老年代。无需等到MaxTenuringThreshold中要求的年龄 空间分配担保 -XX: HandlePromotionFailure TLAB 为什么有TLAB（Thread Local Allocation Buffer）？ 堆区是线程共享区域，任何线程都可以访问到堆区中的共享数据 由于对象实例的创建在JVM中非常频繁，因此在并发环境下从堆区中划分内存空间是线程不安全的 为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度 什么是TLAB ? 从内存模型而不是垃圾收集的角度，对Eden区域继续进行划分，JVM为每个线程分配了一个私有缓存区域，它包含在Eden空间内 多线程同时分配内存时，使用TLAB可以避免一系列的非线程安全问题，同时还能够提升内存分配的吞吐量，因此我们可以将这种内存分配方式称之为快速分配策略 TLAB是线程私有的 说明 尽管不是所有的对象实例都能够在TLAB中成功分配内存，但是JVM明确将TLAB作为内存分配的首选 默认情况下，**TLAB空间的内存非常小，仅占有整个EDen空间的1%**，也可以自定义 一旦对象在TLAB空间分配内存失败时，JVM就会尝试着通过使用加锁机制确保数据操作的原子性，从而直接在Eden空间中分配了内存 堆空间参数小结-XX:+PrintFlagsInitial: 查看所有参数的默认初始值 -XX:+PrintFlagsFinal：查看所有的参数的最终值（可能会存在修改，不再是初始值） 具体查看某个参数的指令： jps：查看当前运行中的进程 jinfo -flag SurvivorRatio 进程id： 查看新生代中Eden和S0&#x2F;S1空间的比例 -Xms: 初始堆空间内存（默认为物理内存的1&#x2F;64） -Xmx: 最大堆空间内存（默认为物理内存的1&#x2F;4） -Xmn: 设置新生代大小（初始值及最大值） -XX:NewRatio: 配置新生代与老年代在堆结构的占比 -XX:SurvivorRatio：设置新生代中Eden和S0&#x2F;S1空间的比例 -XX:MaxTenuringThreshold：设置新生代垃圾的最大年龄(默认15) -XX:+PrintGCDetails：输出详细的GC处理日志 打印gc简要信息：① -XX:+PrintGC ② -verbose:gc -XX:HandlePromotionFailure：是否设置空间分配担保 逃逸分析在Java虚拟机中，对象是在Java堆中分配内存的，这是一个普遍的常识。但是，有一种特殊情况，那就是如果经过逃逸分析（Escape Analysis)后发现，一个对象并没有逃逸出方法的话，那么就可能被优化成栈上分配。这样就无需在堆上分配内存，也无须进行垃圾回收了。这也是最常见的堆外存储技术。 如何将堆上的对象分配到栈？ 使用逃逸分析，这是一种可以有效减少Java程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法 什么是逃逸？ 如果一个对象在方法中被定义，对象只在方法内部使用，则认为没有发生逃逸，在栈中分配内存 如果一个对象在方法中被定义，被外部方法所引用，则认为发生逃逸，在堆中分配内存 123456789101112131415public static StringBuffer craeteStringBuffer(String s1, String s2) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); //逃逸，放在堆里面 return sb;&#125;public static String craeteStringBuffer(String s1, String s2) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); //没有逃逸，放在栈里面 return sb.toString();&#125; 怎么判断逃逸？ new的对象实体是否在方法外被调用？ static局部变量也会发生逃逸 结论：能使用局部变量就不要在方法外定义 使用逃逸分析优化代码1、栈上分配 将堆分配转化为栈分配 进行逃逸分析，如果没有发生逃逸，就可能被优化为栈上分配 2、同步省略 如果一个对象被发现只能从一个线程中被访问到，就不用同步了 借助逃逸分析判断同步代码块所使用的锁对象是否只能够被一个线程访问，如果没有被其他线程访问，JIT编译器在编译这个同步块时就会取消同步，进行锁消除 123456789101112131415161718public class SynchronizedTest &#123; //优化前 public void f() &#123; Object hollis = new Object(); synchronized(hollis) &#123; System.out.println(hollis); &#125; &#125; //代码中对hollis这个对象进行加锁，但是hollis对象的生命周期只在f（）方法中 //并不会被其他线程所访问控制，所以在JIT编译阶段就会被优化掉。 //优化后 public void f2() &#123; Object hollis = new Object(); System.out.println(hollis); &#125;&#125; 3、分离对象或标量替换 有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分可以不用存储在堆空间中，而是存储在栈中 标量：无法被分解成更小的数据的数据，Java的原始数据类型就是标量 聚合量：可以分解的数据，例如java中的对象 在JIT阶段，经过逃逸分析发现一个对象不会被外界访问，经过JIT优化，就会把这个对象拆解成若干个其中包含的若干个成员变量代替，这就是标量替换 123456789101112131415161718class Point&#123; private int x; private int y; public Point(int x,int y)&#123; this.x = x; this.y = y; &#125;&#125;//优化前public static void alloc()&#123; Point point = new Point(1,2);&#125;//优化后public static void alloc()&#123; int x = 1; int y = 2;&#125; 可以看到，Point这个聚合量经过逃逸分析后，发现他并没有逃逸，就被替换成两个标量了。 那么标量替换有什么好处呢？ 可以大大减少堆内存的占用，因为一旦不需要创建对象了，那么就不再需要分配堆内存了。 小结1、这项技术到如今也并不是十分成熟的 其根本原因就是无法保证逃逸分析的性能消耗一定能高于他的消耗。虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除。但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。 2、一个极端的例子，就是经过逃逸分析之后，发现没有一个对象是不逃逸的。那这个逃逸分析的过程就白白浪费掉了。 3、虽然这项技术并不十分成熟，但是它也是即时编译器优化技术中一个十分重要的手段 4、注意到有一些观点，认为通过逃逸分析，JVM会在栈上分配那些不会逃逸的对象，这在理论上是可行的，但是取决于JVM设计者的选择。据我所知，Oracle HotspotJVM中并未这么做，这一点在逃逸分析相关的文档里已经说明，所以可以明确所有的对象实例都是创建在堆上。 5、目前很多书籍还是基于JDK7以前的版本，JDK已经发生了很大变化，intern字符串的缓存和静态变量曾经都被分配在永久代上，而永久代已经被元数据区取代。但是，intern字符串缓存和静态变量并不是被转移到元数据区，而是直接在堆上分配，所以这一点同样符合前面一点的结论：对象实例都是分配在堆上。 小结1、年轻代是对象的诞生、生长、消亡的区域，一个对象在这里产生、应用、最后被垃圾回收器收集、结束生命 2、老年代防止长生命周期对象，通常都是从Survivor区域筛选拷贝过来的Java对象。当然，也有特殊情况，我们知道普通的对象会被分配在TLAB上，如果对象较大，JVM会试图直接分配在Eden其他位置上；如果对象太大，完全无法在新生代找到足够长的连续空闲空间，JVM就会直接分配到老年代 3、当GC只发生在年轻代中，回收年轻对象的行为被称为MinorGC。当GC发生在老年代时则被称为MajorGC或者FullGC。一般的，MinorGC的发生频率要比MajorGC高很多，即老年代中垃圾回收发生的频率大大低于年轻代 什么时候进入老年代？ 策略一:将可能长期存活的对象直接放入老年代（超过阈值） 策略二:避免移区时的复制操作浪费资源（大对象） 策略三:不能将还有引用的对象当做垃圾回收掉（进行移区，被移动的对象大于区域的空间大小） 策略四:将可能长期存活的对象直接放入老年代 如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入到老年代 例如：按照年龄划分了10批对象,对象年龄依次为1-10,现在年龄1到3这批对象的总大小大于Survivor空间一半,则对象为4-10的所有对象会被放入老年代 运行时数据区（三）方法区栈、堆、方法区交互关系 基本理解1、方法区在逻辑上属于堆的一部分，但是一些简单的实现可能不会选择进行垃圾收集或者进行压缩，但是对于HitSpotJVM而言，方法区还有个别名叫做非堆，目的就是要与堆分开。 2、方法区看作是一块独立于Java堆的内存空间 3、方法区是线程共享的区域 4、方法区在启动的时候被创建，实际物理内存可以不连续 5、方法区的大小可以选择固定大小或者可扩展 6、方法区的大小决定了系统可以保存多少个类，如果系统定义了太多的类，会导致方法区溢出，报错java.lang.OutOfMemoryError:PermGen space 或者 java.lang,OutOfMemoryError:Metaspace，造成溢出的情况比如： 加载大量的第三方jar包； Tomcat部署的工程过多； 大量动态生成反射类； 7、方法区的历史演变 元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代最大的区别在于：元空间不再虚拟机设置的内存中，而是使用本地内存 永久代、元空间并不只是名字变了，内部结构也调整了 根据《Java虚拟机规范》得规定，如果方法区无法满足新的内存分配需求时，将抛出OOM异常. 设置方法区大小与OOMjdk7及以前： 通过-XX:PermSize来设置永久代初始分配空间。默认值是20.75M -XX:MaxPermSize来设定永久代最大可分配空间。32位机器默认是64M，64位机器模式是82M 当JVM加载的类信息容量超过了这个值，会报异常OutOfMemoryError:PermGen space jdk8及以后： 元数据区大小可以使用参数-XX:MetaspaceSize和-XX:MaxMetaspaceSize指定，替代上述原有的两个参数。 默认值依赖于平台。windows下，-XX:MetaspaceSize是21M，-XX:MaxMetaspaceSize的值是一1， 即没有限制。| I 与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。 如果元数据区发生溢出，虚拟机一样会拋出异常OutOfMemoryError:Metaspace -XX:MetaspaceSize： 设置初始的元空间大小。对于一个64位的服务器端JVM来说， 其默认的-XX:MetaspaceSize值为21MB.这就是初始的高水位线，一旦触及这个水位线，Full GC将会被触发并卸载没用的类（即这些类对应的类加载器不再存活），然后这个高水位线将会重置。新的高水位线的值取决于GC后释放了多少元空间。如果释放的空间不足，那么在不超过MaxMetaspaceSize时，适当提高该值。如果释放空间过多，则适当降低该值。 如果初始化的高水位线设置过低，.上 述高水位线调整情况会发生很多次。通过垃圾回收器的日志可以观察到Full GC多次调用。为了避免频繁地GC，建议将-XX:MetaspaceSize设置为一个相对较高的值。 解决OOM 1、要解决00M异常或heap space的异常，一般的手段是首先通过内存映像分析工具（如Eclipse Memory Analyzer） 对dump出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，也就是要先分清楚到底是出现了内存泄漏（Memory Leak）还是内存溢出（Memory 0verflow） 。 2、如果是内存泄漏，可进一步通过工具查看泄漏对象到GC Roots 的引用链。于是就能找到泄漏对象是通过怎样的路径与GCRoots相关联并导致垃圾收集器无法自动回收它们的。掌握了泄漏对象的类型信息，以及GC Roots引用链的信息，就可以比较准确地定位出泄漏代码的位置。 3、如果不存在内存泄漏，换句话说就是内存中的对象确实都还必须存活着，那就应当检查虚拟机的堆参数（一Xmx与一Xms） ，与机器物理内存对比看是否还可以调大，从代码_上检查是否存在某些对象生命周期过长、持有状态时间过长的情况，尝试减少程序运行期的内存消耗。 方法区内部结构 它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。 类型信息对每个加载的类型（ 类class、接口interface、枚举enum、注解annotation），JVM必 .须在方法区中存储以下类型信息： ①这个类型的完整有效名称（全名&#x3D;包名.类名） ②这个类型直接父类的完整有效名（对于interface或是java. lang.Object，都没有父类） ③这个类型的修饰符（public， abstract， final的某个子集） ④这个类型直接接口的一个有序列表 域信息（成员变量） JVM必须在方法区中保存类型的所有域的相关信息以及域的声明顺序。 域的相关信息包括：域名称、 域类型、域修饰符（public， private， protected， static， final， volatile， transient的某个子集） 方法信息JVM必须保存所有方法的以下信息，同域信息一样包括声明顺序： 方法名称 方法的返回类型（或void） 方法参数的数量和类型（按顺序） 方法的修饰符（public， private， protected， static， final， synchronized， native ， abstract的一个子集） 方法的字节码（bytecodes）、操作数栈、局部变量表及大小（ abstract和native 方法除外） 异常表（ abstract和native方法除外） 每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引 non-final的类变量（static） 静态变量和类关联在一起，随着类的加载而加载，他们成为类数据在逻辑上的一部分 类变量被类的所有实例所共享，即使没有类实例你也可以访问它。 全局常量 static final被声明为final的类变量的处理方法则不同，每个全局常量在编译的时候就被分配了。(准备阶段赋值) 运行时常量池常量池 1、方法区内部包含运行时常量池 2、字节码文件中包含常量池，加载到方法区之后称为运行时常量池 3、一个有效的字节码文件中除了包含类的版本信息、字段、方法以及接口等描述信息外，还包含一项信息那就是常量池表（Constant Pool Table），包括各种字面量和对类型域和方法的符号引用。 为什么需要常量池？ 一个 java 源文件中的类、接口，编译后产生一个字节码文件，而 Java 中的字节码需要数据支持，通常这种数据会很大以至于不能直接存到字节码里，换另一种方式，可以存到常量池这个字节码包含了指向常量池的引用，在动态链接的时候会用到运行时常量池。 4、几种在常量池内存储的数据类型包括： 数量值 字符串值 类引用 字段引用 方法引用 常量池，可以看做是一张表，虚拟机指令根据这张常量表找到要执行的类名，方法名，参数类型、字面量等信息。 运行时常量池 1、运行时常量池是方法区的一部分 2、常量池表是class文件的一部分，用于存放编译期生成的各种字面量和符号引用，这部分内容在类加载后存放到方法区的运行时常量池中 3、JVM为每个已加载的类型（类或接口）都维护一个常量池。池中的数据项像数组项一样，是通过索引访问的。 4、运行时常量池中包含多种不同的常量，包括编译期就已经明确的数值字面量，也包括到运行期解析后才能够获得的方法或者字段引用。此时不再是常量池中的符号地址了，这里换为真实地址。 运行时常量池，相对于Class文件常量池的另一重要特征是：具备动态性。 String.intern() 方法区演进细节1、只有HostSpot才有永久代 2、Hotspot中 方法区的变化： jdk1.6及之前：有永久代（permanent generation） ，静态变量存放在 永久代上 jdk1.7：有永久代，但已经逐步“去永久代”，字符串常量池、静态变量移除，保存在堆中 jdk1.8及之后： 无永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆 为什么永久代被元空间替代？ 1、为永久代设置空间大小很难确定 动态加载类过多容易产生OOM，在运行中产生很多类容易出现错误 元空间在本地内存中 2、对永久代进行调优很困难 为什么字符串常量池变化？ jdk7中将StringTable放到了堆空间中。因为永久代的回收效率很低，在full gc的时候才会触发。而full GC 是老年代的空间不足、永久代不足时才会触发，这就导致了StringTable回收效率不高。而我们开发中会有大量的字符串被创建，回收效率低，导致永久代内存不足。放到堆里，能及时回收内存。 如何证明静态变量在哪里？ 1、只要是对象实例必然会在Java堆中分配 2、JDK7 及其以后版本的 Hotspot 虚拟机选择把静态变量与类型在 Java 语言一端的映射 Class 对象存放在一起，存储于Java 堆之中，从我们的实验中也明确验证了这一点. 方法区的垃圾回收1、方法区的垃圾收集主要回收两部分内容：常量池中废奔的常量和不再使用的类型 常量池 2、方法区内常量池之中主要存放的两大类常量：字面量和符号引用。 字面量比较接近Java语言层次的常量概念，如文本字符串、被声明为final的常量值等，而符号引用则属于编译原理方面的概念，包括下面三类常量： 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 3、HotSpot虚拟机对常量池的回收策略是很明确的：只要常量池中的常量没有被任何地方引用，就可以被回收。 类型 4、判定一个类型是否属于“不再被使用的类”的条件就比较苛刻了，需要同时满足下面三个条件： 该类所有的实例都已经被回收，也就是Java堆中不存在该类及其任何派生子类的实例。 加载该类的类加载器已经被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如OSGi、JSP的重加载等，否则通常是很难达成的。 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 总结 面试题百度1、说一下JVM内存模型吧，有哪些区？分别干什么的？ 虚拟机栈：Java栈是Java方法执行的内存模型，栈帧（局部变量表、操作数栈、动态链接、方法返回地址） 本地方法栈：调用本地的方法 程序计数器：存储指向下一条指令的地址，本地方法为undefined 堆：线程共享、对象和数组 方法区：存放类 蚂蚁金服1、Java8的内存分代改进 将永久代转为元空间，从虚拟内存移到本地内存 1、为永久代设置空间大小很难确定 动态加载类过多容易产生OOM，在运行中产生很多类容易出现错误 元空间在本地内存中 2、对永久代进行调优很困难 3、JVM内存分布&#x2F;内存结构？栈和堆的区别？堆的结构？为什么两个survivor区？ 对于new的对象，栈中局部变量表只会存放在堆中的地址引用，具体实例变量的空间分配都在堆中 为什么 Survivor 分区不能是 0 个？ 如果 Survivor 是 0 的话，也就是说新生代只有一个 Eden 分区，每次垃圾回收之后，存活的对象都会进入老生代，这样老生代的内存空间很快就被占满了，从而触发最耗时的 Full GC ，显然这样的收集器的效率是我们完全不能接受的。 为什么 Survivor 分区不能是 1 个？ 如果 Survivor 分区是 1 个的话，假设我们把两个区域分为 1:1，那么任何时候都有一半的内存空间是闲置的，显然空间利用率太低不是最佳的方案。 但如果设置内存空间的比例是 8:2 ，只是看起来似乎“很好”，假设新生代的内存为 100 MB（ Survivor 大小为 20 MB ），现在有 70 MB 对象进行垃圾回收之后，剩余活跃的对象为 15 MB 进入 Survivor 区，这个时候新生代可用的内存空间只剩了 5 MB，这样很快又要进行垃圾回收操作，显然这种垃圾回收器最大的问题就在于，需要频繁进行垃圾回收。 为什么 Survivor 分区是 2 个？ 如果 Survivor 分区有 2 个分区，我们就可以把 Eden、From Survivor、To Survivor 分区内存比例设置为 8:1:1 ，那么任何时候新生代内存的利用率都 90% ，这样空间利用率基本是符合预期的。再者就是虚拟机的大部分对象都符合“朝生夕死”的特性，所以每次新对象的产生都在空间占比比较大的 Eden 区，垃圾回收之后再把存活的对象方法存入 Survivor 区，如果是 Survivor 区存活的对象，那么“年龄”就 +1 ，当年龄增长到 15 （可通过 -XX:+MaxTenuringThreshold 设定）对象就升级到老生代。 4、Eden和Survior的比例分配 8:1:1 小米1、jvm内存分区，为什么要有新生代和老年代 因为有的对象寿命长，有的对象寿命短。应该将寿命长的对象放在一个区，寿命短的对象放在一个区。不同的区采用不同的垃圾收集算法。寿命短的区清理频次高一点，寿命长的区清理频次低一点。提高效率。 字节跳动2、讲讲jvm运行时数据区 3、什么时候对象会进入老年代？ 京东5、JVM内存为什么要分成新生代，老年代，持久代。新生代中为什么要分为Eden和Survivor。 如果没有Survivor区，那么Eden每次满了清理垃圾，存活的对象被迁移到老年区，老年区满了，就会触发Full GC，Full GC是非常耗时的 天猫6、 Jvm内存模型以及分区，需要详细到每个区放什么。7、 JVM的内存模型，Java8做了什么修改 拼多多8、JVM内存分哪几个区，每个区的作用是什么？ 美团9、java内存分配 10、jvm的永久代中会发生垃圾回收吗？ 11、 jvm内存分区，为什么要有新生代和老年代？ 堆和栈的区别 （1）申请方式 stack:由系统自动分配。例如，声明在函数中一个局部变量 int b; 系统自动在栈中为 b 开辟空间 heap:需要程序员自己申请，并指明大小，在 c 中 malloc 函数，对于Java 需要手动 new Object()的形式开辟 （2）申请后系统的响应 stack：只要栈的剩余空间大于所申请空间，系统将为程序提供内存，否则将报异常提示栈溢出。 heap：首先应该知道操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时，会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点的空间分配给程序。另外，由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动的将多余的那部分重新放入空闲链表中。 （3）申请大小的限制 stack：栈是向低地址扩展的数据结构，是一块连续的内存的区域。这句话的意思是栈顶的地址和栈的最大容量是系统预先规定好的，在 WINDOWS 下，栈的大小是 2M（默认值也取决于虚拟内存的大小），如果申请的空间超过栈的剩余空间时，将提示 overflow。因此，能从栈获得的空间较小。 heap：堆是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储的空闲内存地址的， 自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小受限于计算机系统中有效的虚拟内存。由此可见， 堆获得的空间比较灵活，也比较大。 （4）申请效率的比较 stack：由系统自动分配，速度较快。但程序员是无法控制的。 heap：由 new 分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便。 （5）heap和stack中的存储内容 stack：在函数调用时，第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可执行语句）的地址， 然后是函数的各个参数，在大多数的 C 编译器中，参数是由右往左入栈的，然后是函数中的局部变量。注意静态变量是不入栈的。 当本次函数调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的地址，也就是主函数中的下一条指令，程序由该点继续运行。 heap：一般是在堆的头部用一个字节存放堆的大小。堆中的具体内容有程序员安排。 对象实例化对象的实例化面试题1、对象在JVM怎么存储的？ 2、Java对象头里面有什么？ 对象创建的方式1、new 最常见的方式 变形1 ： Xxx的静态方法 变形2 ： XxBuilder&#x2F;XxoxFactory的静态方法 2、Class的newInstance（）：反射的方式，只能调用空参的构造器，权限必须是public 3、Constructor的newInstance（Xxx）：反射的方式，可以调用空参、带参的构造器，权限没有要求 4、使用clone（） ：不调用任何构造器，当前类需要实现Cloneable接口，实现clone（） 5、使用反序列化：从文件中、从网络中获取一个对象的二进制流 6、第三方库Objenesis 创建对象的步骤1、判断对象对应的类是否加载、链接、初始化 2、为对象分配内存 如果内存规整一指针碰撞 如果内存不规整： 虚拟机需要维护一个列表 空闲列表分配 3、处理并发安全问题 采用CAS配上失败重试保证更新的原子性 每个线程预先分配一块TLAB 4、初始化分配到的空间一所有属性设置默认值，保证对象实例字段在不赋值时可以直接使用 5、设置对象的对象头 6、执行init方法进行初始化 1) 判断对象对应的类是否加载、链接、初始化虚拟机遇到一条new指令，首先去检查这个指令的参数能否在Metaspace的常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已经被加载、解析和初始化。（ 即判断类元信息是否存在）。如果没有，那么在双亲委派模式下，使用当前类加载器以ClassLoader+包名+类名为Key进行查找对应的.class文件。如果没有找到文件，则抛出ClassNotFoundException异常，如果找到，则进行类加载，并生成对应的Class类对象 2) 为对象分配内存首先计算对象占用空间大小，接着在堆中划分一块内存给新对象。 如果实例成员变量是引用变量，仅分配引用变量空间即可，即4个字节大小。 如果内存规整，使用指针碰撞，指针移动 如果内存是规整的，那么虚拟机将采用的是指针碰撞法（BumpThePointer）来为对象分配内存。意思是所有用过的内存在一边，空闲的内存在另外一边，中间放着一个指针作为分界点的指示器，分配内存就仅仅是把指针向空闲那边挪动一段与对象大小相等的距离罢了。如果垃圾收集器选择的是Serial、ParNew这种基于压缩算法的，虚拟机采用这种分配方式。一般使用带有compact （整理）过程的收集器时，使用指针碰撞。 如果内存不规整，虚拟机需要维护一个列表，使用空闲列表分配 如果内存不是规整的，已使用的内存和未使用的内存相互交错，那么虛拟机将采用的是空闲列表法来为对象分配内存。意思是虚拟机维护了一个列表，记录上哪些内存块是可用的，再分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的内容。这种分配方式成为“空闲列表（Free List） ”。 说明：选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 给对象的属性赋值的操作：① 属性的默认初始化② 显式初始化③ 代码块中初始化④ 构造器中初始化 3) 处理并发安全问题在分配内存空间时，另外一个问题是及时保证new对象时候的线程安全性：创建对象是非常频繁的操作，虚拟机需要解决并发问题。虚拟机采用 了两种方式解决并发问题： CAS （ Compare And Swap ）失败重试、区域加锁：保证指针更新操作的原子性； TLAB把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲区，（TLAB ，Thread Local Allocation Buffer） 虚拟机是否使用TLAB，可以通过一XX：+&#x2F;一UseTLAB参数来 设定。 4) 初始化分配到的空间内存分配结束，虚拟机将分配到的内存空间都初始化为零值（不包括对象头）。这一步保证了对象的实例字段在Java代码中可以不用赋初始值就可以直接使用，程序能访问到这些字段的数据类型所对应的零值。 5) 设置对象的对象头将对象的所属类（即类的元数据信息）、对象的HashCode和对象的GC信息、锁信息等数据存储在对象的对象头中。这个过程的具体设置方式取决于JVM实现。 6) 执行init方法进行初始化在Java程序的视角看来，初始化才正式开始。初始化成员变量，执行实例化代码块，调用类的构造方法，并把堆内对象的首地址赋值给引用变量。 因此一般来说（由字节码中是否跟随有invokespecial指令所决定），new指令之 后会接着就是执行方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全创建出来。 判断对象对应的类是否已经加载——》为对象分配空间——》处理并发安全问题——》初始化分配到的空间——》设置对象头——》初始化 对象的内存布局对象头包括：运行时元数据、类型指针 1、运行时元数据 哈希值（hashcode）：地址值 GC分代年龄 锁状态标志 线程持有的锁 偏向线程ID 偏向时间戳 2、类型指针 指向方法区对象所属的class，确定对象所属的类型 如果创建的是数组，需要记录数组的长度 实例数据说明：它是对象真正存储的有效信息，包括程序代码中定义的各种类型的字段（包括从父类继承下来的和本身拥有的字段） 规则： 相同宽度的字段总被分配在一起 父类中定义的变量会出现在子类之前 如果CompactFields参数为true（默认为true），子类的窄变量可能插入到父类变量的空隙 对齐填充没有特别含义，占位符 小结 对象的访问定位 JVM是如何通过栈帧中的对象引用访问到内部的对象实例？ 通过栈上的引用访问 对象访问的方式句柄访问1、在Java堆开辟一个句柄池，记录到对象实例数据的指针和到对象类型数据的指针 2、优缺点 优点：在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而 reference 本身不需要被修改 缺点：需要专门开辟空间，浪费空间；效率较低 直接指针（默认）1、优缺点 优点：速度快 缺点：对象移动时需要修改reference 执行引擎概述1、Java虚拟机核心的组成部分之一 2、虚拟机的执行引擎是由软件自行实现的 3、JVM的主要任务是负责装载字节码到其内部，但字节码不能够直接运行在操作系统之上，执行引擎的任务就是将字节码指令解释&#x2F;编译为对应平台的本地机器指令 工作过程 Java代码编译和执行过程大部分的程序代码转换成物理机的目标代码或虚拟机能执行的指令集之前，都需要经过下面图中的各个步骤： Java代码编译是由Java源码编译器来完成，流程图如下所示： Java字节码的执行是由JVM执行引擎来完成，流程图如下所示： 什么是解释器（ Interpreter），什么是JIT编译器？ 解释器：当Java虚拟机启动时会根据预定义的规范对字节码采用逐行解释的方式执行，将每条字节码文件中的内容“翻译”为对应平台的本地机器指令执行。 JIT （Just In Time Compiler）编译器（即时编译器）：就是虚拟机将源代码直接编译成和本地机器平台相关的机器语言。 为什么说Java是半编译半解释型语言？ JDK1.0时代，将Java语言定位为“解释执行”还是比较准确的。再后来，Java也发展出可以直接生成本地代码的编译器。 现在JVM在执行Java代码的时候，通常都会将解释执行与编译执行二者结合起来进行。 机器码、指令、汇编语言机器码 各种用二进制编码方式表示的指令，叫做&#x3D;&#x3D;机器指令码&#x3D;&#x3D;。开始，人们就用它采编写程序，这就是机器语言。 机器语言虽然能够被计算机理解和接受，但和人们的语言差别太大，不易被人们理解和记忆，并且用它编程容易出差错。 用它编写的程序一经输入计算机，CPU直接读取运行，因此和其他语言编的程序相比，执行速度最快。 机器指令与CPU紧密相关，所以不同种类的CPU所对应的机器指令也就不同。 指令 由于机器码是有0和1组成的二进制序列，可读性实在太差，于是人们发明了指令。 指令就是把机器码中特定的0和1序列，简化成对应的指令（一般为英文简写，如mov，inc等），可读性稍好 由于不同的硬件平台，执行同一个操作，对应的机器码可能不同，所以不同的硬件平台的同一种指令（比如mov），对应的机器码也可能不同。 指令集 不同的硬件平台，各自支持的指令，是有差别的。因此每个平台所支持的指令，称之为对应平台的指令集。 如常见的 x86指令集，对应的是x86架构的平台 ARM指令集，对应的是ARM架构的平台 汇编语言 由于指令的可读性还是太差，于是人们又发明了汇编语言。 在汇编语言中，用助记符（Mnemonics）代替机器指令的操作码，用地址符号（Symbol）或标号（Label）代替指令或操作数的地址。 在不同的硬件平台，汇编语言对应着不同的机器语言指令集，通过汇编过程转换成机器指令。 由于计算机只认识指令码，所以用汇编语言编写的程序还必须翻译成机器指令码，计算机才能识别和执行。 高级语言 为了使计算机用户编程序更容易些，后来就出现了各种高级计算机语言。高级语言比机器语言、汇编语言更接近人的语言 当计算机执行高级语言编写的程序时，仍然需要把程序解释和编译成机器的指令码。完成这个过程的程序就叫做解释程序或编译程序。 字节码 字节码是一种中间状态（中间码）的二进制代码（文件），它比机器码更抽象，需要直译器转译后才能成为机器码 字节码主要为了实现特定软件运行和软件环境、与硬件环境无关。 字节码的实现方式是通过编译器和虚拟机器。编译器将源码编译成字节码，特定平台上的虚拟机器将字节码转译为可以直接执行的指令。 字节码的典型应用为Java bytecode C、C++源程序执行过程编译过程又可以分成两个阶段：编译和汇编。 编译过程：是读取源程序（字符流），对 之进行词法和语法的分析，将高级语言指令转换为功能等效的汇编代码 汇编过程：实际上指把汇编语言代码翻译成目标机器指令的过程。 解释器JVM设计者们的初衷仅仅只是单纯地为了满足Java程序实现跨平台特性，因此避免采用静态编译的方式直接生成本地机器指令，从而诞生了实现解释器在运行时采用逐行解释字节码执行程序的想法。 解释器真正意义上所承担的角色就是一个运行时“翻译者”，将字节码文件中的内容“翻译”为对应平台的本地机器指令执行。 当一条字节码指令被解释执行完成后，接着再根据PC寄存器中记录的下一条需要被执行的字节码指令执行解释操作。 在Java的发展历史里，一共有两套解释执行器，即古老的字节码解释器、现在普遍使用的模板解释器。 字节码解释器在执行时通过纯软件代码模拟字节码的执行，效率非常低下。· - 而模板解释器将每一 条字节码和一个模板函数相关联，模板函数中直接产生这条字节码执行时的机器码，从而很大程度上提高了解释器的性能。 在HotSpot VM中，解释器主要由Interpreter模块和Code模块构成。 Interpreter模块：实现了解释器的核心功能 Code模块：用于管理HotSpot VM在运行时生成的本地机器指令 现状 由于解释器在设计和实现上非常简单，因此除了Java语言之外，还有许多高级语言同样也是基于解释器执行的，比如Python、 Perl、Ruby等。但是在今天，基于解释器执行已经沦落为低效的代名词，并且时常被一些C&#x2F;C+ +程序员所调侃。 为了解决这个问题，JVM平台支持一种叫作即时编译的技术。即时编译的目的是避免函数被解释执行，而是将整个函数体编译成为机器码，每次函数执行时，只执行编译后的机器码即可，这种方式可以使执行效率大幅度提升。 不过无论如何，基于解释器的执行模式仍然为中间语言的发展做出了不可磨灭的贡献。 JIT编译器1、Java代码的执行分类 源代码编译成字节码文件，在运行时通过解释器将字节码文件转为机器码执行 编译执行，现代虚拟机为了提高执行效率，会使用即使编译技术将方法编译成机器码后再执行 2、HotSpot VM是目前市面上高性能虛拟机的代表作之一。它采用解释器与即时编译器并存的架构。在Java虛拟机运行时，解释器和即时编译器能够相互协作，各自取长补短，尽力去选择最合适的方式来权衡编译本地代码的时间和直接解释执行代码的时间。 为什么还需要解释器？ 首先明确：当程序启动后，解释器可以马上发挥作用，省去编译的时间，立即执行。 编译器要想发挥作用，把代码编译成本地代码，需要一定的执行时间。但编译为本地代码后，执行效率高。 所以：尽管JRockitVM中程序的执行性能会非常高效，但程序在启动时必然需要花费更长的时间来进行编译。对于服务端应用来说，启动时间并非是关注重点，但对于那些看中启动时间的应用场景而言，或许就需要采用解释器与即时编译器并存的架构来换取一一个平衡点。在此模式下。 当Java虚拟器启动时，解释器可以首先发挥作用，而不必等待即时编译器全部编译完成后再执行，这样可以省去许多不必要的编译时间。随着时间的推移，编译器发挥作用，把越来越多的代码编译成本地代码，获得更高的执行效率。 同时，解释执行在编译器进行激进优化不成立的时候，作为编译器的“逃生门”。 JIT编译器概念解释 Java 语言的“编译器” 其实是一段“不确定”的操作过程，因为它可能是指一个前端编译器（其实叫“编译器的前端” 更准确一些）把.java文件转变成.class文件的过程； 也可能是指虚拟机的后端运行期编译器（JIT 编译器，Just In Time Compiler）把字节码转变成机器码的过程。 还可能是指使用静态提前编译器（AOT 编译器，Ahead Of Time Compiler）直接把. java文件编译成本地机器代码的过程。 前端编译器： Sun的Javac、 Eclipse JDT中的增量式编译器（ECJ）JIT编译器： HotSpot VM的C1、C2编译器。AOT编译器： GNU Compiler for the Java （GCJ） 、Excelsior JET。 热点代码及探测方式当然是否需要启动JIT编译器将字节码直接编译为对应平台的本地机器指令，则需要根据代码被调用执行的频率而定。关于那些需要被编译为本地代码的字节码，也被称之为“热点代码” ，JIT编译器在运行时会针对那些频繁被调用的“热点代码”做出深度优化，将其直接编译为对应平台的本地机器指令，以此提升Java程序的执行性能。 一个被多次调用的方法，或者是一个方法体内部循环次数较多的循环体都可以被称之为“热点代码”，因此都可以通过JIT编译器编译为本地机器指令。由于这种编译方式发生在方法的执行过程中，因此也被称之为栈上替换，或简称为OSR （On StackReplacement）编译。 一个方法究竟要被调用多少次，或者一个循环体究竟需要执行多少次循环才可以达到这个标准？必然需要一个明确的阈值，JIT编译器才会将这些“热点代码”编译为本地机器指令执行。这里主要依靠热点探测功能。 目前HotSpot VM所采用的热点探测方式是基于计数器的热点探测 采用基于计数器的热点探测，HotSpot VM将会为每一个方法都建立2个不同类型的计数器，分别为方法调用计数器（Invocation Counter） 和回边计数器（BackEdge Counter）。 方法调用计数器用于统计方法的调用次数 回边计数器则用于统计循环体执行的循环次数 方法调用计数器 这个计数器就用于统计方法被调用的次数，它的默认阈值在Client 模式 下是1500 次，在Server 模式下是10000 次。超过这个阈值，就会触发JIT编译。 这个阈值可以通过虚拟机参数-XX:CompileThreshold来人为设定。 当一个方法被调用时， 会先检查该方法是否存在被JIT编译过的版本，如 果存在，则优先使用编译后的本地代码来执行。如果不存在已被编译过的版本，则将此方法的调用计数器值加1，然后判断方法调用计数器与回边计数器值之和是否超过方法调用计数器的阈值。如果已超过阈值，那么将会向即时编译器提交一个该方法的代码编译请求。 热度衰减 如果不做任何设置，方法调用计数器统计的并不是方法被调用的绝对次数，而是一一个相对的执行频率，即一段时间之内方法被调用的次数。当超过一定的时间限度， 如果方法的调用次数仍然不足以让它提交给即时编译器编译，那这个方法的调用计数器就会被减少一半，这个过程称为方法调用计数器热度的衰减（Counter Decay） ，而这段时间就称为此方法统计的半衰周期（Counter Half Life Time）。 进行热度衰减的动作是在虚拟机进行垃圾收集时顺便进行的，可以使用虚拟机参数 -XX：-UseCounterDecay来关闭热度衰减，让方法计数器统计方法调用的绝对次数，这样，只要系统运行时间足够长，绝大部分方法都会被编译成本地代码。 另外， 可以使用-XX： CounterHalfLifeTime参数设置半衰周期的时间，单位是秒。 回边计数器它的作用是统计一个方法中循环体代码执行的次数，在字节码中遇到控制流向后跳转的指令称为“回边” （Back Edge）。显然，建立回边计数器统计的目的就是为了触发OSR编译。 HotSpot VM 可以设置程序执行方式缺省情况下HotSpot VM是采用解释器与即时编译器并存的架构，当然开发人员可以根据具体的应用场景，通过命令显式地为Java虚拟机指定在运行时到底是完全采用解释器执行，还是完全采用即时编译器执行。如下所示： -Xint： 完全采用解释器模式执行程序； -Xcomp： 完全采用即时编译器模式执行程序。如果即时编译出现问题，解释器会介入执行。 -Xmixed：采用解释器+即时编译器的混合模式共同执行程序。 测试解释器模式和JIT编译模式测试表明： 纯解释器模式速度最慢（JVM1.0版本用的就是纯解释器执行） 混合模式速度更快 HotSpot VM 中的JIT分类在HotSpot VM中内嵌有两个JIT编译器，分别为Client Compiler和Server Compiler，但大多数情况下我们简称为C1编译器和C2编译器。开发人员可以通过如下命.令显式指定Java虚拟机在运行时到底使用哪一种即时编译器，如下所示： -client： 指定Java虚拟机运行在Client模式下，并使用C1编译器； C1编译器会对字节码进行简单和可靠的优化，耗时短。以达到更快的编译速度。 -server： 指定Java虚拟机运行在Server模式下，并使用C2编译器。 C2进行耗时较长的优化，以及激进优化。但优化的代码执行效率更高。 C1和C2编译器不同的优化策略 在不同的编译器上有不同的优化策略，C1编译器上主要有方法内联，去虚拟化、冗余消除。 方法内联：将引用的函数代码编译到引用点处，这样可以减少栈帧的生成，减少参数传递以及跳转过程 去虚拟化：对唯一的实现类进行内联 冗余消除：在运行期间把一些不会执行的代码折叠掉 C2的优化主要是在全局层面，逃逸分析是优化的基础。基于逃逸分析在C2.上有如下几种优化：（server模式下才会有这些优化，64位系统默认就是server模式） 标量替换：用标量值代替聚合对象的属性值 栈上分配：对于未逃逸的对象分配对象在栈而不是堆 同步消除：清除同步操作，通常指synchronized 分层编译（Tiered Compilation）策略：程序解释执行（不开启性能监控）可以触发C1编译，将字节码编译成机器码，可以进行简单优化，也可以加上性能监控，C2编译会根据性能监控信息进行激进优化。 不过在Java7版本之后，一旦开发人员在程序中显式指定命令“一server”时，默认将会开启分层编译策略，由C1编译器和C2编译器相互协作共同来执行编译任务。 总结 一般来讲，JIT编译出来的机器码性能比解释器高。 C2编译器启动时长比C1编译器慢，系统稳定执行以后，C2编译器执行速度远远快于C1编译器。 Graal编译器与AOT编译器Graal编译器 自JDK10起，HotSpot又加入一个全新的即时编译器： Graal编译器 编译效果短短几年时间就追评了C2编译器。未来可期。 目前，带着“实验状态”标签，需要使用开关参数 -XX： +UnlockExperimentalVMOptions 一XX： +UseJVMCICompiler去激活，才可以使用。 AOT编译器 jdk9引入了AOT编译器（静态提前编译器，Ahead Of Time Compiler） Java 9引入了实验性AOT编译工具jaotc。它借助了Graal 编译器，将所输入的Java 类文件转换为机器码，并存放至生成的动态共享库之中。 所谓AOT编译，是与即时编译相对立的一个概念。我们知道，即时编译指的是在程序的运行过程中，将字节码转换为可在硬件上直接运行的机器码，并部署至托管环境中的过程。而AOT编译指的则是，在程序运行之前，便将字节码转换为机器码的过程。 最大好处： Java虚拟机加载已经预编译成二进制库，可以直接执行。不必等待即时编译器的预热，减少Java应用给人带来“第一次运行慢”的不良体验。 缺点： 破坏了java”一次编译，到处运行”，必须为每个不同硬件、oS编译对应的发行包。 降低了Java链接过程的动态性，加载的代码在编译期就必须全部已知。 还需要继续优化中，最初只支持Linux x64 java base StringTable基本特性1、String：字符串，使用一对””引起来表示。 String sl &#x3D; “hello”；&#x2F;&#x2F;字面量的定义方式 String s2 &#x3D; new String（”hello”） ； 2、String声明为final的， 不可被继承 3、String实现了Serializable接口：表示字符串是支持序列化的。 4、实现了Comparable接口：表示String可以比较大小 5、String在jdk8及以前内部定义了final char value[]，value用于存储字符串数据，jdk9时改为byte[] 结论： String再也不用char[] 来存储，改成了byte[] 加上编码标记，节约了一些空间。StringBuffer和StringBuilder也做了一些修改 6、String：代表不可变的字符序列，简称：不可变性。 当对字符串重新赋值时，需要重写指定内存区域赋值，不能使用原有的value进行赋值。 当对现有的字符串进行连接操作时，也需要重新指定内存区域赋值，不能使用原有的value进行赋值。 当调用String的replace（）方法修改指定字符或字符串时，也需要重新指定内存区域赋值，不能使用原有的value进行赋值。 7、通过字面量的方式（区别于new）给一个字符串赋值，此时的字符串值声明在字符串常量池中。 12//字面量String a = &quot;aa&quot;; 8、字符串常量池中是不会存储相同内容的字符串的 String的String Pool 是一个固定大小的Hashtable，默认值大小长度是1009。如果放进StringPool的String非常多， 就会造成Hash冲突严重，从而导致链表会很长，而链表长了后直接会造成的影响就是当调用String. intern时性能会大幅下降。 使用-XX:StringTableSize可设置StringTable的长度 在jdk6中StringTable是固定的，就是1009的长度，所以如果常量池中的字符串过多就会导致效率下降很快。StringTableSize设 置没有要求 在jdk7中，StringTable的长度默认值是60013 jdk8开始,1009是StringTable长度可设置的最小值 String的内存分配1、在Java语言中有8种基本数据类型和一种比较特殊的类型String。这些类型为了使它们在运行过程中速度更快、更节省内存，都提供了一种常量池的概念。 2、常量池就类似一个Java系统级别提供的缓存，8种基本数据类型的常量池都是系统协调的，String类型的常量池比较特殊，它的主要使用方法有两种： 直接使用双引号声明出来的String对象会直接存储在常量池中 比如： String info = &quot;abc&quot; ； 如果不是用双引号声明的String对象，可以使用String提供的intern（）方法 3、变化 Java 6及以前，字符串常量池存放在永久代 Java 7中Oracle的工程师对字符串池的逻辑做了很大的改变，即将字符串常量池的位置调整到Java堆内 所有的字符串都保存在堆（Heap）中，和其他普通对象一样，这样在进行调优应用时仅需要调整堆大小就可以了 字符串常量池概念原本使用得比较多，但是这个改动使得我们有足够的理由让我们重新考虑在Java 7中使用String. intern（） Java8元空间，字符串常量在堆 为什么字符串常量池需要进行改变？ 1、永久代默认情况下比较小 2、永久代的回收效率较低，垃圾回收频率低 String的基本操作例一： 例2: 12345678910111213class Memory &#123; public static void main(String[] args) &#123;//line 1 int i = 1;//line 2 Object obj = new Object();//line 3 Memory mem = new Memory();//line 4 mem.foo(obj);//line 5 &#125;//line 9 private void foo(Object param) &#123;//line 6 String str = param.toString();//line 7 System.out.println(str); &#125;//line 8&#125; String的拼接操作1、常量与常量的拼接结果在常量池，原理是编译期优化 2、常量池中不会存在相同内容的常量。 3、只要其中有一个是变量，结果就在堆中，变量拼接的原理是StringBuilder 4、如果拼接的结果调用intern（）方法，则主动将常量池中还没有的字符串对象放入池中，并返回此对象地址。 123456789101112@Testpublic void test1()&#123; String s1 = &quot;a&quot; + &quot;b&quot; + &quot;c&quot;;//编译期优化：等同于&quot;abc&quot; String s2 = &quot;abc&quot;; //&quot;abc&quot;一定是放在字符串常量池中，将此地址赋给s2 /* * 最终.java编译成.class,再执行.class * String s1 = &quot;abc&quot;; * String s2 = &quot;abc&quot; */ System.out.println(s1 == s2); //true System.out.println(s1.equals(s2)); //true&#125; 123456789101112131415161718192021222324@Testpublic void test2()&#123; String s1 = &quot;javaEE&quot;; String s2 = &quot;hadoop&quot;; String s3 = &quot;javaEEhadoop&quot;; String s4 = &quot;javaEE&quot; + &quot;hadoop&quot;;//编译期优化 //如果拼接符号的前后出现了变量，则相当于在堆空间中new String()，具体的内容为拼接的结果：javaEEhadoop String s5 = s1 + &quot;hadoop&quot;; String s6 = &quot;javaEE&quot; + s2; String s7 = s1 + s2; System.out.println(s3 == s4);//true System.out.println(s3 == s5);//false System.out.println(s3 == s6);//false System.out.println(s3 == s7);//false System.out.println(s5 == s6);//false System.out.println(s5 == s7);//false System.out.println(s6 == s7);//false //intern():判断字符串常量池中是否存在javaEEhadoop值，如果存在，则返回常量池中javaEEhadoop的地址； //如果字符串常量池中不存在javaEEhadoop，则在常量池中加载一份javaEEhadoop，并返回次对象的地址。 String s8 = s6.intern(); System.out.println(s3 == s8);//true&#125; 底层原理1、字符串拼接操作不一定使用StringBuilder 情况一：拼接符号左右两边都是字符串常量：&quot;a&quot;+&quot;b&quot; 情况二：拼接符号左右两边都是常量引用：final String a= &quot;a&quot;;final String b=&quot;b&quot;; a+b; 2、针对final修饰类、方法、基本数据类型、引用数据类型时，能使用final就使用final 3、append的方式比拼接字符串更加高效 使用append的方式，从始至终只需要创建一个stringbuilder对象 使用字符串拼接，每次都需要创建stringbuilder对象、String对象，占用内存过多 4、改进空间 在实际开发中，如果基本确定需要添加字符串的长度，就可以自定义长度实例化stringbuilder 1StringBuilder a = new StringBuilder(10)； intern()方法1public native String intern(); 1、如果不是用双引号声明的String对象，可以使用String提供的intern方法： intern方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中。 比如： String myInfo = new String(&quot;I love u&quot;).intern()； 也就是说，如果在任意字符串上调用String. intern方法，那么其返回结果所指向的那个类实例，必须和直接以常量形式出现的字符串实例完全相同。 2、因此，下列表达式的值必定是true： （&quot;a&quot; + &quot;b&quot; + &quot;c&quot;）.intern（）== &quot;abc&quot;;通俗点讲，Interned String就是确保字符串在内存里只有一份拷贝，这样可以节约内存空间，加快字符串操作任务的执行速度。注意，这个值会被存放在字符串内部池（String Intern Pool）。 new String()创建几个对象？123456public class StringNewTest &#123; public static void main(String[] args) &#123; String str1 = new String(&quot;ab&quot;); String str2 = new String(&quot;a&quot;) + new String(&quot;b&quot;); &#125;&#125; 注意：使用toString方法不会在常量池中生成 面试题1234567891011121314151617181920212223242526272829303132333435/** * 如何保证变量s指向的是字符串常量池中的数据呢？ * 有两种方式： * 方式一： String s = &quot;shkstart&quot;;//字面量定义的方式 * 方式二： 调用intern() * String s = new String(&quot;shkstart&quot;).intern(); * String s = new StringBuilder(&quot;shkstart&quot;).toString().intern(); */public class StringIntern &#123; public static void main(String[] args) &#123; String s = new String(&quot;1&quot;); String s1 = s.intern();//调用此方法之前，字符串常量池中已经存在了&quot;1&quot; String s2 = &quot;1&quot;; //s 指向堆空间&quot;1&quot;的内存地址 //s1 指向字符串常量池中&quot;1&quot;的内存地址 //s2 指向字符串常量池已存在的&quot;1&quot;的内存地址 所以 s1==s2 System.out.println(s == s2);//jdk6：false jdk7/8：false System.out.println(s1 == s2);//jdk6: true jdk7/8：true System.out.println(System.identityHashCode(s));//491044090 System.out.println(System.identityHashCode(s1));//644117698 System.out.println(System.identityHashCode(s2));//644117698 //s3变量记录的地址为：new String(&quot;11&quot;) String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;); //执行完上一行代码以后，字符串常量池中，是否存在&quot;11&quot;呢？答案：不存在！！ // jdk6:创建了一个新的对象&quot;11&quot;,也就有新的地址。 // jdk7:此时常量中并没有创建&quot;11&quot;,而是创建一个指向堆空间中new String(&quot;11&quot;)的地址 s3.intern(); //s4变量记录的地址：使用的是上一行代码代码执行时，在常量池中生成的&quot;11&quot;的地址 String s4 = &quot;11&quot;; System.out.println(s3 == s4);//jdk6：false jdk7/8：true &#125;&#125; 拓展 12345678910public class StringIntern1 &#123; public static void main(String[] args) &#123; String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;);//new String(&quot;11&quot;) //执行完上一行代码以后，字符串常量池中，是否存在&quot;11&quot;呢？答案：不存在！！ String s4 = &quot;11&quot;;//在字符串常量池中生成对象&quot;11&quot; String s5 = s3.intern(); System.out.println(s3 == s4);//false System.out.println(s5 == s4);//true &#125;&#125; 总结jdk6中，将这个字符串对象尝试放入串池 如果串池中有，则不会放入，返回已有的地址 如果没有，将此字符串对象复制一份放入，并返回对象地址 jdk7后，将这个字符串对象尝试放入串池 如果有，不会放入，返回已有的地址 如果没有，将字符串对象的引用地址复制一份放入，返回引用地址 1、两个String拼接，因为最后stringBuilder调用了toString方法，所以返回的是一个new String（）地址 2、如果常量池里面没有拼接后的值，调用intern方法，常量池中放的是new String()的地址 3、如果常量池有拼接后的值，调用intern方法，就会返回常量池这个值的地址 练习123456789101112public class StringExer1 &#123; public static void main(String[] args) &#123; String s = new String(&quot;a&quot;) + new String(&quot;b&quot;);//new String(&quot;ab&quot;) //在上一行代码执行完以后，字符串常量池中并没有&quot;ab&quot; String s2 = s.intern();//jdk6中：在串池中创建一个字符串&quot;ab&quot; //jdk8中：串池中没有创建字符串&quot;ab&quot;,而是创建一个引用，指向new String(&quot;ab&quot;)，将此引用返回 System.out.println(s2 == &quot;ab&quot;);//jdk6:true jdk8:true System.out.println(s == &quot;ab&quot;);//jdk6:false jdk8:true &#125;&#125; jdk6 jdk7&#x2F;8 12345678910public class StringExer1 &#123; public static void main(String[] args) &#123; String x = &quot;ab&quot;; String s = new String(&quot;a&quot;) + new String(&quot;b&quot;);//new String(&quot;ab&quot;) String s2 = s.intern(); System.out.println(s2 == x);//true System.out.println(s == x);//false &#125;&#125; 123456789public class StringExer2 &#123; public static void main(String[] args) &#123; String s1 = new String(&quot;ab&quot;);//执行完以后，会在字符串常量池中会生成&quot;ab&quot; // String s1 = new String(&quot;a&quot;) + new String(&quot;b&quot;);////执行完以后，不会在字符串常量池中会生成&quot;ab&quot; s1.intern(); String s2 = &quot;ab&quot;; System.out.println(s1 == s2); //false &#125;&#125; intern()空间效率大的网站平台，需要内存中存储大量的字符串。比如社交网站，很多人都存储：北京市、海淀区等信息。这时候如果字符串都调用 intern（）方法，就会明显降低内存的大小。 G1中的String去重操作 背景：对许多Java应用（有大的也有小的）做的测试得出以下结果： 堆存活数据集合里面String对象占了25% 堆存活数据集合里面重复的String对象有13.5% String对象的平均长度是45 许多大规模的Java应用的瓶颈在于内存，测试表明，在这些类型的应用里面，Java堆中存活的数据集合差不多25%是String对象。更进一步，这里面差不多一半String对象是重复的，重复的意思是说： string1. equals （string2）=true。堆上存在重复的string对象必然是一种内存的浪费。这个项目将在G1垃圾收集器中实现自动持续对重复的String对象进行去重，这样就能避免浪费内存。 实现 当垃圾收集器工作的时候，会访问堆上存活的对象。对每一个访问的对象都会检查是否是候选的要去重的String对象。 如果是，把这个对象的一个引用插入到队列中等待后续的处理。一个去重的线程在后台运行，处理这个队列。处理队列的一个元素意味着从队列删除这个元素，然后尝试去重它引用的String对象。 使用一个hashtable来记录所有的被String对象使用的不重复的char数组。 当去重的时候，会查这个hashtable，来看堆上是否已经存在一个一模一样的char数组。 如果存在，String对象会被调整引用那个数组，释放对原来的数组的引用，最终会被垃圾收集器回收掉。 如果查找失败，char数组会被插入到hashtable，这样以后的时候就可以共享这个数组了。 命令行选项 UseStringDeduplication （bool） ：开启String去重，默认是不开启的，需要手动开启。 PrintStringDedupl icationStatistics （bool） ：打印详细的去重统计信息， StringDedupl icationAgeThreshold （uintx） ：达到这个年龄的string对象被认.为是去重的候选对象 垃圾回收概述什么是垃圾1、垃圾是指运行程序中没有任何指针指向的对象，这个对象就是需要被回收的垃圾 2、如果不及时对内存中的垃圾进行清理，这些垃圾对象所占的内存空间会所占的内存空间会一直保留到应用程序结束，被保留的空间无法被其他对象使用，甚至可能导致内存溢出 内存溢出和内存泄露1、内存溢出 从字面上的意思即jvm内存不够用了，目前无法存放创建的对象。 2、内存泄露 不再会被使用的对象不能被回收，就是内存泄露。说的通俗点就是：该对象已经需要被GC了，却没有这么做。 大厂面试题 蚂蚁金服： 你知道哪几种垃圾回收器，各自的优缺点，重点讲一下 cms和g1 一面： JVM GC算法有哪些，目前的JDK版本采用什么回收算法 一面： （ G1回收器讲下回收过程 GC是什么？为什么要有GC？ 一面： GC的两种判定方法？ CMS收集器与G1收集器的特点。 百度： 说一下GC算法，分代回收说下 垃圾收集策略和算法 天猫： 一面： jvm GC原理，JVM怎么回收内存 一面： CMS特点，垃圾回收算法有哪些？各自的优缺点，他们共同的缺点是什么？ 滴滴： 一面： java的垃圾回收器都有哪些，说下g1的应用场景，平时你是如何搭配使用垃圾回收器的 京东： 你知道哪几种垃圾收集器，各自的优缺点，重点讲下cms和G1，包括原理，流程，优缺点。垃圾回收算法的实现原理。 阿里： 讲一讲垃圾回收算法。 什么情况下触发垃圾回收？ 如何选择合适的垃圾收集算法？ JVM有哪三种垃圾回收器？ 字节跳动： 常见的垃圾回收器算法有哪些，各有什么优劣？ system.gc （）和runtime.gc（）会做什么事情？ 一面： Java GC机制？ GC Roots有哪些？ 二面： Java对象的回收方式，回收算法。 CMS和G1了解么，CMS解决什么问题，说一下回收的过程。 CMS回收停顿了几次，为什么要停顿两次。 为什么需要GC1、对于高级语言来说，一个基本认知是如果不进行垃圾回收，内存迟早都会被消耗完，因为不断地分配内存空间而不进行回收，就好像不停地生产生活垃圾而从来不打扫一样。 2、除了释放没用的对象，垃圾回收也可以清除内存里的记录碎片。碎片整理将所占用的堆内存移到堆的一端，以便JVM将整理出的内存分配给新的对象。 3、随着应用程序所应付的业务越来越庞大、复杂，用户越来越多，没有GC就不能保证应用程序的正常进行。而经常造成STW的GC又跟不上实际的需求，所以才会不断地尝试对GC进行优化。 早期垃圾回收1、在早期的C&#x2F;C++时代，垃圾回收基本上是手工进行的。开发人员可以使用 new关键字进行内存申请，并使用delete关键字进行内存释放，这种方式可以灵活控制内存释放的时间，但是会给开发人员带来频繁申请和释放内存的管理负担。倘若有一处内存区间由于程序员编码的问题忘记被回收，那么就会产生内存泄漏，垃圾对象永远无法被清除，随着系统运行时间的不断增长，垃圾对象所耗内存可能持续上升，直到出现内存溢出并造成应用程序崩溃。 2、现在，除了Java以外，C#、Python、 Ruby等语言都使用了自动垃圾回收的思想，也是未来发展趋势。可以说，这种自动化的内存分配和垃圾回收的方式己经成为现代开发语言必备的标准。 Java垃圾回收机制1、自动内存管理，无需开发人员手动参与内存的分配与回收，这样降低内存泄漏和内存溢出的风险 没有垃圾回收器，java也会和cpp一样，各种悬垂指针，野指针，泄露问题让你头疼不已。 2、自动内存管理机制，将程序员从繁重的内存管理中释放出来，可以更专心地专注于业务开发 担忧 1、对于Java开发人员而言，自动内存管理就像是一个黑匣子，如果过度依赖于 “自动”，那么这将会是一场灾难，最严重的就会弱化Java开发人员在程序出现内存溢出时定位问题和解决问题的能力。 2、此时，了 解JVM的自动内存分配和内存回收原理就显得非常重要，只有在真 正了解JVM是如何管理内存后，我们才能够在遇见OutOfMemoryError时， 快速地根据错误异常日志定位问题和解决问题。 3、当需要排查各种内存溢出、内存泄漏问题时，当垃圾收集成为系统达到更高 并发量的瓶颈时，我们就必须对这些“自动化”的技术实施必要的监控和调节。 垃圾回收器可以对年轻代回收，也可以对老年代回收，甚至是全堆和方法区的回收。 其中Java堆是垃圾收集器的工作重点 从次数上讲： 频繁收集：Young区 较少收集：old区 基本不动：Perm区（元空间） 垃圾回收算法（一）1、标记阶段：识别哪些是垃圾 引用计数算法 可达性分析算法 2、清除阶段：清除垃圾 标记-清除算法 复制算法 标记-压缩算法 标记阶段：引用计数算法（没有使用）垃圾标记阶段：对象存活判断 在堆里存放着几乎所有的Java对象实例，在GC执行垃圾回收之前，首先需要区分出内存中哪些是存活对象，哪些是已经死亡的对象。只有被标记为己经死亡的对象，GC才会在执行垃圾回收时，释放掉其所占用的内存空间，因此这个过程我们可以称为垃圾标记阶段。 那么在JVM中究竟是如何标记一个死亡对象呢？简单来说，当一个对象已经不再被任何的存活对象继续引用时，就可以宣判为已经死亡。 判断对象存活一般有两种方式：引用计数算法和可达性分析算法 1、引用计数算法：对每个对象保存一个整型的引用计数器（和年龄计数器不同），用于记录对象被引用的情况 对于一个对象A，只要有任何一个对象引用了A，则A的引用计数器加1，当引用失效时，引用计数器减1，只要对象A的引用计数器为0，就说明是垃圾，可以进行回收 2、优点：实现简单、垃圾对象便于辨识、判定效率高、回收没有延迟性 3、缺点： 需要单独的字段存储计数器，增加了存储空间的开销 每次赋值都需要更新计数器，增加了时间开销 无法处理循环引用的情况，内存泄露问题（致命缺陷，导致Java的垃圾回收器没有使用这个算法） 4、Java没有使用引用计数算法 5、Python使用引用计数算法，如何解决循环引用？ 手动解除 ：在合适的时机，解除引用关系 使用弱引用weakref，weakref是Python提供的标准库，旨在解决循环引用 标记阶段：可达性分析算法1、相对于引用计数算法而言，可达性分析算法不仅同样具备实现简单和执行高效等特点，更重要的是该算法可以有效地解决在引用计数算法中循环引用的问题，防止内存泄漏的发生。 2、相较于引用计数算法，这里的可达性分析就是Java、C#选择的。这种类型的垃圾收集通常也叫作追踪性垃圾收集（Tracing GarbageCollection）。 3、”GC Roots”根集合：一组必须活跃的引用 4、基本思路： ➢可达性分析算法是以根对象集合(GCRoots）为起始点，按照从上至下的方式搜索被根对象集合所连接的目标对象是否可达。 ➢使用可达性分析算法后，内存中的存活对象都会被根对象集合直接或间接连接着，搜索所走过的路径称为引用链（Reference Chain） ➢如果目标对象没有任何引用链相连，则是不可达的，就意味着该对象己经死亡，可以标记为垃圾对象。 ➢在可达性分析算法中，只有能够被根对象集合直接或者间接连接的对象才是存活对象。 GC Roots在Java语言中，GC Roots包括以下几类元素： 1、虚拟机栈中引用的对象 比如：各个线程被调用的方法中使用到的参数、局部变量等。 2、本地方法栈内JNI（通常说的本地方法）引用的对象 3、方法区中类静态属性引用的对象 比如：Java类的引用类型静态变量 4、方法区中常量引用的对象 比如：字符串常量池（string Table） 里的引用 5、所有被同步锁synchronized持有的对象 6、Java虚拟机内部的引用 基本数据类型对应的Class对象，一些常驻的异常对象（如： NullPointerException、OutOfMemoryError） ，系统类加载器。 7、反映java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等 除了这些固定的GCRoots集合以外，根据用户所选用的垃圾收集器以及当 前回收的内存区域不同，还可以有其他对象“临时性”地加入，共同构成完整GC Roots集合。比如：分代收集和局部回收（Partial GC）。 如果只针对Java堆中的某一块区域进行垃圾回收（比如：典型的只针 对新生代），必须考虑到内存区域是虚拟机自己的实现细节，更不是孤立封闭的，这个区域的对象完全有可能被其他区域的对象所引用，这时候就需要一并将关联的区域对象也加入GC Roots集合中去考虑，才能保证可达性分析的准确性。 小技巧：由于Root采用栈方式存放变量和指针，所以如果一个指针，它保存了堆内存里面的对象，但是自己又不存放在堆内存里面，那它就是一个Root 注意 1、如果要使用可达性分析算法来判断内存是否可回收，那么分析工作必须在一个能保障一致性的快照中进行。这点不满足的话分析结果的准确性就无法保证。 2、这点也是导致GC进行时必须“StopTheWorld&quot;的一个重要原因。 即使是号称（几乎）不会发生停顿的CMS收集器中，枚举根节点时也是必须要停顿的。 对象的finalization机制（复活） 确定是一个死亡对象，在销毁之前调用finalization方法进行自定义处理逻辑 1、Java语言提供了对象终止（finalization）机制来允许开发人员提供对象被销毁之前的自定义处理逻辑。 2、垃圾回收此对象之前，总会先调用这个对象的finalize（）方法。 3、finalize（）方法允许在子类中被重写，用于在对象被回收时进行资源释放。 通常在这个方法中进行一些资源释放和清理的工作，比如关闭文件、套接字和数据库连接等。 4、应该交给垃圾回收机制调用，永远不要主动调用某个对象的finalize （）方法，原因： 在finalize（） 时可能会导致对象复活。 finalize（）方法的执行时间是没有保障的，它完全由GC线程决定，极端情况下，若不发生GC，则finalize（） 方法将没有执行机会。 一个糟糕的finalize （）会严重影响GC的性能。 对象的三种状态1、由于finalize （）方法的存在，虚拟机中的对象一般处于三种可能的状态： 可触及的：从根节点开始，可以到达这个对象。 可复活的：对象的所有引用都被释放，但是对象有可能在finalize（）中复活 不可触及的：对象的finalize（）被调用，并且没有复活，那么就会进入不可触及状态。不可触及的对象不可能被复活，因为finalize（） 只会被调用一次。 判断对象回收的过程1、判定一个对象objA是否可回收，至少要经历两次标记过程： 可达性分析：如果对象objA到GC Roots没有引用链，则进行第一次标记 进行筛选，判断此对象是否有必要执行finalize（）方法 如果对 象objA没有重写finalize（）方法，或者finalize （）方法已经被虚拟机调用过，则虚拟机视为“没有必要执行”，objA被判定为不可触及的 如果对象objA重写了finalize（）方法，且还未执行过，那么objA会被插入到F-Queue队列中，由一个虚拟机自动创建的、低优先级的Finalizer线程触发其finalize（）方法执行。 finalize（）方法是对象逃脱死亡的最后机会，稍后GC会对F-Queue队列中的对象进行第二次标记 如果objA在finalize（）方法中与引用链上的任何一个对象建立了联系，那么在第二次标记时，objA会被移出“即将回收”集合。 之后对象会再次出现没有引用存在的情况。在这个情况下，finalize方法不会被再次调用，对象会直接变成不可触及的状态，也就是说，一个对象的finalize方法只会被调用一次。 2、两次标记： 第一次标记：可达性分析，没有引用链，进行标记 第二次标记：Finalizer线程执行finalize()方法，进行标记，如果这个对象被救活了就被移除回收集合 3、进入不可触及状态的原因： 对象没有复活 对象复活了一次，再次进入可触及状态，直接进入不可触及状态 MAT与JProfiler的GC Roots溯源MAT是Memory Analyzer的简称，它是一款功能强大的Java堆内存分析器，用于查找内存泄漏以及查看内存消耗情况。 垃圾回收算法（二）当成功区分出内存中存活对象和死亡对象后，GC接下来的任务就是执行垃圾回收，释放掉无用对象所占用的内存空间，以便有足够的可用内存空间为新对象分配内存. 目前在JVM中比较常见的三种垃圾收集算法是 标记一清除算法（ Mark一Sweep） 复制算法（Copying） 标记一压缩算法（Mark一Compact） 清除阶段：标记-清除算法1、标记清除（Mark-Sweep）算法：非常基础和常见的垃圾收集算法 2、执行过程 当堆中的有效内存空间（available memory） 被耗尽的时候，就会停止整个程序（也被称为stop the world），然后进行两项工作，第一项则是标记，第二项则是清除。 标记：Collectors从引用根节点开始遍历，标记所有被引用的对象（可达对象），一般是在对象头中记录为可达对象 清除：Collectors对堆内存从头到尾进行遍历，如果发现某个对象不是可达对象，就回收 3、缺点： 效率不算高 进行GC的时候需要停止整个程序，用户体验差 这种方式整理出来的内存不连续，产生内存碎片；需要维护一个空闲列表（对象实例化为对象分配内存如果内存不规整就需要空闲列表） 4、何为清除？ 不是置空，而是把需要清除的对象地址保存在空闲的地址列表里，需要使用就直接覆盖 清除阶段：复制算法 为了解决标记-清除算法效率低的缺陷，发明了复制算法 1、核心思想： 将活着的内存空间分为两块，每次只使用其中一块，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象，交换两个内存的角色，最后完成垃圾回收。 年轻代的幸存者区就是使用这种方式 使用指针碰撞的方式存放对象 2、优点： 实现简单，运行高效 空间连续，避免碎片问题 3、缺点 需要两倍的空间 对于G1这种拆分成为大量region的GC，复制而不是移动就意味着GC需要维护region之间对象引用关系，内存占用也不小 4、如果系统中的垃圾对象很多，复制算法不会很理想,复制算法需要复制的存活对象数量并不会太大，或者说非常低才行。 应用场景coping算法一般是使用在新生代中，因为新生代中的对象一般都是朝生夕死的，存活对象的数量并不多，这样使用coping算法进行拷贝时效率比较高。 清除阶段：标记-压缩算法 复制算法的高效性是建立在存活对象少、垃圾对象多的前提下，这种情况在新生代中常常发生；但是在老年代更常见的情况是大部分对象都是存活对象，使用复制算法的成本很高 标记-清除算法的确可以使用在老年代，但是该算法执行效率低，内存回收后碎片化严重，所以需要进行优化改进 在许多现代的垃圾收集器中，人们都使用了标记一压缩算法或其改进版本 1、执行过程： 标记：和标记-清除算法一样，从根节点开始标记所有的被引用对象 压缩：将所有存活对象压缩到内存的一端，按顺序排放 清除边界外的空间 2、标记一压缩算法的最终效果等同于标记一清除算法执行完成后，再进行一次内存碎片整理，因此，也可以把它称为标记-清除-压缩（Mark-Sweep-Compact）算法 3、二者的本质差异在于标记-清除算法是一种非移动式的回收算法，标记-压缩是移动式的，是否移动回收后的存活对象是一项优缺点并存的风险决策。 4、可以看到，标记的存活对象将会被整理，按照内存地址依次排列，而未被标记的内存会被清理掉，当我们需要给新对象分配内存时，JVM只需要持有一个内存的起始地址即可，这比维护一个空闲列表显然少了许多开销。 5、优点： 消除了标记-清除算法当中，内存区域分散的缺点，我们需要给新对象分配内存时，JVM只需要持有一个内存的起始地址即可 消除了复制算法当中，内存减半的高额代价 6、缺点： 效率低于复制算法 移动对象的同时如果对象被其他对象引用，需要调整引用的地址 移动过程中需要暂停用户应用程序，即STW 指针碰撞如果内存空间以规整和有序的方式分布，即已用和未用的内存都各自一边，彼此之间维系着一个记录下一次分配起始点的标记指针，当为新对象分配内存时，只需要通过修改指针的偏移量将新对象分配在第一个空闲内存位置上，这种分配方式就叫做指针碰撞（Bump the Pointer） 对比三种算法 1、效率上，复制算法最高，但是浪费了太多内存 2、标记-整理算法相对来说更平滑一些，但是效率上不尽如人意，它比复制算法多了一个标记的阶段，比标记-清除多了一个整理内存的阶段。 执行过程比较 1、标记-清除算法 遍历标记可达对象 遍历清除没有被标记的对象 2、复制算法 将活着的内存空间分为两块，每次只使用一块，将可达对象复制到另一块 3、标记-压缩算法 遍历标记可达对象 将可达对象进行压缩 清除边界外的空间（指针碰撞） 分代收集算法 没有最好的算法,只有更合适的算法 前面所有这些算法中，并没有一种算法可以完全替代其他算法，它们都具有自己独特的优势和特点。分代收集算法应运而生。 1、不同的对象的生命周期是不一样的，因此不同生命周期的对象可以采取不同的收集方式，以便提高回收效率，一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点使用不同的回收算法，以提高垃圾回收的效率。 2、目前几乎所有的GC都是采用分代收集（Generational Collecting） 算法执行垃圾回收的。 在HotSpot中，基于分代的概念，GC所使用的内存回收算法必须结合年轻代和老年代各自的特点 1、年轻代（Young Gen） 年轻代特点：区域相对老年代较小，对象生命周期短、存活率低，回收频繁。 这种情况复制算法的回收整理，速度是最快的。复制算法的效率只和当前存活对象大小有关，因此很适用于年轻代的回收。而复制算法内存利用率不高的问题，通过hotspot中的两个survivor的设计得到缓解。 2、老年代（Tenured Gen） 老年代特点：区域较大，对象生命周期长、存活率高，回收不及年轻代频繁。 这种情况存在大量存活率高的对象，复制算法明显变得不合适。一般是由标记-清除或者是标记-清除与标记-整理的混合实现。 Mark阶段的开销与存活对象的数量成正比。 Sweep阶段的开销与所管理区域的大小成正相关。 Compact阶段的开销与存活对象的数据成正比。 1、以HotSpot中的CMS回收器为例，CMS是基于标记—清除算法实现的，对于对象的回收效率很高。 2、对于碎片问题，CMS采用基于标记—压缩算法的Serial old回收器作为补偿措施：当内存回收不佳（碎片导致的Concurrent Mode Failure时），将采用Serial old执行Full GC以达到对老年代内存的整理。 分代的思想被现有的虚拟机广泛使用，几乎所有的垃圾回收器都区分新生代和老年代 增量收集算法、分区算法增量收集算法 上述现有的算法在垃圾回收过程中，应用软件将处于一种stop the World的状态。在Stop the World状态下，应用程序所有的线程都会挂起，暂停一切正常的工作，等待垃圾回收的完成。如果垃圾回收时间过长，应用程序会被挂起很久，将严重影响用户体验或者系统的稳定性。为了解决这个问题，即对实时垃圾收集算法的研究直接导致了增量收集（Incremental Collecting） 算法的诞生。 1、基本思想 如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以让垃圾收集线程和应用程序线程交替执行。每次，垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成。 总的来说，增量收集算法的基础仍是传统的标记—清除和复制算法。 增量收集算法通过对线程间冲突的妥善处理，允许垃圾收集线程以分阶段的方式完成标记、清理或复制工作。 2、缺点 使用这种方式，由于在垃圾回收过程中，间断性地还执行了应用程序代码，所以能减少系统的停顿时间。但是，因为线程切换和上下文转换的消耗，会使得垃圾回收的总体成本上升，造成系统吞吐量的下降。 分区算法一般来说，在相同条件下，堆空间越大，一次GC时所需要的时间就越长，有关GC产生的停顿也越长。为了更好地控制GC产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标的停顿时间，每次合理地回收若干个小区间，而不是整个堆空间，从而减少一次GC所产生的停顿。 分代算法将按照对象的生命周期长短划分成两个部分，分区算法将整个堆空间划分成连续的不同小区间。 每一个小区间都独立使用，独立回收。这种算法的好处是可以控制一次回收多少个小区间。 垃圾回收相关概念System.gc()1、在默认情况下，通过System.gc()或者Runtime.getRuntime().gc()的调用，会显式触发Full GC，同时对老年代和新生代进行回收，尝试释放被丢弃对象占用的内存。 2、System.gc()调用附带一个免责声明：**无法保证对垃圾收集器的调用(无法保证马上触发GC)**。 3、JVM实现者可以通过system.gc（）调用来决定JVM的GC行为，而一般情况下，垃圾回收应该是自动进行的，无须手动触发，否则就太过于麻烦了。在一些特殊情况下，如我们正在编写一个性能基准，我们可以在运行之间调用System.gc（）。 内存溢出和内存泄露内存溢出1、由于GC一直在发展，所有一般情况下除非应用程序占用的内存增长速度非常快，造成垃圾回收已经跟不上内存消耗的速度，否则不太容易出现O0M的情况。 2、大多数情况下，GC会进行各种年龄段的垃圾回收，实在不行了就放大招，来一次独占式的Full GC操作，这时候会回收大量的内存，供应用程序继续使用。 3、javadoc中对OutOfMemoryError的解释是，没有空闲内存，并且垃圾收集器也无法提供更多内存。 没有空闲内存 Java虚拟机的堆内存设置不够 代码中创建了大量大对象，并且长时间不能被垃圾回收器收集（存在被引用） 垃圾回收后无法提供内存 在抛出OOM之前，通常垃圾收集器会被触发，尽其所能清理出空间 例如：在引用机制分析中，涉及到JVM会去尝试回收软引用指向的对象 在java.nio.BIts.reserveMemory()方法中，System.gc会被调用，清理空间 如果分配一个超大对象，超过了堆的最大值，JVM可以判断出垃圾收集不能解决这个问题，直接抛出OOM 谈谈对 OOM 的认识？如何排查 OOM 的问题？ 除了程序计数器，其他内存区域都有 OOM 的风险。 栈一般经常会发生 StackOverflowError，比如 32 位的 windows 系统单进程限制 2G 内存，无限创建线程就会发生栈的 OOM Java 8 常量池移到堆中，溢出会出 java.lang.OutOfMemoryError: Java heap space，设置最大元空间大小参数无效； 堆内存溢出，报错同上，这种比较好理解，GC 之后无法在堆中申请内存创建对象就会报错； 方法区 OOM，经常会遇到的是动态生成大量的类、jsp 等； 直接内存 OOM，涉及到 -XX:MaxDirectMemorySize 参数和 Unsafe 对象对内存的申请。 排查 OOM 的方法： 增加两个参数 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;&#x2F;tmp&#x2F;heapdump.hprof，当 OOM 发生时自动 dump 堆内存信息到指定目录； 同时 jstat 查看监控 JVM 的内存和 GC 情况，先观察问题大概出在什么区域； 使用 MAT 工具载入到 dump 文件，分析大对象的占用情况，比如 HashMap 做缓存未清理，时间长了就会内存溢出，可以把改为弱引用 。 内存泄露1、严格意义上，内存泄露：对象不会再被程序用到，但是GC又不能回收他们 2、实际情况很多时候一些不太好的实践（或疏忽）会导致对象的生命周期变得很长甚至导致0OM，也可以叫做宽泛意义上的“内存泄漏 将方法内使用的变量定义为成员变量 3、尽管内存泄漏并不会立刻引起程序崩溃，但是一旦发生内存泄漏，程序中的可用内存就会被逐步蚕食，直至耗尽所有内存，最终出现0utOfMemory异常，导致程序崩溃。 注意，这里的存储空间并不是指物理内存，而是指虚拟内存大小，这个虚拟内存大小取决于磁盘交换区设定的大小 4、例子： 单例模式 单例的生命周期和应用程序是一样长的，所以单例程序中，如果持有对外部对象的引用的话，那么这个外部对象是不能被回收的，则会导致内存泄漏的产生。 一些提供close的资源未关闭导致内存泄漏，比如：数据库连接，网络连接和io连接，必须手动close，否则是不能被回收的。 Stop The World（STW）1、Stop一the一World，简称STW，指的是GC事件发生过程中，会产生应用程序的停顿。停顿产生时整个应用程序线程都会被暂停，没有任何响应，有点像卡死的感觉，这个停顿称为STW。 可达性分析算法中枚举根节点（GC Roots）会导致所有Java执行线程停顿。 分析工作必须在一个能确保一致性的快照中进行 一致性指整个分析期间整个执行系统看起来像被冻结在某个时间点上 如果出现分析过程中对象引用关系还在不断变化，则分析结果的准确性无法保证 2、被STW中断的应用程序线程会在完成GC之后恢复，频繁中断会让用户感觉像是网速不快造成电影卡带一样， 所以我们需要减少STW的发生。 3、STW事件和采用哪款GC无关，所有的GC都有这个事件 4、哪怕是G1也不能完全避免Stop一the一world情况发生，只能说垃圾回收器越来越优秀，回收效率越来越高，尽可能地缩短了暂停时间。 5、STW是JVM在后台自动发起和自动完成的。在用户不可见的情况下，把用户正常的工作线程全部停掉。 6、开发中不要用System.gc()，会导致Stop一the一world的发生。 垃圾回收的并行与并发二者对比 并发，指的是多个事情，在同一时间段内同时发生了。 并行，指的是多个事情，在同一时间点上同时发生了。 并发的多个任务之间是互相抢占资源的。 并行的多个任务之间是不互相抢占资源的。 只有在多CPU或者一个CPU多核的情况中，才会发生并行。否则，看似同时发生的事情，其实都是并发执行的。 垃圾回收的并发与并行1、并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态。 如：ParNew、 Parallel Scavenge、 Parallel old； 2、串行（Serial） 相较于并行的概念，单线程执行。 如果内存不够，则程序暂停，启动JVM垃圾回收器进行垃圾回收。回收完，再启动程序的线程。 3、并发（Concurrent） ：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），垃圾回收线程在执行时不会停顿用户程序的运行。 用户程序在继续运行，而垃圾收集程序线程运行于另一个CPU上； 如： CMS、G1 安全点与安全区域安全点(Safepoint)1、程序执行时并非在所有地方都能停顿下来开始GC，只有在特定的位置才能停顿下来开始GC，这些位置称为“安全点（Safepoint） ” 2、Safe Point的选择很重要，如果太少可能导致GC等待的时间太长，如果太频繁可能导致运行时的性能问题。大部分指令的执行时间都非常短暂，通常会根据“是否具有让程序长时间执行的特征”为标准。 比如：选择些执行时间较长的指令作为Safe Point， 如方法调用、循环跳转和异常跳转等。 如何在GC发生时，检查所有线程都跑到最近的安全点停顿下来呢？ 1、抢先式中断： （目前没有虚拟机采用了） 首先中断所有线程。如果还有线程不在安全点，就恢复线程，让线程跑到安全点。 2、主动式中断： 设置一个中断标志，各个线程运行到Safe Point的时候主动轮询这个标志，如果中断标志为真，则将自己进行中断挂起。 安全区域(Safe Region)1、Safepoint机制保证了程序执行时，在不太长的时间内就会遇到可进入GC的Safepoint 。但是，程序“不执行”的时候呢？例如线程处于Sleep 状态或Blocked状态，这时候线程无法响应JVM的中断请求，“走” 到安全点去中断挂起，JVM也不太可能等待线程被唤醒。对于这种情况，就需要安全区域（Safe Region）来解决。 2、安全区域是指在一段代码片段中，对象的引用关系不会发生变化，在这个区域中的任何位置开始GC都是安全的。我们也可以把Safe Region 看做是被扩展了的Safepoint。 实际执行时: 1、当线程运行到Safe Region的代码时，首先标识已经进入了Safe Region，如果这段时间内发生GC，JVM会忽略标识为Safe Region状态 的线程； 2、当线程即将离开Safe Region时， 会检查JVM是否已经完成GC，如果完成了，则继续运行，否则线程必须等待直到收到可以安全离开SafeRegion的信号为止； 引用Reference子类中只有终结器引用是包内可见的，其他3种引用类型均为public，可以在应用程序中直接使用 强引用（StrongReference）：最传统的“引用”的定义，是指在程序代码之中普遍存在的引用赋值，即类似“0bject obj=new object()”这种引用关系。无论任何情况下，只要强引用关系还存在，垃圾收集器就永远不会回收掉被引用的对象。 软引用（SoftReference） ：在系统将要发生内存溢出之前，将会把这些对象列入回收范围之中进行第二次回收，如果这次回收后还没有足够的内存，才会抛出内存溢出异常。 弱引用（WeakReference） ：被弱引用关联的对象只能生存到下一次垃圾收集之前，当垃圾收集器工作时，无论内存空间是否足够，都会回收掉被弱引用关联的对象。 虚引用（PhantomReference） ：一个对象是否有虛引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来获得一个对象的实例。为一个对象设置虛引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知(回收跟踪)。 强引用：不回收1、最常见的引用类型（99%以上都是强引用），也就是我们最常见的普通对象引用，也是默认的引用类型。 2、当在Java语言中使用new操作符创建一个新的对象， 并将其赋值给一个变量的时候，这个变量就成为指向该对象的一个强引用。 3、只要强引用的对象是可触及的，垃圾收集器就永远不会回收掉被引用的对象。 4、对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为null，就是可以当做垃圾被收集了，当然具体回收时机还是要看垃圾收集策略。 5、软引用、 弱引用和虚引用的对象是软可触及、弱可触及和虛可触及的，在一定条件下，都是可以被回收的。所以，强引用是造成Java内存泄漏的主要原因之一。 例子 1、StringBuffer str = new StringBuffer (&quot;Hello,尚硅谷&quot;); 局部变量str指向StringBuffer实例所在堆空间，通过str可以操作该实例，那么str就是StringBuffer实例的强引用对应内存结构： 此时,如果再运行一个赋值语句:StringBuffer str1 = str; 对应内存结构: 本例中的两个引用，都是强引用，强引用具备以下特点： 强引用可以直接访问目标对象 强引用所指向的对象在任何时候都不会被系统回收，虚拟机宁愿抛出OOM异常，也不会回收强引用所指向对象 强引用可能导致内存泄漏 软引用：内存不足就回收1、软引用是用来描述一 些还有用，但非必需的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收（第一次回收：不可触及对象），如果这次回收还没有足够的内存，才会抛出内存溢出异常。 2、软引用通常用来实现内存敏感的缓存。比如：高速缓存就有用到软引用。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 3、垃圾回收器在某个时刻决定回收软可达的对象的时候，会清理软引用，并可选地把引用存放到一个引用队列（ Reference Queue）。 类似弱引用，只不过Java虚拟机会尽量让软引用的存活时间长一些，迫不得已才清理。 4、总结： 当内存足够: 不会回收软引|用的可达对象 当内存不够时: 会回收软引用的可达对象 5、在JDK 1. 2版之后提供了java.lang.ref.SoftReference类来实现软引用。 123Object obj = new object（）； //声明强引用SoftReference&lt;0bject&gt; sf = new SoftReference&lt;0bject&gt;（obj）；//创建软引用obj = null； //销毁强引用，这样就只有一个软引用了 6、创建软引用 123456//方式一SoftReference&lt;User&gt; userSoftRef = new SoftReference&lt;User&gt;(new User(1, &quot;songhk&quot;));//方式二User u1 = new User(1,&quot;songhk&quot;);SoftReference&lt;User&gt; userSoftRef = new SoftReference&lt;User&gt;(u1);u1 = null; 弱引用：发现即回收1、弱引用也是用来描述那些非必需对象，被弱引用关联的对象只能生存到下一次垃圾收集发生为止。在系统GC时，只要发现弱引用，不管系统堆空间使用是否充足，都会回收掉只被弱引用关联的对象。 2、由于垃圾回收器的线程通常优先级很低，因此，并不一 定能很快地发现持有弱引用的对象。在这种情况下，弱引用对象可以存在较长的时间。 3、弱引用和软引用一样，在构造弱引用时，也可以指定一个引用队列，当弱引用对象被回收时，就会加入指定的引用队列，通过这个队列可以跟踪对象的回收情况。 4、软引用、弱引用都非常适合来保存那些可有可无的缓存数据。 当系统内存不足时，这些缓存数据会被回收，不会导致内存溢出。 当内存资源充足时，这些缓存数据又可以存在相当长的时间，从而起到加速系统的作用。 在JDK1.2版之后提后了java.lang.ref.WeakReference类来实现弱引用 123Object obj = new object（）； //声明强引用WeakReference&lt;0bject&gt; sf = new WeakReference&lt;0bject&gt;（obj）；obj = null； //销毁强引用 弱引用对象与软引用对象区别： 软：当GC在进行回收时，需要通过算法检查是否回收软引用对象 弱：GC总是进行回收 你开发中使用过WeakHashMap吗？ 通过查看WeakHashMap源码,可以看到其内部类Entry使用的就是弱引用 虚引用：对象回收跟踪1、虚引用(Phantom Reference),也称为“幽灵引用”或者“幻影引用”，是所有引用类型中最弱的一个。 2、一个对象是否有虚引用的存在，完全不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它和没有引用几乎是一样的，随时都可能被垃圾回收器回收。 3、它不能单独使用，也无法通过虚引用来获取被引用的对象。当试图通过虚引用的get（）方法取得对象时，总是null。 4、为一个对象设置虚引用关联的唯一目的在于跟踪垃圾回收过程。比如：能在这个对象被收集器回收时收到一个系统通知。 5、虚引用必须和引用队列一起使用。虚引用在创建时必须提供一个引用队列作为参数。当垃圾回收器准备回收一个对象时，如果发现它还有虛引用，就会在回收对象后，将这个虚引用加入引用队列，以通知应用程序对象的回收情况。 6、由于虚引用可以跟踪对象的回收时间，因此，也可以将一些资源释放操作放置在虛引用中执行和记录。 在JDK 1. 2版之后提供了PhantomReference类来实现虚引用。 1234object obj = new object();ReferenceQueuephantomQueue = new ReferenceQueue( ) ;PhantomReference&lt;object&gt; pf = new PhantomReference&lt;object&gt;(obj, phantomQueue); obj = null; 终结器引用 它用以实现对象的finalize（）方法，也可以称为终结器引用。 无需手动编码， 其内部配合引用队列使用。 在GC时， 终结器引用入队。由Finali zer线程通过终结器引用找到被引用对象并调用它的finalize（）方法，第二次GC时才能回收被引用对象。 垃圾回收器GC分类与性能指标GC分类1、按照线程数分： 串行垃圾回收器：同一时间段只允许有一个cpu用于执行垃圾回收操作，此时工作线程被暂停，直到垃圾收集工作结束 在单cpu的场合，串行垃圾回收器的性能表现优于并行回收器和并发回收器 默认被应用在客户端的Client模式下的JVM 并行垃圾回收器：运用多个cpu同时执行垃圾回收，因此提升了应用的吞吐量 独占式，使用STW机制 2、按照工作模式分： 并发式垃圾回收器：并发式垃圾回收器与应用程序线程交替工作，以尽可能减少应用程序的停顿时间 独占式垃圾回收器：一旦运行就停止所有的用户线程 3、按碎片处理方式分： 压缩式垃圾回收器：会在回收完成后，对存活对象进行压缩整理，消除回收后的碎片 再分配对象空间使用：指针碰撞 非压缩式垃圾回收器：不进行压缩 在分配对象空间使用：空闲列表 4、按照工作的内存空间分： 年轻代垃圾回收器 老年代垃圾回收器 性能指标1、吞吐量：运行用户代码的时间占总运行时间的比例 （总运行时间：程序的运行时间 + 内存回收的时间） 2、垃圾收集开销：吞吐量的补数，垃圾收集所用时间与总运行时间的比例 3、暂停时间：执行垃圾收集时，程序的工作线程被暂停的时间 4、收集频率：相对于应用程序的执行，收集操作发生的频率 5、内存占用： Java堆区所占的内存大小 6、快速：一个对象从诞生到被回收所经历的时间 吞吐量、暂停时间、内存占用三者共同构成一个“不可能三角”，三者总体的表现会随着技术进步而越来越好，一款优秀的收集器通常最多同时满足其中的两项。 这三项里，暂停时间的重要性日益凸显，因为随着硬件发展，内存占用多些越来越能容忍，硬件性能的提升也有助于降低收集器运行时对应用程序的影响，即提高了吞吐量，而内存的扩大，对延迟反而带来负面效果。 简单来说，主要抓住两点： 吞吐量 暂停时间 吞吐量（throughput）1、吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值 吞吐量 = 运行用户代码时间 /（运行用户代码时间+垃圾收集时间） 比如：虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99% 2、这种情况下，应用程序能容忍较高的暂停时间，因此，高吞吐量的应用程序有更长的时间基准，快速响应是不必考虑的。 暂停时间（pause time）1、“暂停时间”是指一个时间段内应用程序线程暂停，让GC线程执行的状态 例如，GC期间100毫秒的暂停时间意味着在这100毫秒期间内没有应用程序线程是活动的。. 对比吞吐量优先，意味着在单位时间内，STW的总时间最短： 0.2 + 0.2 &#x3D; 0.4 暂停时间优先，意味着尽可能让单次STW的时间最短： 0.1 + 0.1 + 0.1 + 0.1+0.1&#x3D;0.5 1、高吞吐量较好因为这会让应用程序的最终用户感觉只有应用程序线程在做“生产性”工作。直觉上，吞吐量越高程序运行越快。 2、低暂停时间（低延迟）较好因为从最终用户的角度来看不管是GC还是其他原因导致一个应用被挂起始终是不好的。这取决于应用程序的类型，有时候甚至短暂的200毫秒暂停都可能打断终端用户体验。因此，具有低的较大暂停时间是非常重要的，特别是对于一一个交互式应用程序。 3、不幸的是”高吞吐量”和”低暂停时间”是一对相互竞争的目标（矛盾） 因为如果选择以吞吐量优先，那么必然需要降低内存回收的执行频率，但是这样会导致GC需要更长的暂停时间来执行内存回收。 相反的，如果选择以低延迟优先为原则，那么为了降低每次执行内存回收时的暂停时间，也只能频繁地执行内存回收，但这又引起了年轻代内存的缩诚和导致程序吞吐量的下降。 4、在设计（或使用） GC算法时，我们必须确定我们的目标： 一个GC算法只可能针对两个目标之一（即只专注于较大吞吐量或最小暂停时间），或尝试找到一个二者的折中。 5、现在标准：在最大吞吐量优先的情况下，降低停顿时间 不同的垃圾回收器概述垃圾收集器发展史有了虚拟机，就一定需要收集垃圾的机制，这就是Garbage Collection， 对应的产品我们称为Garbage Collector. 1999年随 JDK1.3.1一 起来的是串行方式的Serial GC，它是第一款GC，ParNew垃圾收集器是Serial收集器的多线程版本 2002年2月26日，Parallel GC和Concurrent Mark Sweep GC跟随 JDK1.4.2一起发布 Parallel GC在JDK6之后成为HotSpot默认GC 2012年，在JDK1.7u4版本中，G1可用。 2017年，JDK9中G1变成默认的垃圾收集器，以替代CMS。 2018年3月，JDK10中G1垃圾回收器的并行完整垃圾回收，实现并行性来改善最坏情况下的延迟。 ———–分水岭———— 2018年9月，JDK11发布。引入Epsilon垃圾回收器，又被称为”No一Op （无操作） “回收器。同时，引入ZGC：可伸缩的低延迟垃圾回收器（Experimental）。 2019年3月，JDK12发布。 增强G1，自动返回未用堆内存给操作系统。同时，引入Shenandoah GC：低停顿时间的GC （Experimental）。 2019年9月，JDK13发布。增强ZGC，自动返回未用堆内存给操作系统。 2020年3月，JDK14发布。删除CMS垃圾回收器。扩展ZGC在macOS和Windows.上的应用 7种经典垃圾回收器串行回收器：Serial、Serial Old 并行回收器：ParNew、Paeallel Scavenge、Parallel Old 并发垃圾回收器：CMS、G1 垃圾回收器和垃圾分代的关系 新生代收集器： Serial、 ParNew、Parallel Scavenge 老年代收集器： Serial Old、 Parallel Old、 CMS 整堆收集器（新生代+老年代）： G1 垃圾回收器的组合关系1、两个收集器间有连线，表明它们可以搭配使用： Serial、Serial Old Serial、CMS ParNew、Serial Old ParNew、CMS Parallel Scavenge、Serial Old Parallel Scavenge、Parallel Old G1 2、其中Serial 0ld作为CMS 出现”Concurrent Mode Failure”失败的后 备预案。 3、（红色虚线）由于维护和兼容性测试的成本，在JDK 8时将Serial+CMS、 ParNew+Serial Old这两个组合声明为废弃 ，并在JDK 9中完全取消了这些组合的支持，即：移除。 4、（绿色虚线）JDK 14中：弃用Parallel Scavenge和SerialOld GC组合 5、（青色虚线）JDK 14中：删除CMS垃圾回收器 为什么要有很多收集器个不够吗？ 因为Java的使用场景很多， 移动端，服务器等；所以就需要针对不同的场景，提供不同的垃圾收集器，提高垃圾收集的性能。 如何查看默认的垃圾回收器 -XX：+PrintCommandLineFlags： 查看命令行相关参数（包含使用的垃圾收集器） 使用命令行指令： jinfo -flag 相关垃圾回收器参数 进程ID JDK8：默认Parallel GC + Parallel Old GC JDK9：默认G1 Serial回收器：串行回收1、Jdk1.3之前回收新生代唯一的选择 2、Serial收集器是HotSpot中client模式下的默认新生代垃圾回收器 3、年轻代垃圾回收器：Serial回收器，采用复制算法、串行回收、STW机制的方式执行内存回收 4、老年代垃圾回收器：Serial Old回收器，采用标记-压缩算法、串行回收、STW机制 Client模式下默认的老年代垃圾回收器 Server模式下主要有两个用途： 与新生代的Parallel Scavenge配合使用 作为CMS的后备方案 这个收集器是一个单线程的收集器，“单线程”的意义： 说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作 它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束（Stop The World ）。 5、优势：简单高效（与其他收集器的单线程比，节省切换cpu的时间），运行在Client模式下比较适合 6、使用+XX:+UseSerialGC指定年轻代和老年代使用串行收集器（年轻：Serial，老年：Serial Old） 总结 这种垃圾收集器了解即可，现在已经不用串行的了，而且在限定单核cpu才可以用，现在都不是单核的了。 对于交互较强的应用而言，这种垃圾收集器是不能接受的，一般在Javaweb应用程序中是不会采用串行垃圾收集器的。 ParNew回收器：并行回收1、如果说Serial GC是年轻代中的单线程垃圾收集器，那么ParNew收集器则是Serial收集器的多线程版本。 Par是Parallel的缩写，New： 只能处理新生代 2、ParNew收集器除了采用并行回收的方式执行内存回收外，两款垃圾收集器之间几乎没有任何区别。 3、ParNew收集器在年轻代中同样也是采用复制算法、”Stop一 the一World”机制。 4、ParNew是很多JVM运行在Server模式下新生代的默认垃圾收集器 对于新生代，回收次数频繁，使用并行方式高效。 对于老年代，回收次数少，使用串行方式节省资源。（CPU并行需要切换线程，串行可以省去切换线程的资源） ParNew收集器是基于并行回收，那么是否可以断定ParNew收集器的回收效率在任何场景下都会比Serial收集器更高效？ ParNew 收集器运行在多CPU的环境下，由于可以充分利用多CPU、 多核心等物理硬件资源优势，可以更快速地完成垃圾收集，提升程序的吞吐量。 但是在单个CPU的环境下，ParNew收集器不比Serial收集器更高效。虽然Serial收集器是基于串行回收，但是由于CPU不需要频繁地做任务切换，因此可以有效避免多线程交互过程中产生的一些额外开销。 5、组合方式 Serial old + ParNew（JDK8移除） CMS + ParNew（JDK14移除） 6、使用”XX:+UseParNewGC手动指定使用ParNew收集器执行内存回收任务，它表示年轻代使用并行收集器，不影响老年代 -XX:ParallelGCThreads 限制线程数量，默认开启和CPU数据相同的线程数。 Parallel回收器：吞吐量优先1、HotSpot的年轻代中除了拥有ParNew收集器是基于并行回收的以外， Parallel Scavenge收集器同样也采用了复制算法、并行回收和”Stop the World”机制。 那么Parallel收集器的出现是否多此一举？ 区别1：Parallel Scavenge收集器的目标是达到一个可控制的吞吐量（Throughput），它也被称为吞吐量优先的垃圾收集器。 区别2：自适应调节策略 2、高吞吐量则可以高效率地利用CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。因此，常见在服务器环境中使用。例如，那些执行批量处理、订单处理、工资支付、科学计算的应用程序。 3、Parallel收集器在JDK1.6时提供了用于执行老年代垃圾收集的 Parallel Old收集器，用来代替老年代的Serial Old收集器（串行会拖累性能）。 工作原理 4、Parallel 0ld收集器采用了标记一压缩算法，但同样也是基于并行回收和”Stop一the一World”机制。 在程序吞吐量优先的应用场景中，Parallel 收集器和Parallel 0ld收集器的组合，在Server模式下的内存回收性能很不错。 在Java8中，默认是此垃圾收集器 参数配置 -XX:+UseParallelGC：手动指定 年轻代使用Parallel并行收集器执行内存回收任务。 -XX:+UseParallelOldGc：手动指定老年代都是使用并行回收收集器。 分别适用于新生代和老年代，默认jdk8是开启的。 上面两个参数，默认开启一个，另一个也会被开启（互相激活） -XX:ParallelGCThreads：设置年轻代并行收集器的线程数。一般地，最好与CPU数量相等，以避免过多的线程数影响垃圾收集性能。 在默认情况下，当CPU数量小于8个， ParallelGCThreads 的值等于CPU数量 当CPU数量大于8个， ParallelGCThreads的值等于3+[5*CPU_ Count]&#x2F;8] -XX:MaxGCPauseMillis：设置垃圾收集器最大停顿时间（即STW的时间），单位是毫秒 为了尽可能地把停顿时间控制在MaxGCPauseMills以内，收集器在工作时会调整Java堆大小或者其他一些参数 对于用户来讲，停顿时间越短体验越好。但是在服务器端，我们注重高并发，整体的吞吐量，所以服务器端适合Parallel，进行控制 -XX:GCTimeRatio：垃圾收集时间占总时间的比例（&#x3D; 1 &#x2F; （N + 1））用于衡量吞吐量的大小。 取值范围（0， 100），默认值99，也就是垃圾回收时间不超过1% 与前一个-XX:MaxGCPauseMillis参数有一定矛盾性，暂停时间越长，Radio参数就容易超过设定的比例。 -XX:+UseAdaptiveSizePolicy：设置Parallel Scavenge收集器具有自适应调节策略 在这种模式下，年轻代的大小、Eden和Survivor的比例、晋升老年代的对象年龄等参数会被自动调整，已达到在堆大小、吞吐量和停顿时间之间的平衡点。 在手动调优比较困难的场合，可以直接使用这种自适应的方式，仅指定虚拟机的最大堆、目标的吞吐量（GCTimeRatio）和停顿时间（MaxGCPauseMills），让虚拟机自己完成调优工作 CMS回收器：低延迟1、CMS（Concurrent - Mark - Sweep，并发-标记-清除）收集器：第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程同时工作 2、CMS收集器的关注点：低延迟 停顿时间越短（低延迟）就越适合与用户交互的程序，良好的响应速度能提升用户体验 目前很大一部分的Java应用集中在互联网站或者B&#x2F;S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。 3、CMS的垃圾 收集算法采用标记一清除算法，并且也会” stop一the一world” 4、CMS 作为老年代的收集器，新生代只能选择ParNew或者Serial收集器 5、在G1出现之前，CMS使用还是非常广泛的。一直到今天，仍然有很多系统使用CMS GC。 工作原理 整个过程分为4个主要阶段：初始标记阶段、并发标记阶段、重新标记阶段和并发清除阶段 1、初始标记（STW、时间短） 工作线程因为“Stop一the一World”机制而出现暂停，这个阶段的主要任务仅仅只是标记出GCRoots能直接关联到的对象。一旦标记完成之后就会恢复之前被暂停的所有应用线程，由于直接关联对象比较小，所以这里的速度非常快 2、并发标记（并发、时间长） 从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但是不需要停顿用户线程，可以与垃圾收集线程一起并发运行。 3、重新标记（STW、时间中等） 由于在并发标记阶段中，程序的工作线程会和垃圾收集线程同时运行或者交叉运行，因此为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间通常会比初始标记阶段稍长一些，但也远比并发标记阶段的时间短。 4、并发清除（并发） 此阶段清理删除掉标记阶段判断的已经死亡的对象，释放内存空间。由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的，会存在碎片问题 1、由于最耗费时间的并发标记与并发清除阶段都不需要暂停工作，所以整体的回收是低停顿的 2、由于在垃圾收集阶段用户线程没有中断，所以在CMS回收过程中，还应该确保应用程序用户线程有足够的内存可用。因此，CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，而是当堆内存使用率达到某一阈值时，便开始进行回收，以确保应用程序在CMS工作过程中依然有足够的空间支持应用程序运行。 要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure”失败，这时虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。 3、CMS收集器的垃圾收集算法采用的是标记一清除算法，这意味着每次执行完内存回收后不可避免地将会产生一些内存碎片。 那么CMS在为新对象分配内存空间时只能够选择空闲列表（Free List） 执行内存分配。 为什么不使用标记压缩算法呢？ 因为清除阶段是并发的，标记压缩需要进行整理内存（会改变对象地址），这样会影响用户线程 4、优点 并发收集 低延迟 5、弊端 内存碎片：碎片化严重，导致无法分配大对象，提前触发full gc 对CPU资源敏感：在并发阶段会因为占用一部分线程导致应用程序变慢，吞吐量降低 无法处理浮动垃圾：可能出现“Concurrent Mode Failure” 失败而导致另一次Full GC的产生。在并发标记阶段由于程序的工作线程和垃圾收集线程是同时运行或者交叉运行的，那么在并发标记阶段如果产生新的垃圾对象，CMS将 无法对这些垃圾对象进行标记，最终会导致这些新产生的垃圾对象没有被及时回收，从而只能在下一次执行GC时释放这些之前未被回收的内存空间。 小结如果你想要最小化地使用内存和并行开销，请选Serial GC；如果你想要最大化应用程序的吞吐量，请选Parallel GC；如果你想要最小化GC的中断或停顿时间，请选CMS GC。 G1回收器：区域化分代式 既然我们已经有了前面几个强大的GC，为什么还要发布Garbage First （G1）GC？ 原因就在于应用程序所应对的业务越来越庞大、复杂，用户越来越多，没有GC就不能保证应用程序正常进行，而经常造成STW的GC又跟不上实际的需求，所以才会不断地尝试对GC进行优化。G1 （Garbage一First） 垃圾回收器是在Java7 update4之后引入的一个新的垃圾回收器，是当今收集器技术发展的最前沿成果之一。 与此同时，为了适应现在不断扩大的内存和不断增加的处理器数量，进一步降低暂停时间（pause time） ，同时兼顾良好的吞吐量。 官方给G1设定的目标是在延迟可控的情况下获得尽可能高的吞吐量，所以才担当起“全功能收集器”的重任与期望 为什么名字叫做Garbage First （G1）呢？ 1、因为G1是一个并行回收器，它把堆内存分割为很多不相关的区域（Region）（物理上不连续的），使用不同的Region来表示Eden、幸存者0区，幸存者1区，老年代等。 2、G1 GC有计划地避免在整个Java 堆中进行全区域的垃圾收集。G1跟踪各个Region 里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。 3、由于这种方式的侧重点在于回收垃圾最大量的区间（Region），所以我们给G1一个名字：垃圾优先（Garbage First） 。 4、G1 （Garbage一First） 是一款面向服务端应用的垃圾收集器，主要针对配备多核CPU及大容量内存的机器，以极高概率满足GC停顿时间的同时，还兼具高吞吐量的性能特征。 5、在JDK1. 7版本正式启用，移除了Experimental的标识，是JDK 9以后的默认垃圾回收器，取代了CMS回收器以及Parallel + Parallel Old组合。被Oracle官方称为“全功能的垃圾收集器” 。 6、与此同时，CMS已经在JDK 9中被标记为废弃（deprecated） ，在jdk8中G1 GC还不是默认的垃圾回收器，需要使用-XX:+UseG1GC来启用。 优势和缺点与其他GC收集器相比，G1使用了全新的分区算法，其特点如下所示： 1、兼具并行与并发 并行性： G1在回收期间，可以有多个GC线程同时工作，有效利用多核计算能力，此时用户线程STW 并发性： G1拥有与应用程序交替执行的能力，部分工作可以和应用程序同时执行，因此，一般来说，不会在整个回收阶段发生完全阻塞应用程序的情况 2、分代收集 从分代上看，G1依然属于分代型垃圾回收器，它会区分年轻代和老年代，年轻代依然有Eden区和Survivor区。但从堆的结构，上看，它不要求整个Eden区、年轻代或者老年代都是连续的，也不再坚持固定大小和固定数量。 将堆空间分为若干个区域（Region） ，这些区域中包含了逻辑上的年轻代和老年代 和之前的各类回收器不同，它同时兼顾年轻代和老年代。对比其他回收器，或者工作在年轻代，或者工作在老年代； 3、空间整合（针对碎片化问题） CMS： “标记一清除”算法、内存碎片、若干次GC后进行一次碎片整理 G1：将内存划分为一个个的region， 内存的回收是以region作为基本单位的。Region之间是复制算法，但整体上实际可看作是标记一压缩（Mark一Compact）算法，两种算法都可以避免内存碎片。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。尤其是当Java堆非常大的时候，G1的优势更加明显。 4、可预测的停顿时间模型（即：软实时soft real一time） 这是G1相对于CMS的另一大优势，G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。 由于分区的原因，G1可以只选取部分区域进行内存回收，这样缩小了回收的范围，因此对于全局停顿情况的发生也能得到较好的控制。 G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。保证了G1 收集器在有限的时间内可以获取尽可能高的收集效率。 相比于CMS GC，G1未必能做到CMS在最好情况下的延时停顿，但是最差情况要好很多。 缺点 相较于CMS，G1还不具备全方位、压倒性优势。比如在用户程序运行过程中，G1无论是为了垃圾收集产生的内存占用（Footprint） 还是程序运行时的额外执行负载（overload） 都要比CMS要高。 从经验上来说，在小内存应用上CMS的表现大概率会优于G1，而G1在大内存应用，上则发挥其优势。平衡点在6一8GB之间。 参数设置-XX:+UseG1GC 手动指定使用G1收集器执行内存回收任务。 -XX:G1HeapRegionSize 设置每个Region的大小，值是2的幂，范围是1MB 到32MB之间，目标是根据最小的Java堆大小划分出约2048个区域。默认是堆内存的1&#x2F;2000。 -XX:MaxGCPauseMillis 设置期望达到的最大GC停顿时间指标（JVM会尽力实现，但不保证达到），默认值是200ms -XX:ParallelGCThread 设置sTw.工作线程数的值，最多设置为8 -XX:ConcGCThreads 设置并发标记的线程数。将n设置为并行垃圾回收线程数（ParallelGCThreads）的1&#x2F;4左右。 -XX:InitiatingHeapOccupancyPercent 设置触发并发GC周期的Java堆占用率阈值。超过此值，就触发GC。默认值是45。 常见操作步骤设计原则：简化JVM调优 第一步：开启G1垃圾收集器 第二步：设置堆的最大内存（-xmx、-xms） 第三步：设置最大停顿时间（-XX:MaxGCPauseMillis） G1提供三种垃圾回收模式：Young GC、Mixed GC、Full GC 适用场景1、服务端应用，具有大内存、多处理器的机器 2、需要低GC延迟，并具有大堆的应用程序提供解决方案 如：在堆大小约6GB或更大时，可预测的暂停时间可以低于0.5秒（ G1通过每次只清理一部分而不是全部的Region的增量式清理来保证每次GC停顿时间不会过长） 3、用来替换掉JDK1.5中的CMS收集器： 在下面的情况时，使用G1可能比CMS好： 超过50%的Java堆被活动数据占用； 对象分配频率或年代提升频率变化很大； GC停顿时间过长（长于0. 5至1秒）。 4、HotSpot垃圾收集器里，除了G1以外，其他的垃圾收集器使用内置的JVM线程执行 GC的多线程操作，而G1 GC可以采用应用线程承担后台运行的GC工作，即当JVM的GC线程处理速度慢时，系统会调用应用程序线程帮助加速垃圾回收过程。 Region使用G1收集器时，它将整个Java堆划分成约2048个大小相同的独立Region块，每个Region块大小根据堆空间的实际大小而定，整体被控制在1MB到32MB之间，且为2的N次幂，即1MB， 2MB， 4MB， 8MB， 1 6MB， 32MB。 可以通过-XX:G1HeapRegionSize设定。所有的Region大小相同，且在JVM生命周期内不会被改变。 虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region （不需要连续）的集合。通过Region的动态分配方式实现逻辑上的连续。 角色： E：Eden区 S：Survivor区 O：Old区 H：Humongous区，存储超过0.5个region的大对象 默认大对象被分配给Old区，但是如果这个对象短期存在，就会对垃圾收集器造成负面影响 如果一个H区装不下，就会寻找连续的H区存储 为了能找到连续的H区，有时候不得不启动Full GC G1的大多数行为都把H区作为老年代的一部分来看待 空白：未使用的内存空间 每一个分配的Region，都可以分成两个部分：已分配的和未被分配的。它们之间的界限被称为top。总体上来说，把一个对象分配到Region内，只需要简单增加top的值，这个做法实际上就是bump-the-pointer（指针碰撞），过程如下： Region可以说是G1回收器一次回收的最小单元，即每一次回收都是回收N个Region。这个N是多少，主要受到G1回收的效率和用户设置的软实时目标有关 每一次的回收，G1会选择可能回收最多垃圾的Region进行回收。与此同时，G1回收器会维护一个空间Region的链表。每次回收之后的Region都会被加入到这个链表中 每一次都只有一个Region处于被分配的状态中，被称为current region。在多线程的情况下，这会带来并发的问题。G1回收器采用和CMS一样的TLABs的手段。即为每一个线程分配一个Buffer，线程分配内存就在这个Buffer内分配。但是当线程耗尽了自己的Buffer之后，需要申请新的Buffer，这个时候依然会带来并发的问题，G1回收器采用的是CAS（Compate And Swap）操作 为线程分配Buffer的过程大概是： 记录top值； 准备分配； 比较记录的top值和现在的top值，如果一样，则执行分配，并且更新top的值；否则，重复1； 执行步骤1、初始标记（STW）：暂停其他线程，记录下gc roots直接引用的对象 2、并发标记：同CMS 3、最终标记（STW）：同CMS 4、筛选回收（STW）：首先对各个Region的回收价值和成本进行排序，根据用户期望的GC停顿STW时间制定回收计划，回收算法主要使用复制算法，将一个region中的存活对象复制到另外一个region中 G1垃圾收集分类 三个环节： 年轻代GC（Young GC） 老年代并发标记过程（Concurrent Marking） 混合回收（Mixed GC） 如果需要，单线程、独占式、高强度的Full GC还是会继续存在，针对GC的评估失败提供了一种失败保护机制，即强力回收 顺时针， young gc 一&gt; young gc + concurrent mark 一&gt; Mixed GC顺序，进行垃圾回收 1、应用程序分配内存，当年轻代的Eden区用尽时开始年轻代回收过程； G1的年轻代收集阶段是一个并行的独占式收集器。在年轻代回收期，G1 GC暂停所有应用程序线程，启动多线程执行年轻代回收。然后从年轻代区间移动存活对象到Survivor区间或者老年区间，也有可能是两个区间都会涉及。 2、当堆内存使用达到一定值（默认45%）时，开始老年代并发标记过程。 3、标记完成马上开始混合回收过程，对于一个混合回收期，G1 GC从老年区间移动存活对象到空闲区间，这些空闲区间也就成为了老年代的一部分。和年轻代不同，老年代的G1回收器和其他GC不同，G1的老年代回收器不需要整个老年代被回收，一次只需要扫描&#x2F;回收一小部分老年代的Region就可以了。同时，这个老年代Region是和年轻代一起被回收的。 回收过程一：年轻代GC JVM启动时，G1 先准备好Eden区，程序在运行过程中不断创建对象到Eden区，当Eden空间耗尽时，G1会启动一次年轻代垃圾回收过程。 年轻代垃圾回收只会回收Eden区和Survivor区。 YGC时，首先G1停止应用程序的执行（Stop一The一World），G1创建回收集（Collection Set），回收集是指需要被回收的内存分段的集合，年轻代回收过程的回收集包含年轻代Eden区和Survivor区所有的内存分段。 回收过程： 第一阶段，扫描根 根引用连同记忆集记录的外部引用作为扫描存活对象的入口 第二阶段，更新记忆集 处理dirty card queue中的card，更新RSet。 此阶段完成后，记忆集可以准确的反映老年代对所在的内存分段中对象的引用 第三阶段，处理记忆集 识别被老年代对象指向的Eden中的对象，这些被指向的Eden中的对象被认为是存活的对象 第四阶段，复制对象 遍历对象树 Eden区内存段中存活的对象会被复制到Survivor区中空的内存分段 Survivor区内存段中存活的对象如果年龄未达阈值，年龄会加1 达到阀值会被会被复制到Old区中空的内存分段 如果Survivor空间不够，Eden空间的部分数据会直接晋升到老年代空间 第五阶段，处理引用 处理Soft，Weak， Phantom， Final， JNI Weak等引用 最终Eden空间的数据为空，GC停止工作，而目标内存中的对象都是连续存储的，没有碎片，所以复制过程可以达到内存整理的效果，减少碎片。 回收过程二：并发标记过程 1、初始标记阶段：标记从根节点直接可达的对象，这个阶段是STW的，并且会触发一次年轻代GC 2、根区域扫描（Root Region Scanning） ： G1 GC 扫描Survivor区 直接可达的老年代区域对象，并标记被引用的对象。这一过程必 须在young GC之前完成。 3、并发标记（Concurrent Marking）： 在整个堆中进行并发标记（和应用程序并发执行），此过程可能被young GC中断。在并发标记阶段，若发现区域对象中的所有对象都是垃圾，那这个区域会被立即回收。同时，并发标记过程中，会计算每个区域的对象活性（区域中存活对象的比例）。 4、再次标记（Remark）： 由 于应用程序持续进行，需要修正上一次的标记结果。是STW的。G1中采用了比CMS更快的初始快照算法：snapshot一at一the一beginning （SATB）。 5、独占清理（cleanup，STW）：计算各个区域的存活对象和GC回收比例，并进行排序，识别可以混合回收的区域。为下阶段做铺垫。是STW的。 这个阶段并不会实际上去做垃圾的收集 并发清理阶段：识别并清理完全空闲的区域。 回收过程三：混合回收 当越来越多的对象晋升到老年代old region时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即Mixed GC， 该算法并不是一个Old GC，除了回收整个Young Region，还会回收一部分的Old Region。 这里需要注意：是一部分老年代， 而不是全部老年代。可以选择哪些OldRegion进行收集，从而可以对垃圾回收的耗时时间进行控制 Full GC G1的初衷就是要避免Full GC的出现。但是如果上述方式不能正常工作，G1会停止应用程序的执行（Stop一 The一World），使用单线程的内存回收算法进行垃圾回收，性能会非常差，应用程序停顿时间会很长。 要避免Full GC的发生，一旦发生需要进行调整。什么时候会发生Full GC呢？比如堆内存太小，当G1在复制存活对象的时候没有空的内存分段可用，则会回退到full gc， 这种情况可以通过增大内存解决。 导致G1Full GC的原因可能有两个： Evacuation的时候没有足够的to一 space来存放晋升的对象； 并发处理过程完成之前空间耗尽。 记忆集一个对象被不同区域引用的问题(分代引用问题) 一个Region不可能是孤立的，一个Region中的对象可能被其他任意Region中对象引用，判断对象存活时，是否需要扫描整个Java堆才能保证准确？ 在其他的分代收集器，也存在这样的问题（ 而G1更突出） 回收新生代也不得不同时扫描老年代？ 这样的话会降低MinorGC的效率； 解决方法： 无论G1还是其他分代收集器，JVM都是使用RememberedSet来避免全局扫描： 每个Region都有一个对应的Remembered Set； 每次Reference类型数据写操作时，都会产生一个Write Barrier暂时中断操作； . 然后检查将要写入的引用指向的对象是否和该Reference类型数据在不同的Region （其他收集器：检查老年代对象是否引用了新生代对象） ； 如果不同，通过CardTable把相关引用信息记录到引用指向对象的所在Region对应的Remembered Set中； 当进行垃圾收集时，在GC根节点的枚举范围加入Remembered Set；就可以保证不进行全局扫描，也不会有遗漏。 总结 怎么选择垃圾回收器 1、Java垃圾收集器的配置对于JVM优化来说是一个很重要的选择，选择合适的垃圾收集器可以让JVM的性能有一个很大的提升。 2、怎么选择垃圾收集器？ 优先调整堆的大小让JVM自适应完成。 如果内存小于100M，使用串行收集器 如果是单核、单机程序，并且没有停顿时间的要求，串行收集器 如果是多CPU、需要高吞吐量、允许停顿时间超过1秒，选择并行或者JVM自己选择 如果是多CPU、追求低停顿时间，需快速响应（比如延迟不能超过1秒，如互联网应用），使用并发收集器 官方推荐G1，性能高。现在互联网的项目，基本都是使用G1 ZGC回收器ZGC与Shenandoah目标高度相似，在尽可能对吞吐量影响不大的前提下，实现在任意堆内存大小下都可以把垃圾收集的停顿时间限制在十毫秒以内的低延迟。 ZGC收集器是一款基于Region内存布局的，（暂时） 不设分代的，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记一压缩算法的，以低延迟为首要目标的一款垃圾收集器。 ZGC的工作过程可以分为4个阶段：并发标记一并发预备重分配一并发重分配一并发重映射等 类的加载过程概述1、在Java中数据类型分为基本数据类型和引用数据类型。基本数据类型由虚拟机预先定义，引用数据类型则需要进行类的加载 2、类的整个生命周期包括如下7个阶段: 其中，验证+准备+解析&#x3D;链接 从程序中类的使用过程看: 加载阶段加载的理解 将Java类的字节码文件加载到机器内存中，并在内存中构建出Java类的原型一一类模板对象 所谓类模板对象，其实就是Java类在JVM内存中的一个快照，JVM将从字节码文件中解析出的常量池、类字段、类方法等信息存储到类模板中，这样JVM在运行期便能通过类模板而获取Java类中的任意信息，能够对Java类的成员变量进行遍历，也能进行Java方法的调用。 反射的机制即基于这一基础，如果JVM没有将Java类的声明信息存储起来，则JVM在运行期也无法反射。 加载完成的操作 加载阶段，简言之：查找并加载类的二进制数据，生成Class的实例。 在加载类时，Java虚拟机必须完成以下3件事情: 通过类的全名，获取类的二进制数据流。 解析类的二进制数据流为方法区内的数据结构（Java类模型） 创建java.lang.Class类的实例，表示该类型，作为方法区这个类的各种数据的访问入口 获取二进制数据流对于类的二进制数据流，虚拟机可以通过多种途径产生或获得。（只要所读取的字节码符合JVM规范即可） 虚拟机可能通过文件系统读入一个class后缀的文件（最常见） 读入jar、zip等归档数据包，提取类文件 事先存放在数据库中的类的二进制数据 使用类似于HTTP之类的协议通过网络进行加载 在运行时生成一段Class的二进制信息等 在获取到类的二进制信息后，Java虚拟机就会处理这些数据，并最终转为一个java.lang.Class的实例。 如果输入数据不是ClassFile的结构，则会抛出ClassFormatError（比如如果不是cafebabe开头，就会抛出ClassFormatError） 类模型与Class实例1、类模型的位置 加载的类在JVM中创建相应的类结构，类结构会存储在方法区（JDK1.8之前：永久代；JDK1.8及之后：元空间） 2、Class实例的位置 类将.class文件加载至元空间后，会在堆中创建一个Java.lang.Class对象，用来封装类位于方法区内的数据结构，该Class对象是在加载类的过程中创建的，每个类都对应有一个Class类型的对象。（instanceKlass -&gt; mirror : Class的实例） 外部可以通过访问代表Order类的Class对象来获取Order的类数据结构 Class类的构造方法是私有的，只有JVM才可以创建 java.lang.Class实例是访问类型元数据的接口，也是实现反射的关键数据、入口。通过Class类提供的接口，可以获得目标类所关联的.class文件中具体的数据结构:方法、字段等信息。 数组类的加载创建数组类的情况稍微有些特殊，因为数组类本身并不是由类加载器负责创建，而是由JVM在运行时根据需要而直接创建的，但数组的元素类型仍然需要依靠类加载器去创建。 创建数组类（下述简称A）的过程: 如果数组的元素类型是引用类型（String[]），那么就遵循定义的加载过程递归加载和创建数组A的元素类型（加载String）； JVM使用指定的元素类型和数组维度来创建新的数组类 如果数组的元素类型是引用类型，数组类的可访问性就由元素类型的可访问性决定 如果数组的元素类型是基本数据类型，类的可访问性将被缺省定义为public 链接阶段验证1、目的：保证加载的字节码是合法、合理并符合规范的 说明： 1、格式验证：和加载阶段一起运行 下面三个验证是针对方法区的类模版对象： 2、语义检查：查看语法是否符合规范 是否所有的类都有父类的存在 是否继承final 非抽象的类是否实现了抽象方法或者接口方法 3、字节码检查 4、符号引用验证：符号引用的直接引用是否存在 如果一个需要使用类无法在系统中找到，则会抛出NoClassDefFoundError，如果一个方法无法被找到，则会抛出NoSuchMethodError. 此阶段在解析环节才会执行 准备1、为类的静态变量分配内存，并初始化默认值 2、这里不包含基本数据类型的字段用static final修饰的情况，因为final在编译的时候就会分配了，准备阶段会显式赋值。 3、注意这里不会为实例变量分配初始化，类变量会分配在方法区中，而实例变量是会随着对象一起分配到Java堆中 4、在这个阶段并不会像初始化阶段中那样会有初始化或者代码被执行 解析1、将类、接口、字段和方法的符号引用转为直接引用 2、符号引用：就是一些字面量的引用，和虚拟机的内部数据结构和和内存布局无关。 比较容易理解的就是在Class类文件中，通过常量池进行了大量的符号引用。但是在程序实际运行时，只有符号引用是不够的，比如当如下println（）方法被调用时，系统需要明确知道该方法的位置。 举例: 输出操作System.out.println()对应的字节码 invokevirtual #24 &lt;java/io/PrintStream.println&gt; 以方法为例，Java虚拟机为每个类都准备了一张方法表，将其所有的方法都列在表中，当需要调用一个类的方法的时候，只要知道这个方法在方法表中的偏移量就可以直接调用该方法。通过解析操作，符号引用就可以转变为目标方法在类中方法表中的位置，从而使得方法被成功调用。 2.小结所谓解析就是将符号引用转为直接引用，也就是得到类、字段、方法在内存中的指针或者偏移量。因此，如果直接引用存在，那么可以肯定系统中存在该类、方法或者字段。但只存在符号引用，不能确定系统中一定存在该结构。 不过Java虚拟机规范并没有明确要求解析阶段一定要按照顺序执行。在HotSpot VM中，加载、验证、准备和初始化会按照顺序有条不紊地执行，但链接阶段中的解析操作往往会伴随着JVM在执行完初始化之后再执行。 初始化阶段1、初始化静态变量，赋予正确的值 2、初始化阶段才开始执行类中定义的java程序代码 3、重要工作：**&lt;clint&gt;()**方法 该方法自动生成 类静态变量的赋值语句+静态代码块语句 4、父类的**&lt;clint&gt;()方法优先于子类的&lt;clint&gt;()**方法 什么情况下不生成**&lt;clint&gt;()**方法？ 没有声明类变量、静态代码块 有类变量，但没有显式赋值 只有静态常量static final（在准备阶段就显式赋值了） 5、static+final搭配问题 1234567891011121314151617181920212223242526/** * 结论： * 在链接阶段的准备环节赋值的情况： * 1. 对于基本数据类型的字段来说，如果使用static final修饰，则显式赋值(直接赋值常量，而非调用方法）通常是在链接阶段的准备环节进行 * 2. 对于String来说，如果使用字面量的方式赋值，使用static final修饰的话，则显式赋值通常是在链接阶段的准备环节进行 * * 在初始化阶段&lt;clinit&gt;()中赋值的情况： * 排除上述的在准备环节赋值的情况之外的情况。 * * 最终结论：使用static + final修饰，且显示赋值中不涉及到方法或构造器调用的基本数据类型或String类型的显式赋值，是在链接阶段的准备环节进行。 */public class InitializationTest2 &#123; public static int a = 1;//在初始化阶段&lt;clinit&gt;()中赋值 public static final int INT_CONSTANT = 10;//在链接阶段的准备环节赋值 public static final Integer INTEGER_CONSTANT1 = Integer.valueOf(100);//在初始化阶段&lt;clinit&gt;()中赋值 public static Integer INTEGER_CONSTANT2 = Integer.valueOf(1000);//在初始化阶段&lt;clinit&gt;()中赋值 public static final String s0 = &quot;helloworld0&quot;;//在链接阶段的准备环节赋值 public static final String s1 = new String(&quot;helloworld1&quot;);//在初始化阶段&lt;clinit&gt;()中赋值 public static String s2 = &quot;helloworld2&quot;; public static final int NUM = 2;//字面量，在链接阶段的准备环节赋值 public static final int NUM1 = new Random().nextInt(10);//在初始化阶段&lt;clinit&gt;()中赋值，编译阶段确定不了具体值&#125; 6、**&lt;clint&gt;()**线程安全性问题 虚拟机会保证一个类的**&lt;clint&gt;()方法在多线程环境中被正确地加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的&lt;clint&gt;()方法，其他线程都需要阻塞等待，直到活动线程执行&lt;clint&gt;()**方法完毕。 正是因为**&lt;clint&gt;()带锁线程安全的，因此，如果在一个类的&lt;clint&gt;()**方法中有耗时很长的操作，就可能造成多个线程阻塞，引发死锁，并且这种死锁是很难发现的，因为看起来它们并没有可用的锁信息。 如果之前的线程成功加载了类，则等在队列中的线程就没有机会再执行**&lt;clint&gt;()**方法了。那么，当需要使用这个类时虚拟机会直接返回给它已经准备好的信息 类的主动使用和被动使用主动使用会调用类的&lt;clint&gt;()方法 如果出现如下的情况，则会对类进行初始化操作，而初始化操作之前的加载、验证、准备已经完成： 1、当创建一个类的实例时，比如使用new关键字，或者通过反射、克隆、反序列化。 2、当调用类的静态方法时，即当使用了字节码invokestatic指令。 3、当使用类、接口的静态字段时（final修饰特殊考虑），比如，使用getstatic或者putstatic指令。（对应访问变量、赋值变量操作） 4、当使用java.lang.reflect包中的方法反射类的方法时。比如:Class.forName（”com.atguigu.java.Test”） 5、当初始化子类时，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 6、如果一个接口定义了default方法，那么直接实现或者间接实现该接口的类的初始化，该接口要在其之前被初始化。 7、当虚拟机启动时，用户需要指定一个要执行的主类（包含main（）方法的那个类），虚拟机会先初始化这个主类。 8、当初次调用 MethodHandle实例时，初始化该MethodHandle指向的方法所在的类。（涉及解析REF_getStatic、REF_putStatic、REF_invokeStatic方法句柄对应的类） 被动使用也就是说:并不是在代码中出现的类，就一定会被加载或者初始化。如果不符合主动使用的条件，类就不会初始化。 1、当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 当通过子类引用父类的静态变量，不会导致子类初始化 2、通过数组定义类引用，不会触发此类的初始化 类作为数组的类型，如：record[] test = new record[10]; 3、引用常量不会触发此类或接口的初始化，因为常量在链接阶段就已经被显式赋值了。 4、调用ClassLoader类的loadClass（）方法加载一个类，并不是对类的主动使用，不会导致类的初始化。 使用开发人员可以在程序中访问和调用它的静态类成员信息（比如:静态字段、静态方法），或者使用new关键字为其创建对象实例。 例：加载一个类时，以Order类为例： 方法区：存放Order类模板数据&#x2F;对象 堆空间：创建一个Order类的Class实例，这个实例指向了方法区中的类模板对象 栈中（栈帧的局部变量表中）中：声明了一个class对象，class对象指向了堆空间中的Class实例 Order的对象实例存放在堆中 卸载类存在于方法区中，jdk8中方法区的落地实现是元空间，元空间使用的是系统内存，所以当类没有被及时卸载时，可能会出现方法区的OOM 类、类的加载器、类的实例1、某个类的Class实例与其类的加载器之间为双向关联关系 在类加载器的内部实现中，用一个Java集合来存放所加载类的引用 一个Class对象总是会引用它的类加载器，调用Class对象的getClassLoader（）方法，就能获得它的类加载器 2、类的实例总是引用代表这个类的Class对象，在0bject类中定义了getClass（）方法，这个方法返回代表对象所属类的Class对象的引用。 类的生命周期1、当Sample类被加载、链接和初始化后，它的生命周期就开始了。 2、当代表Sample类的Class对象不再被引用，即不可触及时，Class对象就会结束生命周期，Sample类在方法区内的数据也会被卸载，从而结束Sample类的生命周期。 一个类何时结束生命周期，取决于代表它的Class对象何时结束生命周期。 1、loader1变量和obj变量间接应用代表Sample类的Class对象，而objClass变量则直接引用它 2、如果程序运行过程中，将上图左侧三个引用变量都置为null Sample对象结束生命周期 Myclass Loader对象结束生命周期 SampleClass类的对象也结束生命周期 Sample类在方法区内的二进制数据被卸载 3、当再次有需要时，会检查Sample类的Class对象是否存在 如果存在会直接使用 如果不存在 Sample类会被重新加载，在Java虚拟机的堆区会生成一个新的代表 SampleClass类的实例。 回顾：方法区的垃圾回收方法区的垃圾收集主要回收两部分内容:常量池中废弃的常量和不再使用的类型。 HotSpot虚拟机对常量池的回收策略是很明确的，只要常量池中的常量没有被任何地方引用，就可以被回收。 判定一个常量是否“废弃”还是相对简单，而要判定一个类型是否属于“不再被使用的类”的条件就比较苛刻了，需要同时满足下面三个条件: 该类所有的实例都已经被回收 也就是Java堆中不存在该类及其任何派生子类的实例 加载该类的类加载器已经被回收 这个条件除非是经过精心设计的可替换类加载器的场景，如OSGi、JSP的重加载等，否则通常是很难达成的 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法 Java虚拟机被允许对满足上述三个条件的无用类进行回收，这里说的仅仅是“被允许”，而并不是和对象一样，没有引用了就必然会回收。 类的卸载1、启动类加载器加载的类型在整个运行期间是不可能被卸载的(jvm和jls规范) 2、被系统类加载器和扩展类加载器加载的类型在运行期间不太可能被卸载，因为系统类加载器实例或者扩展类的实例基本上在整个运行期间总能直接或者间接的访问的到，其达到 unreachable的可能性极小。 3、被开发者自定义的类加载器实例加载的类型只有在很简单的上下文环境中才能被卸载，而且一般还要借助于强制调用虚拟机的垃圾收集功能才可以做到。可以预想，稍微复杂点的应用场景中被加载的类型在运行期间也是几乎不太可能被卸载的(至少卸载的时间是不确定的)。 综合以上三点，一个已经加载的类型被卸载的几率很小至少被卸载的时间是不确定的。同时我们可以看的出来,开发者在开发代码时候，不应该对虚拟机的类型卸载做任何假设的前提下，来实现系统中的特定功能。 类的加载器概述1、类加载器是JVM执行类加载机制的前提 2、ClassLoader 所有的class都是由ClassLoader加载的 负责通过各种方式将class信息的二进制数据流读入JVM内部，转为一个与目标类对应的java.lang.Class对象实例 3、类的加载分类 显式加载：在代码中通过调用ClassLoader加载Class对象，如：Class.forName(name) 隐式加载：不直接在代码中调用ClassLoader的方法加载class对象，而是通过虚拟机自动加载到内存中，如：在加载某个类的class文件时，该类的class文件中引用了另外一个类的对象，此时额外引用的类将通过JVM自动加载到内存中。 123456789101112public class UserTest &#123; public static void main(String[] args) &#123; User user = new User(); //隐式加载 try &#123; Class clazz = Class.forName(&quot;com.dsh.jvmp2.chapter04.java.User&quot;); //显式加载 ClassLoader.getSystemClassLoader().loadClass(&quot;com.dsh.jvmp2.chapter04.java.User&quot;);//显式加载 &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 4、类的加载器的必要性 一般情况下， Java开发人员并不需要在程序中显式地使用类加载器，但是了解类加载器的加载机制却显得至关重要。从以下几个方面说: 避免在开发中遇到java.lang.ClassNotFoundException异常或java.lang.NoClassDefFoundError异常时，手足无措。只有了解类加载器的加载机制才能够在出现异常的时候快速地根据错误异常日志定位问题和解决问题 需要支持类的动态加载或需要对编译后的字节码文件进行加解密操作时，就需要与类加载器打交道了。 开发人员可以在程序中编写自定义类加载器来重新定义类的加载规则，以便实现一些自定义的处理逻辑。 5、类的唯一性？ 对于任意一个类，都需要由加载它的类加载器和这个类本身一同确认其在Java虚拟机中的唯一性。 每一个类加载器，都拥有一个独立的类名称空间：比较两个类是否相等，只有在这两个类是由同一个类加载器加载的前提下才有意义。否则，即使这两个类源自同一个Class文件，被同一个虚拟机加载，只要加载他们的类加载器不同，那这两个类就必定不相等。 6、命名空间 每个类加载器都有自己的命名空间，由该类加载器及所有的父加载器所加载的类组成 在同一命名空间中，不会出现类的完整名字相同的两个类 在不同的命名空间中，可能会出现类的完整名字相同的两个类 在大型应用中，我们往往借助这一特性运行同一个类的不同版本 7、类加载器三个基本特征 双亲委派模型 可见性：子类加载器可以访问父类加载器，反过来是不允许的 单一性：父加载器加载过的类型在子加载器中不会重复加载 类的加载器分类1、JVM支持两种类型的类加载器，分别为引导类加载器和自定义类加载器 Java虚拟机规范将所有派生于抽象类ClassLoader的类加载器都划分为自定义类加载器 3、无论类加载器的类型如何划分，在程序中我们最常见的类加载器结构主要是如下情况: 除了顶层的启动类加载器外，其余的类加载器都应当有自己的“父类”加载器。 不同类加载器看似是继承关系，实际上是包含关系，在下层加载器中包含着上层加载器的引用，如代码所示 123456789101112131415161718class ClassLoader&#123; ClassLoader parent;//父类加载器 public ChildClassLoader(ClassLoader parent)&#123;//parent = new ParentClassLoader() this.parent = parent; &#125;&#125;class ParentClassLoader extends ClassLoader&#123; public ParentClassLoader(ClassLoader parent)&#123; super(parent) &#125;&#125;class ChildClassLoader extends ClassLoader&#123; public ChildClassLoader(ClassLoader parent)&#123;//parent = new ParentClassLoader(); super(parent); &#125;&#125; 启动类加载器1、这个类加载使用C&#x2F;C++语言实现的，嵌套在JVM内部。 2、它用来加载Java的核心库（JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;rt.jarbsun.boot.class.path路径下的内容）。用于提供JVM自身需要的类。 3、并不继承自java.lang.ClassLoader，没有父加载器。 4、出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类 5、加载扩展类和应用程序类加载器，并指定为他们的父类加载器 扩展类加载器1、Java语言编写，由sun.misc.Launcher$ExtClassLoader实现。 2、继承于ClassLoader类 3、父类加载器为启动类加载器 4、从java.ext.dirs系统属性所指定的目录中加载类库，或从JDK的安装目录的jre&#x2F;lib&#x2F;ext子目录下加载类库。如果用户创建的JAR放在此目录下，也会自动由扩展类加载器加载。 系统类加载器1、java语言编写，由sun.misc.Launcher$AppClassLoader实现 2、继承于ClassLoader类 3、父类加载器为扩展类加载器 4、它负责加载环境变量classpath或系统属性java.class.path指定路径下的类库 5、应用程序中的类加载器默认是系统类加载器 6、它是用户自定义类加载器的默认父加载器 7、通过ClassLoader的getSystemClassLoader（）方法可以获取到该类加载器 用户自定义类加载器1、Java开发者可以自定义类加载器来实现类库的动态加载，加载源可以是本地的JAR包，也可以是网络上的远程资源。 2、通过类加载器可以实现非常绝妙的插件机制，这方面的实际应用案例举不胜举。例如,著名的SGI组件框架,再如Eclipse的插件机制。类加载器为应用程序提供了一种动态增加新功能的机制，这种机制无须重新打包发布应用程序就能实现。 3、自定义加载器能够实现应用隔离，例如 Tomcat、Spring等中间件和组件框架都在内部实现了自定义的加载器，并通过自定义加载器隔离不同的组件模块。这种机制比C&#x2F;C++程序要好太多，想不修改C&#x2F;C++程序就能为其新增功能，几乎是不可能的，仅仅一个兼容性便能阻挡住所有美好的设想。 5、自定义类加载器通常需要继承于classLoader 测试不同的类加载器每个Class对象都会包含一个定义它的ClassLoader的一个引用 获取classLoader的途径 途径 获得当前类的ClassLoader -&gt; clazz.getClassLoader() 获得当前线程上下文的ClassLoader -&gt; Thread.currentThread().getContextClassLoader() 获得系统的ClassLoader -&gt; ClassLoader.getSystemClassLoader() 1234567891011121314151617//获取系统类加载器ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader();System.out.println(systemClassLoader);//sun.misc.Launcher$AppClassLoader@18b4aac2//获取扩展类加载器ClassLoader parent = systemClassLoader.getParent();System.out.println(parent);//sun.misc.Launcher$ExtClassLoader@5cad8086//获取引导类加载器ClassLoader parent1 = parent.getParent();System.out.println(parent1);//nullClassLoader classLoader = Class.forName(&quot;java.lang.String&quot;).getClassLoader();System.out.println(classLoader);//nullClassLoader tt = Class.forName(&quot;tt&quot;).getClassLoader();System.out.println(tt);//sun.misc.Launcher$AppClassLoader@18b4aac2 数组类型的加载123//数组类型的加载String[] test = new String[7];System.out.println(test.getClass().getClassLoader());//null 1、数组类的Class对象，不是由类加载器去创建的，而是在Java运行期JVM根据需要自动创建的 2、对于数组类的类加载器来说，通过Class.getClassLoader（）返回的与数组当中元素类型的类加载器是一样的 3、如果数组当中的元素类型是基本数据类型，数组类是没有类加载器的 ClassLoader源码 除了以上虚拟机自带的加载器外，用户还可以定制自己的类加载器 Java提供了抽象类java.lang.ClassLoader，所有用户自定义的类加载器都应该继承ClassLoader类 主要方法抽象类 classLoader的主要方法：(内部没有抽象方法) 1、public final classLoader getParent()：返回该类加载器的超类加载器 2、public Class&lt;?&gt; loadclass(String name) ：加载名称为name的类，返回结果为java.lang.Class类的实例。如果找不到类，则返回classNotFoundException异常，该方法中的逻辑就是双亲委派模式的实现。 12345678910111213141516171819202122232425262728293031323334353637383940414243public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false);&#125;protected Class&lt;?&gt; loadClass(String name, boolean resolve)//resolve：加载class的同时进行解析操作 throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123;//保证只能加载一次 // 检查class是否已经加载同名的类 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; //获取当前类加载器的父类加载器 if (parent != null) &#123; //加载父类加载器，双亲委派机制 c = parent.loadClass(name, false); &#125; else &#123; //父类加载器是引导类加载器 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; &#125; //情况一：当前类加载器的父类加载器未加载此类 //情况二：当前类加载器未加载此类 if (c == null) &#123; //调用当前classloader的findclass方法 long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123;//是否进行解析操作 resolveClass(c); &#125; return c; &#125;&#125; 3、protected Class&lt;?&gt; findclass（String name）：查找二进制名称为name的类，返回结果为java.lang.Class类的实例。这是一个受保护的方法，JVM鼓励我们重写此方法，需要自定义加载器遵循双亲委托机制，该方法会在检查完父类加载器之后被loadClass()方法调用。 123protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; throw new ClassNotFoundException(name);&#125; JDK1.2之前，在自定义类加载时，总会去继承ClassLoader类并重写loadClass方法，从而实现自定义的类加载类。但是在IDK1.2之后已不再建议用户去覆盖loadClass（）方法，而是建议把自定义的类加载逻辑写在findClass（）方法中. ​ findClass（）方法是在loadClass（）方法中被调用的，当 loadClass（）方法中父加载器加载失败后，则会调用自己的findClass（）方法来完成类加载，这样就可以保证自定义的类加载器也符合双亲委托模式。 需要注意的是ClassLoader类中并没有实现findClass（）方法的具体代码逻辑，取而代之的是抛出 ClassNotFoundException异常，同时应该知道的是findClass方法通常是和defineClass方法一起使用的。一般情况下，在自定义类加载器时，会直接覆盖ClassLoader的findClass（）方法并编写加载规则，取得要加载类的字节码后转换成流，然后调用defineClass（）方法生成类的Class对象。 4、protected final Class&lt;?&gt; defineClass（String name， byte[] b， int off， int len） 根据给定的字节数组b转换为Class的实例，off和len参数表示实际Class信息在byte数组中的位置和长度，其中byte数组b是ClassLoader从外部获取的。这是受保护的方法，只有在自定义ClassLoader子类中可以使用。 defineClass（）方法是用来将byte字节流解析成JVM能够识别的Class对象（ClassLoader中己实现该方法逻辑），通过这个方法不仅能够通过class文件实例化class对象，也可以通过其他方式实例化class对象，如通过网络接收一个类的字节码，然后转换为byte字节流创建对应的Class对象。 defineClass（）方法通常与findClass（）方法一起使用，一般情况下，在自定义类加载器时，会直接覆盖 ClassLoader的findClass（）方法并编写加载规则，取得要加载类的字节码后转换成流，然后调用defineClass()方法生成类的Class对象 12345678910protected Class&lt;?&gt; findclass（String name） throws ClassNotFoundException&#123; //获取类的字节数组 byte[] classData = getclassData（name）; if （classData == null） &#123; throw new ClassNotFoundException（）； &#125; else &#123; //使用defineClass生成class对象 return defineclass（name， classData， 0， classData.length）; &#125;&#125; 5、protected final void resolveclass(Class&lt;?&gt; c)：链接指定的一个Java类。使用该方法可以使用类的Class对象创建完成的同时也被解析。前面我们说链接阶段主要是对字节码进行验证，为类变量分配内存并设置初始值同时将字节码文件中的符号引用转换为直接引用。 6、protected final Class&lt;?&gt; findLoadedClass(String name)：查找名称为name的已经被加载过的类，返回结果为java.lang.Class类的实例。这个方法是final方法，无法被修改。 7、private final ClassLoader parent;：它也是一个ClassLoader的实例，这个字段所表示的ClassLoader也称为这个ClassLoader的双亲。在类加载的过程中，ClassLoader可能会将某些请求交予自己的双亲处理。 子类 SecureClassLoader与URLClassLoader接着SecureClassLoader扩展了ClassLoader，新增了几个与使用相关的代码源（对代码源的位置及其证书的验证）和权限定义类验证（主要指对class源码的访问权限）的方法，一般我们不会直接跟这个类打交道，更多是与它的子类 URLClassLoader有所关联。 ClassLoader是一个抽象类，很多方法是空的没有实现，比如 findClass（）、findResource（）等 URLClassLoader这个实现类为这些方法提供了具体的实现。并新增了URLClassPath类协助取得Class字节码流等功能。在编写自定义类加载器时，如果没有太过于复杂的需求，可以直接继承URLClassLoader类，这样就可以避免自己去编写findClass（）方法及其获取字节码流的方式，使自定义类加载器编写更加简洁。 ExtClassLoader与AppClassLoader这两个类都继承自URLClassLoader，是sun.misc.Launcher的静态内部类。 sun.misc.Launcher主要被系统用于启动主应用程序，ExtClassLoader和AppClassLoader都是由sun.misc.Launcher创建的，其类主要类结构如下: 我们发现ExtClassLoader并没有重写loadClass（）方法，这足矣说明其遵循双亲委派机制，而AppClassLoader重载了loadClass（）方法，但最终调用的还是父类loadClass（）方法，因此依然遵守双亲委派模式。 Class.forName()与ClassLoader.loadClass()1、Class.forName（）:是一个静态方法，最常用的是Class.forName（String className）；根据传入的类的全限定名返回一个Class对象。 该方法在将 Class 文件加载到内存的同时，会执行类的初始化。（主动使用）如：Class.forName（”com.atguigu.java.HelloWorld”）； 2、ClassLoader.loadClass（）:这是一个实例方法，需要一个ClassLoader对象来调用该方法。 该方法将Class文件加载到内存时，并不会执行类的初始化，直到这个类第一次使用时才进行初始化。（被动使用） 该方法因为需要得到一个ClassLoader对象，所以可以根据需要指定使用哪个类加载器. 123ClassLoader cl=......；cl.loadClass（&quot;com.atguigu.java.HelloWorld&quot;）； 双亲委派模型定义和本质1.定义 如果一个类加载器在接到加载类的请求时，它首先不会自己尝试去加载这个类，而是把这个请求任务委托给父类加载器去完成，依次递归，如果父类加载器可以完成类加载任务，就成功返回。只有父类加载器无法完成此加载任务时，才自己去加载。 2.本质 规定了类加载的顺序是： 引导类加载器先加载，若加载不到，由扩展类加载器加载，若还加载不到，才会由系统类加载器或自定义的类加载器进行加载。 优势1、避免类的重复加载，确保一个类的全局唯一性 Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次。 2、保护程序安全，防止核心API被随意篡改 代码支持双亲委派机制在java.lang.ClassLoadelr.loadClass（String，boolean）接口中体现。该接口的逻辑如下: （1）先在当前加载器的缓存中查找有无目标类，如果有，直接返回。 （2）判断当前加载器的父加载器是否为空，如果不为空，则调用parent.loadClass（name， false）接口进行加载。 （3）反之，如果当前加载器的父类加载器为空，则调用findBootstrapClassOrNull（name）接口，让引导类加载器进行加载。 （4）如果通过以上3条路径都没能成功加载，则调用findClass（name）接口进行加载，该接口最终会调用 java.lang.ClassLoader接口的defineClass系列的native接口加载目标Java类， 双亲委派的模型就隐藏在这第2和第3步中。 举例 假设当前加载的是java.lang.Object这个类，很显然，该类属于JDK中核心得不能再核心的一个类，因此一定只能由引导类加载器进行加载。当JVM准备加载javaJang.Object时，JVM默认会使用系统类加载器去加载，按照上面4步加载的逻辑，在第1步从系统类的缓存中肯定查找不到该类，于是进入第2步。由于从系统类加载器的父加载器是扩展类加载 思考 如果在自定义的类加载器中重写java.lang.ClassLoader.loadClass（String）或 java.lang.ClassLoader.loadClass（String， boolean）方法，抹去其中的双亲委派机制，仅保留上面这4步中的第1步与第4步，那么是不是就能够加载核心类库了呢？ 这也不行！因为JDK还为核心类库提供了一层保护机制。不管是自定义的类加载器，还是系统类加载器或扩展类加载器，最终都必须调用java.lang.ClassLoader.defineClass（String， byte[]， int， int，ProtectionDomain）方法，而该方法会执行preDefineClass（）接口，该接口中提供了对JDK核心类库的保护。 弊端检查类是否加载的委托过程是单向的，这个方式虽然从结构上说比较清晰，使各个ClassLoader的职责非常明确，但是同时会带来一个问题，即顶层的ClassLoader无法访问底层的ClassLoader所加载的类。 通常情况下，启动类加载器中的类为系统核心类，包括一些重要的系统接口，而在应用类加载器中，为应用类。按照这种模式，应用类访问系统类自然是没有问题，但是系统类访问应用类就会出现问题。比如在系统类中提供了一个接口，该接口需要在应用类中得以实现，该接口还绑定一个工厂方法，用于创建该接口的实例，而接口和工厂方法都在启动类加载器中。这时，就会出现该工厂方法无法创建由应用类加载器加载的应用实例的问题。 结论由于Java虚拟机规范并没有明确要求类加载器的加载机制一定要使用双亲委派模型，只是建议采用这种方式而已。 比如在Tomcat中，类加载器所采用的加载机制就和传统的双亲委派模型有一定区别，当缺省的类加载器接收到一个类的加载任务时，首先会由它自行加载，当它加载失败时，才会将类的加载任务委派给它的超类加载器去执行，这同时也是Servlet规范推荐的一种做法。 Tomcat类加载器 按照 Servlet 规范的建议，Webapp 加载器略有不同，它首先会在自己的资源库中搜索，而不是向上委托，打破了标准的委托机制，来看下 Tomcat 的设计和实现。 1、 JDK 内部提供的类加载器分别是： Bootstrap - 启动类加载器，属于 JVM 的一部分，加载 &#x2F;lib&#x2F; 目录下特定的文件 Extension - 扩展类加载器，加载 &#x2F;lib&#x2F;ext&#x2F; 目录下的类库 Application - 应用程序类加载器，也叫系统类加载器，加载 CLASSPATH 指定的类库 2、Tomcat 自定义实现的类加载器分别是： Common - 父加载器是 AppClassLoader，默认加载 ${catalina.home}&#x2F;lib&#x2F; 目录下的类库 Catalina - 父加载器是 Common 类加载器，加载 catalina.properties 配置文件中 server.loader 配置的资源，一般是 Tomcat 内部使用的资源 Shared - 父加载器是 Common 类加载器，加载 catalina.properties 配置文件中 shared.loader 配置的资源，一般是所有 Web 应用共享的资源 WebappX - 父加载器是 Shared 加载器，加载 /WEB-INF/classes 的 class 和 /WEB-INF/lib/ 中的 jar 包 JasperLoader - 父加载器是 Webapp 加载器，加载 work 目录应用编译 JSP 生成的 class 文件 3、WebappClassLoader 则按规范实现以下顺序的查找并加载： 从 JVM 内部的 Bootstrap 仓库加载 从应用程序加载器路径，即 CLASSPATH 下加载 从 Web 程序内的 /WEB-INF/classes 目录 从 Web 程序内的 /WEB-INF/lib 中的 jar 文件 从容器 Common 加载器仓库，即所有 Web 程序共享的资源加载 那么Tomcat为什么要自定义类加载器呢？ 隔离不同应用：部署在同一个Tomcat中的不同应用A和B，例如A用了Spring2.5。B用了Spring3.5，那么这两个应用如果使用的是同一个类加载器，那么Web应用就会因为jar包覆盖而无法启动。 灵活性：Web应用之间的类加载器相互独立，那么就可以根据修改不同的文件重建不同的类加载器替换原来的。从而不影响其他应用。 性能：如果在一个Tomcat部署多个应用，多个应用中都有相同的类库依赖。那么可以把这相同的类库让Common类加载器进行加载。 Tomcat自定义了WebAppClassLoader类加载器。打破了双亲委派的机制，即如果收到类加载的请求，会尝试自己去加载，如果找不到再交给父加载器去加载，目的就是为了优先加载Web应用自己定义的类。我 打破双亲委派机制第一次：JDK1.2之前双亲委派模型的第一次“被破坏”其实发生在双亲委派模型出现之前一一即JDK1.2面世以前的“远古”时代。 由于双亲委派模型在JDK1.2之后才被引入，但是类加载器的概念和抽象类java.lang.ClassLoader则在Java的第一个版本中就已经存在，面对已经存在的用户自定义类加载器的代码，Java设计者们引入双亲委派模型时不得不做出一些妥协。 为了兼容这些已有代码，无法再以技术手段避免loadClass（）被子类覆盖的可能性，只能在IDK1.2之后的java.lang.ClassLoader中添加一个新的protected方法findClass（），并引导用户编写的类加载逻辑时尽可能去重写这个方法，而不是在loadClass（）中编写代码。 上节我们已经分析过loadClass（）方法，双亲委派的具体逻辑就实现在这里面，按照loadClass（）方法的逻辑，如果父类加载失败，会自动调用自己的findClass（）方法来完成加载，这样既不影响用户按照自己的意愿去加载类，又可以保证新写出来的类加载器是符合双亲委派规则的。 第二次：线程上下文类加载器 双亲委派模型的第二次“被破坏”是由这个模型自身的缺陷导致的，双亲委派很好地解决了各个类加载器协作时基础类型的一致性问题（越基础的类由越上层的加载器进行加载），基础类型之所以被称为“基础”，是因为它们总是作为被用户代码继承、调用的API存在，但程序设计往往没有绝对不变的完美规则，如果有基础类型又要调用回用户的代码，那该怎么办呢？ 一个典型的例子便是JNDI服务，JNDI现在已经是Java的标准服务，它的代码由启动类加载器来完成加载（在JDK1.3时加入到rt.jar的），肯定属于Java中很基础的类型了。但JNDI存在的目的就是对资源进行查找和集中管理，它需要调用由其他厂商实现并部署在应用程序的ClassPath下的INDI服务提供者接口（ Service Provider Interface， SPI）的代码，现在问题来了，启动类加载器是绝不可能认识、加载这些代码的，那该怎么办？（SPI:在Java平台中，通常把核心类rt.jar中提供外部服务、可由应用层自行实现的接口称为SPI） 线程上下文类加载器（Thread ContextClassLoader） 这个类加载器可以通过java.lang.Thread类的setContextClassLoader（）方法进行设置，如果创建线程时还未设置，它将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置过的话，那这个类加载器默认就是应用程序类加载器。 JNDI服务使用这个线程上下文类加载器去加载所需的SPI服务代码，这是一种父类加载器去请求子类加载器完成类加载的行为，这种行为实际上是打通了双亲委派模型的层次结构来逆向使用类加载器，已经违背了双亲委派模型的一般性原则，但也是无可奈何的事情。Java中涉及SPI的加载基本上都采用这种方式来完成，例如JNDI、JDBC、JCE、JAXB和JBI等。不过，当SPI的服务提供者多于一个的时候，代码就只能根据具体提供者的类型来硬编码判断，为了消除这种极不优雅的实现方式，在JDK 6时，JDK提供了java.util.ServiceLoader类，以META-INF&#x2F; services中的配置信息，辅以责任链模式，这才算是给SPI的加载提供了一种相对合理的解决方案。 默认上下文加载器就是应用类加载器，这样以上下文加载器为中介，使得启动类加载器中的代码也可以访问应用类加载器中的类。 第三次：OSGI双亲委派模型的第三次“被破坏”是由于用户对程序动态性的追求而导致的。如:代码热替换（Hot Swap）、模块热部署（Hot Deployment）等 IBM公司主导的JSR一291 （即OSGiR4.2）实现模块化热部署的关键是它自定义的类加载器机制的实现，每一个程序模块（OSGi中称为Bundle）都有一个自己的类加载器，当需要更换一个Bundle时，就把Bundle连同类加载器一起换掉以实现代码的热替换。在OSGi环境下，类加载器不再双亲委派模型推荐的树状结构，而是进一步发展为更加复杂的网状结构。 当收到类加载请求时，OSGi将按照下面的顺序进行类搜索: *1）将以java.开头的类，委派给父类加载器加载。 2）否则，将委派列表名单内的类，委派给父类加载器加载。 3）否则，将Import列表中的类，委派给Export这个类的Bundle的类加载器加载。 4）否则，查找当前Bundle的ClassPath，使用自己的类加载器加载。 5）否则，查找类是否在自己的Fragment Bundle中，如果在，则委派给Fragment Bundle的类加载器加载。 6）否则，查找Dynamic Import列表的Bundle，委派给对应Bundle的类加载器加载。 7）否则，类查找失败。 说明：只有开头两点仍然符合双亲委派模型的原则，其余的类查找都是在平级的类加载器中进行的 小结:这里，我们使用了“被破坏”这个词来形容上述不符合双亲委派模型原则的行为，但这里“被破坏”并不一定是带有贬义的。只要有明确的目的和充分的理由，突破旧有原则无疑是一种创新。 正如：OSGi中的类加载器的设计不符合传统的双亲委派的类加载器架构，且业界对其为了实现热部署而带来的额外的高复杂度还存在不少争议，但对这方面有了解的技术人员基本还是能达成一个共识，认为OSGi中对类加载器的运用是值得学习的，完全弄懂了0SGi的实现，就算是掌握了类加载器的精粹。 热替换的实现热替换是指在程序的运行过程中，不停止服务，只通过替换程序文件来修改程序的行为。热替换的关键需求在于服务不能中断，修改必须立即表现正在运行的系统之中。基本上大部分脚本语言都是天生支持热替换的，比如:PHP，只要替换了PHP源文件，这种改动就会立即生效，而无需重启Web服务器。 但对Java来说，热替换并非天生就支持，如果一个类已经加载到系统中，通过修改类文件，并无法让系统再来加载并重定义这个类。因此，在Java中实现这一功能的一个可行的方法就是灵活运用ClassLoader。 注意：由不同ClassLoader加载的同名类属于不同的类型，不能相互转换和兼容。即两个不同的ClassLoader加载同一个类，在虚拟机内部，会认为这2个类是完全不同的。 根据这个特点，可以用来模拟热替换的实现，基本思路如下图所示: 例子 首先在Demo1中定义输出方法，使用javac编译为class 运行程序，输出OldDemo1 修改Demo1中的输出方法，使用javac再次编译为class文件，此时class文件发生了替换 观察程序输出,程序输出了OldDemo1---&gt; NewDemo1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * 自定义类的加载器 */public class MyClassLoader extends ClassLoader &#123; private String rootDir; public MyClassLoader(String rootDir) &#123; this.rootDir = rootDir; &#125; protected Class&lt;?&gt; findClass(String className) throws ClassNotFoundException &#123; Class clazz = this.findLoadedClass(className); FileChannel fileChannel = null; WritableByteChannel outChannel = null; if (null == clazz) &#123; try &#123; String classFile = getClassFile(className); FileInputStream fis = new FileInputStream(classFile); fileChannel = fis.getChannel(); ByteArrayOutputStream baos = new ByteArrayOutputStream(); outChannel = Channels.newChannel(baos); ByteBuffer buffer = ByteBuffer.allocateDirect(1024); while (true) &#123; int i = fileChannel.read(buffer); if (i == 0 || i == -1) &#123; break; &#125; buffer.flip(); outChannel.write(buffer); buffer.clear(); &#125; byte[] bytes = baos.toByteArray(); clazz = defineClass(className, bytes, 0, bytes.length); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (fileChannel != null) fileChannel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; try &#123; if (outChannel != null) outChannel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; return clazz; &#125; /** * 类文件的完全路径 */ private String getClassFile(String className) &#123; return rootDir + &quot;/&quot; + className.replace(&#x27;.&#x27;, &#x27;/&#x27;) + &quot;.class&quot;; &#125;&#125; 沙箱安全机制1、沙箱安全机制 保证程序安全 保护Java原生的JDK代码 2、Java安全模型的核心就是Java沙箱（sandbox）。 什么是沙箱？ 沙箱是一个限制程序运行的环境，沙箱机制就是将Java代码限定在虚拟机（JVM）特定的运行范围中，并且严格限制代码对本地系统资源访问。通过这样的措施来保证对代码的有限隔离，防止对本地系统造成破坏。 沙箱主要限制系统资源访问，那系统资源包括什么？CPU、内存、文件系统、网络。不同级别的沙箱对这些资源访问的限制也可以不一样。 所有的Java程序运行都可以指定沙箱，可以定制安全策略 1. JDK1.0时期在Java中将执行程序分成本地代码和远程代码两种，本地代码默认视为可信任的，而远程代码则被看作是不受信的。对于授信的本地代码，可以访问一切本地资源。而对于非授信的远程代码在早期的Java实现中，安全依赖于沙箱（ Sandbox）机制。如下图所示IDK1.0安全模型 2. JDK1.1时期JDK1.0中如此严格的安全机制也给程序的功能扩展带来障碍，比如当用户希望远程代码访问本地系统的文件时候，就无法实现。 因此在后续的Java1.1版本中，针对安全机制做了改进，增加了安全策略。允许用户指定代码对本地资源的访问权限。如下图所示JDK1.1安全模型 3. JDK1.2时期在Java1.2版本中,再次改进了安全机制,增加了代码签名。不论本地代码或是远程代码,都会按照用户的安全策略设定,由类加载器加载到虚拟机中权限不同的运行空间,来实现差异化的代码执行权限控制。如下图所示JDK1.2安全模型： 4. JDK1.6时期当前最新的安全机制实现，则引入了域（Domain）的概念。 虚拟机会把所有代码加载到不同的系统域和应用域。系统域部分专门负责与关键资源进行交互，而各个应用域部分则通过系统域的部分代理来对各种需要的资源进行访问。虚拟机中不同的受保护域（Protected Domain），对应不一样的权限 （Permission）。存在于不同域中的类文件就具有了当前域的全部权限，如下图所示，最新的安全模型（jdk1.6） 性能调优背景1、目的 为了避免出现OOM 解决OOM 减少full gc出现的频率 2、监控的依据 运行日志 异常堆栈 GC日志 线程快照 堆转储快照 3、步骤 发现问题：性能监控 GC频繁 cpu load过高 OOM 内存泄漏 死锁 程序响应时间长 排除问题：性能分析 打印GC日志 使用命令行工具，jstack、jmap、jinfo等 dump堆，使用mat分析 jstack查看堆栈信息 解决问题：性能调优 适当增加内存、根据业务背景选择垃圾回收器 优化代码 增加机器 合理设置线程池线程数量 4、性能测试指标 停顿时间 系统：提交请求和返回响应的间隔时间 垃圾回收：STW时间 吞吐量 系统：单位时间完成的工作量 GC：运行用户代码的时间占总运行时间的比例 并发数 内存占用 相互间的关系 监控诊断工具（命令行）jps：查看正在运行的java进程123456789101112131415161718192021jps [-q] [-mlvV] [&lt;hostid&gt;]zhangtao@zhangtaodeMacBook-Pro test % jps -q53575925699249192492zhangtao@zhangtaodeMacBook-Pro test % jps -l 53575 92491 org.jetbrains.jps.cmdline.Launcher92587 jdk.jcmd/sun.tools.jps.Jps92492 com.tao.testzhangtao@zhangtaodeMacBook-Pro test % jps -m53575 92491 Launcher /Applications/IntelliJ IDEA.app/Contents/lib/netty-common-4.1.52.Final.jar:/Applications/IntelliJ IDEA.app/Contents/lib/netty-resolver-4.1.52.Final.jar:/Applications/IntelliJ IDEA.app/Contents/plugins/java/lib/javac2.jar:/Applications/IntelliJ IDEA.app/Contents/lib/httpclient-4.5.12.jar:/Applications/IntelliJ IDEA.app/Contents/lib/plexus-component-annotations-1.7.1.jar:/Applications/IntelliJ IDEA.app/Contents/lib/maven-resolver-spi-1.3.3.jar:/Applications/IntelliJ IDEA.app/Contents/lib/util.jar:/Applications/IntelliJ IDEA.app/Contents/lib/platform-api.jar:/Applications/IntelliJ IDEA.app/Contents/lib/qdox-2.0-M10.jar:/Applications/IntelliJ IDEA.app/Contents/lib/asm-all-9.0.jar:/Applications/IntelliJ IDEA.app/Contents/lib/commons-lang3-3.10.jar:/Applications/IntelliJ IDEA.app/Contents/lib/jna.jar:/Applications/IntelliJ IDEA.app/Contents/lib/trove4j.jar:/Applications/IntelliJ IDEA.app/Contents/lib/nanoxml-2.2.3.jar:/Applications/IntelliJ IDEA.app/Contents/lib/maven-resolver-api92603 Jps -m92492 test hello //传递参数，输出传递给main的参数jps -v：列出JVM参数 jstat：查看JVM统计信息1、用于监控JVM运行状态的信息，显示本地或者远程虚拟机进程的类装载、内存、GC、JIT编译等运行数据 2、常用于检测垃圾回收问题以及内存泄漏问题 3、基本语法 1jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]] 4、option参数 类装载相关 123zhangtao@zhangtaodeMacBook-Pro test % jstat -class 92492Loaded Bytes Unloaded Bytes Time 675 1349.5 0 0.0 0.13 垃圾回收相关 -gc：显示与GC相关的堆信息，包括Eden区、S区、O区、永久代等的容量、已用空间、GC时间合计等信息 123456789zhangtao@zhangtaodeMacBook-Pro test % jstat -gc 92492 第一个S区大小、第二个S区大小、第一个S区使用大小、第二个S区使用大小、Eden区大小、Eden区使用大小老年代大小、老年代使用大小方法区大小、方法区使用大小、压缩类空间大小、压缩类空间使用大小ygc的次数、ygc消耗的时间、fullgc次数、fullgc消耗时间、gc总时间 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT CGC CGCT GCT 5120.0 5120.0 0.0 0.0 33280.0 4671.6 87552.0 0.0 4480.0 781.0 384.0 76.6 0 0.000 0 0.000 - - 0.000 -gccapacity：与-gc基本相同，主要关注java堆各个区域使用到的最大、最小空间 -gcutil：与-gc基本相同，输出主要关注已使用空间占总空间的百分比 12345678910zhangtao@zhangtaodeMacBook-Pro test % jstat -gcutil 92492S0 - S0区域的使用比例S1 - S1区域的使用比例E - Eden区域的使用比例O - Old区域的使用比例M - 元数据区域的使用比例CCS - Compressed class空间的使用比例S0 S1 E O M CCS YGC YGCT FGC FGCT CGC CGCT GCT 0.00 0.00 14.04 0.00 17.43 19.94 0 0.000 0 0.000 - - 0.000 -gccause：与-gcutil功能一样，额外输出导致最后一次或当前GC产生的原因 1234567zhangtao@zhangtaodeMacBook-Pro test % jstat -gccause 92492LGCC - 上次GC的原因GCC - 当前GC的原因 S0 S1 E O M CCS YGC YGCT FGC FGCT CGC CGCT GCT LGCC GCC 0.00 0.00 14.04 0.00 17.43 19.94 0 0.000 0 0.000 - - 0.000 No GC No GC -gcnew：显示新生代GC状况 -gcnewcapacity：与-gcnew基本相同，主要关注使用到的最大、最小空间 -gcold：显示老年代GC状况 -gcoldcapacity：与-gcold基本相同，主要关注使用到的最大、最小空间 -gcpermcapacity：显示永久代使用的最大最小空间 JIT相关 123456789显示JIT编译器编译过的方法、耗时等信息zhangtao@zhangtaodeMacBook-Pro test % jstat -compiler 92492 Compiled Failed Invalid Time FailedType FailedMethod 85 0 0 0.03 0 输出已经被JIT编译的方法zhangtao@zhangtaodeMacBook-Pro test % jstat -printcompilation 92492 Compiled Size Type Method 85 20 1 java/lang/StringBuilder &lt;init&gt; 5、interval参数：指定输出统计数据的周期，单位为毫秒 6、count参数：指定查询的次数 1zhangtao@zhangtaodeMacBook-Pro test % jstat -class 92492 1000 10 7、-t 参数：显示程序的运行时间 比较Java进程的启动时间以及GC时间（-gc的GCT列），或者两次测量的间隔时间以及总gc时间的增量，来得出GC的时间占比 如果大于20%，说明堆的压力较大，超过90%说明堆几乎没有可用空间，随时可能抛出OOM异常 123zhangtao@zhangtaodeMacBook-Pro test % jstat -class -t 92492 Timestamp Loaded Bytes Unloaded Bytes Time 683.5 675 1349.5 0 0.0 0.13 8、-h 参数：每隔3个打印一次表头 123456789zhangtao@zhangtaodeMacBook-Pro test % jstat -class -h3 92492 1000Loaded Bytes Unloaded Bytes Time 675 1349.5 0 0.0 0.13 675 1349.5 0 0.0 0.13 675 1349.5 0 0.0 0.13Loaded Bytes Unloaded Bytes Time 675 1349.5 0 0.0 0.13 675 1349.5 0 0.0 0.13 675 1349.5 0 0.0 0.13 判断内存泄漏 使用jstat获取多行性能数据，并取这几行数据的OU列（已占用的老年代内存）的最小值 每隔一段时间重复上述操作，如果这些值呈现上涨趋势，说明老年代内存在不断上涨，意味着无法回收的对象在不断增加，可能出现内存泄漏 jinfo：查看和修改JVM参数查看JVM参数，也可以调整JVM参数 1jinfo &lt;option&gt; &lt;pid&gt; 1、option参数 查看 -sysprops -flags：查看曾经赋值过的一些参数 123zhangtao@zhangtaodeMacBook-Pro test % jinfo -flags 92492VM Flags:-XX:CICompilerCount=4 -XX:InitialHeapSize=134217728 -XX:MaxHeapSize=2147483648 -XX:MaxNewSize=715653120 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=44564480 -XX:OldSize=89653248 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps -XX:+UseParallelGC -flag 具体参数：查看某个java进程的具体参数 12zhangtao@zhangtaodeMacBook-Pro test % jinfo -flag UseParallelGC 92492-XX:+UseParallelGC 修改 针对boolean类型：-flag [+|-]具体参数 非boolean：-flag 具体参数=具体参数值 jmap：导出内存映像文件&amp;内存使用情况-dump：生成Java堆转储快照：dump文件 -heap：输出整个堆空间的详细信息，包括GC的使用、堆配置信息、内存的使用信息等 -histo：输出堆中对象的统计信息、包括类、实例数量和合集容量 1、导出内存映像文件 手动：jmap -dump:format=b,file=/tmp/a.prof pid 自动：-XX:+HeapDumpOnOutOfMemoryError、-XX:HeapDumpPath=/tmp/a.hprof 2、显示堆内存相关进行 jmap -heap pid jmap -histo pid jhat：JDK自带堆分析工具分析生成的dump文件 jstack：打印JVM中线程快照生成虚拟机指定进程当前时刻的线程快照 用于定位线程出现长时间停顿的原因","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"Zookeeper","slug":"Zookeeper","date":"2022-02-07T08:48:31.000Z","updated":"2022-02-07T13:51:36.235Z","comments":true,"path":"2022/02/07/Zookeeper/","link":"","permalink":"http://example.com/2022/02/07/Zookeeper/","excerpt":"","text":"CAP理论C、A、P1、C（Consistency）：一致性 在一个分布式的系统中，同一个数据的所有备份，在同一时刻是否有相同的值。也就是，对于同一个数据的读写，是否立刻对于所有副本都能看到一致的结果。一种比较常见的强一致性实现就是，在看到一致的结果之前，写请求不返回，读请求阻塞或者超时。 需要满足原子一致性，也就是任何读写都是具有原子性的，也就是对于同一个数据的写之后的读取，一定能读取到写的值，也就是最新的值 2、A（Avaliability）：可用性 在集群中一些节点故障时，集群还可以响应读写请求。 对于所有成功的请求，都需要在有限的时间内返回，也就是成功请求是有效的，可终止的。 3、P（Partition-tolerance）：分区容忍性 分布式系统具有多个节点，如果节点间网络中断，就会造成分区。 可能节点间传输丢失一些消息。 CAP并不能全部满足，一般选择两个满足 CA、CP、APCA（不选择）如果选择了CA而放弃了P，若发生分区现象，为了保证C，系统需要禁止写入，此时就与A发生冲突，如果是为了保证A，则会出现正常的分区可以写入数据，有故障的分区不能写入数据，则与C就冲突了。 因此分布式系统理论上不可能选择CA架构，而必须选择CP或AP架构。 CP1、不要求高可用性，要求强一致性的系统 哪怕当前业务不可用也不能出现数据不一致的情况，如果节点间传输消息丢失导致没有同步成功，回滚更新需求 2、应用：分布式锁 一般，如果没有获取到锁，或者获取锁失败都会选择阻塞等待或者直接失败，分布式锁必须保持所有节点看到的锁状态一致，否则认为获取锁失败 3、大部分分布式数据库都是CP系统，但是他们的一致性协议方案不同，例如：2PC、3PC等 AP1、要求高可用性不要求强一致性的系统 一旦分区发生，节点间的数据可能会不一致，每个节点使用自己的本地数据继续提供服务，这种情况下数据可能会出现不一致，系统一般会实现最终一致性（在分区结束后通过一些机制将数据同步） 2、应用：具有多层缓存的系统，例如DNS、客户端缓存、浏览器缓存、进程缓存等 业务场景选择服务注册中心 服务注册中心需要解决的问题： 服务注册：实例将自身服务信息注册到注册中心，包括服务的主机IP和服务的Port，以及暴露服务自身状态和访问协议信息等 服务发现：实例请求注册中心所依赖的服务信息，服务实例通过注册中心，获取到注册到其中的服务实例的信息，通过这些信息去请求他们的服务 1、zookeeper选择CP 对于注册请求采用过半写和2PC的同步机制，只有更新成功这个注册请求才成功，这样读取每个节点都会读取到这个更新请求，否则会回滚已经更新的节点。 每个节点的数据是一致的，如果过半的节点不可用，那么整个集群都不能处理注册实例请求以及读取实例的请求。 从实际情况来分析，在使用zookeeper获取服务列表时，如果zk正在选举或者zk集群中半数以上的机器不可用，那么将无法获取数据。所以说，zk不能保证服务可用性。 2、Eureka选择AP 注册请求发送到一个Eureka实例上之后，这个Eureka会转发到集群内其他Eureka节点 即使某些节点失败，也不会回滚已经更新的，无论集群内哪些Eureka挂了也不会影响其他Eureka继续服务工作，虽然可能读取到的数据会不一致 3、Zookeeper和eureka的数据一致性问题 先要明确一点，eureka的创建初心就是为一个注册中心，但是zk更多是作为分布式协调服务的存在，只不过因为它的特性被dubbo赋予了注册中心，它的职责更多是保证数据（配置数据，状态数据）在管辖下的所有服务之间保持一致，所有这个就不难理解为何zk被设计成CP而不是AP，zk最核心的算法ZAB，就是为了解决分布式系统下数据在多个服务之间一致同步的问题。 更深层的原因，zookeeper是按照CP原则构建，也就是说它必须保持每一个节点的数据都保持一致，如果zookeeper下节点断开或者集群中出现网络分割（例如交换机的子网间不能互访），那么zk会将它们从自己的管理范围中剔除，外界不能访问这些节点，即使这些节点是健康的可以提供正常的服务，所以导致这些节点请求都会丢失。 而eureka则完全没有这方面的顾虑，它的节点都是相对独立，不需要考虑数据一致性的问题，这个应该是eureka的诞生就是为了注册中心而设计，相对zk来说剔除了leader节点选取和事务日志极致，这样更有利于维护和保证eureka在运行的健壮性。 再来看看，数据不一致性在注册服务中中会给eureka带来什么问题，无非就是某一个节点被注册的服务多，某个节点注册的服务少，在某一个瞬间可能导致某些ip节点被调用数少，某些ip节点调用数少的问题。也有可能存在一些本应该被删除而没被删除的脏数据。 4、小结：服务注册应该选择AP还是CP 对于服务注册来说，针对同一个服务，即使注册中心的不同节点保存的服务注册信息不相同，也并不会造成灾难性的后果，对于服务消费者来说，能消费才是最重要的，就算拿到的数据不是最新的数据，消费者本身也可以进行尝试失败重试。总比为了追求数据的一致性而获取不到实例信息整个服务不可用要好。 所以，对于服务注册来说，可用性比数据一致性更加的重要，选择AP。 分布式锁这里实现分布式锁的方式选取了三种： 基于数据库实现分布式锁 基于redis实现分布式锁 基于zookeeper实现分布式锁 基于数据库创建表lock 12345CREATE TABLE `lock` ( `method_lock` varchar(255) NOT NULL, `update_time` bigint DEFAULT &#x27;0&#x27;, PRIMARY KEY (`method_lock`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci; 利用method_lock作为唯一主键，当进行上锁的时候进行insert动作，数据库成功录入则认为上锁成功，当数据库报出Duplicate entry 则表示无法获取该锁 不过这种方式对于单主却无法自动切换主从的mysql来说，基本就无法现实P分区容错性，（Mysql自动主从切换在目前并没有十分完美的解决方案）。可以说这种方式强依赖于数据库的可用性，数据库写操作是一个单点，一旦数据库挂掉，就导致锁的不可用。这种方式基本不在CAP的一个讨论范围。 基于Redis（AP）redis单线程串行处理天然就是解决串行化问题，用来解决分布式锁是再适合不过。 实现方式： 12setnx key value Expire_time获取到锁 返回 1 ， 获取失败 返回 0 为了解决数据库锁的无主从切换的问题，可以选择redis集群，或者是 sentinel 哨兵模式，实现主从故障转移，当master节点出现故障，哨兵会从slave中选取节点，重新变成新的master节点。 哨兵模式故障转移是由sentinel集群进行监控判断，当maser出现异常即复制中止，重新推选新slave成为master，sentinel在重新进行选举并不在意主从数据是否复制完毕具备一致性。 所以redis的复制模式是属于AP的模式。保证可用性，在主从复制中“主”有数据，但是可能“从”还没有数据，这个时候，一旦主挂掉或者网络抖动等各种原因，可能会切换到“从”节点，这个时候可能会导致两个业务县城同时获取得两把锁 这个过程如下： 业务线程-1 向主节点请求锁 业务线程-1 获取锁 业务线程-1 获取到锁并开始执行业务 这个时候redis刚生成的锁在主从之间还未进行同步 redis这时候主节点挂掉了 redis的从节点升级为主节点 业务线程-2 想新的主节点请求锁 业务线程-2 获取到新的主节点返回的锁 业务线程-2 获取到锁开始执行业务 这个时候 业务线程-1 和 业务线程-2 同时在执行任务 上述的问题其实并不是redis的缺陷，只是redis采用了AP模型，它本身无法确保我们对一致性的要求。 redis官方推荐redlock算法来保证，问题是redlock至少需要三个redis主从实例来实现，维护成本比较高，相当于redlock使用三个redis集群实现了自己的另一套一致性算法，比较繁琐，在业界也使用得比较少。 能否使用redis作为分布式锁？ 能不能使用redis作为分布式锁，这个本身就不是redis的问题，还是取决于业务场景，我们先要自己确认我们的场景是适合 AP 还是 CP ，如果在社交发帖等场景下，我们并没有非常强的事务一致性问题，redis提供给我们高性能的AP模型是非常适合的，但如果是交易类型，对数据一致性非常敏感的场景，我们可能要寻在一种更加适合的 CP 模型 基于zookeeper（CP）redis其实无法确保数据的一致性，先来看zookeeper是否合适作为我们需要的分布式锁，首先zk的模式是CP模型，也就是说，当zk锁提供给我们进行访问的时候，在zk集群中能确保这把锁在zk的每一个节点都存在。 1、zk锁实现的原理 特性： 有序节点 当在一个父目录下如 &#x2F;lock 下创建 有序节点，节点会按照严格的先后顺序创建出自节点 lock000001,lock000002,lock0000003,以此类推，有序节点能严格保证各个自节点按照排序命名生成。 临时节点 客户端建立了一个临时节点，在客户端的会话结束或会话超时，zookepper会自动删除该节点 事件监听 在读取数据时，我们可以对节点设置监听，当节点的数据发生变化时，zookeeper会通知客户端。 结合这几个特点，来看下zk是怎么组合分布式锁的 业务线程-1、业务线程-2 分别向zk的&#x2F;lock目录下，申请创建有序的临时节点 业务线程-1 抢到&#x2F;lock0001 的文件，也就是在整个目录下最小序的节点，也就是线程-1获取到了锁 业务线程-2 只能抢到&#x2F;lock0002的文件，并不是最小序的节点，线程2未能获取锁 业务线程-1 与 lock0001 建立了连接，并维持了心跳，维持的心跳也就是这把锁的租期 当业务线程-1 完成了业务，将释放掉与zk的连接，也就是释放了这把锁 2、zk分布式锁的代码实现 zk官方提供的客户端并不支持分布式锁的直接实现，我们需要自己写代码去利用zk的这几个特性去进行实现。 使用CP还是AP的分布式锁？首先得了解清楚我们使用分布式锁的场景，为何使用分布式锁，用它来帮我们解决什么问题，先聊场景后聊分布式锁的技术选型。 无论是redis，zk，例如redis的AP模型会限制很多使用场景，但它却拥有了几者中最高的性能，zookeeper的分布式锁要比redis可靠很多，但他繁琐的实现机制导致了它的性能不如redis，而且zk会随着集群的扩大而性能更加下降。 分布式事务如果说到事务，ACID是传统数据库常用的设计理念，追求强一致性模型，关系数据库的ACID模型拥有高一致性+可用性，所以很难进行分区，所以在微服务中ACID已经是无法支持，我们还是回到CAP去寻求解决方案，不过根据上面的讨论，CAP定理中，要么只能CP，要么只能AP，如果我们追求数据的一致性而忽略可用性这个在微服务中肯定是行不通的，如果我们追求可用性而忽略一致性，那么在一些重要的数据（例如支付，金额）肯定出现漏洞百出，这个也是无法接受；所以我们既要一致性，也要可用性。 都要是无法实现的，但我们能不能在一致性上作出一些妥协，不追求强一致性，转而追求最终一致性，所以引入BASE理论 BASE理论： 在分布式事务中，BASE最重要是为CAP提出了最终一致性的解决方案，BASE强调牺牲高一致性，从而获取可用性，数据允许在一段时间内不一致，只要保证最终一致性就可以了。 实现最终一致性1、弱一致性：系统不能保证后续访问返回更新的值。需要在一些条件满足之后，更新的值才能返回。从更新操作开始，到系统保证任何观察者总是看到更新的值的这期间被称为不一致窗口。 2、最终一致性：这是弱一致性的特殊形式；存储系统保证如果没有对某个对象的新更新操作，最终所有的访问将返回这个对象的最后更新的值。 BASE模型BASE模型是传统ACID模型的反面，不同与ACID，BASE强调牺牲高一致性，从而获得可用性，数据允许在一段时间内的不一致，只要保证最终一致就可以了。 Basically Available：基本可用，支持分区失败 Soft state：软状态，状态可以有一段时间不同步 Eventually consistent：最终一致，最终数据是一致的就可以了，而不是时时一致 分布式事务在分布式系统中，要实现分布式事务，无外乎几种解决方案。方案各有不同，不过其实都是遵循BASE理论，是最终一致性模型。 两阶段提交（2PC） 补偿事务（TCC） 本地消息表 MQ事务消息 1、两阶段提交（2PC） 其实还有一个数据库的XA事务，不过目前在真正的互联网中实际的应用基本很少，两阶段提交就是使用XA原理。 在 XA 协议中分为两阶段： 事务管理器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是否可以提交。 事务协调器要求每个数据库提交数据，或者回滚数据。 说一下，为何在互联网的系统中没被改造过的两阶段提交基本很少被业界应用，最最大的缺点就是同步阻塞问题，在资源准备就绪之后，资源管理器中的资源就一直处于阻塞，直到提交完成之后，才进行资源释放。这个在互联网高并发大数据的今天，两阶段的提交是不能满足现在互联网的发展。 还有就是两阶段提交协议虽然为分布式数据强一致性所设计，但仍然存在数据不一致性的可能，例如： 比如在第二阶段中，假设协调者发出了事务 Commit 的通知，但是因为网络问题该通知仅被一部分参与者所收到并执行了 Commit 操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。 2、补偿事务（TCC） TCC是服务化的两阶段变成模型，每个业务服务都必须实现 try，confirm，calcel三个方法，这三个方式可以对应到SQL事务中Lock，Commit，Rollback。 相比两阶段提交，TCC解决了几个问题 同步阻塞，引入了超时机制，超时后进行补偿，并不会像两阶段提交锁定了整个资源，将资源转换为业务逻辑形式，粒度变小。 因为有了补偿机制，可以由业务活动管理器进行控制，保证数据一致性。 1). try阶段 try只是一个初步的操作，进行初步的确认，它的主要职责是完成所有业务的检查，预留业务资源 2). confirm阶段 confirm是在try阶段检查执行完毕后，继续执行的确认操作，必须满足幂等性操作，如果confirm中执行失败，会有事务协调器触发不断的执行，直到满足为止 3). cancel是取消执行，在try没通过并释放掉try阶段预留的资源，也必须满足幂等性，跟confirm一样有可能被不断执行 一个下订单，生成订单扣库存的例子： 接下来看看，我们的下单扣减库存的流程怎么加入TCC 在try的时候，会让库存服务预留n个库存给这个订单使用，让订单服务产生一个“未确认”订单，同时产生这两个预留的资源， 在confirm的时候，会使用在try预留的资源，在TCC事务机制中认为，如果在try阶段能正常预留的资源，那么在confirm一定能完整的提交 在try的时候，有任务一方为执行失败，则会执行cancel的接口操作，将在try阶段预留的资源进行释放。 这个并不是重点要论tcc事务是怎么实现，重点还是讨论分布式事务在CAP+BASE理论的应用。实现可以参考：github.com&#x2F;changmingxi… 3、本地消息表 本地消息表这个方案最初是 eBay 提出的，eBay 的完整方案 queue.acm.org&#x2F;detail.cfm?… 本地消息表这种实现方式应该是业界使用最多的，其核心思想是将分布式事务拆分成本地事务进行处理。 对于本地消息队列来说，核心就是将大事务转变为小事务，还是用上面下订单扣库存的例子说说明 当我们去创建订单的时候，我们新增一个本地消息表，把创建订单和扣减库存写入到本地消息表，放在同一个事务（依靠数据库本地事务保证一致性） 配置一个定时任务去轮训这个本地事务表，扫描这个本地事务表，把没有发送出去的消息，发送给库存服务，当库存服务收到消息后，会进行减库存，并写入服务器的事务表，更新事务表的状态。 库存服务器通过定时任务或直接通知订单服务，订单服务在本地消息表更新状态。 这里须注意的是，对于一些扫描发送未成功的任务，会进行重新发送，所以必须保证接口的幂等性。 本地消息队列是BASE理论，是最终一致性模型，适用对一致性要求不高的情况。 4、MQ事务 RocketMq在4.3版本已经正式宣布支持分布式事务，在选择Rokcetmq做分布式事务请务必选择4.3以上的版本。 RocketMQ中实现了分布式事务，实际上是对本地消息表的一个封装，将本地消息表移动到了MQ内部。 事务消息作为一种异步确保型事务， 将两个事务分支通过 MQ 进行异步解耦，RocketMQ 事务消息的设计流程同样借鉴了两阶段提交理论，整体交互流程如下图所示： MQ事务是对本地消息表的一层封装，将本地消息表移动到了MQ内部，所以也是基于BASE理论，是最终一致性模式，对强一致性要求不那么高的事务适用，同时MQ事务将整个流程异步化了，也非常适合在高并发情况下使用。 基本理论什么是ZooKeeper？ZooKeeper 是一个开源的分布式应用程序协调服务器，其为分布式系统提供一致性服务。其一致性是通过基于 Paxos 算法的 ZAB 协议完成的。其主要功能包括：配置维护、分布式同步、集群管理、分布式事务等。 分布式和集群？ 比如，我现在有一个秒杀服务，并发量太大单机系统承受不住，那我加几台服务器也 一样 提供秒杀服务，这个时候就是 Cluster 集群 。 但是，我现在换一种方式，我将一个秒杀服务 拆分成多个子服务 ，比如创建订单服务，增加积分服务，扣优惠券服务等等，然后我将这些子服务都部署在不同的服务器上 ，这个时候就是 Distributed 分布式 。 加机器更加适用于构建集群，因为它真是只有加机器。 对于分布式来说，首先需要将业务进行拆分，然后再加机器（不仅仅是加机器那么简单），同时还要去解决分布式带来的一系列问题，比如各个分布式组件如何协调起来，如何减少各个系统之间的耦合度，分布式事务的处理，如何去配置整个分布式系统等等。ZooKeeper 主要就是解决这些问题的。 一致性问题 分布式系统必然存在的问题：CAP问题 例子：把一个班级当成一个系统，学生是系统中独立的子系统，小红和小明谈恋爱被小花发现了，小花告诉了周围的人，消息在班级里传播起来了。在消息传播过程中，你抓到一个同学问他情况，如果他不知道说明系统出现了消息不一致问题；如果他不回答你，说明系统出现了可用性问题。 为了解决数据一致性问题，出现了很多一致性协议和算法，比如2PC、3PC、Paxos算法等。 2PC（两阶段提交）涉及两个角色：协调者、参与者 第一阶段：当要执行一个分布式事务的时候 事务发起者首先向协调者发起事务请求 然后协调者给所有的参与者发送prepare请求（告诉参与者你们需要执行事务了，如果能执行就先执行但是不提交，执行后给我回复） 参与者收到prepare消息后，开始执行事务（但是不提交），并将Undo和Redo信息记入事务日志中，之后参与者向协调者反馈是否准备好（ready或not ready） 第二阶段：协调者根据反馈者的反馈决定接下来是否可以进行事务的提交 如果所有的参与者都返回ready消息，这个时候就进行事务的提交，协调者给所有的参与者发送commit请求，参与者收到commit请求时会执行事务的提交操作，提交完毕后给协调者发送提交成功的响应 如果不是所有参与者返回ready消息，协调者给所有的参与者发送rollback请求 带来的问题 单点故障：如果协调者挂了，整个系统都不可用了 阻塞问题：当协调者发送prepare请求，参与者如果可以处理就会进行事务处理但是不提交，就会一直占用资源，如果协调者挂了，这些资源也不会被释放 数据不一致问题：在第二阶段，协调者只发送一部分的commit请求就挂了，那么就意味着部分参与者会进行事务提交，这个时候就会出现不一致问题 3PC（三阶段提交） CanCommit阶段：协调者向所有参与者发送CanCommit请求，参与者收到请求后根据自己的情况查看是否能执行事务，如果可以则返回yes响应并进入预备状态，否则返回no； PreCommit阶段： 协调者根据参与者返回的响应来决定是否可以进行下面的preCommit操作。 如果参与者返回的都是yes，那么协调者将向所有参与者发送preCommit预提交请求，参与者收到预提交请求后会进行事务的执行操作，并将Undo和Redo信息记入事务日志中，最后如果参与者顺利执行了就返回成功的响应。 如果第一阶段协调者收到了一个no的信息，或者在一定时间没有收到全部参与者的响应，那么就会中断事务，向所有参与者发送中断请求，参与者一定时间没有收到协调者的请求也会中断； DoCommit阶段： 如果协调者收到了所有参与者的yes请求，那么协调者就会给所有参与者发送DoCommit请求，参与者收到请求后进行事务的提交，完成则会返回响应，协调者收到所有的成功响应后则完成事务。 若协调者在 PreCommit 阶段 收到了任何一个 NO 或者在一定时间内没有收到所有参与者的响应 ，那么就会进行中断请求的发送，参与者收到中断请求后则会 通过上面记录的回滚日志 来进行事务的回滚操作，并向协调者反馈回滚状况，协调者收到参与者返回的消息后，中断事务。 带来的问题 3PC缓解了阻塞问题，但是一致性没有得到根本的解决，比如在PreCommit阶段，当一个参与者收到请求后其他参与者和协调者挂了或者出现了网络分区，这个时候收到消息的参与者都会进行事务提交，出现数据不一致问题。 Paxos算法Paxos算法是基于消息传递且具有高度容错特性的一致性算法，其解决的问题就是在分布式系统中就某个值达成一致 三个角色：Proposer（提案者）、Acceptor（表决者）、Learner（学习者） 阶段： perpare阶段： Proposer（提案者）：提出proposal，每个提案者提出提案时都会首先获得到一个具有全局唯一性的、递增的提案编号N，即在整个集群中是唯一的编号N，然后将该变好赋予其要提出的提案，在第一阶段只将提案编号发送给所有表决者 Acceptor（表决者）：每个表决者在accept某个提案后，记录编号N在本地，这样每个表决者保存的已经被accept的提案中会存在一个编号最大的提案MaxN。每个表决者只会accept编号比本地MaxN大的提案，在批准提案时表决者会将以前接受过的最大编号的提案作为响应反馈给提案者 accepet阶段： 当一个提案被Proposer提出后，如果Proposer收到了超过半数的Acceptor的批准，那么此时Proposer会给所有的Acceptor发送真正的提案，发送内容和编号 Acceptor收到提案请求后再次比较本身已经批准过的最大提案编号和该提案编号，如果该提案编号大于等于已经批准的最大编号，就accept该提案，执行提案内容不提交，随后将情况返回给Proposer，如果不满足则不回应或者返回NO 当 Proposer 收到超过半数的 accept ，那么它这个时候会向所有的 acceptor 发送提案的提交请求。需要注意的是，因为上述仅仅是超过半数的 acceptor 批准执行了该提案内容，其他没有批准的并没有执行该提案内容，所以这个时候需要向未批准的 acceptor 发送提案内容和提案编号并让它无条件执行和提交，而对于前面已经批准过该提案的 acceptor 来说 仅仅需要发送该提案的编号 ，让 acceptor 执行提交就行了。 而如果 Proposer 如果没有收到超过半数的 accept 那么它将会将 递增 该 Proposal 的编号，然后 重新进入 Prepare 阶段 。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"Kafka","slug":"kafka","date":"2022-02-07T08:48:31.000Z","updated":"2022-02-07T13:50:49.851Z","comments":true,"path":"2022/02/07/kafka/","link":"","permalink":"http://example.com/2022/02/07/kafka/","excerpt":"","text":"引入1、Kafka是一个多分区、多副本且基于 ZooKeeper 协调的分布式消息系统，是一个分布式流式处理平台，以高吞吐、可持久化、可水平扩展、支持数据处理等多种特性被广泛使用 2、Kafka是一个分布式的基于发布&#x2F;订阅模式的消息队列 2、三大角色： 消息系统：系统解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等功能，还提供了消息顺序性保障和回溯消费功能 存储系统：持久化功能和多副本机制 流式处理平台：提供一个完整的流式处理类库，比如窗口、连接、变换、聚合等操作 消息队列1、应用场景—异步处理 2、好处 解耦 允许你独立的扩展或修改两边的处理过程，只需要确保它们遵守同样的接口约束 可恢复性 系统的一部分组件失效时，不会影响整个系统，消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列的消息仍然可以在系统恢复后被处理 缓冲 有助于控制和优化数据流经过系统的速度，解决生产和消费处理速度不一致的问题 灵活性 &amp; 峰值处理能力 在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而崩溃 异步通信 用户不需要立刻处理信息，消息队列提供了异步处理机制，允许用户把一个消息放入队列，但是不立刻处理。 3、消息队列的两种模式 点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除） 消息生产者生产消息后发送到queue中，然后消费者从queue中取出并且消费消息。消息被消费后queue中不再有存储，所以消费者不能消费到已经被消费的消息。queue支持存在多个消费者，但是对于一个消息只有一个消费者可以消费 发布&#x2F;订阅模式（一对多，消费者消费后不会清除消息） 消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息，和点对点的方式不同，发布到topic的消息会被所有订阅者消费 两种方式： 类似于公众号，topic队列进行主动推送 消费者主动拉取（Kafka），消费者可以控制自己的消费速度，但是需要长轮询来询问是否有新消息，比较浪费资源 Kafka基本概念Kafka体系结构： 若干生产者（Producer）：将数据发送到Broker 消费者：从Broker订阅并消费信息 消费者组：同一个消费者组内的不同消费者不能消费同一个分区数据 好处：提高消费能力 Kafka 集群（Kafka Cluster）包含若干Broker：将收到的消息存储到磁盘中（默认保存7天） Topic 主题 Partition 分区：为了实现拓展性，一个topic可以分布到多个broker上，每个partition是一个有序队列 Replica 副本：为了保证集群中某个节点发生故障时，该节点上的partition数据不丢失，且kafka能过继续工作，一个topic的每个分区都有若干副本（一个Leader和多个Follower） Leader：主，生产者发送数据的对象和消费者消费数据的对象 Follower：从，实时从leader同步数据，保持和leader数据同步 AR：分区中所有的副本 ISR：与leader副本保持一定程度同步的副本（包括leader副本） HW：高水位，标识特定的消息偏移量，消费者只能拉取这个offset之前的消息 LEO：标识当前日志文件下一条写入消息的offset ISR、HW、LEO的关系 初始状态： Leader消息：0、1、2 follower1消息：0、1、2 follower2消息：0、1、2 发送消息3、4（情况1：follower2只收到3） Leader消息：0、1、2、3、4 follower1消息：0、1、2、3、4 follower2消息：0、1、2、3 HW：4 ；LEO：5 发送消息3、4（情况2） Leader消息：0、1、2、3、4 follower1消息：0、1、2、3、4 follower2消息：0、1、2、3、4 HW：5 ；LEO：5 Zookeeper： 帮助kafka集群存储一些信息 帮助消费者存储消费的位置信息offset 0.9版本之前存储在zk 0.9版本之后存储在kafka本地 mac下Kafka的安装1、brew install kafka 2、修改配置文件，目录：/usr/local/etc/kafka/server.properties 1234567891011# broker的全局唯一编号，不能重复，int类型broker.id=0# 允许日志存储路径log.dirs=/usr/local/var/lib/kafka-logs# 存储时间：168个小时log.retention.hours=168# 配置zookeeperzookeeper.connect=localhost:2181/kafka 3、启动zookeeper 1zkServer.sh start 4、启动kafka 1kafka-server-start -daemon /usr/local/etc/kafka/server.properties 5、常见命令 12-- 列出所有topickafka-topics --zookeeper localhost:2181/kafka --list 123456-- 创建topickafka-topics --zookeeper localhost:2181/kafka --create --replication-factor 1 --partitions 3 --topic test--topic 定义topic名字--replication-factor 定义副本数--partitions 分区数 12-- 删除topickafka-topics --zookeeper localhost:2181/kafka --delete --topic test 12-- 详情kafka-topics --zookeeper localhost:2181/kafka --describe --topic test 12-- 生产者kafka-console-producer --topic test --broker-list localhost:9092 1234-- 消费者kafka-console-consumer --topic test --bootstrap-server localhost:9092 --from-beginning--from-beginning 从开头进行消费 kafka入门工作流程消息层次1、第一层：主题层 每个topic可以配置M个partition，每个partition可以设置N个副本 2、第二层：分区层 每个partition的N个副本中只能有一个充当领导的角色，对外提供服务；其他N-1个副本是追随者副本，只是提供数据冗余之用 3、第三层：消息层 partition包含若干条消息，每条消息的位移从0开始，依次递增 持久化数据1、消息日志（Log） kafka使用log（磁盘上一个只能追加写的物理文件，避免了缓慢的随机I&#x2F;O，该用性能较好的顺序I&#x2F;O）来保存数据 Kafka定期删除消息以回收磁盘 日志段机制（Log Segment）：将日志细分为多个日志段，消息被追加写入搭配当前最新的日志段中，写满一个日志段就自动切分一个新的日志段，将老的日志段封存起来，kakfa在后台有定时任务定期检查老的日志段是否能够被删除 消费者1、点对点模型（P2P） 消费者组（Consumer group）：把多个消费者实例（可以是一个进程，也可以是一个线程）共同组成一个组来消费一组主题 可以提高消费者端的吞吐量，多个消费者实例同时消费，加速整个消费端的吞吐量（TPS） 重平衡：消费者组里所有的消费者彼此协助，如果某个实例挂了，就会把这个实例负责的分区转移给其他消费者，kafka消费者实现高可用的重要手段 2、消费位移（offset） 随时变化，表示消费者的消费进度 每个消费者都有自己的消费者位移 是消息引擎系统也是分布式流处理平台1、Kafka设计之初的目的是为了提供三个方面的特性 提供一套API实现生产者和消费者 降低网络传输和磁盘存储开销 实现高伸缩性架构 2、kafka Streams 在大数据工程领域，Kafka在承接上下游、串联数据管道方面发挥重要的作用 Kafka于0.10.0.0版本推出流处理组件Kafka Streams 3、Kafka Streams的优势 容易实现端到端的正确性：处理一条消息有且只有一次机会能够影响系统状态 其他框架只能保证在读取kafka消息之后的计算对于状态的影响只有一次，但是计算结果可能多次写入kafka 对于流式计算的定位 4、分布式存储系统 kafka基本使用Kafka线上集群部署方案 集群：多个kafka节点机器 操作系统1、部署在Linux系统 I&#x2F;O模型的使用 数据网络传输效率 社区支持度 2、I&#x2F;O模型的使用 I&#x2F;O模型就是操作系统执行I&#x2F;O指令的方法 主流I&#x2F;O模型：阻塞式I&#x2F;O、非阻塞式I&#x2F;O、I&#x2F;O多路复用、信号驱动I&#x2F;O、异步I&#x2F;O java的Socket阻塞模式和非阻塞模式：阻塞式I&#x2F;O、非阻塞式I&#x2F;O Linux系统的select函数：I&#x2F;O多路复用 epoll系统调用：介于I&#x2F;O多路复用、信号驱动I&#x2F;O之间 kafka客户端使用java的selector，在linux的实现机制是epoll，在windows实现机制是select，因此部署在linux优势在于能够获得更高效的I&#x2F;O性能 3、网络传输效率 kafka生产消费的消息都是通过网络传输的，消息保存在磁盘，因此kafka需要在磁盘和网络间大量数据传输 Linux 零拷贝（zero copy）技术：避免将数据从磁盘复制到缓冲区，再将缓冲区数据发送到socket的性能损耗 RocketMQ 选择了 mmap + write 这种零拷贝方式，适用于业务级消息这种小块文件的数据持久化和传输； Kafka 采用的是 sendfile 这种零拷贝方式，适用于系统日志消息这种高吞吐量的大块文件的数据持久化和传输。但是值得注意的一点是，Kafka 的索引文件使用的是 mmap + write 方式，数据文件使用的是 sendfile 方式。 磁盘1、机械磁盘 or 固态硬盘？ 机械磁盘：成本低且容量大，但是容易损坏 固态硬盘：性能优势大，但是成本高 选择机械硬盘即可 kafka使用的方式多是顺序读写，一定程度上规避了机械磁盘的劣势（随机读写操作慢） kafka在软件方面可以保证机械硬盘因易损坏造成的可靠性差等缺陷 2、是否使用磁盘阵列（RAID）？ 使用RAID的优势：提供冗余的磁盘存储空间、提供负载均衡 kafka自身实现了冗余机制，通过分区也可以实现负载均衡 3、建议： 追求性价比的公司可以不搭建 RAID，使用普通磁盘组成存储空间即可 使用机械磁盘完全能够胜任 Kafka 线上环境。 磁盘容量1、需要多大存储空间？ kafka需要把消息存储在磁盘，默认存储一段时间后自动删除 kafka集群出了消息数据还有其它类型数据，比如索引数据等 例子：假设消息平均大小1KB，每天1亿条1KB消息，保存两份且留存两周，总的空间大小等于200GB，加上为其他数据预留的10%磁盘空间，共220GB，保存两周后整体容量大约3TB左右，kafka支持消息压缩，假设压缩0.75，即需要2.25TB空间 2、kafka规划磁盘容量需要考虑的因素 新增消息数量 消息留存时间 平均消息大小 备份数量 是否启用压缩 带宽1、带宽容易成为瓶颈 kafka通过网络大量进行数据传输 在真实案例当中，带宽资源不足导致 Kafka 出现性能问题的比例至少占 60% 以上，如果还涉及跨机房传输，那么情况可能就更糟了 一般公司网络使用普通以太网的1Gbps千兆网络，如何进行带宽资源的规划？ 真正需要规划的是kafka服务器的数量 假设机房环境是千兆网络，即 1Gbps，现在的业务目标是在 1 小时内处理 1TB 的业务数据。需要多少台 Kafka 服务器来完成这个业务呢？ 带宽1Gbps，即每秒处理1Gb数据，假设每台kafka服务器都在专属机器上，没有其他服务。通常kafka会用到70%的带宽资源（需要为其他进程留资源，超70%的阈值会出现网络丢包），也就是说kafka服务器最多使用大约700Mb的带宽资源 kafka服务器不能常规性使用这么多带宽资源，通常需要额外流出2&#x2F;3的资源，即每台服务器使用带宽240Mbps 如果需要1小时处理1TB数据，每秒需要处理2336Mb数据，除以240，约等于10台服务器，如果消息还需要额外复制两份，那么总的服务器需要乘以3，即30台 总结 集群参数配置 生产者1234567891011121314151617181920212223242526public class testProducer &#123; public static final String brokerList = &quot;localhost:9092&quot;; public static final String topic = &quot;test&quot;; public static Properties intConfig() &#123; Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, brokerList); props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(&quot;client.id&quot;, &quot;producer.client.id.demo&quot;); return props; &#125; public static void main(String[] args) &#123; Properties props = intConfig(); KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(topic, &quot;hello, Kafka 1&quot;); try &#123; RecordMetadata recordMetadata = producer.send(record).get(); System.out.println(recordMetadata.partition()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 发送消息1、生产者发送消息的三种方式：Fire and Fogret、同步、异步 12public Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; record) public Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; record, Callback callback) Fire and Fogret 1producer.send(new ProducerRecord&lt;String, String&gt;(&quot;my-topic&quot;, Integer.toString(i), Integer.toString(i))); 同步 12345方式一：producer.send(record).get()方式二： Future&lt;RecordMetadata&gt; future = producer.send(record) ; RecordMetadata metadata = future.get();System out.println(metadata top () + &quot;-&quot; + metadata.partition() + &quot;:&quot; + metadata.offset() ); 异步 123456789producer.send(myRecord,new Callback() &#123; public void onCompletion(RecordMetadata metadata, Exception e) &#123; if(e != null) &#123; e.printStackTrace(); &#125; else &#123; System.out.println(&quot;The offset of the record we just sent is: &quot; + metadata.offset()); &#125; &#125;&#125;); 源码分析 异步：调用dosend方法（同步的send，callback传了null，还是走了这个方法） 123456@Overridepublic Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; record, Callback callback) &#123; // intercept the record, which can be potentially modified; this method does not throw exceptions ProducerRecord&lt;K, V&gt; interceptedRecord = this.interceptors.onSend(record); return doSend(interceptedRecord, callback);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859private Future&lt;RecordMetadata&gt; doSend(ProducerRecord&lt;K, V&gt; record, Callback callback) &#123; TopicPartition tp = null; try &#123; throwIfProducerClosed(); // first make sure the metadata for the topic is available long nowMs = time.milliseconds(); ClusterAndWaitTime clusterAndWaitTime; try &#123; //这个方法就是一直在等一个条件，这个条件达到了就返回，否则一直等待超时退出。而这个条件就是当前的版本号要大于上个版本号。 clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), nowMs, maxBlockTimeMs); &#125; catch (KafkaException e) &#123; ..... &#125; nowMs += clusterAndWaitTime.waitedOnMetadataMs; long remainingWaitMs = Math.max(0, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs); Cluster cluster = clusterAndWaitTime.cluster; //序列化key、value byte[] serializedKey; serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key()); byte[] serializedValue; serializedValue = valueSerializer.serialize(record.topic(), record.headers(), record.value()); int partition = partition(record, serializedKey, serializedValue, cluster); //分区 tp = new TopicPartition(record.topic(), partition); setReadOnly(record.headers()); Header[] headers = record.headers().toArray(); int serializedSize = AbstractRecords.estimateSizeInBytesUpperBound(apiVersions.maxUsableProduceMagic(), compressionType, serializedKey, serializedValue, headers); ensureValidRecordSize(serializedSize); long timestamp = record.timestamp() == null ? nowMs : record.timestamp(); // callback Callback interceptCallback = new InterceptorCallback&lt;&gt;(callback, this.interceptors, tp); //result，添加到消息累加器 RecordAccumulator.RecordAppendResult result = accumulator.append (tp, timestamp, serializedKey,serializedValue, headers, interceptCallback, remainingWaitMs, true, nowMs); //如果是新的批次 if (result.abortForNewBatch) &#123; int prevPartition = partition; partitioner.onNewBatch(record.topic(), cluster, prevPartition); partition = partition(record, serializedKey, serializedValue, cluster); tp = new TopicPartition(record.topic(), partition); interceptCallback = new InterceptorCallback&lt;&gt;(callback, this.interceptors, tp); //result，添加到消息累加器 result = accumulator.append(tp, timestamp, serializedKey, serializedValue, headers, interceptCallback, remainingWaitMs, false, nowMs); &#125; 。。。。。。 return result.future;&#125; 2、如果想使用同步方式，其实是通过异步方式间接实现，因为异步方式返回的是一个future对象，在这对象上调用get方法，将被阻塞直到返回结果。 Future：表示一个任务的生命周期，并提供相应的方法判断任务是否已经完成或取消，以及获取任务的结果和取消任务等。 3、producer一般有两种类型异常：可重试异常、不可重试异常 可重试异常：网络异常、分区leader副本不可用 不可重试异常：消息太大 4、通常一个producer不会只负责发送单条消息，更多是发送多条消息，发送完这些消息后需要调用kafkaProducer的close方法回收资源 12public void close()public void close(long timeout , TimeUnit timeUnit) 序列化生产者需要使用序列化器（serializer）把对象转换成字节数组才能通过网络发送给kafka；消费者需要使用反序列化器（deserializer）把从kafka收到的字节数组转换成相应的对象 分区器 消息通过send方法发往broker过程中，有可能需要经过拦截器（非必需）、序列化器、分区器的一系列作用之后才能被真正发往broker 1、消息通过序列化之后需要确定它发往的分区，如果消息ProducerRecord没有指定partition字段，那么就需要依赖分区器，根据key这个字段来计算partition的值。 分区器的作用：为消息分配分区 2、默认分区器：org.apache.kafka.clients.producer.internals.DefaultPartitioner，实现了org.apache.kafka.clients.producer.Partitioner接口，定义了2个方法 12public int partition(String topic,Object key,byte[] keyBytes,Object value,byte[] valueBytes,Cluster cluster);public void close(); partition方法：计算分区号，返回int类型 close方法：关闭分区器的时候回收一些资源 拦截器1、两种拦截器 生产者拦截器：在消息发送前做一些准备工作、发送回调逻辑前做一些定制化需求 消费者拦截器 整体架构 1、整个生产者客户端由两个线程协调运行：主线程、sender线程 主线程：KafkaProducer创建消息，通过可能的拦截器、序列化器、分区器的作用后缓存到消息累加器 sender线程：从消息累加器中获取消息发送到kafka中 2、消息累加器 缓存消息以便sender线程可以批量发送，减少网络传输的资源消耗 缓存大小可以通过生产者客户端参数buffer.memory配置，默认32MB 如果生产者发送速度超过发往服务器的速度，就会导致生产者空间不足，这个时候send方法要么阻塞要么异常 主线程发送的消息会被追加到消息累加器的某个双端队列（Deque）中，队列的内容就是ProducerBatch，包含多个ProducerRecord 3、sender线程 获取消息后，进一步将原来&lt;分区,Deque&lt;ProducerBatch&gt;&gt;转换为&lt;Node,List&lt;ProducerBatch&gt;&gt;的形式，其中node表示kafka的broker节点 sender进一步封装成&lt;Node,Request&gt;的形式，发往各个node sender发送之前会保存到InFightRequest中，保持对象的形式是Map&lt;NodeId,Deque&lt;Request&gt;&gt;，主要是缓存已经发出去但是还没有收到响应的请求 重要参数1、acks 指定分区中必须有多少副本收到这条消息，之后生产者才认为消息是成功写入的 1：只要leader写入就会响应 0：不需要等待服务端响应 -1或者all：ISR中副本都成功写入就会响应 2、max.request.size 限制生产者发送消息的最大值，默认1MB 3、retries 生产者重试次数，默认0 4、linger.ms 生产者发送ProducerBatch之前等待更多消息（ProducerRecord）加入的时间，默认0 生产者消息分区机制为什么分区？1、kafka的消息组织方式 主题：主题下每条消息只会保存在某一个分区（同一topic消息不保证数据顺序性） 分区 消息 2、分区的作用：负载均衡、实现系统的高伸缩性 不同分区被放置到不同节点的机器上，数据的读写操作也是针对分区这个粒度进行的，每个节点的机器能够独立执行各自分区的读写请求 分区策略 分区策略：决定生产者把消息发送到哪个分区的算法 1、自定义配置分区策略 编写生产者程序时，编写具体的类实现org.apache.kafka.clients.producer.Partitioner接口 两个方法：partition()和close() topic、key、keyBytes、value和valueBytes都属于消息数据，cluster则是集群信息（比如当前 Kafka 集群共有多少主题、多少 Broker 等） 1int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster); 2、轮询策略 比如3个分区，那么第一条消息发送到分区0，第二条到分区1，第三条道分区2，以此类推。 Kafka Java 生产者API的默认分区策略 有非常优秀的负载均衡表现，最常用的策略之一 3、随机策略 随机把消息放置到任意一个分区 实现的partition方法：获取分区List，返回一个小于分区数量的随机数 12List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);return ThreadLocalRandom.current().nextInt(partitions.size()); 把数据均匀打散，逊色于轮询策略 4、按消息键保序策略 允许为每个消息定义消息key 保证一个key的消息放入一个分区，分区下的消息处理都是有序的 实现 12List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);return Math.abs(key.hashCode()) % partitions.size(); Kafka默认分区策略 如果指定key，默认按消息键保序策略 不指定key，使用轮询策略 如何保证消息的顺序？ 设置单分区，保证全局的顺序性，但是丧失了多分区的高吞吐量和负载均衡优势 按照消息的特点设置自定义分区策略，保证一个特点的消息发送到同一个分区，保证了消息的顺序 5、其他分区策略 按照地理位置分区 针对跨城市、跨国家的集群 生产者压缩算法1、压缩（compression） 时间换空间 用cpu时间换磁盘空间或网络I&#x2F;O传输量 怎么压缩？1、Kafka有两大消息格式：V1版本、V2版本（Kafka 0.11.0.0 中正式引入） 2、Kafka消息层次 消息集合（message set） 消息（message） Kafka通常不会直接操作具体一条条消息，总是在消息集合这个层面进行写入操作 3、V1和V2版本区别 v1：message、message set v2：record、record batch v2把消息的公共部分抽取出来放到外层消息集合，这样就不用每条消息都保存这些信息了 V1版本每条消息都需要执行CRC校验，但有些情况下消息的 CRC 值是会发生变化的，对每条消息都执行 CRC 校验就有点没必要了，不仅浪费空间还耽误 CPU 时间，因此在 V2 版本中，消息的 CRC 校验工作就被移到了消息集合这一层 保存压缩消息的方法发生了变化 V1 版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中；而 V2 版本的做法是对整个消息集合进行压缩 4、对两个版本分别做了一个简单的测试，结果显示，在相同条件下，不论是否启用压缩，V2 版本都比 V1 版本节省磁盘空间。当启用压缩时，这种节省空间的效果更加明显。 什么时候压缩？1、可能发生的两个地方：生产者、Broker 2、生产者端压缩 配置 compression.type 参数 123456789Properties props = new Properties();props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);props.put(&quot;acks&quot;, &quot;all&quot;);props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);// 开启GZIP压缩props.put(&quot;compression.type&quot;, &quot;gzip&quot;);Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); 比较关键的代码行是 props.put(“compression.type”, “gzip”)，它表明该 Producer 的压缩算法使用的是 GZIP。这样 Producer 启动后生产的每个消息集合都是经 GZIP 压缩过的，故而能很好地节省网络传输带宽以及 Kafka Broker 端的磁盘占用。 3、Broker端压缩 出现的情况： Broker与Producer使用的压缩算法不同，Broker会解压然后重新压缩; Broker 端发生了消息格式转换（为了兼容老版本引入） 什么时候解压？1、Producer端压缩、Broker端保持、Consumer端解压 kafka将使用的消息压缩算法封装到消息集合中 2、Broker端解压 目的：对消息执行各种验证 压缩算法对比1、2.1.0 版本之前，Kafka 支持 3 种压缩算法：GZIP、Snappy 和 LZ4。 2、从 2.1.0 开始，Kafka 正式支持 Zstandard 算法（简写为 zstd）。它是 Facebook 开源的一个压缩算法，能够提供超高的压缩比（compression ratio）。 最佳实践1、启用压缩的比较合适的时机 Producer程序运行机器上的cpu资源充足 带宽资源有限 如果客户端机器 CPU 资源有很多富余，强烈建议你开启 zstd 压缩，这样能极大地节省网络资源消耗 2、解压 对不可抗拒的解压缩无能为力，但至少能规避掉那些意料之外的解压缩（比如：为了兼容老版本引入的解压操作） Java生产者管理TCP连接为何采用TCP？ Apache Kafka通信都是基于TCP的 1、原因 从社区角度来看，在开发客户端时，人们能够利用 TCP 本身提供的一些高级功能，比如多路复用请求以及同时轮询多个连接的能力。 2、多路复用请求 将多个数据流合并到底层单一物理连接 TCP的多路复用请求会在一条物理连接上创建若干虚拟连接，每个虚拟连接负责流转对应的数据流 Kafka 生产者程序概览Kafka的Java生产者API主要对象就是KafkaProducer，通常开发生产者的步骤有4步： 构造生产者对象所需参数 利用参数创建KafkaProducer对象实例 使用KafkaProducer的send方法发送消息 同步生产者：这个生产者写一条消息的时候，它就立马发送到某个分区去。follower还需要从leader拉取消息到本地，follower再向leader发送确认，leader再向客户端发送确认。由于这一套流程之后，客户端才能得到确认，所以很慢。 异步生产者：这个生产者写一条消息的时候，先是写到某个缓冲区，这个缓冲区里的数据还没写到broker集群里的某个分区的时候，它就返回到client去了。虽然效率快，但是不能保证消息一定被发送出去了。 调用KafkaProducer的close方法关闭生产者并释放资源 当我们开发一个 Producer 应用时，生产者会向 Kafka 集群中指定的主题（Topic）发送消息，这必然涉及与 Kafka Broker 创建 TCP 连接。那么，Kafka 的 Producer 客户端是如何管理这些 TCP 连接的呢？ 何时创建TCP连接？1、时间：创建KafkaProducer对象实例的时候建立与Broker的TCP连接 在创建 KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会创建与 Broker 的连接 创建时会与bootstrap.servers（producer的一个参数）所有的broker建立连接 通常指定3～4台即可，因为一旦连接到一台broker就可以拿到整个集群的broker消息（发送METADATA请求，metadata消息） 2、KafkaProducer类是线程安全的 KafkaProducer 实例创建的线程和前面提到的 Sender 线程共享的可变数据结构只有 RecordAccumulator 类，故维护了 RecordAccumulator 类的线程安全，也就实现了 KafkaProducer 类的线程安全。 主要的数据结构是一个 ConcurrentMap。TopicPartition 是 Kafka 用来表示主题分区的 Java 对象，本身是不可变对象。而 RecordAccumulator 代码中用到 Deque 的地方都有锁的保护，所以基本上可以认定 RecordAccumulator 类是线程安全的 3、总结：TCP连接的创建时间 创建KafkaProducer实例时 更新元数据后（可能创建） 发现新的broker加入集群，需要和没有创建连接的Broker建立TCP连接 场景： 当producer尝试给一个不存在的topic发送信息，broker会告诉producer这个topic不存在，producer会发送METADATA请求给kafka集群获取最新的元数据信息 Producer 通过 metadata.max.age.ms 参数定期地去更新元数据信息（默认5分钟） 消息发送时（可能创建） 发现broker还没有建立连接 何时关闭TCP连接？1、关闭方式 用户主动关闭：producer.close() kafka自动关闭 2、Kafka自动关闭 与参数connections.max.idle.ms 的值有关（默认9分钟） 9分钟没有任何请求经过某个TCP连接，Kafka会主动关闭（Broker端发起），客户端会出现大量CLOSE_WAIT连接（客户端可能会hold住这个连接） 小结1、KafkaProducer 实例创建时启动 Sender 线程，从而创建与 bootstrap.servers 中所有 Broker 的 TCP 连接。 2、KafkaProducer 实例首次更新元数据信息之后，还会再次创建与集群中所有 Broker 的 TCP 连接。 3、如果 Producer 端发送消息到某台 Broker 时发现没有与该 Broker 的 TCP 连接，那么也会立即创建连接。 4、如果设置 Producer 端 connections.max.idle.ms 参数大于 0，则步骤 1 中创建的 TCP 连接会被自动关闭；如果设置该参数 &#x3D;-1，那么步骤 1 中创建的 TCP 连接将无法被关闭，从而成为“僵尸”连接。 幂等生产者和事务生产者 Kafka消息交付可靠性保障以及精确处理一次语义的实现 1、可靠性保障：kafka对生产者和消费者需要处理的消息提供的承诺 最多一次：消息可能会丢失，但是绝对不会重复 至少一次：消息不会丢失，可能会重复（Kafka默认） 精确一次：消息不会丢失，不会重复 2、至少一次（at least once） 只有生产者获得broker的应答才算发送成功，如果没有应答就会重试发送，可能会出现消息重复发送 3、最多一次（at most once） 禁止producer重试 4、精确一次（exactly once） Kafka通过两个机制来实现 幂等性（Idempotence） 事务（Transaction） 什么是幂等性？1、概念 在命令式编程语言（比如 C）中，若一个子程序是幂等的，那它必然不能修改系统状态。这样不管运行这个子程序多少次，与该子程序关联的那部分系统状态保持不变。 在函数式编程语言（比如 Scala 或 Haskell）中，很多纯函数（pure function）天然就是幂等的，它们不执行任何的 side effect 2、好处 可以安全的重试，反正也不会破坏系统状态 幂等性 Producer1、在Kafka 中，Producer 默认不是幂等性的 2、创建幂等性 Producer props.put(“enable.idempotence”, ture) Kafka自动帮你做消息的重复去重 3、底层原理 空间换时间：在Broker多保存一些字段：ProducerID、SequenceNumber ProducerID：每个producer初始化时会被分配一个唯一的id，对客户端不可见 SequenceNumber：producer发送的每个topic和partition都对应一个从0开始递增的值 4、作用范围 只能保证某个topic的一个partition不出现重复消息，无法实现多个分区的幂等 只能实现单会话的幂等 事务型 Producer1、事务 Kafka 自 0.11 版本开始也提供了对事务的支持，目前主要是在 read committed 隔离级别上做事情。它能保证多条消息原子性地写入到目标分区，同时也能保证 Consumer 只能看到事务成功提交的消息。 2、设置方法 开启 enable.idempotence = true。 设置 Producer 端参数 transactional.id，可以穿越多次对话 实现机制：两阶段提交（2PC）、事务协调器 代码调整 12345678910111213//初始化事务producer.initTransactions();try &#123; //开启事务 producer.beginTransaction(); producer.send(record1); producer.send(record2); //提交事务 producer.commitTransaction();&#125; catch (KafkaException e) &#123; //终止事务 producer.abortTransaction();&#125; 上述代码，Record1和Record2被当作一个事务提交，同时写入成功或失败，但是kafka还是会写入底层日志，也就是说消费者还是可以看见这些消息，因此需要设置消费者读取消息的参数： read_uncommitted：这是默认值，表明 Consumer 能够读取到 Kafka 写入的任何消息，不论事务型 Producer 提交事务还是终止事务，其写入的消息都可以读取。很显然，如果你用了事务型 Producer，那么对应的 Consumer 就不要使用这个值。 read_committed：表明 Consumer 只会读取事务型 Producer 成功提交事务写入的消息。当然了，它也能看到非事务型 Producer 写入的所有消息。 Kafka副本机制1、副本机制的概念 分布式系统在多台网络互联的机器上保存有相同的数据拷贝 2、副本机制好处 提供数据冗余 提供高伸缩性：支持横向扩展，能够通过增加机器的方式来提升读性能 改善数据局部性：允许将数据放入与用户地理位置相近的地方 Kafka的副本机制只提供了数据冗余 副本定义1、副本的概念实际上是在分区层级下定义的，每个分区有若干副本 2、本质：只能追加写消息的提交日志 同一个分区下的所有副本保存相同的消息序列，分散在不同的broker上 3、相关概念 AR：分区中所有副本 ISR：与leader保持同步的副本集合 LEO：标识每个分区最后一条消息的下一个位置，每个副本都有自己的LEO HW：ISR最小的LEO，消费者只能拉取到HW之前的消息 副本角色 如何保证副本中所有消息都一致？ 解决：基于领导者的副本机制 1、工作原理 副本分为两类：领导者副本（每个分区创建时选举）、追随者副本 追随者副本不对外提供服务，唯一的任务：从领导者副本异步拉取消息，写入自己的提交日志 当领导者副本宕机时，zookeeper提供的监控功能能够实时感知到，并立即开始新一轮的领导者选举 2、为什么要这么设计？ 方便实现“Read-your-writes” Read-your-writes：当使用生产者API向kafka成功写入消息后，马上使用消费者API去读取生产的消息 方便实现单调读 单调读：对于一个消费者用户在多次消费消息时不会看到某条消息一会村庄一会不存在（一致性） In-sync Replicas（ISR） 追随者副本异步拉取领导者副本的消息，异步就会存在不可能与Leader实时同步的风险 1、ISR副本集合 ISR副本都是和Leader同步的副本，不在ISR的副本就是不同步的 Leader副本必然在ISR中 动态调整 2、判断是否同步的标准 Broker参数：replica.lag.time.max.ms，表示追随者副本能够落后领导者副本的最长时间间隔，默认10s；只要不连续超过10s就认为是同步的 Unclean 领导者选举 ISR是动态调整的，自然会出现ISR为空的情况，即leader副本挂了，kafka需要选举一个新的leader，但是ISR为空，如何选举呢？ 1、Kafka把所有不在ISR的存活副本称为非同步副本，在kafka中选举这种副本的过程称为Unclean领导者选举 2、设置：Broker参数unclean.leader.election.enable（建议不开启） 3、可能会造成数据丢失，但是至少不至于停止对外服务，因此提高了高可用性 4、CAP理论 C：一致性 A：可用性 P：分区容错性 Controller1、Controller是kafka最核心的组件 为集群所有主题分区选举领导者副本 承载集群的全部元数据信息，并负责将这些信息同步到其他broker上 2、Controller启动：kafka集群中每个broker启动时会实例化一个kafkaController类，该类会执行一系列业务逻辑，选举出主题分区的Leader节点，步骤如下： 第一个启动的代理节点，会在Zookeeper系统里面创建一个临时节点&#x2F;controller，并写入该节点的注册信息，使该节点成为控制器； 其他的代理节点陆续启动时，也会尝试在Zookeeper系统中创建&#x2F;controller节点，但是由于&#x2F;controller节点已经存在，所以会抛出“创建&#x2F;controller节点失败异常”的信息。创建失败的代理节点会根据返回的结果，判断出在Kafka集群中已经有一个控制器被成功创建了，所以放弃创建&#x2F;controller节点，这样就确保了Kafka集群控制器的唯一性； 其他的代理节点，会在控制器上注册相应的监听器，各个监听器负责监听各自代理节点的状态变化。当监听到节点状态发生变化时，会触发相应的监听函数进行处理。 3、Kafka Contoller本质上就是一个broker 4、Broker选举的过程是在zk创建&#x2F;controller临时节点，每个broker会对&#x2F;controller节点添加监听器，以此坚挺此节点的数据变化，当&#x2F;controller节点发生变化就会触发选举 5、分区Leader选举 基本策略：按照AR集合（全部副本）中副本的顺序查找第一个存活的副本，并且这个副本在ISR集合中 AR副本顺序不变，ISR副本顺序可能会改变 消费者123456789101112131415161718192021222324252627282930313233343536public class testConsumer &#123; public static final String brokerList = &quot;localhost:9092&quot;; public static final String topic = &quot;test&quot;; public static final String groupid = &quot;group.demo&quot;; public static final AtomicBoolean isRunning =new AtomicBoolean(true); public static Properties initConfig() &#123; Properties props = new Properties(); props.put(&quot;key.deserializer&quot;,&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); props.put(&quot;value.deserializer&quot;,&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); props.put(&quot;bootstrap.servers&quot;, brokerList); //消费组名称 props.put(&quot;group.id&quot;, groupid); //对应客户端id props.put(&quot;client.id&quot;,&quot;consumer.client.id.demo&quot;); return props; &#125; public static void main(String[] args) &#123; Properties props = initConfig(); KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props); consumer.subscribe(Arrays.asList(topic)); try&#123; while (isRunning.get())&#123; ConsumerRecords&lt;String ,String&gt; records = consumer.poll(Duration.ofMillis(1000)); for(ConsumerRecord&lt;String,String&gt; record : records)&#123; System.out.println(record.value()); &#125; &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; consumer.close(); &#125; &#125;&#125; 消费者组1、什么是消费者组？ Kafka提供的可扩展且具有容错性的消费者机制 组内多个消费者共享一个Group ID 消费者组内所有消费者消费topic的所有partition，但是每个partition只能被一个消费者消费 同一个分区也可以被其他消费者组消费 2、消息引擎模型：P2P、发布&#x2F;订阅模型 P2P：伸缩性差，下游多个消费者需要抢消息 发布&#x2F;订阅模型：伸缩性不够，每个订阅者需要订阅所有分区 消费者组解决了这个缺陷 如果所有实例都是一个group（每个消息只被组内的一个消费者消费），那么实现的就是消息队列模型 如果实例不是一个group（不同组的消费者可以同时消费一个消息），实现发布&#x2F;订阅模型 3、group下消费者的数量 理想情况下，消费者数量和topic的partition数量一致 4、针对消费组，kafka如何管理offset？ 消费者在消费过程中需要记录自己消费了多少数据，即消费位置信息 对于消费者组，offset是一组KV（key是分区，V是该分区的最新位移），但是kafka源码的数据结构比这个复杂的多 对于老版本，位移保存在Zookeeper中，减少了broker端的状态保存开销 在新版本中，位移保存在kafka内部topic中（__consumer_offsets） 5、重平衡（Rebalance） 本质上是一种协议，规定了一个group下所有消费者如何达成一致，来分配订阅topic的每个分区； 比如一个有20个consumer的group订阅了一个100个partition的topic，正常情况下kafka会为每个consumer分配5个partition，这个分配过程为重平衡 触发条件 conusmer实例数量发生变化 订阅的topic数量发生变化 订阅的topic的partition数量发生变化 分配策略（consumer如何知道应该消费哪些分区） Range分配策略：对同一个topic的partition按照序号进行排序，按照消费者线程的字母顺序进行排序，然后用分区数量除以消费者线程数量，剩下的前面几个消费者多消费一个分区 RoundRobin分配策略：将消费者和partition按照字典序排序，然后通过轮询算法诸葛分配给每个消费者 Sticky分配策略 缺点 重平衡的时候所有消费者实例会停止消费 目前的设计所有的消费者都需要参与重平衡，不够高效 速度慢 订阅主题和分区1、方法：subscribe()，可以订阅多个主题 1234567public void subscribe(Collect on&lt;String&gt; toplics, ConsumerRebalanceListener listener) //集合public void subscribe(Collection&lt;String&gt; topics) public void subscribe (Pattern pattern, ConsumerRebalanceListener listener) //正则表达式public void subscribe (Pattern pattern) 2、方法：assign() 1public void assign(Collection&lt;TopicPartition&gt; partition) 指定需要订阅的分区集合 ToplicPartition：partition、topic属性 3、区别 subscribe()方法支持消费者重平衡 消息消费1、kafka消息消费是一个不断轮询的过程，消费者需要重复调用poll()方法，返回的是订阅的一组消息 1public ConsumerRecords&lt;K, V&gt; poll(final Duration timeout) timeout：控制方法的阻塞时间，在没有可用数据的时候会发生阻塞，设为0会立刻返回，不管是否有消息 2、ConsumerRecord 1234567891011121314151617181920public class ConsumerRecord&lt;K, V&gt; &#123; //主题名称 private final String topic; //分区编号 private final int partition; //消息偏移量 private final long offset; private final long timestamp; private final TimestampType timestampType; private final int serial zedKeySize; private final int serializedValueSize; //消息头部内容 private final Headers headers; //消息的键 private final K key ; //消息的值 private final V value ; private volatile Long checksum; //省略若干方法&#125; 3、ConsumerRecords poll方法返回的是ConsumerRecords，表示一次拉取操作获得的消息集，内部包含若干ConsumerRecord，提供了一个iterator()方法遍历消息内部的消息 可以按照分区维度获取消息，提供了records(TopicPartition)方法获取消息中指定分区的消息，partitions()获取消息集中所有分区 位移主题1、主题名称：__consumer_offsets 2、出现背景 老版本的位移存储在zk中，但是zk不适合高频写的操作，因此新版本中使用位移主题管理位移 3、位移管理机制 将consumer的位移数据作为一条普通的kafka消息提交到__consumer_offsets中 这就是个普通的kafka主题，但是消息格式是kafka自定义的，用户不能修改，也就是说不能往这个主题随意写消息，如果写的话broker会出现崩溃（消息格式不一致） 4、消息格式 格式1：存储格式可以简单理解为KV对 key保存的内容：group id、topic、partition号 value保存的内容：位移值、时间戳等元数据 格式2：保存消费者组信息的消息，注册group 格式3：tombstone 消息（墓碑消息） 用于删除group过期位移、删除group的消息 一旦group下的所有consumer都停止了，并且他们的位移数据都被删除时会写入这个消息，表示彻底删除group 5、什么时候创建？ Kafka集群第一个consumer程序启动时自动创建 分区数：50；副本数：3 6、consumer如何提交位移？ 自动提交：只要consumer一直启动就会一直写入消息，无消费的时候也会一直写入这个位移 默认每隔5s拉取每个分区最大的消息位移进行提交 问题：延时提交、重复提交 手动提交：调用API 异步提交、同步提交 7、删除过期消息 方法：整理（compaction） 使用Compact策略删除位移主题的过期消息，避免该主题无限膨胀 如何定义过期？ 同一个key的两条消息M1和M2，M1发送时间早，那么就是过期消息 过程 扫描日志所有信息，剔除过期消息，整理剩下的消息 定期巡检等待整理主题的线程：Log Cleaner 重平衡1、新版的消费者客户端对此进行了重新设计，将全部消费组分成多个子集，每个消费组的子集在服务端对应一个 GroupCoordinator 进行管理， GroupCoordinator是Kafka 服务端中用于管理消费组的组件。而消费者客户端中的 ConsumerCoordinator 组件负责与 GroupCoordinator交互 ConsumerCoordinator和GroupCoordinator之间最重要的职责就是负责执行消费者重平衡的操作，包括分区分配工作也是在重平衡期间完成 2、触发重平衡的操作 有新的消费者加入消费者组 消费者下线，不一定真的下线，可能是长时间GC、网络延迟导致消费者长时间没有向GroupCorrdinator发送心跳 消费者退出（leaveGroupRequest请求） 消费者的GroupCoorinator节点发生变化 消费者组订阅的任一topic或者partition数量发生变化 当有消费者加入消费者组时，消费者、消费组及协调器会经历以下阶段 3、第一阶段（find_coordinator） 目的：消费者需要确定所属消费组对应的groupCoordinator所在的broker，并与该broker创建相互通信的网络连接 步骤： 如果消费者已经保存了对应协调器节点的信息就进入第二阶段 向集群负载最小的节点发送FindCoordinatorRequest请求来查找对应的GroupCoordinator FindCoordinatorRequest请求体：消费组名称（group id） kafka收到FindCoordinatorRequest请求后根据groupid查找对应的GroupCoordinator节点，如果找到对应的就会返回其对应的node_id、host、port信息 查找方法： 根据groupid的哈希值计算__consumer_offsets中分区的编号 寻找此分区leader副本所在的broker节点，该节点就是为这个groupid所对应的GroupCoordinator节点 消费者组groupid最终的分区方案及组内消费者所提交的消费位移信息都会发送给此分区leader副本所在的broker节点 4、第二阶段（join_group） 目的：加入消费组 步骤： 向groupCoordinator发送JoinGroupRequest请求 参数： groupId session_timeout（心跳时间） rebalance_timeout（重平衡的时候GroupCoordinator等待各个消费者重新加入的最长等待时机） member_id（消费者id，第一次发送时为null） 服务端接收到请求后交给GroupCoordinator处理；对请求进行合法性校验，给第一次请求加入的消费者生成member_id 选举消费组的leader 如果还没有leader，第一个加入消费组的消费者为leader 如果leader退出了消费组，会进行重新选举，过程很随意 在GroupCoordinator中消费者信息以HashMap存储，key为消费者id，value为元数据 选举时取hashMap第一个键值对 选举分区分配策略 每个消费者都可以设置自己的分区分配策略，消费组的策略需要进行选举投票，过程如下： 收集各个消费者支持的所有分配策略，组成候选集candidates 每个消费者从候选集中找出第一个自身支持的策略，投上一票 得分多的策略为消费组的策略 5、第三阶段（sync_group） 目的：转发同步分区分配方案；各个消费者给GroupCoordinator发送SyncGroupRequest请求来同步分配方案 6、第四阶段（heartbeat） 目的：消费者确定拉取消息的其实位置 消费者通过向GroupCoordinator发送心跳来维持他们与消费组的从属关系，心跳线程是一个独立的线程；如果消费者停止发送心跳的时间足够长整个会话就会判定过期 能够避免重平衡吗？1、在Rebalance 过程中，所有 Consumer 实例共同参与，在协调者组件的帮助下，完成订阅主题分区的分配，整个过程中所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。 2、协调者（Coordinator） 专门为group服务，负责group执行重平衡以及提供位移管理等 consumer提交位移时是向coordinator所在的broker提交位移 当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作 所有的broker都有自己的coordinator组件 group如何确定为它服务的coordinator在哪个broker上？ 确定位移主题__consumer_offsets的哪个分区保存该group的数据 找到该分区leader副本所在的broker，该broker即对应的coordinator 3、目前，无法解决重平衡慢的问题，所以选择避免重平衡，重平衡发生的时机有三个： group成员数量变化 增加：通常都是计划内的，不属于需要避免的不必要重平衡 减少：除了计划内的，某些情况下协调者会错误认为消费者已经停止 consumer需要定期给coordinator发送心跳请求，如果不能及时发送就会被误认为这个consumer挂了，默认10s consumer消费时间过长（默认5分钟），可以预留足够的时间避免这个情况 topic数量变化 partition数量变化 多线程开发消费者实例Kafka Java Consumer设计原理1、单线程设计，从0.10.1.0版本开始变为双线程（用户主线程+心跳线程） 用户主线程：启动Consumer应用程序main方法的那个线程 心跳线程：负责定期给broker机器发送心跳请求 2、单线程的设计容易实现 多线程方案1、KafkaConsumer类不是线程安全的 所有的I&#x2F;O处理都发生在用户主线程中，因此你需要确保线程安全 2、方案一：消费者启动多个线程，每个线程维护专属的KafkaConsumer实例，负责完整的消息获取、处理 3、方案二：消费者使用单或多线程获取消息，同时创建多个消费线程执行消费处理逻辑 消费者管理TCP连接什么时候创建TCP连接？1、消费者的入口是KafkaConsumer类，和生产者不同，创建实例时没有创建TCP连接 2、TCP连接在调用KafkaConsumer.poll方法时被创建 3、在poll方法内部有3个时机可以创建TCP连接 发起FindCoordinator请求时 当消费者程序首次启用调用poll方法时，需要向kafka集群发送FindCoordinator请求，希望kafka告诉他哪个broker是管理它的协调者 连接协调者时 broker处理完上一步发送的请求后会返回response，告诉消费者哪个是协调者，因此在这一步消费者会创建连向该broker的TCP连接 消费数据时 消费者会为每个要消费的分区创建与该分区leader副本所在broker连接的TCP 创建多少个TCP连接？1、通常来说，消费者程序会创建 3 类 TCP 连接： 确定协调者和获取集群元数据。 连接协调者，令其执行组成员管理操作。 执行实际的消息获取。 删除TCP连接和生产者类似，消费者关闭 Socket 也分为主动关闭和 Kafka 自动关闭 主动关闭：是指你显式地调用消费者 API 的方法去关闭消费者，具体方式就是手动调用 KafkaConsumer.close() 方法，或者是执行 Kill 命令，不论是 Kill -2 还是 Kill -9； 自动关闭：是由消费者端参数 connection.max.idle.ms 控制的，该参数现在的默认值是 9 分钟，即如果某个 Socket 连接上连续 9 分钟都没有任何请求“过境”的话，那么消费者会强行“杀掉”这个 Socket 连接。 和生产者有些不同的是，如果使用了循环的方式来调用 poll 方法消费消息，那么上面提到的所有请求都会被定期发送到 Broker，因此这些 Socket 连接上总是能保证有请求在发送，从而也就实现了“长连接”的效果。 针对上面提到的三类 TCP 连接，你需要注意的是，当第三类 TCP 连接成功创建后，消费者程序就会废弃第一类 TCP 连接，之后在定期请求元数据时，它会改为使用第三类 TCP 连接。也就是说，最终你会发现，第一类 TCP 连接会在后台被默默地关闭掉。对一个运行了一段时间的消费者程序来说，只会有后面两类 TCP 连接存在。 重要参数1、fetch.min.bytes 拉取的最小数据量，默认1B 如果小于这个值就需要进行等待 2、fetch.max.bytes 拉取的最大数据量，默认50MB 3、fetch.max.wait.ms 指定kafka等待的时间，默认500ms 4、max.poll.records 一次拉取的最大消息数量，默认500条 5、heartbeat.interval.ms 使用kafka分组管理时，心跳到消费者协调器之间的预计时间 默认3000ms 6、connections.max.idle.ms 指定多久之后关闭限制的连接，默认9分钟 实现无消息丢失配置 kafka在什么情况下能保证消息不丢失？ 只对已提交的消息做有限度的持久化保证 已提交：kafka集群收到消息并写入日志 有限度：在保证存放消息的broker至少有一个存活的前提下保证消息成功持久化 “消息丢失”案例生产者程序丢失数据 目前Kafka Producer是异步发送消息的，调用的是producer.send(msg)这个API，通常会立刻返回，但是此时不能认为消息成功发送 导致发送失败的因素： 网络抖动，消息未到broker 消息不合格，broker拒绝接受（比如消息过大等） 解决方案 Producer永远要使用带回调通知的发送API，使用producer.send(msg,callback)这个API，callback可以准备告诉你消息是否提交成功 消费者程序丢失数据 Conusmer端要消费的消息不见了 Consumer 程序有个“位移（offset）”的概念，表示的是这个 Consumer 当前消费到的 Topic 分区的位置 如上图，对于Consumer A 而言，它当前的位移值就是 9；Consumer B 的位移值是 11 1、使用位移的步骤（顺序不能颠倒） 读取数据 更新位移 顺序颠倒会导致消息丢失 问题：消息重复处理 2、消费者程序丢失消息的原因 先更新位移后读取数据 多线程异步处理消息，如果某个线程运行失败了，位移已经被更新了 解决：手动提交位移 最佳实践1、不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。记住，一定要使用带有回调通知的 send 方法。 2、设置 acks = all。acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。 3、设置 retries 为一个较大的值。这里的 retries 同样是 Producer 的参数，对应前面提到的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries &gt; 0 的 Producer 能够自动重试消息发送，避免消息丢失。 4、设置 replication.factor &gt;&#x3D; 3。这也是 Broker 端的参数。其实这里想表述的是，最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余。 5、设置 min.insync.replicas &gt; 1。这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。 6、确保 replication.factor &gt; min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 replication.factor &#x3D; min.insync.replicas + 1。 7、确保消息消费完成再提交。Consumer 端有个参数 enable.auto.commit，最好把它设置成 false，并采用手动提交位移的方式。就像前面说的，这对于单 Consumer 多线程处理的场景而言是至关重要的。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"从尾到头打印链表","slug":"1、从尾到头打印链表","date":"2022-02-04T15:25:35.000Z","updated":"2022-02-08T09:57:42.793Z","comments":true,"path":"2022/02/04/1、从尾到头打印链表/","link":"","permalink":"http://example.com/2022/02/04/1%E3%80%81%E4%BB%8E%E5%B0%BE%E5%88%B0%E5%A4%B4%E6%89%93%E5%8D%B0%E9%93%BE%E8%A1%A8/","excerpt":"","text":"问题描述 我的代码1234567891011121314151617181920212223242526/*** public class ListNode &#123;* int val;* ListNode next = null;** ListNode(int val) &#123;* this.val = val;* &#125;* &#125;**/import java.util.ArrayList;public class Solution &#123; public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; ArrayList&lt;Integer&gt; list = new ArrayList(); while(listNode!=null)&#123; list.add(listNode.val); listNode = listNode.next; &#125; ArrayList&lt;Integer&gt; l = new ArrayList(); for(int i=list.size()-1;i&gt;=0;--i)&#123; l.add(list.get(i)); &#125; return l; &#125;&#125; 主要问题 &#x3D;&#x3D;在ArrayList插入数据时，只会进行正向插入，导致需要多进行一次循环将集合倒序。&#x3D;&#x3D; 解决办法迭代方法非递归方法，循环遍历链表时将数据倒序插入集合之中。 &#x3D;&#x3D;ArrayList 中有个方法是 add(index,value)，可以指定 index 位置插入 value 值。&#x3D;&#x3D;所以我们在遍历 listNode 的同时将每个遇到的值插入到 list 的 0 位置，最后输出 listNode 即可得到逆序链表。 123456789101112import java.util.*;public class Solution &#123; public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); ListNode tmp = listNode; while(tmp!=null)&#123; list.add(0,tmp.val); tmp = tmp.next; &#125; return list; &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(n) 递归方法由于最终要求**&#x3D;&#x3D;先进后出，想到利用栈&#x3D;&#x3D;**。利用递归方法，用系统的栈帮忙打印。 1234567891011import java.util.*;public class Solution &#123; ArrayList&lt;Integer&gt; list = new ArrayList(); public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; if(listNode!=null)&#123; printListFromTailToHead(listNode.next); list.add(listNode.val); &#125; return list; &#125;&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(n)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}]},{"title":"用两个栈实现队列","slug":"29、用两个栈实现队列","date":"2022-02-04T15:25:35.000Z","updated":"2022-02-08T10:17:24.540Z","comments":true,"path":"2022/02/04/29、用两个栈实现队列/","link":"","permalink":"http://example.com/2022/02/04/29%E3%80%81%E7%94%A8%E4%B8%A4%E4%B8%AA%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/","excerpt":"","text":"问题描述 主要问题 没有明白题意，对Java的Stack类不够熟悉。 解决办法模拟法如果我知道队列是FIFO，栈是FILO，但是这道题我还是不知道怎么写怎么办？对于这种感觉不难，但是又不会写的，方法就是模拟。比如有如下操作：(pop操作确保栈中有元素） 1push(1);push(2);pop(3);push(4); 根据队列的特性，只能pop(1),pop(2),pop之后的结果 上述是队列的操作。 当push的时候，我们必须要用一个stack来存，假设用stack1来存。 那么push操作解决了。那么pop操作怎么办呢？如果pop(1)，但是此时在stack1的栈底，如果要pop，必须再将stack1中的数据push到stack2中，然后再pop，如图 这样直接弹出stack2的栈顶就可以了。如果要继续pop，那就继续弹出stack2就可以了 但是现在总感觉哪里还是有点问题。如果是这样就继续测试几个例子。如果push(5)， 所以最后总结一下：push操作就直接往stack1中push， pop操作需要分类一下：如果stack2为空，那么需要将stack1中的数据转移到stack2中，然后在对stack2进行pop，如果stack2不为空，直接pop就ok。 12345678910111213141516171819202122import java.util.Stack;public class Solution &#123; Stack&lt;Integer&gt; stack1 = new Stack&lt;Integer&gt;(); Stack&lt;Integer&gt; stack2 = new Stack&lt;Integer&gt;(); public void push(int node) &#123; stack1.push(node); &#125; public int pop() &#123; if(stack2.isEmpty()&amp;stack1.isEmpty())&#123; throw new RuntimeException(&quot;队列中没有元素，无法删除！&quot;); &#125; if(stack2.isEmpty())&#123; while(!stack1.isEmpty())&#123; stack2.push(stack1.pop()); &#125; &#125; return stack2.pop(); &#125;&#125; 复杂度分析 时间复杂度：O(1) 空间复杂度：O(n)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"栈和队列","slug":"算法/剑指offer/栈和队列","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"栈和队列","slug":"算法/剑指offer/栈和队列","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/"}]},{"title":"合并两个排序的链表","slug":"3、合并两个排序的链表","date":"2022-02-04T12:18:24.000Z","updated":"2022-02-08T09:58:50.968Z","comments":true,"path":"2022/02/04/3、合并两个排序的链表/","link":"","permalink":"http://example.com/2022/02/04/3%E3%80%81%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%8E%92%E5%BA%8F%E7%9A%84%E9%93%BE%E8%A1%A8/","excerpt":"","text":"问题描述 我的代码12345678910111213141516171819202122232425262728293031323334353637383940414243/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode Merge(ListNode list1,ListNode list2) &#123; ListNode node,p; if(list1 == null)&#123; return list2; &#125;else if(list2 == null)&#123; return list1; &#125; if(list1.val&lt;=list2.val)&#123; node = list1; list1 = list1.next; &#125;else&#123; node = list2; list2 = list2.next; &#125; p = node; while(list1!=null&amp;list2!=null)&#123; if(list1.val&lt;=list2.val)&#123; node.next = list1; list1 = list1.next; &#125;else&#123; node.next = list2; list2 = list2.next; &#125; node = node.next; &#125; if(list1 == null)&#123; node.next = list2; &#125;else&#123; node.next = list1; &#125; return p; &#125;&#125; 主要问题 没有考虑到开始时如果存在空链表的情况应该怎么办 在链表连接后向后遍历时，过程过于复杂 解决办法迭代解法思路与上述解决方法一致 技巧：一般创建单链表，都会设一个虚拟头结点，也叫哨兵，因为这样每一个结点都有一个前驱结点。 复杂度分析 时间复杂度：O(m+n)，m，n分别为两个单链表的长度 空间复杂度：O(1) 递归解法123456789101112131415161718192021222324252627/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode Merge(ListNode list1,ListNode list2) &#123; if(list1==null)&#123; return list2; &#125; else if(list2==null)&#123; return list1; &#125; if(list2.val&gt;list1.val)&#123; list1.next = Merge(list1.next,list2); return list1; &#125; else&#123; list2.next = Merge(list1,list2.next); return list2; &#125; &#125;&#125; 复杂度分析 时间复杂度：O(m+n) 空间复杂度：O(m+n)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}]},{"title":"反转链表","slug":"2、反转链表","date":"2022-02-04T11:25:35.000Z","updated":"2022-02-08T09:58:08.124Z","comments":true,"path":"2022/02/04/2、反转链表/","link":"","permalink":"http://example.com/2022/02/04/2%E3%80%81%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/","excerpt":"","text":"问题描述 我的代码12345678910111213141516171819202122232425262728293031323334353637383940414243/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode ReverseList(ListNode head) &#123;// 空链表直接返回 if(head==null||head.next == null)&#123; return head; &#125; ListNode temp = new ListNode(0); ListNode node = null; while(head!=null)&#123; if(node == null)&#123; temp.val = head.next.val; temp.next = head; node = temp; temp = head.next; head.next = null; head = temp.next; temp.next = null; &#125;else&#123; temp.val = head.val; temp.next = node; node = temp; temp = head; if(temp.next!=null)&#123; head = temp.next; &#125;else&#123; head = null; &#125; temp.next = null; &#125; &#125; return node; &#125;&#125; 主要问题 想要通过只创建一到两个新结点的方法利用循环解决问题以减少空间复杂度，但是没有考虑到头结点在开始、结束以及中间位置时情况不同导致的算法复用率较低的问题，是代码极为繁琐。 解决办法使用栈解决由于反转链表类似于倒序输出的问题，我们可以先顺序遍历链表并将链表节点压入栈中，然后出栈并修改后继节点即可。 12345678910111213141516171819202122232425import java.util.Stack;public class Solution &#123;public ListNode ReverseList(ListNode head) &#123; Stack&lt;ListNode&gt; stack= new Stack&lt;&gt;(); //把链表节点全部摘掉放到栈中 while (head != null) &#123; stack.push(head); head = head.next; &#125; if (stack.isEmpty()) return null; ListNode node = stack.pop(); ListNode dummy = node; //栈中的结点全部出栈，然后重新连成一个新的链表 while (!stack.isEmpty()) &#123; ListNode tempNode = stack.pop(); node.next = tempNode; node = node.next; &#125; //最后一个结点就是反转前的头结点，一定要让他的next //等于空，否则会构成环 node.next = null; return dummy;&#125;&#125; 构建新链表思想类似于我的代码，将原链表的节点一个一个全部从表中摘掉，并让他成为新链表的头结点即可。 12345678910111213141516171819public ListNode ReverseList(ListNode head) &#123; //新链表 ListNode newHead = null; while (head != null) &#123; //先保存访问的节点的下一个节点，保存起来 //留着下一步访问的 ListNode temp = head.next; //每次访问的原链表节点都会成为新链表的头结点， //其实就是把新链表挂到访问的原链表节点的 //后面就行了 head.next = newHead; //更新新链表 newHead = head; //重新赋值，继续访问 head = temp; &#125; //返回新链表 return newHead;&#125; 递归解决我们再来回顾一下递归的模板，终止条件，递归调用，逻辑处理。 1234567891011public ListNode reverseList(参数0) &#123; if (终止条件) return; 逻辑处理（可能有，也可能没有，具体问题具体分析） //递归调用 ListNode reverse = reverseList(参数1); 逻辑处理（可能有，也可能没有，具体问题具体分析）&#125; 终止条件就是链表为空，或者是链表没有尾结点的时候，直接返回。 12if (head == null || head.next == null) return head; 递归调用是要从当前节点的下一个结点开始递归。逻辑处理这块是要把当前节点挂到递归之后的链表的末尾。 123456789101112131415161718public ListNode ReverseList(ListNode head) &#123; //终止条件 if (head == null || head.next == null) return head; //保存当前节点的下一个结点 ListNode next = head.next; //从当前节点的下一个结点开始递归调用 ListNode reverse = ReverseList(next); //reverse是反转之后的链表，因为函数reverseList // 表示的是对链表的反转，所以反转完之后next肯定 // 是链表reverse的尾结点，然后我们再把当前节点 //head挂到next节点的后面就完成了链表的反转。 next.next = head; //这里head相当于变成了尾结点，尾结点都是为空的， //否则会构成环 head.next = null; return reverse;&#125; 因为递归调用之后head.next节点就会成为reverse节点的尾结点，我们可以直接让head.next.next &#x3D; head;，这样代码会更简洁一些。 12345678public ListNode ReverseList(ListNode head) &#123; if (head == null || head.next == null) return head; ListNode reverse = ReverseList(head.next); head.next.next = head; head.next = null; return reverse;&#125; 这种递归往下传递的时候基本上没有逻辑处理，当往回反弹的时候才开始处理，也就是从链表的尾端往前开始处理的。我们还可以再来改一下，在链表递归的时候从前往后处理，处理完之后直接返回递归的结果，这就是所谓的尾递归，这种运行效率要比上一种好很多。这种处理方法的思想类似于我自己写的代码的处理思想，即从前往后处理，先断链再连新链。 1234567891011public ListNode ReverseList(ListNode head) &#123; return reverseListInt(head, null);&#125;private ListNode reverseListInt(ListNode head, ListNode newHead) &#123; if (head == null) return newHead; ListNode next = head.next; head.next = newHead; return reverseListInt(next, head);&#125; 复杂度分析 时间复杂度：O(n) 空间复杂度：O(1)","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"剑指offer","slug":"算法/剑指offer","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/"},{"name":"链表","slug":"算法/剑指offer/链表","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%89%91%E6%8C%87offer/%E9%93%BE%E8%A1%A8/"}]},{"title":"操作系统","slug":"操作系统","date":"2022-02-03T12:22:14.000Z","updated":"2022-02-07T13:04:56.524Z","comments":true,"path":"2022/02/03/操作系统/","link":"","permalink":"http://example.com/2022/02/03/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"概述特征 并发1、概念：同一时间间隔内执行和调度多个程序的能力 2、特点： 宏观上，处理机同时执行多道程序 微观上，处理机在多道程序间高速切换 关注单个处理机在多道程序间高速切换 共享1、概念：系统中的资源可以被多个并发进程共同使用 2、有两种共享方式： 互斥共享：资源称为临界资源，例如打印机等 同时共享：同一时段允许多个程序同时访问共享资源 并发和共享互为前提 共享要求OS中同时运行多个程序 并发性难以避免地导致多道程序同时访问同一个资源 虚拟1、概念：使用虚拟技术把一个物理实体转换为多个逻辑实体 2、两种虚拟技术： 时（时间）分复用技术 虚拟处理机技术：四核八线程 虚拟设备技术：虚拟打印机 空（空间）分复用技术 虚拟磁盘技术：将一个硬盘虚拟出若干个卷 虚拟存储器技术 异步1、多道程序环境下，允许多个程序并发执行；单处理机环境下，多个程序分时交替执行 2、宏观上一气呵成，微观上走走停停 3、原因：程序执行的不可预知性 进程概念1、进程是资源分配的基本单位。 2、结构： 控制块（PCB）：识别进程的唯一标志，描述进程的基本信息和运行状态 数据段：存放原始数据、中间数据 程序段：存放在文本区域，可被多个进程共享（同一个程序的进程） 3、特征： 动态性：由创建而生，撤销而亡 并发性 独立性 异步性 和线程的区别 什么是线程？ 进程的轻型实体，是一系列活动按照事先设定好的顺序执行的过程，是一系列指令的集合 是一条执行路径，不能单独存在，必须包含在进程中 是OS中运算调度的最小单位 为什么需要线程？ 提高OS的并发性 区别： 拥有资源：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。 调度：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。 系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I&#x2F;O 设备等，所付出的开销远大于创建或撤销线程时的开销，而线程切换时只需保存和设置少量寄存器内容，开销很小。 通信方面：线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。 4、状态 new、ready、blocked、running、terminated 5、进程控制 OS通过原语操作实现进程控制 原子操作 在内核态执行 是内核三大支撑概念（中断处理、时钟管理、原语操作）之一 原语： 创建：create 阻塞：block 唤醒：wakeup 撤销：destroy 为了系统和用户观察和分析进程 将暂时不能运行的进程调到外存，进程状态为挂起状态（阻塞挂起、就绪挂起） 挂起：suspend 激活：active CPU调度 处理机调度：根据一定的算法和原则将处理机资源进行重新分配的过程 目的：提高资源利用率 评价指标1、周转时间：任务结束时间—任务进入时间 2、吞吐量：单位时间完成的作业 CPU调度算法FCFS1、先来先服务 2、非抢占的算法 3、优点：公平、算法实现简单 4、缺点：带权周转时间很长，对长作业有利，对短作业不利 SJF1、短作业优先 2、非抢占的算法 SRTN最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。 时间片轮转抢占式的算法 保证响应时间 优先级调度算法1、思想：根据任务的紧急程度决定 2、可能导致饥饿 多级反馈队列调度算法1、思想：折中权衡（RR+优先级调度） 2、内容： 设置多个按优先级排序的就绪队列 优先级从高到低，时间片从小到大 新进程采用队列降级法 进入第一级队列，按FCFS分时间片 没有执行完，降级 前面的队列不为空不执行后续队列进程 3、优点：公平、新到达进程很快响应 4、调度方式：抢占式 进程通信 进程之间的信息交换 进程是资源分配的基本单位，各进程内存空间独立 共享存储1、允许多个进程共享一个给定的存储区 2、因为数据不需要在进程之间复制，所以这是最快的一种 IPC 3、分类： 基于共享数据结构的通信方式：效率低 基于共享存储区的通信方式：效率高 消息传递1、直接通信：点到点发送 2、间接通信：广播信箱 管道通信1、半双工通信 2、用于连接读&#x2F;写进程的共享文件（pipe文件），本质是内存中固定大小的缓冲区 进程同步 协调进程间的相互制约关系，使它们按照预期的方式执行的过程 信号量1、通过使用OS提供的一对原语对信号量进行操作（PV操作） 2、分类： 整型信号量 记录型信号量 整型信号量用整数表示资源的数量 123456789int s = 1;void wait(int s)&#123; while(s&lt;=0)&#123; s=s-1; &#125;&#125;void signal(int s)&#123; s=s+1;&#125; 记录型信号量信号量为正：资源数量 信号量为负：等待线程数量 12345678910111213141516int value;//剩余资源数量Queue process L;//等待队列void wait(Semphore S)&#123; S.value--; if(S.value&lt;0)&#123; block(S.L);//阻塞 &#125;&#125;void signal(Semphore S)&#123; S.value++; if(S.value&lt;=0)&#123; wake up(S.L);//唤醒一个进程 &#125;&#125; 实现进程互斥初始值为1 在临界区之前执行P，在临界区之后执行V 实现进程同步初始值为0 在前操作之后执行V，在后操作之前执行P 123456789P1&#123; 前操作; V(S);&#125;P2&#123; P(S); 后操作;&#125; 内存基本概念 什么是内存？ 内存是用于存放数据的硬件，程序执行前需要先放到内存才能被CPU处理 在多道程序环境下，系统中会有多个程序并发执行，也就是说会有多个程序的数据需要同时放到内存中，那么如何区分各个程序的数据存放的地方呢？ 给内存的存储单元编地址 4GB内存，什么意思？ 指的是该内存中可以存放4* 2的30次方个字节，如果是按照字节编址的话，也就是有4* 2的30次方个字节 逻辑地址 根据起始位置获得绝对地址 装入的三种方式 1、绝对装入 在编译时，如果知道程序将放到内存中的哪个位置，编译程序将产生绝对地址的目标代码，装入程序按照地址将程序和数据装入内存 编译、链接后得到的指令直接使用绝对地址 只适合单道程序环境 2、静态重定位 编译、链接后的地址是逻辑地址，装入时对地址进行重定位，将逻辑地址转为物理地址 由装入程序进行 一个作业装入内存时必须分配其要求的所有内存空间，如果没有足够内存就不能装入作业 3、动态重定位 程序真正执行时进行地址转换 借助重定位寄存器，存放装入模块的起始位置 特点： 允许程序在内存中移动（只需要修改重定位寄存器的值） 可以将程序分配到不连续的存储区 在程序运行前只需要装入部分代码，在程序运行期间可以动态申请分配内存 便于程序段的共享，可以向用户提供比存储空间更大的地址空间","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}]},{"title":"源码分析","slug":"源码分析","date":"2022-01-28T05:19:58.000Z","updated":"2022-02-07T13:53:33.305Z","comments":true,"path":"2022/01/28/源码分析/","link":"","permalink":"http://example.com/2022/01/28/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"","text":"ArrayList底层是数组 有参构造1234567891011public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; //创建一个数组 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); &#125;&#125; 12345678910111213141516171819public ArrayList(Collection&lt;? extends E&gt; c) &#123; //将集合转成数组 elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // 再次进行判断 if (elementData.getClass() != Object[].class) //数组的创建和拷贝 elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // 空数组的地址赋值给集合存元素的数组 this.elementData = EMPTY_ELEMENTDATA; &#125;&#125;public Object[] toArray() &#123; //调用数组工具类的方法 return Arrays.copyOf(elementData, size);&#125; add方法add(E e)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; //添加元素之后，默认容量大小为10 //如果没有向集合添加元素时，容量为0 private static final int DEFAULT_CAPACITY = 10; //存放元素的数组 transient Object[] elementData; //实际元素个数 private int size; //添加元素add方法 public boolean add(E e) &#123; ensureCapacityInternal(size + 1); elementData[size++] = e; return true; &#125; private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity)); &#125; private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; //判断是不是空数组 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; //10和1比大小，返回10 return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity; &#125; private void ensureExplicitCapacity(int minCapacity) &#123; //增长实际修改集合个数 modCount++; //判断需不需要扩容 if (minCapacity - elementData.length &gt; 0) //数组扩容 grow(minCapacity); &#125; //数组扩容 private void grow(int minCapacity) &#123; //获取长度 int oldCapacity = elementData.length; // &gt;&gt;：右移，右移几位就相当于除以2的几次幂 //新的容量 ，扩容的核心算法：原来容量的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) //把10赋值给newCapacity newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); //复制长度为新容量的数组 elementData = Arrays.copyOf(elementData, newCapacity); &#125;&#125; add(int index, E element) public void add(int index, E element)：指定位置添加元素 123456789101112131415161718192021public void add(int index, E element) &#123; //检查索引越界 rangeCheckForAdd(index); //可能会扩容（在容量不够的情况下） ensureCapacityInternal(size + 1); //数组元素的拷贝 System.arraycopy(elementData, //原数组 index, //从哪里开始拷贝 elementData, //目标数组 index + 1,//目标数组的开始位置 size - index);//需要拷贝多少个元素 //添加元素 elementData[index] = element; //增加size size++;&#125;private void rangeCheckForAdd(int index) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125; addAll(Collection&lt;? extends E&gt; c) public boolean addAll(Collection&lt;? extends E&gt; c)：将指定集合的Iterator返回的顺序将指定集合中的所有元素追加到列表的末尾 123456789101112public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); //获取集合长度 int numNew = a.length; //判断需不需要扩容 ensureCapacityInternal(size + numNew); //数组元素拷贝 System.arraycopy(a, 0, elementData, size, numNew); //增加size size += numNew; return numNew != 0;&#125; addAll(int index, Collection&lt;? extends E&gt; c) public boolean addAll(int index, Collection&lt;? extends E&gt; c)：将指定集合中所有元素从指定位置插入到集合中 12345678910111213141516171819202122232425262728public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; //索引越界检查 rangeCheckForAdd(index); Object[] a = c.toArray(); //获取集合长度 int numNew = a.length; //判断需不需要扩容 ensureCapacityInternal(size + numNew); //需要移动的元素的个数 int numMoved = size - index; //把索引后面的元素往后移动 if (numMoved &gt; 0) System.arraycopy(elementData, //原数组 index, //开始移动的索引 elementData, //目标数组 index + numNew,//目标数组的开始位置 numMoved);//需要移动的元素的数量 //把数组的元素移动进去 System.arraycopy(a, //原数组 0, //开始移动的索引 elementData, //目标数组 index, //目标数组的开始位置 numNew);//需要移动元素的数量 //增加size size += numNew; return numNew != 0;&#125; set方法12345678910public E set(int index, E element) &#123; //索引越界检查 rangeCheck(index); //获得原始元素值 E oldValue = elementData(index); //更改元素值 elementData[index] = element; //返回原是元素值 return oldValue;&#125; get方法12345678910public E get(int index) &#123; //越界检查 rangeCheck(index); //返回数组的指定索引的值 return elementData(index);&#125;E elementData(int index) &#123; return (E) elementData[index];&#125; toString方法12345678910111213141516171819public abstract class AbstractCollection&lt;E&gt; implements Collection&lt;E&gt; &#123; public String toString() &#123; //获取迭代器 Iterator&lt;E&gt; it = iterator(); //如果没有元素 if (! it.hasNext()) return &quot;[]&quot;; //使用StringBuilder进行字符串拼接 StringBuilder sb = new StringBuilder(); sb.append(&#x27;[&#x27;); for (;;) &#123; E e = it.next(); sb.append(e == this ? &quot;(this Collection)&quot; : e); if (! it.hasNext()) return sb.append(&#x27;]&#x27;).toString(); sb.append(&#x27;,&#x27;).append(&#x27; &#x27;); &#125; &#125;&#125; 迭代器（并发修改异常） 需求：有一个集合list，里面三个元素：hello、world、java，遍历集合得到每一个元素，看看有没有world，如果有就添加一个javaee元素 12345678910111213List&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;hello&quot;);list.add(&quot;world&quot;);list.add(&quot;java&quot;);Iterator&lt;String&gt; it = list.iterator();while(it.hasNext())&#123; String s = it.next(); if(s.equals(&quot;world&quot;))&#123; list.add(&quot;javaee&quot;); &#125;&#125; 1、结果： 1报错：Exception in thread &quot;main&quot; java.util.ConcurrentModificationException 2、源码分析： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public interface List&lt;E&gt;&#123; boolean add(E e); Iterator&lt;E&gt; iterator();&#125;public abstract class AbstractList&lt;E&gt;&#123; int modCount = 0;&#125;public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;&#123; //获取迭代器 public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; private class Itr implements Iterator&lt;E&gt; &#123; //光标 默认0 int cursor; //记录 -1 int lastRet = -1; //将集合实际修改次数赋值给预期修改次数 int expectedModCount = modCount; //判断集合是否有元素 public boolean hasNext() &#123; return cursor != size; &#125; //获取下一个元素 public E next() &#123; checkForComodification(); //将光标赋值给i int i = cursor; //判断，如果大于size说明没有元素了 if (i &gt;= size) throw new NoSuchElementException(); //把集合存储数组的地址复制给该方法的局部变量 Object[] elementData = ArrayList.this.elementData; //进行判断，条件满足抛出并发修改异常 if (i &gt;= elementData.length) throw new ConcurrentModificationException(); //光标自增 cursor = i + 1; //返回局部变量数组的元素 return (E) elementData[lastRet = i]; &#125; //校验预期修改次数和实际修改次数是否一致 final void checkForComodification() &#123; if (modCount != expectedModCount) //抛出并发修改异常 throw new ConcurrentModificationException(); &#125; &#125; &#125; 分析： 12345报错行：String s = it.next();由于ArrayList的内部类Itr的next方法中首先调用了checkForComodification方法，而这个方法中如果modCount不等于expectedModCount的话就会抛出异常；在add操作中，会在ensureExplicitCapacity方法中对modCount进行++，因此，modeCount不等于expectedModCount了，所以会抛出异常 结论： 当要删除的元素在集合的倒数第二个元素的位置，不会发生并发修改异常 原因：调用hasnext方法时，光标的值和集合的长度一样，就会返回false，因此不会再去调用next方法，不会产生并发修改异常 解决方案：使用Itr的remove方法即可 迭代器的删除方法1234567891011121314151617public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); //删除前检查并发修改异常 checkForComodification(); try &#123; //根据索引删除元素 ArrayList.this.remove(lastRet); //将光标变成删除元素的索引，-1 cursor = lastRet; lastRet = -1; //赋值 expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; 清空方法123456789public void clear() &#123; //增加实际修改次数 modCount++; //把所有值设置为null for (int i = 0; i &lt; size; i++) elementData[i] = null; //修改size size = 0;&#125; 包含方法1234567891011121314151617//使用for循环遍历数组完成操作public boolean contains(Object o) &#123; return indexOf(o) &gt;= 0;&#125;public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1;&#125; 判断是否为空123public boolean isEmpty() &#123; return size == 0;&#125; 面试题ArrayList如何扩容？答：在第一次使用add方法时，由于size为0，所以调用calculateCapacity方法使得参数为10，10大于当前集合中数组的长度，所以需要进行扩容，扩容到10；在以后的每次add方法时，都需要先进行判断是否需要扩容（需要的容量和集合存储的数组长度比大小），如果需要扩容就扩容1.5倍。 ArrayList频繁扩容导致添加性能下降，如何处理？答：使用带参构造方法构造指定容量的空列表 ArrayList插入或者删除元素一定比LinkedList慢吗？答：不是 12345678910111213141516//ArrayList的删除方法public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; //进行元素的复制 if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; return oldValue;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//LinkedList的删除方法public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125;Node&lt;E&gt; node(int index) &#123; //判断索引是否小于集合长度的一半 if (index &lt; (size &gt;&gt; 1)) &#123; //如果小于把第一个节点赋值给x Node&lt;E&gt; x = first; //从头向后找 for (int i = 0; i &lt; index; i++) //获取下一个节点 x = x.next; //返回找到的节点 return x; &#125; else &#123; //把最后一个节点赋值给x Node&lt;E&gt; x = last; //从后往前找 for (int i = size - 1; i &gt; index; i--) //获取前一个节点 x = x.prev; //返回找到的节点 return x; &#125;&#125;E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125; ArrayList是线程安全的吗？不是线程安全的 如何复制ArrayList到另外一个ArrayList中？1、clone方法 2、使用ArrayList的构造方法 3、使用addAll方法 已知成员变量集合存储N多用户名称，在多线程的环境下，使用迭代器在读取集合数据的同时保证正常的写入数据到集合？使用读写分离CopyOnWriteArrayList ArrayList和LinkedList区别？ArrayList 基于动态数组的数据结构 对于随机访问的get和set，ArrayList要优于LinkedList 对于随机操作的add和remove，ArrayList不一定比LinkedList慢 LinkedList 基于链表的数据结构 对于顺序操作，LinkedList不一定比ArrayList慢 对于随机操作，LinkedList效率明显低 LinkedList链表是一种物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。 链表的分类：单链表、双链表、循环链表 链表：由链将一个个元素连接，每一个元素我们通常称其为Node节点（优势：用多少空间申请多少空间） Node节点：由两部分组成 数据值的变量 Node next存放下一个节点的Node对象 因为没有索引，链表查询速度非常慢（和数组相比） 自定义单向链表 目的：为了体系的完整，以及代码的复用，设计出以下结构： 需要实现的方法 1234567891011public int size();public boolean isEmpty();public boolean conatins(E element);public void add(E element);public E get(int index);public E set(int index,E element);public void add(int index,E element);public E remove(int index);public int indexOf(E element);public void clear();public String toString(); List接口含有共性的方法 1234567891011public interface List&lt;E&gt; extends Collection&lt;E&gt; &#123; int size(); boolean isEmpty(); boolean contains(Object o); boolean add(E e); void clear(); E get(int index); E set(int index, E element); E remove(int index); int indexOf(Object o);&#125; AbstractList抽象类实现共性的方法，实现List 因为只实现了部分方法，所以是abstract类，其余的具有特性的方法交给集合自己实现 双向链表 addNode类 1234567891011private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));&#125;private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;//在最后添加元素void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125;//添加元素void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++;&#125;//获取指定索引的nodeNode&lt;E&gt; node(int index) &#123; if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; remove123456789101112131415161718192021222324252627282930313233public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125;E unlink(Node&lt;E&gt; x) &#123; //x:要删除的元素 //获取要删除元素的值 final E element = x.item; //获取要删除元素下一个node final Node&lt;E&gt; next = x.next; //获取要删除元素上一个node final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125; indexOf1234567891011121314151617public int indexOf(Object o) &#123; int index = 0; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) return index; index++; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) return index; index++; &#125; &#125; return -1;&#125; conatins123public boolean contains(Object o) &#123; return indexOf(o) != -1;&#125; 并发修改异常1234567891011public Iterator&lt;E&gt; iterator() &#123; return listIterator();&#125;public ListIterator&lt;E&gt; listIterator() &#123; return listIterator(0);&#125;public ListIterator&lt;E&gt; listIterator(final int index) &#123; rangeCheckForAdd(index); return new ListItr(index);&#125; 12345678910111213141516171819202122232425262728293031private class ListItr implements ListIterator&lt;E&gt; &#123; private Node&lt;E&gt; lastReturned; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; ListItr(int index) &#123; next = (index == size) ? null : node(index); nextIndex = index; &#125; public boolean hasNext() &#123; return nextIndex &lt; size; &#125; public E next() &#123; checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; next = next.next; nextIndex++; return lastReturned.item; &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125; 常用方法节点node 1234567891011private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; 1、获得第一个值 123456public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item;&#125; 2、获得最后一个值 123456public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item;&#125; 3、删除第一个值 123456public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f);&#125; 4、删除最后一个值 123456public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l);&#125; 5、添加第一个值 123456789101112131415public void addFirst(E e) &#123; linkFirst(e);&#125;private void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); first = newNode; if (f == null) last = newNode; else f.prev = newNode; size++; modCount++;&#125; 6、添加最后一个值 123456789101112131415public void addLast(E e) &#123; linkLast(e);&#125;void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125; HashMap简介1、HashMap基于哈希表的Map接口实现，以key-value的存储形式存在。 2、HashMap的实现不是同步的，这意味着它不是线程安全的 3、JDK1.8之前HashMap是由数组+链表组成的，数组是HashMap的主体，链表主要是为了解决哈希冲突（两个对象调用的hashcode方法计算的哈希值一致导致计算的数组索引值相同）而存在的（“拉链法”解决冲突） 4、JDK1.8之后，解决哈希冲突的方法发生变化，当链表长度大于某个值（或者红黑树的边界值，默认为8）并且当前数组的长度大于64时，此时索引位置上的所有数据改为使用红黑树存储 注意：将链表转换成红黑树前会判断，即使大于8，但是数组长度小于64，此时不会将链表变为红黑树，而是选择对数组进行扩容 这样做的目的是因为数组比较小，尽量避开红黑树结构，这种情况下红黑树结构反而会降低效率，因为红黑树需要进行左旋、右旋，变色这些操作来保持平衡。同时数组长度小于64时，搜索时间相对快一点，所以当底层阙值大于8并且数组长度大于64，才会转换。（treeifyBin） 5、特点： 存取无序 键和值位置都可以为null 键位置是唯一的，底层的数据结构控制键 jdk1.8前，链表+数组；jdk1.8后，链表+数组+红黑树 底层数据结构数据结构存储数据的过程1、创建HashMap 1HashMap&lt;String, Integer&gt; a = new HashMap&lt;&gt;(); 创建HashMap集合对象时 jdk8前，构造方法中创建一个长度为16的Entry[] table来存储键值对数据； jdk8后，不是在HashMap的构造方法底层创建数组了，是在第一次调用put方法时创建数组， Node[] table存储键值对数据 2、put数据 1a.put(&quot;a&quot;,1); 根据a调用String类中重写之后的hashCode()方法计算出值，然后结合数组长度采用某种算法计算出向Node数组中存储数据的空间的索引值；如果计算出的索引空间没有数据，就直接存储到数组中 3、向哈希表存储数据b-2，假设b计算出的hashcode方法结合数组长度计算出的索引值与a相同，那么此时数组空间不是null，此时底层会比较a和b的哈希值是否一致： hash值不相等，在此空间上划出一个节点来存储键值对数据b-2（拉链法） hash值相等（哈希冲突），进一步调用元素的equals方法，比较Key的内容是否一致 如果Key的值一致，就会将原来的value值覆盖 如果Key的值不一致，就会在当前索引位置上划分一个节点来存储当前的元素 链表长度大于8，数组长度大于64，转为红黑树 3、在不断添加数据的过程中，会涉及到扩容的问题，超出临界值（且要存放的位置非空）时，扩容。 默认的扩容方式：扩容为原来容量的两倍，并将原有的数据复制过来 说明： 1、size表示HashMap中K-V的实时数量，这个不是数组的长度 2、threshold（临界值）&#x3D; capacity（容量）*loadFactor（加载因子，0.75），这个值是当前已占有数组长度的最大值，size超过这个临界值就重新resize（扩容），扩容后的HashMap容量是之前容量的两倍。 HashMap继承关系1public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable&#123;&#125; 说明： Cloneable：空接口，表示可以克隆 Serializable：序列化接口 AbstractMap：父类提供了Map实现接口，减少实现此接口所需要完成的工作 java集合框架的创始人描述这样的写法是一个失误，后面的工程师认为这个失误不值得去修改，所以就保存下来了 HashMap集合类的成员成员变量1、序列化版本号 1private static final long serialVersionUID = 362498820763181265L; 2、集合的初始化容量（必须是2的n次幂） 1static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 见面试题6和7 小结： 当我们根据key的hash确定其在数组的位置时，如果n为2的幂次方，可以保证数据的均匀插入，如果n不是2的幂次方，可能数组的一些位置永远不会插入数据，浪费数组的空间，加大hash冲突 取余数的方式性能不如&amp;运算，而且当n是2的幂次方时：hash&amp;(length-1) &#x3D;&#x3D; hash%length HashMap容量为2的幂次方是为了数据的均匀分布，减少hash冲突 如果创建HashMap对象时，输入的数组长度为10，不是2的幂次方，HashMap通过位运算和或运算得到的肯定是2的幂次数，而且离那个数最近的数字 1234567891011121314151617181920212223242526public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 可以看到，实例化hashMap时，如果给定了初始容量，由于HashMap的容量必须是2的幂，因此使用tableSizeFor方法找到大于等于初始容量的最小的2的幂 分析： 对cap减1，这是为了防止cap已经是2的n次幂，没有执行这个操作经过后面的无符号右移操作后，这个容量会变成cap的两倍 经过运算，最后二进制都会变成连续的1 返回threshold 3、负载因子，默认0.75 1static final float DEFAULT_LOAD_FACTOR = 0.75f; 4、链表的值超过8就会转红黑树 1static final int TREEIFY_THRESHOLD = 8; 5、值小于6转回链表 1static final int UNTREEIFY_THRESHOLD = 6; 6、数组长度大于64才会转红黑树，如果小于64，节点值超过8就选择扩容 1static final int MIN_TREEIFY_CAPACITY = 64; 7、table用来初始化 1transient Node&lt;K,V&gt;[] table; table就是HashMap中的数组，jdk8以前是Entry类型，jdk8以后是Node类型 8、HashMap中存放元素的个数 1transient int size; 9、修改的次数 1transient int modCount; 10、边界值 1int threshold; threshold（临界值）&#x3D; capacity（容量）*loadFactor（加载因子，0.75） size超过这个值进行扩容 11、加载因子 1final float loadFactor; 说明： 0和1之间，越靠近1说明数组越密集。表示HashMap的疏密程度 计算公式：size&#x2F;capacity （capacity是桶的数量，table的长度） 默认值0.75，不建议修改 如果HashMap里面容纳的元素已经达到了HashMap数组长度的75%，表示很拥挤，需要扩容 在HashMap的构造器中可以定制loadFactor 构造方法1、无参构造 123public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; &#125; 2、指定初始化容量 如果指定容量10，容量会变成16 123public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125; 3、指定加载因子和初始化容量 12345678910111213public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; //在put方法才会乘0.75 this.threshold = tableSizeFor(initialCapacity);&#125; 4、包含另外一个Map的构造函数 12345public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; //加载因子默认0.75 this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125; 成员方法put方法① 调用 putVal 方法添加元素。 ② 如果 table 为空或长度为 0 就进行扩容，否则计算元素下标位置，不存在就调用 newNode 创建一个节点。 ③ 如果存在且是链表，如果首节点和待插入元素的 hash 和 key 都一样，更新节点的 value。 ④ 如果首节点是 TreeNode 类型，调用 putTreeVal 方法增加一个树节点，每一次都比较插入节点和当前节点的大小，待插入节点小就往左子树查找，否则往右子树查找，找到空位后执行两个方法：balanceInsert 方法，插入节点并调整平衡、moveRootToFront 方法，由于调整平衡后根节点可能变化，需要重置根节点。 ⑤ 如果都不满足，遍历链表，根据 hash 和 key 判断是否重复，决定更新 value 还是新增节点。如果遍历到了链表末尾则添加节点，如果达到建树阈值 7，还需要调用 treeifyBin 把链表重构为红黑树。 ⑥ 存放元素后将 modCount 加 1，如果 ++size &gt; threshold ，调用 resize 扩容。 123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 123456789//计算哈希值static final int hash(Object key) &#123; int h; //当key为null，返回0 //key不为null，首先计算出key的hashcode值赋值给h，然后与h无符号右移16位后的二进制进行按位异或得到最后的hash值 //hashCode的高位变化很大，而低位变化很小或者没有变化，那么如果直接和数组长度进行&amp;运算，会很容易造成计算的结果一样的，导致hash碰撞 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 为什么要这么操作？ 如果n即数组长度很小，假设为16，这样的值和hashCode直接进行操作，实际上只是用了哈希值的后面4位，如果当哈希值的高位变化，低位变化很小，这样很容易造成哈希冲突 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182final V putVal(int hash,//哈希值 K key, V value, boolean onlyIfAbsent,//false，代表更改现有值；true代表不更改现有值 boolean evict) &#123;//true //表示引用当前hashmap的散列表 Node&lt;K,V&gt;[] tab; //表示当前散列表的元素 Node&lt;K,V&gt; p; //n：散列表数组的长度 //i：路由寻址的结果 int n, i; //如果hashmap的散列表没有初始化 if ((tab = table) == null || (n = tab.length) == 0) //初始化数组，散列表唱的为16 n = (tab = resize()).length; //计算i：路由算法 (n - 1) &amp; hash //如果数组这个索引的位置为null，直接插入node if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //如果数组这个索引的位置元素（p）不为null else &#123; //e：不为null的话，表示找到了一个当前要插入的key-value一致的node元素 Node&lt;K,V&gt; e; //k：临时的一个key K k; //如果p的hash值和hash值相同并且key的值相同，表示后续需要进行替换操作 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果这个key值是TreeNode，说明是红黑树 else if (p instanceof TreeNode) //插入到红黑树 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //说明是链表 else &#123; //遍历链表 for (int binCount = 0; ; ++binCount) &#123; //如果这个节点下一个节点为null，说明到末尾了，可以直接添加了 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //如果大于等于7的时候，代表前面已经有八个元素了 if (binCount &gt;= TREEIFY_THRESHOLD - 1) //树化 treeifyBin(tab, hash); break; &#125; //判断key是否一样 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) //跳出做替换，e这个元素就是需要被替换的代码 break; //下一个节点 p = e; &#125; &#125; //e不等于null说明有节点需要进行替换 if (e != null) &#123; //旧的值 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) //覆盖 e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //实际操作数量+1 ++modCount; //判断是否需要扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; resize方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135//扩容final Node&lt;K,V&gt;[] resize() &#123; //获取扩容前的table Node&lt;K,V&gt;[] oldTab = table; //获取table的旧容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; //获取旧阈值 int oldThr = threshold; int newCap, newThr = 0; //说明hashmap中散列表已经初始化过了，是一次正常扩容 if (oldCap &gt; 0) &#123; //如果散列表长度已经达到了最大容量了 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; //设置阈值为很大的值 threshold = Integer.MAX_VALUE; return oldTab; &#125; //容量翻倍，如果小于最大容量的话 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //阈值变为两倍 newThr = oldThr &lt;&lt; 1; &#125; //oldCap==0，说明hashmap的散列表还没有初始化 //情况一：new HashMap（初始容量，加载因子） //情况二：new HashMap（初始容量） //情况三：new HashMap（map） else if (oldThr &gt; 0) //新容量=旧阈值 newCap = oldThr; //oldCap==0，说明hashmap的散列表还没有初始化 //情况一：new Hash（） else &#123; //默认容量16 newCap = DEFAULT_INITIAL_CAPACITY; //默认阈值=16*0.75=12 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //在第二种情况下出现这个情况（三个构造方法） if (newThr == 0) &#123; //计算出阈值 float ft = (float)newCap * loadFactor; //基本上都是 newThr = ft newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //设置HashMap的阈值为局部变量newThr threshold = newThr; /** * 做真正的扩容操作 */ //初始化扩容后的新数组 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; //把新数组引用赋值给table table = newTab; //如果hashmap扩容前不为null if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; //当前node节点 Node&lt;K,V&gt; e; //说明当前桶中有数据，但是数据具体内容（单个数据、链表、红黑树）并不知道 if ((e = oldTab[j]) != null) &#123; //方便JVM GC回收内存 oldTab[j] = null; //说明是单个数据 if (e.next == null) //根据寻址算法计算出新的索引，插入到新数组中 newTab[e.hash &amp; (newCap - 1)] = e; //说明是红黑树 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //说明是链表，将这个链表分为低位链表和高位链表 else &#123; //低位链表：存放在扩容之后数组的下标位置与当前的下标位置一致 Node&lt;K,V&gt; loHead = null, loTail = null; //高位链表：存放在扩容之后的数组的下标位置=当前位置+扩容前数组的长度 Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; //如果与旧容量的与hash的与为0，位置不动，放入低位链表 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; //如果与旧容量的与hash的与为1，位置=当前位置+旧容量，放入改为链表 else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); //如果低位链表有数据 if (loTail != null) &#123; //设置最后元素的next为null loTail.next = null; //将这个链表的首元素指到新哈希表的位置 newTab[j] = loHead; &#125; //如果高位链表有数据 if (hiTail != null) &#123; //设置最后元素的next为null hiTail.next = null; //将这个链表的首元素指到新哈希表的位置 newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; //返回新数组 return newTab;&#125; get方法1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 1234567891011121314151617181920212223242526272829303132333435final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; //当前hashmap的散列表 Node&lt;K,V&gt;[] tab; //当前桶的头元素 Node&lt;K,V&gt; first, //临时node元素 e; //数组长度 int n; //key K k; //获取tab、n、first if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //如果第一个元素就是需要查的元素，直接返回 if (first.hash == hash &amp;&amp; ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; //如果是红黑树 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); //遍历链表，返回查到的元素 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 树化12345678910111213141516171819202122final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125; Hashtable成员变量123456789101112131415161718192021//Entry类型数组private transient Entry&lt;?,?&gt;[] table;//元素的个数private transient int count;//阈值private int threshold;//加载因子private float loadFactor;//实际修改个数private transient int modCount = 0;private static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; //哈希值 final int hash; //key final K key; //value V value; //下一个 Entry&lt;K,V&gt; next;&#125; 构造方法1、无参构造 容量默认11，加载因子默认0.75 123public Hashtable() &#123; this(11, 0.75f);&#125; 2、容量、加载因子 1234567891011121314151617public Hashtable(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal Load: &quot;+loadFactor); //如果设置容量为0，则置为1 if (initialCapacity==0) initialCapacity = 1; //设置加载因子 this.loadFactor = loadFactor; //创建table table = new Entry&lt;?,?&gt;[initialCapacity]; //计算阈值 threshold = (int)Math.min(initialCapacity * loadFactor, MAX_ARRAY_SIZE + 1);&#125; 3、容量 123public Hashtable(int initialCapacity) &#123; this(initialCapacity, 0.75f);&#125; put方法1234567891011121314151617181920212223242526272829303132public synchronized V put(K key, V value) &#123; //判断value是否为空 if (value == null) &#123; throw new NullPointerException(); &#125; //寻找是否有相同值 //获取散列表 Entry&lt;?,?&gt; tab[] = table; //计算哈希值 int hash = key.hashCode(); //计算索引 int index = (hash &amp; 0x7FFFFFFF) % tab.length; //获得该索引下的元素 @SuppressWarnings(&quot;unchecked&quot;) Entry&lt;K,V&gt; entry = (Entry&lt;K,V&gt;)tab[index]; //如果该元素不是null，进行遍历 for(; entry != null ; entry = entry.next) &#123; //如果hash值和key相同 if ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) &#123; //替换 V old = entry.value; entry.value = value; //返回被替换的value return old; &#125; &#125; addEntry(hash, key, value, index); return null;&#125; 1234567891011121314151617181920212223private void addEntry(int hash, K key, V value, int index) &#123; //增加操作次数 modCount++; //获取散列表 Entry&lt;?,?&gt; tab[] = table; //元素个数是否大于阈值 if (count &gt;= threshold) &#123; //进行扩容 rehash(); tab = table; hash = key.hashCode(); index = (hash &amp; 0x7FFFFFFF) % tab.length; &#125; //插入元素 @SuppressWarnings(&quot;unchecked&quot;) Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) tab[index]; tab[index] = new Entry&lt;&gt;(hash, key, value, e); //增加元素个数 count++;&#125; rehash方法12345678910111213141516171819202122232425262728293031323334353637383940protected void rehash() &#123; //获得旧容量 int oldCapacity = table.length; //获得旧散列表 Entry&lt;?,?&gt;[] oldMap = table; //定义新容量=就容量*2+1 int newCapacity = (oldCapacity &lt;&lt; 1) + 1; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) &#123; if (oldCapacity == MAX_ARRAY_SIZE) return; newCapacity = MAX_ARRAY_SIZE; &#125; //初始化新的散列表 Entry&lt;?,?&gt;[] newMap = new Entry&lt;?,?&gt;[newCapacity]; //增加操作次数 modCount++; //计算新的阈值 threshold = (int)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + 1); //把新的散列表设置为table table = newMap; //变量旧的散列表 for (int i = oldCapacity ; i-- &gt; 0 ;) &#123; for (Entry&lt;K,V&gt; old = (Entry&lt;K,V&gt;)oldMap[i] ; old != null ; ) &#123; //获得旧的元素 Entry&lt;K,V&gt; e = old; //下一个 old = old.next; //计算旧元素的index int index = (e.hash &amp; 0x7FFFFFFF) % newCapacity; //头部插入 e.next = (Entry&lt;K,V&gt;)newMap[index]; newMap[index] = e; &#125; &#125;&#125; 面试题答题思路1.7和1.8的区别：结构、头插法和尾插法 初始化hashmap：无参数构造和有参数构造，无参数构造会初始化加载因子，有参构造会初始化加载因子和阈值（这个阈值。。。会变成长度，最接近的2的次幂） 为什么要用2的次幂？主要是为了使得元素均匀分布，因为2的次幂-1就全是1，和哈希值进行与运算能够充分利用高位的数字 为什么初始化加载因子0.75？因为是空间和时间的平衡 为什么要用红黑树？为了提高查询效率 什么时候用红黑树？链表大于8且数组长度大于64 什么时候扩容？元素个数大于阈值、链表大于8且数组长度小于64 哈希碰撞 和hashtable的区别？hashtable线程安全，hashmap不能保证元素位置不变 哈希表底层采用何种算法计算哈希值？还有那些算法可以计算出哈希值底层采用的是key的hashCode方法的值结合数组长度进行**无符号右移(&gt;&gt;&gt;)、按位异或(^)、按位与(&amp;)**计算出索引 还可以采用：平方取中法，取余数、伪随机数法 其他计算方式比较低，而位运算效率比较高，所以底层采用这种方式 &gt;&gt;&gt;表示无符号右移，也叫逻辑右移，即若该数为正，则高位补0，而若该数为负数，则右移后高位同样补0 如果两个对象hashCode相等怎么办？会产生哈希碰撞，如果key值内容相同则替换旧的value，不同就连接到链表后面，链表长度大于8且数组长度大于64就转为红黑树存储 何时发生哈希碰撞？什么是哈希碰撞？如何解决哈希碰撞？只要两个元素的key计算的哈希值相同就会发生哈希碰撞，jdk8前使用链表解决哈希碰撞，jdk8之后使用链表+红黑树解决哈希碰撞 如何两个键的hashCode相同，如何存储键值对？hashcode相同，通过equals比较内容是否相同 相同：新的value覆盖旧的value 不同：将新的键值对添加到哈希表中 为什么1.8要引入红黑树？1.8以前HashMap使用数组+链表，即使哈希函数取的再好也很难达到元素百分百均匀分布，当HashMap有大量的元素存放在同一个桶中，这个桶下有一条长链表，这个时候HashMap就相当于一个单链表，遍历的时间复杂度为O(n)，完全失去了优势。 红黑树的查找时间复杂度为O(logn)，可以进行优化； 链表长度小的时候即使遍历速度也很快，但是链表变长以后会对查询性能产生影响 为什么集合的初始化容量必须是2的n次幂？2的n次方实际就是1后面n个0，2的n次方-1实际就是n个1； 如果数组的长度不是2的n次方，计算出的索引特别容易相同 ，哈希碰撞的几率增大，导致数组空间很大程度上并没有存储数据，链表或红黑树过长，效率降低。 当数组的长度为2的n次幂时，可以保证数据的均匀插入，减少hash冲突，提高hashamap的性能 hash&amp;(length-1) 这种算法如何减少hash碰撞？让空间均匀分配数组长度为2的n次幂 数组长度不是2的n次幂，计算出的索引特别容易相同，极其容易发生哈希碰撞，导致其余数组空间很大程度上并没有存储数据，链表或红黑树过长，效率降低 为什么Map桶的节点数超过8才变成红黑树？为了空间和时间的权衡 红黑树的占用空间是链表的两倍，根据泊松分布，数量超过8的概率很低，所以只要包含足够多节点才会转为红黑树，链表长度大于8转为红黑树，小于6又回变回链表 为什么加载因子0.75，初始化临界值12？加载因子：hash表中元素填满程度 加载因子过小，元素在数组中过于分散，有些空间一直没有元素，会造成空间的浪费 加载因子是0.4 。那么16* 0.4—–&gt;6 如果数组中满6个空间就进行扩容会造成数组利用率太低了 加载因子过大，元素在数组中会特别的拥挤，查找元素的效率降低，造成链表过长，增加hash碰撞几率，根据泊松分布规律，和官方给出的测试数据，加载因子为0.75时最合适，既不会因为扩容带来的rehash，复制数据等操作而影响性能，也不会因为数组长度太小导致利用率降低。 加载因子是0.9。那么16* 0.9——-&gt;14那么这样就会导致链表有点多了，导致查找元素效率低。 所以既兼顾数组利用率又考虑链表不要太多，经过大量测试0.75是最佳方案 什么时候需要扩容？情况1：元素个数超过数组的长度*负载因子的时候会进行扩容 情况2：添加元素的时候，当HashMap其中一个链表的对象个数达到了8个，但是数组长度没有达到64，就会进行扩容 扩容为原容量的2倍 HashMap的扩容是什么分为两步: 扩容：创建一个新的Entry空数组，长度是原数组的2倍。 ReHash：遍历原Entry数组，把所有的Entry重新Hash到新数组 长度扩大以后，Hash的规则也随之改变。 进行扩容，会伴随一次重新hash分配，并且会遍历hash表中所有的元素，是非常耗时的。 每次扩容都是翻倍，与原来计算的值多了一个bit位，所以节点要么在原来的位置（比特位是0），要么被分配到“原位置+旧容量”的位置（1） 为什么HashMap不安全？HashMap会进行resize操作，在resize操作的时候会造成线程不安全。下面将举两个可能出现线程不安全的地方。 1、put的时候导致的多线程数据不一致。 这个问题比较好想象，比如有两个线程A和B，首先A希望插入一个key-value对到HashMap中，首先计算记录所要落到的桶的索引坐标，然后获取到该桶里面的链表头结点，此时线程A的时间片用完了，而此时线程B被调度得以执行，和线程A一样执行，只不过线程B成功将记录插到了桶里面，假设线程A插入的记录计算出来的桶索引和线程B要插入的记录计算出来的桶索引是一样的，那么当线程B成功插入之后，线程A再次被调度运行时，它依然持有过期的链表头但是它对此一无所知，以至于它认为它应该这样做，如此一来就覆盖了线程B插入的记录，这样线程B插入的记录就凭空消失了，造成了数据不一致的行为。 2、另外一个比较明显的线程不安全的问题是HashMap的get操作可能因为resize而引起死循环（cpu100%），具体分析如下： 死循环： 扩容时 resize 调用 transfer 使用头插法迁移元素，虽然 newTable 是局部变量，但原先 table 中的 Entry 链表是共享的，问题根源是 Entry 的 next 指针并发修改，某线程还没有将 table 设为 newTable 时用完了 CPU 时间片，导致数据丢失或死循环。 JDK8 在 resize 方法中完成扩容，并改用尾插法，不会产生死循环，但并发下仍可能丢失数据。可用 ConcurrentHashMap 或 Collections.synchronizedMap 包装成同步集合。 与Hashtable比较 Hashtable 使用 synchronized 来进行同步。 HashMap 可以插入键为 null 的 Entry。 HashMap 的迭代器是 fail-fast 迭代器。 HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的 HashMap1.7和1.8的区别java7是头插法，就是说新来的值会取代原有的值，原有的值就顺推到链表中去，就像上面的例子一样，因为写这个代码的作者认为后来的值被查找的可能性更大一点，提升查找的效率。 扩容死循环 单线程扩容没有问题 多线程扩容： 第二个线程阻塞，第一个线程进行扩容 第一个线程扩容结束，也会进行一样的再次扩容，进入死循环 但是，在java8之后，都是所用尾部插入了 红黑树 底层数据结构：特殊的二叉查找树 链表-》二叉树-》二叉查找树-》特殊的二叉查找树 1、红黑树是一个二叉查找树 2、性质： 每个结点不是红色就是黑色 不可能有连在一起的红色结点 根节点都是黑色root（入度为0） 每个红色结点的两个子结点都是黑色，叶子节点都是黑色：出度为0满足了性质就可以近似的平衡了，不一定要红黑，可以为其他的 3、变换规则： 所有插入的点默认为红色 变色：红变黑，黑变红 情况：当前节点的父亲是红色，且叔叔也是红色 过程： 把父亲设为黑色 把叔叔设为黑色 把爷爷设为红色 分析爷爷需不需要操作 左旋： 情况：当前父亲为红色，叔叔为黑色，且当前结点是右子树，以父节点进行左旋（上图2-下图1） 右旋： 情况：当前父亲为红色，叔叔是黑色，且当前结点是左子树 把父亲变为黑色 把爷爷变为红色 以爷爷旋转 ConcurrentHashMap 1、扩容过程中，读访问能否访问到数据，如何实现？ 2、扩容过程中，写访问如何处理？ 3、假设指定桶位形成红黑树，目前红黑树正在自平衡，此时的读线程是被阻塞还是什么？ 4、JDK8中，统计当前散列表中的元素个数如何实现？为什么不使用AtomicLong？ 5、简单说一下LastRun机制？ jdk1.7一个Segment数组和多个HashEntry组成 Segment数组的意义就是将一个大的table分割成多个小的table来进行加锁，也就是锁分离技术，而每一个Segment元素存储的是HashEntry数组+链表，这个和HashMap的数据存储结构一样。 ConcurrentHashMap 与HashMap和Hashtable 最大的不同在于：put和 get 两次Hash到达指定的HashEntry，第一次hash到达Segment,第二次到达Segment里面的Entry,然后在遍历entry链表. Segment 是 ConcurrentHashMap 的一个内部类，主要的组成如下 123456789101112static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; // 和 HashMap 中的 HashEntry 作用一样，真正存放数据的桶 transient volatile HashEntry&lt;K,V&gt;[] table; transient int count; // 记得快速失败（fail—fast）么？ transient int modCount; // 阈值 transient int threshold; // 负载因子 final float loadFactor;&#125; HashEntry 123456static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next;&#125; 构造方法12345public ConcurrentHashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, //默认容量16 DEFAULT_LOAD_FACTOR, //默认负载因子0.75 DEFAULT_CONCURRENCY_LEVEL);//默认支持线程并发数16&#125; 123456//构造一个指定初始容量的concurrentHashMappublic ConcurrentHashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);&#125; 123456//构造一个指定初始容量和指定负载因子public ConcurrentHashMap(int initialCapacity, float loadFactor) &#123; this(initialCapacity, loadFactor, DEFAULT_CONCURRENCY_LEVEL);&#125; 初始化 Segment的大小：大于currentlevel的第一个2的次幂 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public ConcurrentHashMap(int initialCapacity,//初始容量：所有Hashentry数组的长度和 float loadFactor, //加载因子 int concurrencyLevel) &#123;//并发等级 //如果负载因子小于0,初始容量小于0 段数小于0 抛异常 if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); //如果segment段数大于最大阈值,那么就让其等于最大值 if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; //初始化1：Segment的大小：大于currentlevel的第一个2的次幂 int sshift = 0; int ssize = 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; &#125; this.segmentShift = 32 - sshift; this.segmentMask = ssize - 1; if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //计算Hashentry的大小 int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; int cap = MIN_SEGMENT_TABLE_CAPACITY; //cap为大于c的2的次幂 while (cap &lt; c) cap &lt;&lt;= 1; //保留一个segment信息 Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; UNSAFE.putOrderedObject(ss, SBASE, s0); this.segments = ss;&#125; put方法123456789101112131415public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; //value不能为空 if (value == null) throw new NullPointerException(); //第一次hash int hash = hash(key); int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) s = ensureSegment(j); //执行segement的put方法 return s.put(key, hash, value, false);&#125; 首先是通过key定位到要保存的具体的segment位置,然后执行segment的put方法: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; //尝试获取锁,如果获取失败说明有其他线程竞争,则调用scanAndLockForPut自旋获取锁. HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab = table; //确定链表头的位置 int index = (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; first = entryAt(tab, index); //循环链表 for (HashEntry&lt;K,V&gt; e = first;;) &#123; if (e != null) &#123; //如果链表不是空的,且找到了相同的key,则覆盖value,返回旧的value值 K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; ++modCount; &#125; break; &#125; e = e.next; &#125; //如果链表为空,则创建一个HashEntry并加入到segment中,同时会判断是否需要扩容 else &#123; if (node != null) node.setNext(first); else node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; //如果数量超过阈值则需要扩容 if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; //释放锁 unlock(); &#125; return oldValue;&#125; 在put方法中,首先要加锁,如果获取锁失败就会通过自旋的方式阻塞保证能拿到锁.通过key的hash值来确定具体的链表头. 遍历该链表,如果不为空则判断传入的key和当前遍历的key是否相等,相等则覆盖value 如果链表为空则需要新建一个HashEntry并加入到Segment中,同时会先判断是否需要扩容. 最后会释放锁 Jdk1.8主要对 JDK7 做了三点改造： ① 取消分段锁机制，进一步降低冲突概率。 ② 引入红黑树结构，同一个哈希槽上的元素个数超过一定阈值后，单向链表改为红黑树结构。 ③ 使用了更加优化的方式统计集合内的元素数量。具体优化表现在：在 put、resize 和 size 方法中设计元素总数的更新和计算都避免了锁，使用 CAS 代替。 利用CAS + synchronized来保证并发更新的安全底层：数组+链表+红黑树来实现 成员变量12345678910//初始化发生在第一次插入操作，默认大小为16的数组，用来存储Node节点数据，扩容时大小总是2的幂次方transient volatile Node&lt;K,V&gt;[] table;//扩容时新生成的数组，其大小为原数组的两倍private transient volatile Node&lt;K,V&gt;[] nextTable;//默认为0，用来控制table的初始化和扩容操作//-1表示正在初始化//-n表示有n-1个线程正在进行扩容操作private transient volatile int sizeCtl; 12345678910111213141516171819// Node：保存key，value及key的hash值的数据结构。 // 其中value和next都用volatile修饰，保证并发的可见性。class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; //... 省略部分代码&#125;// ForwardingNode：一个特殊的Node节点，hash值为-1，其中存储nextTable的引用。 // 只有table发生扩容的时候，ForwardingNode才会发挥作用，作为一个占位符放在table中表示当前节点为null或则已经被移动。final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED, null, null, null); this.nextTable = tab; &#125;&#125; 构造方法1、无参构造 123//默认容量16public ConcurrentHashMap() &#123;&#125; 2、带参数构造(1) 123456789public ConcurrentHashMap(int initialCapacity) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : //大于1.5x+1的2的次幂 tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap;&#125; 3、带参数构造(2) 1234public ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.sizeCtl = DEFAULT_CAPACITY; putAll(m);&#125; 4、带参数构造(3) 123public ConcurrentHashMap(int initialCapacity, float loadFactor) &#123; this(initialCapacity, loadFactor, 1);&#125; 5、带参数构造(4) 123456789101112public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins initialCapacity = concurrencyLevel; // as estimated threads long size = (long)(1.0 + (long)initialCapacity / loadFactor); int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); this.sizeCtl = cap;&#125; 初始化12345678910111213141516171819202122232425262728293031private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; //如果为空 while ((tab = table) == null || tab.length == 0) &#123; //如果sizeCtl小于0，等于-1，表示有其他线程正在初始化 if ((sc = sizeCtl) &lt; 0) //该线程停止，让出cpu时间片 Thread.yield(); //CAS成功，修改sc的值为-1，进行初始化 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; //如果 sizeCtl&gt;0 初始化大小为sizeCtl，否则初始化大小为16 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; //sc赋值，如果n为16,则sc = 16-16/4 = 12， sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; //赋值给sizeCtl，初始化结束，sizeCtl的值&gt;0 sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; put方法假设table已经初始化完成，put操作采用CAS+synchronized实现并发插入或更新操作： 当前bucket为空时，使用CAS操作，将Node放入对应的bucket中。 出现hash冲突，则采用synchronized关键字。倘若当前hash对应的节点是链表的头节点，遍历链表，若找到对应的node节点，则修改node节点的val，否则在链表末尾添加node节点；倘若当前节点是红黑树的根节点，在树结构上遍历元素，更新或增加节点。 倘若当前map正在扩容f.hash &#x3D;&#x3D; MOVED， 则跟其他线程一起进行扩容 123public V put(K key, V value) &#123; return putVal(key, value, false);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //不可以为null if (key == null || value == null) throw new NullPointerException(); //获取hash值，这个值一定是正数，方便判断该节点的类型 int hash = spread(key.hashCode()); int binCount = 0; //变量table for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; //如果table是空的，进行初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); //如果当前位置为null，进行CAS操作插入元素 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; &#125; //判断是否需要扩容，MOVED=-1 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); //解决hash冲突 else &#123; V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; 面试1、加载因子不可变 2、为什么hash值大于等于0 forwadingload的hash是-1 代理节点treebin的hash是-2 3、sizeCtl -1：表示当前散列表正在初始化，确保在并发条件下只会被创建一次 大于0：表示下次触发扩容的阈值 是-n：表示当前散列表正在进行扩容","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"排序","slug":"排序","date":"2022-01-25T10:45:08.000Z","updated":"2022-02-07T12:59:03.782Z","comments":true,"path":"2022/01/25/排序/","link":"","permalink":"http://example.com/2022/01/25/%E6%8E%92%E5%BA%8F/","excerpt":"","text":"Comparable接口案例： 1、定义一个学生类stu，具有年龄age和姓名name，通过Comparable接口提供比较规则 2、定义测试类，在测试类定义测试方法完成测试 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class tt &#123; public static void main(String[] args) throws InterruptedException &#123; stu s1 = new stu(1,&quot;zhang&quot;); stu s2 = new stu(2,&quot;li&quot;); Comparable compare = Compare(s1, s2); System.out.println(compare.toString()); &#125; public static Comparable Compare(Comparable c1,Comparable c2)&#123; int result = c1.compareTo(c2); // result&lt;0,c1比c2小 // result&gt;0,c1比c2大 // result=0,c1和c2一样大 if(result&gt;=0)&#123; return c1; &#125;else &#123; return c2; &#125; &#125;&#125;class stu implements Comparable&lt;stu&gt;&#123; public int age; public String name; public stu(int age, String name) &#123; this.age = age; this.name = name; &#125; @Override public int compareTo(stu o) &#123; return this.age-o.age; &#125; @Override public String toString() &#123; return &quot;stu&#123;&quot; + &quot;age=&quot; + age + &quot;, name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 冒泡排序需求：排序前：{4,5,6,3,2,1} 原理： 1、比较相邻的元素，如果前一个元素比后一个元素大，就交换位置 2、对每一对相邻的元素做一样的工作 123456789for(int i=0;i&lt;a.length-1;i++)&#123; for(int j=0;j&lt;a.length-1-i;j++)&#123; int temp = a[j]; if(a[j]&gt;a[j+1])&#123; a[j] = a[j+1]; a[j+1] = temp; &#125; &#125;&#125; 时间复杂度分析最坏情况，初始顺序为{6,5,4,3,2,1}，那么： 需要比较的次数为：(n-1)+(n-2)+…..+1&#x3D;[n*(n-1)]&#x2F;2 元素交换的次数为：(n-1)+(n-2)+…..+1&#x3D;[n*(n-1)]&#x2F;2 总执行次数：相加&#x3D;n^2-n 因此，时间复杂度为O(n^2)，最好O(n)，最坏O(n^2) 选择排序需求：排序前{4,6,8,7,9,2,10,1} 原理： 在每次遍历过程中，都假定第一个索引处的位置最小，和其他索引相比较，如果比它小就假定为最小值，最后可以找到最小值所在的索引 交换第一个索引处和最小值所在索引处的值 123456789101112131415161718public static void sort(int[] a)&#123; //遍历所有的数 for(int i=0;i&lt;a.length;i++)&#123; int minIndex = i; //和后面的数字进行比较，找出最小值的索引 for(int j=i+1;j&lt;a.length;j++)&#123; if(a[j]&lt;a[minIndex])&#123; minIndex=j; &#125; &#125; //如果最终的结果和这个i不一致，就交换元素 if(minIndex!=i)&#123; int temp = a[i]; a[i] = a[minIndex]; a[minIndex] = temp; &#125; &#125;&#125; 时间复杂度分析 比较的次数：(n-1)+(n-2)+…..+1&#x3D;[n*(n-1)]&#x2F;2 交换的次数：n-1 时间复杂度 &#x3D; [n*(n-1)]&#x2F;2 +（n-1）&#x3D;n^2&#x2F;2+n&#x2F;2-1; 时间复杂度O(n^2) 插入排序插入排序的工作方式类似于排序扑克牌，找到正确的位置放 原理： 将元素分为两组：已经排序、未排序 找到未排序的第一个元素，向已排序的组中插入 倒叙遍历已经排序的元素，依次和待插入的元素进行比较，直到找到一个元素小于等于待插入元素，那么就把待插入元素放到这个位置，其他元素向后移动一位 123456789101112131415161718public static void sort(int[] a)&#123; //遍历数组 for(int i =1;i&lt;a.length;i++)&#123; //如果当前元素比前一个元素小 if(a[i]&lt;a[i-1])&#123; //保存当前元素 int temp = a[i]; int j; //遍历当前数字前面的所有数字 for(j=i-1 ; j&gt;=0 &amp;&amp; temp&lt;a[j] ; j--)&#123; //把前一个数字赋给后一个数字 a[j+1] = a[j]; &#125; //把临时变量赋值给不满足条件的第一个元素 a[j+1]=temp; &#125; &#125;&#125; 时间复杂度比较次数：(n-1)+(n-2)+…..+1&#x3D;[n*(n-1)]&#x2F;2 交换次数：(n-1)+(n-2)+…..+1&#x3D;[n*(n-1)]&#x2F;2 总执行次数：相加&#x3D;n^2-n 因此，时间复杂度为O(n^2)，最好O(n)，最坏O(n^2) 希尔排序改进插入排序 原理： 选定一个增长量h，按照增长量h作为数据分组的依据，对数据进行分组 对分好组的每一组数据完成插入排序 减小增长量，最小减为1，重复第二步操作 规则： 123456int h=1;while(h&lt;数组长度/2)&#123; h=2h+1;&#125;//循环结束后就可以确定h的最大值减小规则：h/2 123456789101112131415161718192021222324252627public static void sort(int[] a)&#123; int h =1; while (h&lt;a.length/2)&#123; h=h*2+1; &#125; //当增长量小于1，排序结束 while(h&gt;=1)&#123; //排序 //1、找到待插入的元素 for(int i=h;i&lt;a.length;i++)&#123; //2、把待插入的元素插入到有序数列中 for (int j=i;j&gt;=h;j-=h)&#123; //待插入的元素是a[j],比较a[j]和a[j-h] if(a[j]&lt;a[j-h])&#123; int temp = a[j-h]; a[j-h]=a[j]; a[j]=temp; &#125;else &#123; break; &#125; &#125; &#125; //减少h的值 h = h/2; &#125;&#125; 归并排序原理 1、尽可能的一组数据拆分成两个元素相等的子组，并对每一个子组继续拆分，直到拆分后的每个子组的元素个数是1为止 2、将相邻的两个子组进行合并成一个有序的大组 3、不断重复2 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public static void main(String[] args) &#123; int[] a = new int[]&#123;4,5,6,3,2,1,7,7,9,1,2&#125;; sort(a,0,a.length-1); for(int aa:a)&#123; System.out.print(aa); &#125;&#125;public static void sort(int[] a,int low,int high)&#123; if(high&lt;=low)&#123; return; &#125; int middle = (high+low)/2; sort(a,low,middle); sort(a,middle+1,high); merge(a,low,middle,high);&#125;public static void merge(int[] a,int low,int middle,int high)&#123; //临时数组 int[] temp = new int[high-low+1]; //第一个数组的下标 int i= low; //第二个数组的下标 int j = middle+1; //临时数组的下标 int index = 0; //遍历两个数组，取出小的数字放入临时数组 while (i&lt;=middle&amp;&amp;j&lt;=high)&#123; //第一个数组的数据更小 if(a[i]&lt;=a[j])&#123; //把小的元素放入临时数组 temp[index] = a[i]; i++; &#125;else &#123; temp[index]=a[j]; j++; &#125; index++; &#125; //处理多余数据 while (i&lt;=middle)&#123; temp[index]=a[i]; i++; index++; &#125; while (j&lt;=high)&#123; temp[index]=a[j]; j++; index++; &#125; //把临时数组存入数组 for(int k=0;k&lt;temp.length;k++)&#123; a[k+low]=temp[k]; &#125;&#125; 快速排序原理： 1、设定一个界值，通过该界值分为两部分 2、将大于或等于分界值的数据放到右边，小于分界值的数据放到左边 3、左边和右边的数据独立排序，对于左侧又可以取一个分界值分为两部分，右边一样 4、重复上述过程，这是一个递归定义。 12345678910111213141516171819public static void quick(int[] a,int start,int end)&#123; if(start&gt;=end) return; int temp = a[start]; int low = start; int high = end; while (low&lt;high)&#123; while (low&lt;high &amp;&amp; temp &lt;=a[high])&#123; high--; &#125; a[low] = a[high]; while (low&lt;high &amp;&amp; temp &gt;=a[low])&#123; low++; &#125; a[high]=a[low]; &#125; a[low]=temp; quick(a,start,low); quick(a,low+1,end);&#125; 堆排序","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"}]},{"title":"算法","slug":"算法","date":"2022-01-25T10:45:08.000Z","updated":"2022-02-07T12:59:56.342Z","comments":true,"path":"2022/01/25/算法/","link":"","permalink":"http://example.com/2022/01/25/%E7%AE%97%E6%B3%95/","excerpt":"","text":"二叉树层次遍历123456789101112131415//层次遍历public void level(Node node)&#123; Queue&lt;Node&gt; res = new LinkedList&lt;&gt;(); res.add(node); while (!res.isEmpty())&#123; Node root = res.poll(); System.out.print(root.val+&quot;,&quot;); if(root.left!=null)&#123; res.add(root.left); &#125; if (root.right!=null)&#123; res.add(root.right); &#125; &#125;&#125; BST 二叉搜索树特性： 1、对于 BST 的每一个节点node，左子树节点的值都比node的值要小，右子树节点的值都比node的值大。 2、对于 BST 的每一个节点node，它的左侧子树和右侧子树都是 BST。 3、BST的中序遍历是有序的 1234567void traverse(TreeNode root) &#123; if (root == null) return; traverse(root.left); // 中序遍历代码位置 print(root.val); traverse(root.right);&#125; 题目：BST转化累加树 思路：二叉搜索树中序遍历是从小到大，反过来就是从大到小，那么只需要维护一个sum，在遍历到节点的时候重新赋值即可 代码： 123456789101112131415161718TreeNode convertBST(TreeNode root) &#123; traverse(root); return root;&#125;// 记录累加和int sum = 0;void traverse(TreeNode root) &#123; if (root == null) &#123; return; &#125; traverse(root.right); // 维护累加和 sum += root.val; // 将 BST 转化成累加树 root.val = sum; traverse(root.left);&#125; 回溯基础回溯算法解决的问题： 组合 切割 子集 排列 棋盘 模版： for循环+递归 123456789101112void backtracking(参数)&#123; if(终止条件)&#123; 收集结果;//叶子节点 return; &#125; for(集合的元素集)&#123; 处理节点; 递归函数; 回溯操作;//撤销处理节点的情况 &#125;&#125; 题目一：组合https://leetcode-cn.com/problems/combinations/ 题目：给定两个整数 n 和 k，返回 1 … n 中所有可能的 k 个数的组合。 12345678910输入: n = 4, k = 2输出:[ [2,4], [3,4], [2,3], [1,2], [1,3], [1,4],] 代码： 123456789101112131415161718192021class Solution &#123; List&lt;List&lt;Integer&gt;&gt; res = new LinkedList&lt;&gt;(); LinkedList&lt;Integer&gt; track = new LinkedList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) &#123; LinkedList&lt;Integer&gt; track = new LinkedList&lt;&gt;(); backtracking(n,k,1); return res; &#125; public void backtracking(int n,int k,int start)&#123; if(track.size()==k)&#123; res.add(new LinkedList&lt;&gt;(track)); return; &#125; for(int i=start;i&lt;=n;i++)&#123; track.add(i); backtracking(n,k,i+1); track.removeLast(); &#125; &#125;&#125; 题目二：组合总和题目：给定一个无重复元素的数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。 candidates 中的数字可以无限制重复被选取。 123456输入：candidates = [2,3,6,7], target = 7,所求解集为：[ [7], [2,2,3]] 代码： 123456789101112131415161718192021222324252627class Solution &#123; List&lt;List&lt;Integer&gt;&gt; res = new LinkedList&lt;&gt;(); LinkedList&lt;Integer&gt; track = new LinkedList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) &#123; backtracking(candidates,target,0,0); return res; &#125; void backtracking(int[] nums,int target,int start,int sum)&#123; if(sum==target)&#123; res.add(new LinkedList&lt;Integer&gt;(track)); return; &#125; for(int i=start;i&lt;nums.length;i++)&#123; int temp=sum+nums[i]; if(temp&gt;target)&#123; continue; &#125; sum = sum+nums[i]; track.add(nums[i]); backtracking(nums,target,i,sum); sum = sum-nums[i]; track.removeLast(); &#125; &#125;&#125; 题目三：分割回文串给你一个字符串 s，请你将 s 分割成一些子串，使每个子串都是 回文串 。返回 s 所有可能的分割方案。 回文串 是正着读和反着读都一样的字符串。 12输入：s = &quot;aab&quot;输出：[[&quot;a&quot;,&quot;a&quot;,&quot;b&quot;],[&quot;aa&quot;,&quot;b&quot;]] 代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123; List&lt;List&lt;String&gt;&gt; res = new LinkedList&lt;&gt;(); LinkedList&lt;String&gt; track = new LinkedList&lt;&gt;(); public List&lt;List&lt;String&gt;&gt; partition(String s) &#123; String[] r = new String[s.length()]; for(int i=0;i&lt;s.length();i++)&#123; r[i]=String.valueOf(s.charAt(i)); &#125; backtracking(r,0); return res; &#125; void backtracking(String[] in,int start)&#123; if(start==in.length)&#123; res.add(new LinkedList&lt;String&gt;(track)); return; &#125; for(int i=start;i&lt;in.length;i++)&#123; StringBuilder temp = new StringBuilder(); for(int j=start;j&lt;=i;j++)&#123; temp.append(in[j]); &#125; if(isVaild(temp.toString())==false)&#123; continue; &#125; track.add(temp.toString()); backtracking(in,i+1); track.removeLast(); &#125; &#125; boolean isVaild(String a)&#123; if(a.length()==0)&#123; return false; &#125; StringBuilder b = new StringBuilder(); for(int i=a.length()-1;i&gt;=0;i--)&#123; b.append(a.charAt(i)); &#125; return a.equals(b.toString()); &#125;&#125; 二叉树深度遍历123456789101112131415161718192021222324class Solution &#123; List&lt;List&lt;Integer&gt;&gt; res = new LinkedList&lt;&gt;(); LinkedList track = new LinkedList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, int target) &#123; backtracking(root,target); return res; &#125; void backtracking(TreeNode root,int target)&#123; if(root==null)&#123; return; &#125; track.add(root.val); target-=root.val; if((target==0)&amp;&amp; (root.left == null)&amp;&amp;(root.right==null))&#123; res.add(new LinkedList&lt;&gt;(track)); &#125;else&#123; backtracking(root.left,target); backtracking(root.right,target); &#125; track.removeLast(); &#125;&#125; 全排列1234567891011121314151617181920212223242526class Solution &#123; List&lt;List&lt;Integer&gt;&gt; res = new LinkedList&lt;&gt;(); public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123; LinkedList&lt;Integer&gt; track = new LinkedList&lt;&gt;(); test(nums,track); return res; &#125; public void test(int[] nums,LinkedList&lt;Integer&gt; track)&#123; if(track.size()==nums.length)&#123; res.add(new LinkedList(track)); return; &#125; for(int i=0;i&lt;nums.length;i++)&#123; //排除不合法 if(track.contains(nums[i]))&#123; continue; &#125; track.add(nums[i]); test(nums,track); track.removeLast(); &#125; &#125;&#125; n皇后动态规划求最优解 动态规划的的四个解题步骤是： 定义子问题 写出子问题的递推关系 确定 DP 数组的计算顺序 空间优化（可选） 打家劫舍1234567891011121314151617class Solution &#123; public int rob(int[] nums) &#123; if(nums == null || nums.length == 0)&#123; return 0; &#125;else if(nums.length == 1)&#123; return nums[0]; &#125; int dp[][] = new int[2][nums.length]; dp[0][0]=nums[0]; dp[1][0]=0; for(int i=1;i&lt;nums.length;i++)&#123; dp[0][i] = dp[1][i-1]+nums[i]; dp[1][i] = Math.max(dp[0][i-1],dp[1][i-1]); &#125; return Math.max(dp[0][nums.length-1],dp[1][nums.length-1]); &#125;&#125; 矩阵总路径https://leetcode-cn.com/problems/unique-paths/submissions/ https://www.bilibili.com/video/BV1wf4y1U787 1234567891011121314151617181920class Solution &#123; public int uniquePaths(int m, int n) &#123; //状态容器 int[][] r = new int[m][n]; //初始化状态 for(int i=0;i&lt;m;i++)&#123; r[i][0]=1; &#125; for(int i=0;i&lt;n;i++)&#123; r[0][i]=1; &#125; //状态转移 for(int i=1;i&lt;m;i++)&#123; for(int j=1;j&lt;n;j++)&#123; r[i][j]= r[i][j-1] + r[i-1][j]; &#125; &#125; return r[m-1][n-1]; &#125;&#125; 有障碍矩阵总路径一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为“Start” ）。 机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为“Finish”）。 现在考虑网格中有障碍物。那么从左上角到右下角将会有多少条不同的路径？ 网格中的障碍物和空位置分别用 1 和 0 来表示。 1234567输入：obstacleGrid = [[0,0,0],[0,1,0],[0,0,0]]输出：2解释：3x3 网格的正中间有一个障碍物。从左上角到右下角一共有 2 条不同的路径：1. 向右 -&gt; 向右 -&gt; 向下 -&gt; 向下2. 向下 -&gt; 向下 -&gt; 向右 -&gt; 向右 123456789101112131415161718192021222324252627282930class Solution &#123; public int uniquePathsWithObstacles(int[][] obstacleGrid) &#123; //定义容器 int m = obstacleGrid.length; if(m==0)&#123;return 0;&#125; int n = obstacleGrid[0].length; if(n==0)&#123;return 0;&#125; int[][] r = new int[m][n]; //初始化 for(int i=0;i&lt;m;i++)&#123; if(obstacleGrid[i][0]==1)break; r[i][0]=1; &#125; for(int i=0;i&lt;n;i++)&#123; if(obstacleGrid[0][i]==1)break; r[0][i]=1; &#125; //状态转移 for(int i=1;i&lt;m;i++)&#123; for(int j=1;j&lt;n;j++)&#123; if(obstacleGrid[i][j]==1)continue; r[i][j]=r[i-1][j]+r[i][j-1]; &#125; &#125; return r[m-1][n-1]; &#125;&#125; 最小路径和给定一个包含非负整数的 m x n 网格 grid ，请找出一条从左上角到右下角的路径，使得路径上的数字总和为最小。 说明：每次只能向下或者向右移动一步。 示例 1： 12345678910111213141516171819202122232425class Solution &#123; public int minPathSum(int[][] grid) &#123; //状态容器 int m = grid.length; int n = grid[0].length; int[][] r= new int[m][n]; //初始化 r[0][0]=grid[0][0]; for(int i=1;i&lt;m;i++)&#123; r[i][0]= r[i-1][0]+grid[i][0]; &#125; for(int i=1;i&lt;n;i++)&#123; r[0][i]= r[0][i-1]+grid[0][i]; &#125; //状态转移 for(int i=1;i&lt;m;i++)&#123; for(int j=1;j&lt;n;j++)&#123; r[i][j]=Math.min(r[i-1][j],r[i][j-1])+grid[i][j]; &#125; &#125; return r[m-1][n-1]; &#125;&#125; 等差数列在 A[i] - A[i-1] &#x3D;&#x3D; A[i-1] - A[i-2] 时，dp[i] &#x3D; dp[i-1] + 1 12345678910111213141516171819class Solution &#123; public int numberOfArithmeticSlices(int[] nums) &#123; int[] dp = new int[nums.length]; dp[0]=0; dp[1]=0; for(int i=2;i&lt;nums.length;i++)&#123; if(nums[i]==2*nums[i-1]-nums[i-2])&#123; dp[i]=dp[i-1]+1; &#125; &#125; int sum=0; for(int c:dp)&#123; System.out.println(c); sum+=c; &#125; return sum; &#125;&#125; 整数拆分123456789101112131415161718class Solution &#123; public int integerBreak(int n) &#123; if(n==1)&#123;return 1;&#125; if(n==2)&#123;return 1;&#125; if(n==3)&#123;return 2;&#125; int[] dp = new int[n+1]; dp[1]=1; for(int i=2;i&lt;=n;i++)&#123; dp[i]=i; for(int j=1;j&lt;i;j++)&#123; dp[i]=Math.max(dp[i],j*dp[i-j]); &#125; &#125; return dp[n]; &#125;&#125; 整数拆分平方1234567891011121314class Solution &#123; public int numSquares(int n) &#123; int[] dp = new int[n+1]; dp[1]=1; for(int i=2;i&lt;=n;i++)&#123; dp[i]=i; for(int j = 1; i-j*j &gt;= 0 ; j++)&#123; dp[i] = Math.min(dp[i], dp[i-j*j]+1); &#125; &#125; System.out.println(Arrays.toString(dp)); return dp[n]; &#125;&#125; 最长递增子序列123456789101112131415161718192021class Solution &#123; public int lengthOfLIS(int[] nums) &#123; //以nums[n]结尾的最长 int n = nums.length; int[] dp = new int[n]; for(int i=0;i&lt;n;i++)&#123; int max = 1; for(int j=0;j&lt;i;j++)&#123; if(nums[i]&gt;nums[j])&#123; max = Math.max(max,dp[j]+1); &#125; &#125; dp[i]=max; &#125; int ret = 0; for (int i = 0; i &lt; n; i++) &#123; ret = Math.max(ret, dp[i]); &#125; return ret; &#125;&#125; 最长数对链12345678910111213141516171819202122class Solution &#123; public int findLongestChain(int[][] pairs) &#123; int n = pairs.length; int[] dp = new int[n]; Arrays.fill(dp,1); Arrays.sort(pairs, (a, b) -&gt; (a[0] - b[0])); for(int i=0;i&lt;n;i++)&#123; int max = 1; for(int j=0;j&lt;i;j++)&#123; if(pairs[j][1]&lt;pairs[i][0])&#123; max=Math.max(max,dp[j]+1); &#125; &#125; dp[i]=max; &#125; int ret = 0; for (int i = 0; i &lt; n; i++) &#123; ret = Math.max(ret, dp[i]); &#125; return ret; &#125;&#125; BFS每k个一组反转链表 12345678910111213141516171819202122232425262728293031import java.util.*;public class Solution &#123; /** * * @param head ListNode类 * @param k int整型 * @return ListNode类 */ public ListNode reverseKGroup (ListNode head, int k) &#123; if(head==null||head.next==null||k==1) return head; ListNode res = new ListNode(0); res.next = head; int length=0; ListNode pre = res ,cur=head,temp=null; while(head!=null)&#123; length++; head = head.next; &#125; for(int i=0;i&lt;length/k;i++)&#123; for(int j=1;j&lt;k;j++)&#123; temp = cur.next; cur.next = temp.next; temp.next = pre.next; pre.next = temp; &#125; pre=cur; cur=cur.next; &#125; return res.next; &#125;&#125; 剑指Offer12 矩阵路径（DFS、剪枝）https://leetcode-cn.com/problems/ju-zhen-zhong-de-lu-jing-lcof/submissions/ 给定一个 m x n 二维字符网格 board 和一个字符串单词 word 。如果 word 存在于网格中，返回 true ；否则，返回 false 。 单词必须按照字母顺序，通过相邻的单元格内的字母构成，其中“相邻”单元格是那些水平相邻或垂直相邻的单元格。同一个单元格内的字母不允许被重复使用。 例如，在下面的 3×4 的矩阵中包含单词 “ABCCED”（单词中的字母已标出）。 1234567891011121314151617181920212223242526272829class Solution &#123; public boolean exist(char[][] board, String word) &#123; char[] words = word.toCharArray(); for(int i = 0; i &lt; board.length; i++) &#123; for(int j = 0; j &lt; board[0].length; j++) &#123; if(dfs(board, words, i, j, 0)) return true; &#125; &#125; return false; &#125; boolean dfs(char[][] board, char[] word, int i, int j,int k) &#123; if(i &gt;= board.length || i &lt; 0 || j &gt;= board[0].length || j &lt; 0 || board[i][j] != word[k])&#123; return false; &#125; if(k == word.length - 1)&#123; return true; &#125; char temp = board[i][j]; board[i][j] = &#x27;/&#x27;; boolean res = dfs(board, word, i + 1, j, k + 1) || dfs(board, word, i - 1, j, k + 1) || dfs(board, word, i, j + 1, k + 1) || dfs(board, word, i , j - 1, k + 1); board[i][j] = temp; return res; &#125;&#125; 13 机器人运动范围https://leetcode-cn.com/problems/ji-qi-ren-de-yun-dong-fan-wei-lcof/ 地上有一个m行n列的方格，从坐标 [0,0] 到坐标 [m-1,n-1] 。一个机器人从坐标 [0, 0] 的格子开始移动，它每次可以向左、右、上、下移动一格（不能移动到方格外），也不能进入行坐标和列坐标的数位之和大于k的格子。例如，当k为18时，机器人能够进入方格 [35, 37] ，因为3+5+3+7&#x3D;18。但它不能进入方格 [35, 38]，因为3+5+3+8&#x3D;19。请问该机器人能够到达多少个格子？ 12345678910111213141516171819202122232425262728class Solution &#123; public int movingCount(int m, int n, int k) &#123; boolean[][] board = new boolean[m][n]; for(int i=0;i&lt;m;i++)&#123; for(int j=0;j&lt;n;j++)&#123; board[i][j]=false; &#125; &#125; return dfs(0,0,m,n,k,board); &#125; int sums(int x)&#123; int s = 0; while(x != 0) &#123; s += x % 10; x = x / 10; &#125; return s; &#125; int dfs(int i, int j, int m, int n, int k,boolean[][] board) &#123; if (sums(i)+sums(j)&gt;k || i &lt; 0 || i &gt; m - 1 || j &lt; 0 || j &gt; n - 1 || board[i][j]) &#123; return 0; &#125; board[i][j]=true; return 1 + dfs(i+1,j,m,n,k,board) + dfs(i,j+1,m,n,k,board); &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"}]},{"title":"计算机网络","slug":"计算机网络","date":"2022-01-23T08:48:31.000Z","updated":"2022-02-07T13:27:47.128Z","comments":true,"path":"2022/01/23/计算机网络/","link":"","permalink":"http://example.com/2022/01/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","excerpt":"","text":"[TOC] 面试题汇总网络层传输层1、请详细介绍TCP的三次握手协议，为什么要三次握手？ 核心点：为什么需要握手？为什么是三次？ TCP重要特性：可靠性 需要同步序号、mss、是否使用sack、滑动窗口系数 建立连接不允许出现半打开状态 2、CLOSE_WAIT状态的产生原因 CLOSE_WAIT 状态在服务器停留时间很短，如果你发现大量的 CLOSE_WAIT 状态，那么就意味着被动关闭的一方没有及时发出 FIN 包，一般有如下几种可能： 程序问题：如果代码层面忘记了 close 相应的 socket 连接，那么自然不会发出 FIN 包，从而导致 CLOSE_WAIT 累积；或者代码不严谨，出现死循环之类的问题，导致即便后面写了 close 也永远执行不到。 响应太慢或者超时设置过小：如果连接双方不和谐，一方不耐烦直接 timeout，另一方却还在忙于耗时逻辑，就会导致 close 被延后。响应太慢是首要问题，不过换个角度看，也可能是 timeout 设置过小。 BACKLOG 太大：此处的 backlog 不是 syn backlog，而是 accept 的 backlog，如果 backlog 太大的话，设想突然遭遇大访问量的话，即便响应速度不慢，也可能出现来不及消费的情况，导致多余的请求还在队列里就被对方关闭了。 3、服务器的最大并发连接数是多少？ 由TCP四元组决定，包括源IP地址、目标IP地址、源端口、目标端口 4、TCP和UDP协议应该如何选择？ UDP： 一对多通讯 效率高 简单 实时性好 TCP： 字符流协议，可以传任意长度的消息 可靠 流量控制、拥塞控制 应用层1、HTTP协议中缓存的处理流程？ 2、URL之后发生了什么？ DNS解析 TCP连接 发送HTTP请求 服务器处理请求并返回HTTP报文 浏览器解析渲染页面 连接结束 3、使用HTTP长连接的优点？ 减少了握手次数 减少慢启动的影响 如何区别HTTP的长连接和短连接？ 在HTTP&#x2F;1.0中，默认使用的是短连接 从 HTTP&#x2F;1.1起，默认使用长连接，Connection:keep-alive 使用HTTP长连接的缺点？ TCP协议是字符流协议，顺序不能乱 会出现对头阻塞 4、HTTP1.0&#x2F;1.1&#x2F;2.0的区别 HTTP&#x2F;1.1相较于 HTTP&#x2F;1.0 协议的区别主要体现在： 长连接 : 在HTTP&#x2F;1.0中，默认使用的是短连接，也就是说每次请求都要重新建立一次连接。HTTP 是基于TCP&#x2F;IP协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。HTTP 1.1起，默认使用长连接 ,默认开启Connection： keep-alive。 HTTP&#x2F;1.1的持续连接有非流水线方式和流水线方式 。流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。 错误状态响应码 :在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。 缓存处理 :在HTTP1.0中主要使用header里的If-Modified-Since，Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。 带宽优化及网络连接的使用 :HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。 5、HTTP和HTTPS 端口 ：HTTP的URL由“http:&#x2F;&#x2F;”起始且默认使用端口80，而HTTPS的URL由“https:&#x2F;&#x2F;”起始且默认使用端口443。 安全性和资源消耗：HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL&#x2F;TLS之上的HTTP协议，SSL&#x2F;TLS 运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。 对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等； 非对称加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等。 基本概念互联网（internet） 思考：数据是如何从一个设备传递到另外一个设备的？ 1、互联网、移动互联网、物联网都离不开网络协议 2、最熟悉的网络协议：HTTP 3、为了满足各种需求，有各式各样的网络协议（HTTPS、SMTP、MQIT等） 客户端-服务器1、C&#x2F;C++跨平台原理 2、Java跨平台原理 3、客户端vs服务器 OSI网络互联模型国际标准化组织ISO在1985年制定了网络互联模型 OSI参考模型（open system interconnect reference model），7层结构 注意：OSI参考模型是理论模型，实战模型使用TCP&#x2F;IP协议模型，学习研究使用第三种模型 请求过程 经过每一层的包装从客户端的应用层到物理层，传输到服务器的物理层后再一层层的解析 ARP协议ARP（Address Resolution Protocol）即地址解析协议， 用于实现从 IP 地址到 MAC 地址的映射，即询问目标IP对应的MAC地址。 例：A向B发送数据 根据ARP表差查询MAC地址，如果查不到就使用广播地址，所有节点都可以收到，再根据IP地址获得B的MAC地址，再返回A 计算机之间的连接方式1、需要得知对方的IP地址 2、最终根据MAC地址（网卡地址），输送数据到网卡，被网卡接收 3、如果网卡发现数据的目标MAC地址是自己，就会把数据传递给上一层进行处理；不是自己就会进行丢弃 网线直连 需要使用交叉线（不是直通线） 同轴电缆（Coaxial） 半双工通信 容易冲突 不安全 集线器（Hub） 半双工通信 容易冲突 不安全 网桥（Bridge） 能够自学习得知每个接口那侧的MAC地址 隔绝冲突域 交换机（Switch） 相当于接口更多的网桥 比集线器安全 全双工通信 路由器（Router） 上面的几种方式连接的设备必须在同一网段，连接的设备处在同一个广播域 路由器：可以在不同网段之间转发数据，隔绝广播域 主机发数据之前，首先判断目标主机的IP地址跟它是否在同一个网段 在同一个网段：ARP、通过交换机&#x2F;集线器传递数据 不在同一个网段：通过路由器转发数据 设置路由器网关的IP地址，路由器的网关需要和一边的主机在同一个网段，同时主机需要设置网关 比如：计算机0和计算机3进行第一次通信 主机0通过ARP知道网关的MAC地址，将地址返回主机0 主机0通过ICMP传输数据到另一边的网关 另一边的网关发出ARP，找到目标主机3的MAC地址，返回网关 网关通过ICMP传输数据到主机3 MAC地址1、每一个网卡都有一个6字节（48bit）的MAC地址（Media Access Control Address） 2、MAC地址全球唯一，固化在网卡的ROM中，由IEEE802标准规定 3、前3字节：OUI，组织唯一标识符（厂商不同，OUI不同） 4、后3字节：网络接口标识符（厂商自行分配） 5、12位十六进制 6、广播地址：48位都为1，FF-FF-FF-FF-FF-FF（二进制1111&#x3D;十六进制F） 7、MAC地址的获取 当不知道对方的MAC地址，使用ARP广播进行获取对方的MAC地址 获取成功后，会缓存IP地址、MAC地址的映射信息，又称为ARP缓存 通过ARP广播获取的MAC地址，属于动态缓存，存储时间较短，超时删除 IP地址1、IP地址：互联网上每一个主机都有一个IP地址 2、IPv4版本，32bit（4字节），已经被用完 3、IPv6版本，128bit（16字节） 4、IP地址的组成：网络标识（网络ID）+主机标识（主机ID） 同一个网段的主机，网络ID相同 通过子网掩码可以算出网络ID：子网掩码&amp;IP地址（&amp;运算：同为1则为1，否则为0） ⚠️：必须要通过子网掩码计算出网络ID，网络ID有多少位是不一定的 ⚠️：主机位不能全0（网段），不能全1（广播IP地址） 例如：网段为192.168.0.0，能够容纳主机数量为256*256-2 计算机和其他计算机通信时，需要判断是否在同一个网段，如果在就不需要使用路由器进行转发 IP地址的分类 1、A类地址 网络ID 0开头 0不能使用，127不能使用（保留），127.0.0.1是本地环回地址，代表本机地址 可以分配给主机：1-126 主机ID 第2、3、4部分取值范围：0-255 最大主机容量：256 * 256 * 256 - 2 &#x3D; 2^24 - 2 &#x3D; 16777214 2、B类地址 网络ID 10开头 范围：128.0 到 191.255 主机ID 第3、4部分取值范围：0-255 最大主机容量：256 * 256 - 2 &#x3D; 2^16 -2 3、C类地址 网络ID： 110开头 第1部分取值范围：192-223 第2、3部分取值范围：0-255 主机ID： 第4部分取值范围：0-255 最大主机容量：256 - 2 &#x3D; 254 4、D类地址 5、E类地址 子网掩码的CIDR表示1、192.168.1.100&#x2F;24，代表子网掩码24个1，也就是255.255.255.0 2、123.210.100.200&#x2F;16，代码子网掩码16个1，也就是255.255.0.0 子网划分 为什么要子网划分？ 如果需要让200台主机在同一个网段内，可以分配一个C类网段，比如192.168.1.0&#x2F;24 共254个可用IP地址，192.168.1.1— 192.168.1.254 如果需要让500台主机在同一个网段内，分配一个B类网段，比如：191.100.0.0&#x2F;16 共65534个可用Ip地址 多出65034个空闲IP地址，属于极大的浪费资源 1、子网划分：借用主机位作为子网位，划分出多个子网 可以分为： 等长子网划分：将一个网段等分成多个子网，每个子网的可用IP地址数量一样 变长子网划分：每个子网的可用IP地址数量可用不一样 1、等长子网划分 往右移1位，等分出两个子网 往右移2位，等分出四个子网 规律：后移n位，等分出(1&#x2F;2)^n个子网 2、变长子网划分 如果一个子网地址块的长度是原网段的(1&#x2F;2)^n，子网的子网掩码就增加n 不等长的子网，子网掩码不同 超网将多个连续的网段合并成一个更大的网段 需求：200台计算机使用192.168.0.0&#x2F;24网段，现在希望增加200台设备到同一个网段 200台在192.168.0.0&#x2F;24网段，200台在192.168.1.0&#x2F;24网段 合并为一个网段：192.168.0.0&#x2F;23（子网掩码左移1位） 判断子网和超网 路由在不同网段之间传输数据，需要路由器的支持 在默认情况下，路由器只知道和它直连的网段，非直连的网段需要通过静态路由、动态路由告诉它 静态路由 管理员手动添加路由信息 适用于小规模网络 动态路由 路由器通过路由选择协议（RIP、OSPF）自动获取路由信息 适用于大规模网络 数据包传递过程 网络、互联网、因特网 ISPISP：Internet服务提供商，比如：移动、电信、网通等 平时拉宽带都是通过ISP连接到Internet的 网络分类安装网络范围分类：局域网、城域网、广域网 局域网 LAN，几百米到十几公里内构成的计算机网络 局域网中最广泛使用的网络技术：以太网（Ethernet） WLAN：无线局域网 城域网：MAN 广域网：WAN 一般范围是几百公里和几千公里，通常需要租用ISP的线路 上网方式1、电话线入户 2、光纤入户 3、网线入户 公网IP、私网IP1、公网IP（public） Internet上的路由器只有到达公网的路由表，没有到达私网的路由表 公网IP由因特网信息中心统一分配和管理 ISP需要向Inter NIC申请公网IP 2、私网IP（private） 主要用于局域网 A类：10.0.0.0&#x2F;8 B类：172.16.0.0&#x2F;16—172.31.0.0&#x2F;16 C类：192.168.0.0&#x2F;24—192.168.255.0&#x2F;24，256个C类网络 NAT私网IP访问Internet需要进行NAT转换为公网IP NAT（Network Address Translation） 这一步由路由器完成 NAT特点： 可以节约公网IP资源 会隐藏内部真实IP NAT的分类： 静态转换（不常用） 手动配置NAT映射表 一对一转换，一个私网IP对应一个公网IP 动态转换（不常用） 定义外部地址池，动态随机转换 一对一转换 PAT（Port Address Translation） 多对一转换，最大程度节约公网IP资源 利用端口号标识不同的数据请求 目前应用最广泛 网络分层网络互联模型 OSI参考模型7层结构 每一层都接收由它的下一层所提供的特定服务，并且为上一层提供特定的服务。 接口：上下层之间交互所遵循的约定 协议：同一层之间交互所遵循的约定 TCP&#x2F;IP 数据链路层1、链路 从一个节点到相邻节点的一段物理线路（有线或无线），中间没有其他交换节点 2、数据链路 在一条链路上传输数据时，需要有对应的通信协议控制数据的传输 不同类型的数据链路，所用的通信协议可能是不同的 广播信道：CSMA&#x2F;CD协议（比如同轴电缆、集线器等组成的网络） 点对点信道：PPP协议（比如两个路由器之间的信道） 3、数据链路层的3个基本问题 封装成帧 透明传输 差错检验 作用数据链路层的协议定义了通信媒介互连的设备之间传输的规范（双绞线电缆、光纤等）；此外，各个设备之间有时也会通过交换机、网桥等中专数据。 三个基本问题封装成帧1、帧的数据部分： 网络层传输过来的：IP数据包 2、最大传输单元MTU（上一层的数据包要小于MTU） 每一种数据链路层协议都规定了能够传送的帧的数据长度上线 以太网的MTU为1500个字节 透明传输使用SOH作为帧开始符、使用EOT作为帧结束符 数据部分一旦出现了SOH、EOT，需要进行转义 差错检验传输前计算出FCS（根据数据部分+首部计算） 传输后再次计算，进行验证 CSMA&#x2F;CD协议 不同协议的帧首部和尾部不同，进行传输会进行拆除再封装 1、使用了CSMA&#x2F;CD的网络称为以太网（Ethernet），它传输的是以太网帧 格式：Ethernet V2标准 2、为了检测正在发送的帧是否发生冲突，以太网的帧需要至少64个字节 3、用交换机组建的网络，已经支持全双工通信，不需要再使用CSMA&#x2F;CD，但是它传输的依然是以太网帧，所以交换机组建的网络依然叫以太网 Ethernet V2帧的格式 ⚠️ 没有帧开始符和帧结束符 以太网使用曼彻斯特编码，不需要帧开始符、帧结束符 1、以太网帧结构 首部：目标MAC地址 + 源MAC地址 + 类型（ipv4或者ipv6） 数据：IP数据包 尾部：FCS 数据长度至少：64 - 4 - 6 - 6 - 2 &#x3D; 46字节，最多1500个字节（MTU） 2、当数据部分长度小于46字节时 数据链路层会在数据后面加入一些字节填充 接收端会将添加的字节删除 3、长度总结 以太网帧的数据长度：46—1500字节 以太网帧的长度：64—1518字节（目标MAC+源MAC+类型+数据+FCS） PPP协议点对点协议 PPP帧 网络层TCP&#x2F;IP的心脏是网络层，这一层主要由IP和ICMP协议组成。 与数据链路层的关系数据链路层提供直连两个设备之间通信的功能 每张票只能在限定区间内移动，这个区间就如同数据链路，出发地和终点就如同源地址和目标地址 行程表就相当于网络层 数据包网络层数据包（IP数据包，packet）由首部、数据2部分组成 数据：一般由传输层传递下来的数据段（segment） 首部版本、首部长度、区分服务1、版本（Version） 4位 占4位 0b0100：IPv4 0b0110：IPv6 2、首部长度 4位 占4位 二进制乘以4才是最终长度 0b0101：20（最小值） 0b1111：60（最大值），首部固定长度20个字节，可变部分最大40个字节 3、区分服务 8位 占8位 可以提高网络的服务质量 总长度1、占16个字节 2、就是首部+数据长度之和，最大值是65535字节 由于帧的数据不能超过1500字节（MTU），所以过大的IP数据包，需要进行分片传输给数据链路层 每一片都有自己的网络层首部（IP首部） 标识、标志1、标识 占16位 数据包的ID，当数据包过大时进行分片时，同一个数据包的所有片的标识都是一样的 有一个计数器专门管理数据包的ID，每发出一个数据包，ID就加1 2、标志 占3位 第一位：保留 第二位：DF（Don’t Fragment）：1代表不允许分片，0代表允许分片 第三位：MF（More Fragments）：1代表不是最后一片，0代表是最后一片 片偏移1、作用：为了将分片后的数据包按顺序还原 偏移为0，说明在最前面 2、占13位 3、片偏移*8：字节偏移 4、每一片的长度一定是8的倍数 生存时间（TTL）1、占8位 2、每个路由器在转发之前将TTL减1，TTL为0，路由器返回错误报告 3、使用ping命令后的TTL，能够推测出对方的操作系统，中间经过了多少路由器 协议、首部检验和1、协议 占8位 表明所封装的数据使用的协议 例如： ICMP：1 IGMP：2 TCP：6 UDP：17 IPv6：41 2、首部检验和 用于检查首部是否有错误 ICMPhttps://juejin.cn/post/6844904102988611598 ping命令使用ICMP协议 在网络中ping是一个十分强大的TCP&#x2F;IP工具。它的作用主要为： （1）用来检测网络的连通情况和分析网络速度； （2）根据域名得到服务器IP； （3）根据ping返回的TTL值来判断对方所使用的操作系统及数据包经过路由器数量。 我们通常会用它来直接ping IP地址，来测试网络的连通情况。 ICMP 的全称是 Intent Control Message Protocol, 中文过来就是 互联网控制报文协议。 它是互联网协议族的核心协议之一。 它用于TCP&#x2F;IP网络中发送控制消息，提供可能发生在通信环境中的各种问题反馈，通过这些信息，使管理者可以对所发生的问题作出诊断，然后采取适当的措施解决。 在IP通信中，经常有数据包到达不了对方的情况。原因是，在通信途中的某处的一个路由器由于不能处理所有的数据包，就将数据包一个一个丢弃了。或者，虽然到达了对方，但是由于搞错了端口号，服务器软件可能不能接受它。这时，在错误发生的现场，为了联络而飞过来的信鸽就是ICMP 报文。 在IP 网络上，由于数据包被丢弃等原因，为了控制将必要的信息传递给发信方。ICMP 协议是为了辅助IP 协议，交换各种各样的控制信息而被制造出来的。 ICMP的主要功能： 1.确认IP包是否成功送达目标地址。2.通知在发送过程当中IP包被废弃的具体原因。 报文ICMP报文主要分为两种类型： 查询报文 差错报文 1、查询报文 （Echo Request与 Echo Reply） 定义：发送端主动发起请求，并且获取到应答。 常见应用：Ping Ping 就是主动请求，获取到主动应答。但是 Ping 是在原生的 ICMP 中添加了自定义格式区域。例如 Ping 中放了发送的请求时间，以此计算出路程。所以，其实在 Ping 的报文中会加入序号，以用来区分数据包，从而提高计算时间或者路程的准确性。 ICMP实现之ping命令ping 命令用来在IP 层次上调查与指定机器是否连通，调查数据包往复需要多少时间。 为了实现这个功能，ping 命令使用了两个ICMP 报文。 1.向目标服务器发送回送请求。 首先，向目标服务器发出回送请求（类型是8，代码是0）报文（同2）。 在这个回送请求报文里，除了类型和代码字段，还被追加了标识符和序号字段。标识符和序号字段分别是16 位的字段。ping 命令在发送回送请求报文时，在这两个字段里填入任意的值。对于标识符，应用程序执行期间送出的所有报文里填入相同的值。对于序号，每送出一个报文数值就增加1。而且，回送请求的选项数据部分用来装任意数据。这个任意数据用来调整ping 的交流数据包的大小。 2.返回回送回答。 计算机送出的回送请求到达目标服务器后，服务器回答这一请求，向送信方发送回送请求（类型是0，代码是0）（同3）。 这个ICMP 回送回答报文在IP 层来看，与被送来的回送请求报文基本上一样。不同的只是，源和目标IP 地址字段被交换了，类型字段里填入了表示回送回答的0。也就是，从送信方来看，自己送出的ICMP 报文从目标服务器那里象鹦鹉学舌那样原样返回了。 送信方的计算机可以通过收到回送回答报文，来确认目标服务器在工作着。进一步，记住发送回送请求报文的时间，与接收到回送回答报文的时间一比较，就能计算出报文一去一回往复所需要的时间（同4）。 但是，收到的回送回答报文里写的只是类型和代码的话，发送方计算机将无法判断它是否是自己发出去请求的回答。因此，前面说到的标识符和序号字段就有它的意义了。将这两个值与回送回答报文中的相同字段值一比较，送行方计算机就能够简单地检测回送回答是否正确了。执行ping 命令而调查的结果没什么问题的话，就将目标服务器的IP 地址，数据大小，往复花费的时间打印到屏幕上。 3.用ping 命令不能确定与对方连通的原因大致有三个。 1）目标服务器不存在； 2)花在数据包交流上的时间太长ping 命令认为超时； 3）目标服务器不回答ping 命令。 如果是原因2），通过ping 命令的选项来延长到超时的等待时间，就能正确显示结果了。如果原因是1）或3）的话，仅凭ping 命令的结果就不能判断是哪方了。正如这样，ping 命令不一定一定能判断对方是否存在。 传输层传输层有2个协议 TCP（Transmission Control Protocol）：传输控制协议 UDP（User Datagram Protocol）：用户数据包协议 区别： TCP需要建立连接（三次握手，四次挥手）；UDP无连接（不管能不能连接上，直接把数据扔过去） TCP是可靠传输，不会丢包（会重新发）；UDP不可靠 1、TCP提供可靠交付，无差错、不丢失、不重复，并且按照顺序到达；UDP继承了IP包的特性，不保证不丢失，不保证按顺序到达 2、TCP面向字节流，UDP继承了IP的特性，基于数据报，一个个发送一个个收 3、TCP可以有拥塞控制，会调整自己发送速度；UDP不会控制 UDP数据格式 UDP是无连接的，减少了建立和释放连接的开销 UDP尽最大能力交付，不保证可靠交付 因此，不需要维护一些复杂的参数，只有8个字节 UDP长度 占16位 首部长度+数据长度 UDP检验和 1、计算内容：伪首部+首部+数据 2、伪首部 12位 源IP地址、目的IP地址、保留（0）、协议号（17）、UDP长度 只在计算检验和起作用，不会传递给网络层 源端口、目标端口 1、目标端口 16位 端口号：0-65535 服务器的端口，监听客户端的数据 2、源端口 16位 客户端的端口 临时开启的随机端口 UDP的三大特点 沟通简单，不需要大量的数据结构、处理逻辑、包头字段 轻信他人，不会建立连接；可以一对多传输数据 不会拥塞控制 UDP的三大使用场景 需要的资源少，在网络比较好的内网，对于丢包不敏感的应用 不需要一对一沟通，建立连接，可以广播的应用 UDP的不面向连接的功能可以使得可以承载广播或者多播的协议； DHCP就是广播的形式 需要处理速度快，时延低，可以容忍少数丢包 TCP数据格式 数据偏移 占4位，取值范围：0101到1111 乘以4：首部长度（最小20，最大60） ❓UDP首部有个16位的字段记录了整个UDP报文段的长度（首部+数据），但是TCP的首部中仅仅有个4个字段记录了TCP报文段的首部长度，并没有记录TCP报文段的数据长度 分析： UDP首部16位的长度字段是冗余的，纯粹是为了保证首部是32bit对齐 TCP&#x2F;UDP的数据长度，完全可以由IP数据包的首部推测出来 传输层的数据长度 &#x3D; 网络层的总长度 - 网络层的首部长度 - 传输层的首部长度 保留 占6位，目前全位0 检验和 和UDP一样，TCP检验和的计算内容：伪首部+首部+数据 伪首部：占用12字节，仅在计算检验和时起作用，不会传递给网络层 标志位（Flags） 1、URG（urgent）紧急位 当URG&#x3D;1时，紧急指针字段才有效，表示当前报文段中有紧急数据，应优先传送 2、ACK（acknowledge） 当ACK&#x3D;1时，确认号字段才有效 3、PSH（push） 4、RST（rest）重置 当RST&#x3D;1，表示连接中出现严重差错，如图 5、SYN（Syn） 当SYN&#x3D;1，ACK&#x3D;0时，表示这是一个建立连接的请求 当SYN&#x3D;1，ACK&#x3D;1时，表示对方同意建立连接 6、FIN（Finsh） 当FIN&#x3D;1，表示数据发送完毕，要求释放连接 序号、确认号 1、序号（seq） 4个字节，32位 首先，在传输过程中的每一个字节都有一个编号 在建立连接后，序号代表：这一次传递给对方的TCP数据部分的第一个字节的编号 2、确认号（ack） 4个字节，32位 在建立连接之后，代表：期望对方下一次传过来的TCP数据部分的第一个字节编号 窗口 2个字节，16位 这个字段有流量控制功能，用来告诉对方下一次允许发送的数据大小（字节为单位） 可靠传输 停止等待ARQ协议自动重传请求，超时重传 1) 无差错情况: 发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送。 2) 出现差错情况（超时重传）: 停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。 因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。 这种自动重传方式常称为 自动重传请求 ARQ 。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。 3) 确认丢失和确认迟到 确认丢失 ：确认消息在传输过程丢失。 当A发送M1消息，B收到后，B向A发送了一个M1确认消息，但却在传输过程中丢失。而A并不知道，在超时计时过后，A重传M1消息，B再次收到该消息后采取以下两点措施：1. 丢弃这个重复的M1消息，不向上层交付。 2. 向A发送确认消息。（不会认为已经发送过了，就不再发送。A能重传，就证明B的确认消息丢失）。 确认迟到 ：确认消息在传输过程中迟到。 A发送M1消息，B收到并发送确认。在超时时间内没有收到确认消息，A重传M1消息，B仍然收到并继续发送确认消息（B收到了2份M1）。此时A收到了B第二次发送的确认消息。接着发送其他数据。过了一会，A收到了B第一次发送的对M1的确认消息（A也收到了2份确认消息）。处理如下：1. A收到重复的确认后，直接丢弃。2. B收到重复的M1后，也直接丢弃重复的M1。 优缺点： 优点： 简单 缺点： 信道利用率低，等待时间长 连续ARQ协议+滑动窗口协议 发送方的窗口大小由接收方决定 流程： 优缺点： 优点： 信道利用率高，容易实现，即使确认丢失，也不必重传。 缺点： 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。 SACK（选择性确认）1、在TCP通信过程中，如果发送序列中间某个数据包丢失（比如发送1、2、3、4，其中3丢失了） TCP会通过重传最后确认的分组后续的分组（最后确认的是2，会重传3、4） 这样原先已经正确传输的分组也可能会重复发送（比如4），降低了TCP的性能 2、为了改善上述情况，使用SACK（selective acknowledge）技术 告诉发送方哪些数据丢失，哪些数据已经提前收到 使TCP只重新发送丢失的包（比如3），不会发送后续所有的分组（比如4） 3、SACK会放在TCP首部的选项部分 Kind：占1字节，值为5代表这是SACK选项 Length：占1字节，表明SACK选项共占用多少字节 Left Edge：占4字节，左边界 Right Edge：占4字节，右边界 通过左边界和右边界表示收到的数据，一对8个字节，最多携带4组，（40-1-1）&#x2F;8 SACK最大占用字节数：4 * 8 + 2 &#x3D; 34 为什么在传输层进行分段，而不是在网络层分片？ 1、可以提高重传的性能 2、可靠传输是在传输层进行控制的 如果在传输层不分段，一旦出现数据丢失，整个传输层的数据都需要重传 如果在传输层分段，一旦出现数据丢失，只需要重传丢失的那些段 流量控制1、如果接收方的缓存区满了，发送方还在发数据 接收方只能把收到的数据包丢掉，大量的丢包会极大浪费网络资源 所以要进行流量控制 2、什么是流量控制？ 让发送方的发送速率不要太快，让接收方来得及处理 3、原理 通过确认报文中窗口字段来控制发送方的发送速率 发送方的发送窗口大小不能超过接收方给出的窗口大小 当发送方收到接收窗口大小为0时，发送方就会停止发送数据 特殊情况接收方给发送方发送了0窗口的报文段 接收方又有了一些存储空间，给发送方发送的非0窗口的报文段丢失了 解决方案： 当发送方收到0窗口，这时发送方停止发送报文 并且同时开启定时器，隔一段时间就去询问最新的窗口大小 如果还是0，就会重置定时器 拥塞控制 1、拥塞控制 防止过多的数据注入到网络中 避免网络中路由器或链路过载 2、拥塞控制是一个全局性的过程 涉及所有的主机、路由器、与降低网络性能有关的所有因素 3、相比而言，流量控制时点对点通信的控制 几个名词1、MSS（maxium segment size） 每个段最大的数据部分大小 在连接时确定，只在连接时出现 理论上是1460字节，实际需要双方协商 2、cwnd：拥塞窗口 发送方根据自己估算的网络拥塞程度而设置的窗口值 动态的 3、rwnd：接收窗口 4、swnd：发送窗口 发送窗口 &#x3D; min（拥塞窗口，接收窗口） 慢开始（slow start） 1、令拥塞窗口为1个包，发送1个MSS 2、收到一个确认之后，将拥塞窗口加倍，下一次就可以发送2个MSS 3、同理加倍 拥塞避免（congestion avoidance） 1、ssthresh（slow start threshold）：慢开始阈值，cwnd达到阈值后，以线性方式增长（加法增大） 2、拥塞避免（加法增大）：拥塞窗口缓慢增大，防止网络过早出现拥塞 3、乘法减小：只要网络出现拥塞，把ssthresh减半，于此同时，执行慢开始算法（拥塞窗口返回初始值：1个包） 如果网络出现频繁拥塞，阈值就会变得很小 快速重传（fast retransmit） 1、接收方 每收到一个失序的分组后（m1 m2 m4），立即发出重复确认（m2） 使发送方及时知道有分组没有到达，而不要等待自己发送数据时才进行确认（SACK） 2、发送方 只要连续收到三个重复确认（总共4个确认），就应该立即重传没有收到的报文段 不需要等待重传计数器到期后再重传（超时重传） 快速恢复（fast recovery） 当发送方连续收到3个重复确认，就执行“乘法减小”，阈值减半 为了预防网络丢包 与之前不同的是这次从阈值开始执行拥塞避免算法（加法增大） 小结 1、可靠传输：保证丢掉的包可以发给你（ARQ），超时重传 2、流量控制：希望发的慢一点，点对点，接收端改变接收窗口放在缓存区溢出 3、拥塞控制：大家一起维护网络不要这么拥塞，在流量控制的基础上控制 V1：慢开始 -&gt; 拥塞避免 -&gt; 乘法减小（阈值减半） -&gt; 慢开始 -&gt; 拥塞避免…… V2：慢开始 -&gt; 拥塞避免 -&gt; 快重传 -&gt; 乘法减小（阈值减半） -&gt; 快恢复 -&gt; 拥塞避免 …… 序号和确认号相对值 原生值建立连接时，客户端和服务器都会生成随机的序号初始值 具体分析SYN&#x3D;1，代表第一次发信息，seq都为0 连接管理建立连接（三次握手） 1、发起连接请求（SYN报文段），客户端发送初始序号x，请求发送到服务器；客户端进行同步已发送状态（第一次握手） 2、服务器接收连接请求，发送初始序号y，期望获得客户端的x+1个字节，确认发送到客户端（SYN+ACK）；服务器进入同步已接收状态（第二次握手） 3、客户端发出确认（ACK报文段），因为对方需要x+1，所以当前发送的是x+1，期望获得y+1个字节，连接已经建立（第三次握手） 状态CLOSED：客户端处于关闭状态 LISTEN：服务器处于监听状态，等待客户端连接 SYN-RCVD：表示服务器接受到了SYN报文，进入ESTABLISHED状态 前两次握手的特点： SYN都为1 数据部分长度都为0 TCP头部一般是32个字节 固定：20字节 选项：12字节 MSS 窗口缩放系数 是否支持SACK 双方交换确认一些信息，比如MSS、是否支持SACK、窗口缩放系数等 问题 为什么要三次握手？不是两次？ 主要目的：防止服务器端一直等待，浪费资源 如果建立连接只需要2次握手，可能会出现的情况： 如果客户端发出的第一个连接请求因为网络延迟，在连接释放后的才到达服务器，本来这是一个早已失效的连接请求，但服务器收到这个请求后误以为是客户端再次发出的一个新的连接请求，于是发出了确认，新的连接就建立了。但是由于客户端没有想连接服务器的意愿，所以客户端不会理睬服务器的确认，服务器会一直等待，浪费了资源。 如果采用三次握手的方法，服务器进行确认时，客户端不会理睬，就不会进行第三次握手，所以服务器就不会进入连接建立状态。 第三次握手失败了怎么处理？ 此时服务器状态为同步已接收状态，如果收不到客户端的确认，就会再次发送SYN+ACK包，多次重发还是不行就会发送RTS报文段，强制关闭连接 半连接队列和全连接队列 TCP三次握手时，Linux内核会维护两个队列： 半连接队列，被称为SYN队列 全连接队列，被称为 accept队列 服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到半连接队列，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。 不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 RST 包。 当服务端并发处理大量请求时，如果 TCP 全连接队列过小，就容易溢出。发生 TCP 全连接队溢出的时候，后续的请求就会被丢弃，这样就会出现服务端请求数量上不去的现象。 如果半连接队列满了，并且没有开启 tcp_syncookies，则会丢弃； 若全连接队列满了，且没有重传 SYN+ACK 包的连接请求多于 1 个，则会丢弃； 如果没有开启 tcp_syncookies，并且 max_syn_backlog 减去 当前半连接队列长度小于 (max_syn_backlog &gt;&gt; 2)，则会丢弃； 释放连接（四次挥手） 状态1、FIN-WAIT-1 向对方发送FIN报文，此时进入这个状态 一旦进入这个状态，说明这一方是主动关闭的 2、CLOSE-WAIT 当对方发送FIN给自己时，自己会回应一个ACK给对方，进入这个状态 这个状态下，要考虑是否有数据需要发送给对方，如果没有就发送FIN报文给对方 3、FIN-WAIT-2 只要对方发送ACK确认后，主动方进入这个状态，等待对方的FIN报文 4、CLOSING：一种罕见的状态 表示你发送FIN报文后，没有收到对方的ACK报文，反而收到了FIN报文 如果双方几乎同时准备关闭连接时，就出现双方同时发送FIN报文段情况，进入这种状态 5、TIME-WAIT 表示收到了对方的FIN报文，并发出了ACK报文 等待2MSL后即可进入CLOSED状态 6、LAST-ACK 被动方发送FIN报文后，最后等待对方的ACK报文 细节1、TCP&#x2F;IP协议栈的设计上，允许任何一方先发起断开请求 2、TIME-WAIT状态，等待一段时间后再真正关闭 一般是等待2倍的MSL（最大分段生存期） MSL是TCP报文在Internet上的最长生存时间 每个具体的TCP实现都必须选择一个确定的MSL值，建议是2分钟 如果直接进入CLOSED状态，因为网络原因对方没有收到ACK，所以对方就会重发FIN 可能出现的情况： 客户端没有任何响应，服务器干等，甚至多次发送FIN，浪费资源 客户端有个新的应用程序刚好分配了同一个端口号，新的应用程序收到FIN后马上开始断开连接的操作，本来是想建立连接的 问题 为什么要4次挥手？ 1、TCP是全双工模式 2、第一次挥手：主机1发出FIN报文段 主机1告诉主机2，主机1已经没有数据需要发送了，但是主机1还是可以接受主机2发来的数据 3、第二次挥手：主机2发出ACK报文段 主机2已经知道主机1没有数据发送了，但是主机2还是可以发送数据给主机1的 4、第三次挥手：主机2发出FIN报文段 主机2告诉主机1，主机2没有数据需要发送了 5、第四次挥手：主机1返回ACK报文段 主机1知道主机2没有数据发送了 半关闭状态 TCP提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力 半打开 如果一方已经关闭或异常终止，而另一方却对此毫不知情，这种连接就称为半打开的。 定时器1、连接建立定时器 当发送端发送 SYN 报文想建立一条新连接时，会开启连接建立定时器，如果没有收到对端的 ACK 包将进行重传。 2、重传定时器 第一个定时器讲的是连接建立没有收到 ACK 的情况，如果在发送数据包的时候没有收到 ACK 呢？ 这就是这里要讲的第二个定时器重传定时器，重传定时器的时间是动态计算的，取决于 RTT 和重传的次数。 3、延迟 ACK 定时器 在 TCP 收到数据包以后在没有数据包要回复时，不马上回复 ACK。这时开启一个定时器，等待一段时间看是否有数据需要回复。如果期间有数据要回复，则在回复的数据中捎带 ACK，如果时间到了也没有数据要发送，则也发送 ACK。 4、坚持计时器 Persist 定时器是专门为零窗口探测而准备的。 我们都知道 TCP 利用滑动窗口来实现流量控制，当接收端 B 接收窗口为 0 时，发送端 A 此时不能再发送数据，发送端此时开启 Persist 定时器，超时后发送一个特殊的报文给接收端看对方窗口是否已经恢复，这个特殊的报文只有一个字节 5、保活定时器（keepalive timer） 如果通信以后一段时间有再也没有传输过数据，怎么知道对方是不是已经挂掉或者重启了呢？于是 TCP 提出了一个做法就是在连接的空闲时间超过 2 小时，会发送一个探测报文，如果对方有回复则表示连接还活着，对方还在，如果经过几次探测对方都没有回复则表示连接已失效，客户端会丢弃这个连接。 6、FIN_WAIT_2 定时器 四次挥手过程中，主动关闭的一方收到 ACK 以后从 FIN_WAIT_1 进入 FIN_WAIT_2 状态等待对端的 FIN 包的到来，FIN_WAIT_2 定时器的作用是防止对方一直不发送 FIN 包，防止自己一直傻等。 7、TIME_WAIT 定时器 TIME_WAIT 定时器也称为 2MSL 定时器，可能是这七个里面名气最大的，主动关闭连接的一方在 TIME_WAIT 持续 2 个 MSL 的时间，超时后端口号可被安全的重用。 应用层 （一） DNS协议域名由于IP地址不方便记忆，并且不能表达组织的名称和性质，人们设计出了域名（比如：baidu.com） 但是，实际上为了访问到具体的主机，最终还得知道目标主机的IP地址 为什么不全程直接使用域名？ IP地址4个字节，域名基本都需要十几个字节，这会增加路由器的负担，浪费流量 域名分类 可以分为： 1、顶级域名（TLD） 通用顶级域名（gTLD）：.com、.net、.org等 国家及地区顶级域名（ccTLD） 新通用顶级域名（new gTLD） 2、二级域名：顶级域名之下的域名 在通用顶级域名下，一般指域名注册人的名称，例如baidu、google等 在国家及地区顶级域名下，一般指注册类别，例如com、edu、gov等（比如：neu.eud.cn 😊） 3、三级域名 ….. DNS概述1、DNS（Domain Name System），域名系统 2、作用：利用DNS协议，可以将域名解析成对应的IP地址 3、DNS可以基于UDP协议，也可以基于TCP协议 4、DNS服务器占用53端口 DNS服务器 1、客户端先访问最近一台DNS服务器（客户端自己配置的服务器） 2、所有的DNS服务器都记录了DNS根域名服务器的IP地址 3、上级DNS服务器记录了下一级DNS服务器的IP地址 4、全球共13台IPv4的DNS根DNS服务器、25台IPv6DNS根DNS服务器 DNS解析流程那么，在浏览器输入域名的时候，DNS是怎样解析的呢？分以下几步： 本地hosts文件 本地DNS缓存 DNS服务器缓存 DNS服务器递归查找 本地hosts文件 修改hosts文件对于开发者来说并不陌生，这样我们可以不改变线上域名的配置，然后直接通过域名访问我们想要访问的机器。 本地DNS缓存 如果hosts文件没有的话，那么DNS就会查看本地的DNS缓存，如果有的话就直接返回对应的ip即可。下面是我本地对tlab.cloud.tencent.com的DNS解析，因为之前已经解析过来，所以缓存里就有对应的ip地址：193.112.230.97。 DNS服务器缓存 如果是第一次访问某个域名的话，那本地缓存肯定是没有的。 所以就会到DNS服务器查找，链接网络之后，我们的电脑就会有对应的DNS服务器的地址，下图： 本地DNS服务器一般由ISP进行维护 访问本地DNS服务器，如果缓存中有映射关系，就返回；否则，访问根DNS服务器 DNS服务器递归查找 如果DNS服务器也没有缓存的话，那就要进行递归查找: 1、本地DNS服务器访问根DNS服务器，发现是.com结尾，返回负责.com区域对应的顶级域名服务器的IP地址 2、本地DNS服务器访问顶级域名服务器，发现microsoft.com，返回权威DNS服务器的IP地址 3、本地DNS服务器访问权威DNS服务器，最终找到域名对应的IP地址，并且缓存 DHCP协议IP地址的分配IP地址可以分为：静态IP地址、动态IP地址 1、静态IP地址 手动设置 使用场景：不挪动的台式机、服务器等 2、动态IP地址 从DHCP服务器自动获取IP地址 使用场景：无线设备（无线网）、移动设备（笔记本）等 DHCP概述1、DHCP，动态主机配置协议 2、基于UDP协议，客户端是68端口，服务器是67端口 3、DHCP服务器会从IP池中，挑选一个IP地址“出租”给客户端一段时间，时间到期就进行回收 平时上网的路由器就可以当作DHCP服务器 DHCP分配IP地址的四个阶段1、DISCOVER：发现服务器 发广播包（源IP是0.0.0.0，目标IP是255.255.255.255，目标MAC是FF:FF:FF:FF:FF:FF） 2、OFFER：提供租约 服务器返回可以租用的IP地址，以及租用期限、子网掩码、网关、DNS等信息 3、REQUEST：选择IP地址 客户端选择一个OFFER，发送广播包进行回应 4、ACKNOWLEDGE：确认 被选中的服务器发送ACK数据包给客户端 细节1、自动续约 客户端在租期不足的时候，自动向DHCP服务器发送REQUEST信息申请续约 2、DHCP可以跨网段分配IP地址吗 可以使用DHCP中继代理实现 应用层（二）HTTP协议概述1、HTTP：超文本传输协议 2、是互联网中应用最广泛的应用层协议之一 3、基于TCP 4、最初的目的：提供一种发布和接收HTML页面的方法，用URI来标识具体的资源 URI：表示的是web上每一种可用的资源，如 HTML文档、图像、视频片段、程序等都由一个URI进行标识的。 URI通常由三部分组成： ①资源的命名机制； ②存放资源的主机名； ③资源自身的名称。 URI包括URL 5、HTML：超文本标记语言 可以用来编写网页 版本和标准 请求过程HTTP 请求的发送HTTP 协议是基于 TCP 协议的，所以它使用面向连接的方式发送请求，通过 stream 二进制流的方式传给对方。当然，到了 TCP 层，它会把二进制流变成一个个报文段发送给服务器。 在发送给每个报文段的时候，都需要对方有一个回应 ACK，来保证报文可靠地到达了对方。如果没有回应，那么 TCP 这一层会进行重新传输，直到可以到达。同一个包有可能被传了好多次，但是 HTTP 这一层不需要知道这一点，因为是 TCP 这一层在埋头苦干。 TCP 层发送每一个报文的时候，都需要加上自己的地址（即源地址）和它想要去的地方（即目标地址），将这两个信息放到 IP 头里面，交给 IP 层进行传输。 IP 层需要查看目标地址和自己是否是在同一个局域网。如果是，就发送 ARP 协议来请求这个目标地址对应的 MAC 地址，然后将源 MAC 和目标 MAC 放入 MAC 头，发送出去即可；如果不在同一个局域网，就需要发送到网关，还要需要发送 ARP 协议，来获取网关的 MAC 地址，然后将源 MAC 和网关 MAC 放入 MAC 头，发送出去。 网关收到包发现 MAC 符合，取出目标 IP 地址，根据路由协议找到下一跳的路由器，获取下一跳路由器的 MAC 地址，将包发给下一跳路由器。 这样路由器一跳一跳终于到达目标的局域网。这个时候，最后一跳的路由器能够发现，目标地址就在自己的某一个出口的局域网上。于是，在这个局域网上发送 ARP，获得这个目标地址的 MAC 地址，将包发出去。 目标的机器发现 MAC 地址符合，就将包收起来；发现 IP 地址符合，根据 IP 头中协议项，知道自己上一层是 TCP 协议，于是解析 TCP 的头，里面有序列号，需要看一看这个序列包是不是我要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。 TCP 头里面还有端口号，HTTP 的服务器正在监听这个端口号。于是，目标机器自然知道是 HTTP 服务器这个进程想要这个包，于是将包发给 HTTP 服务器。HTTP 服务器的进程看到，原来这个请求是要访问一个网页，于是就把这个网页发给客户端。 报文格式请求报文 1、请求行 由三部分构成：方法、请求资源的URL、HTTP的版本。 HTTP请求的方法主要有：GET、POST、PUT、DELETE、OPTIONS、HEAD、TRANCE、CONNECT等 **GET:**想特定的资源发出请求。 **POST:**向指定的资源提交相应的数据金星焕处理请求，比如说提交表单、上传文件。数据被包含在请求实体中。 **PUT:**从客户端向服务器传送的数据取代指定的文档的内容。 **DELETE:**请求服务器删除指定的页面 **OPTIONS:**允许客户端查看服务器的性能。 HEAD：类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头 TRANS：回显服务器收到的请求，主要用于测试或诊断。 **CONNECT:**HTTP&#x2F;1.1协议中预留给能够将连接改为管道方式的代理服务器。 2、请求头部 是一个个的key-value值 3、请求数据 GET方法没有携带数据， POST方法会携带一个body 响应报文 1、请求行 版本+空格+状态码+空格+短语+回车换行 2、请求头 是一个个的key-value值 3、请求数据 响应的data，本例中是一段HTML GET请求和POST请求 最直观的就是语义上的区别 1、get用来获取数据，post用来提交数据 2、get参数有长度限制（受限于url长度，具体的数值取决于浏览器和服务器的限制，最长2048字节），而post无限制。 3、get请求的数据会附加在url之后 ，以 “ ？ “分割url和传输数据，多个参数用 “&amp;”连接，而post请求会把请求的数据放在http请求体中。 4、get是明文传输，post是放在请求体中，但是开发者可以通过抓包工具看到，也相当于是明文的。 5、get请求会保存在浏览器历史记录中，还可能保存在web服务器的日志中 get是获取数据，post是修改数据 get把请求的数据放在url上， 以?分割URL和传输数据，参数之间以&amp;相连，所以get不太安全。而post把数据放在HTTP的包体内（requrest body） get提交的数据最大是2k（ 限制实际上取决于浏览器）， post理论上没有限制。 GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200(返回数据); POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)。 GET请求会被浏览器主动缓存，而POST不会，除非手动设置。 本质区别：GET是幂等的，而POST不是幂等的 这里的幂等性：幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。 正因为它们有这样的区别，所以不应该且不能用get请求做数据的增删改这些有副作用的操作。因为get请求是幂等的，在网络不好的隧道中会尝试重试。如果用get请求增数据，会有重复操作的风险，而这种重复操作可能会导致副作用（浏览器和操作系统并不知道你会用get请求去做增操作）。 状态码1、固定3个数字 2、用来表示当前HTTP请求是否已经成功完成 3、分类： 100—199：信息响应 200—299：成功响应 300—399：重定向 400—499：客户端错误 500—599：服务器错误 1开头 100：Continue 请求的初始部分已经被服务器收到，并且没有被服务器拒绝；客户端应该继续发送剩余请求，如果请求已经完成就忽略这个响应 允许客户端发送带请求体的请求前，判断服务器是否愿意接收请求（服务器通过请求头判断） 在某些情况下，如果服务器在不看请求体就拒绝连接，客户端就发送请求体是不恰当的 2开头 200：OK 请求成功 3开头 301 永久重定向 旧地址A的资源已经被永久地移除了（这个资源不可访问了），搜索引擎在抓取新内容的同时也将旧的网址交换为重定向之后的网址； 302 临时重定向 请求的资源被暂时移动到了由Location指定的URL上 旧地址A的资源还在（仍然可以访问），这个重定向只是临时地从旧地址A跳转到地址B，搜索引擎会抓取新的内容而保存旧的网址。 响应302，Location 请求Location 响应HTML 301和302的区别？ 301: 302: 304 Not Modified 说明无需再次传输 缓存里面有 4开头 400 Bad Request 由于语法无效，服务器无法理解该请求 没有传该传的数据（比如需要name和age，只有name） 请求报文的格式不正确 401 缺乏目标资源要求的身份验证凭证 403 Forbidden 服务器端有能力处理这个请求，但是拒绝授权访问 404 Not Found 服务器端无法找到所请求的资源 405 服务器禁止了使用当前HTTP请求方法（get、post等） 406 服务器端无法提供与能接受指定的值所匹配的响应 408 Request TimeOut 服务器想要将没有在使用的连接关闭 5开头 500 服务器出现意外问题（比如后台出现1&#x2F;0） 501 请求的方法不被服务器支持 服务器必须支持：GET和HEAD 502 Bad Gateway 作为网关或代理角色的服务器从上游服务器接收的响应是无效的 503 服务器停机维护、已超载 HTTP2.0HTTP 1.1 在应用层以纯文本的形式进行通信。每次通信都要带完整的 HTTP 的头，而且不考虑 pipeline 模式的话，每次的过程总是像上面描述的那样一去一回。这样在实时性、并发性上都存在问题。 为了解决这些问题，HTTP 2.0 会对 HTTP 的头进行一定的压缩，将原来每次都要携带的大量 key value 在两端建立一个索引表，对相同的头只发送索引表中的索引。 另外，HTTP 2.0 协议将一个 TCP 的连接中，切分成多个流，每个流都有自己的 ID，而且流可以是客户端发往服务端，也可以是服务端发往客户端。它其实只是一个虚拟的通道。流是有优先级的。 HTTP 2.0 还将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。常见的帧有 Header 帧，用于传输 Header 内容，并且会开启一个新的流。再就是 Data 帧，用来传输正文实体。多个 Data 帧属于同一个流。 通过这两种机制，HTTP 2.0 的客户端可以将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输。这些帧可以打散乱序发送， 然后根据每个帧首部的流标识符重新组装，并且可以根据优先级，决定优先处理哪个流的数据。 我们来举一个例子。 假设我们的一个页面要发送三个独立的请求，一个获取 css，一个获取 js，一个获取图片 jpg。如果使用 HTTP 1.1 就是串行的，但是如果使用 HTTP 2.0，就可以在一个连接里，客户端和服务端都可以同时发送多个请求或回应，而且不用按照顺序一对一对应。 HTTP 2.0 其实是将三个请求变成三个流，将数据分成帧，乱序发送到一个 TCP 连接中。 HTTP 2.0 成功解决了 HTTP 1.1 的队首阻塞问题，同时，也不需要通过 HTTP 1.x 的 pipeline 机制用多条 TCP 连接来实现并行请求与响应；减少了 TCP 连接数对服务器性能的影响，同时将页面的多个数据 css、js、 jpg 等通过一个数据链接进行传输，能够加快页面组件的传输速度。 Cookie和Session请求头： 响应头： 1、Cookie 在客户端存储一些数据，存储到本地磁盘 服务器可以返回cookie交给客户端去存储 2、Session 在服务器存储一些数据，存储到内存中 Session 代表着服务器和客户端一次会话的过程。 Session 对象存储特定用户会话所需的属性及配置信息。这样，当用户在应用程序的 Web 页之间跳转时，存储在 Session 对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。当客户端关闭会话，或者 Session 超时失效时会话结束。 过程： 登录成功后，服务器为浏览器创建一个session对象（在服务器内存） 登录成功，返回响应头：set-cookie：JSESSIONID&#x3D;666，服务器希望客户端存储cookie domain、path存储一个地址，访问这个地址的时候就会带上对应的cookie 浏览器就获得了cookie 浏览器发出请求头：cookie：JSESSIONID&#x3D;666 服务器发现请求中有cookie，JSESSIONID相同，说明这个浏览器成功登陆过，就会返回user的json数据 什么是 Cookie？ HTTP Cookie（也叫 Web Cookie或浏览器 Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。 通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能。 Cookie 主要用于以下三个方面： 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） 什么是 Session？ Session 代表着服务器和客户端一次会话的过程。Session 对象存储特定用户会话所需的属性及配置信息。这样，当用户在应用程序的 Web 页之间跳转时，存储在 Session 对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。当客户端关闭会话，或者 Session 超时失效时会话结束。 Cookie 和 Session 有什么不同？ 1、作用范围不同 Cookie 保存在客户端（浏览器） Session 保存在服务器端。 2、存取方式的不同 Cookie 只能保存 ASCII Session 可以存任意数据类型，一般情况下我们可以在 Session 中保持一些常用变量信息，比如说 UserId 等。 3、有效期不同 Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能 Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。 4、隐私策略不同 Cookie 存储在客户端，比较容易遭到不法获取，早期有人将用户的登录名和密码存储在 Cookie 中导致信息被窃取； Session 存储在服务端，安全性相对 Cookie 要好一些。 5、存储大小不同 单个 Cookie 保存的数据不能超过 4K Session 可存储数据远高于 Cookie。 为什么需要 Cookie 和 Session，他们有什么关联？ 说起来为什么需要 Cookie ，这就需要从浏览器开始说起，我们都知道浏览器是没有状态的(HTTP 协议无状态)，这意味着浏览器并不知道是张三还是李四在和服务端打交道。这个时候就需要有一个机制来告诉服务端，本次操作用户是否登录，是哪个用户在执行的操作，那这套机制的实现就需要 Cookie 和 Session 的配合。那么 Cookie 和 Session 是如何配合的呢？ 1、用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建创建对应的 Session ，请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器，浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名。 2、当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信息，如果存在自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。 根据以上流程可知，SessionID 是连接 Cookie 和 Session 的一道桥梁，大部分系统也是根据此原理来验证用户登录状态。 禁用Cookie后，怎么办 既然服务端是根据 Cookie 中的信息判断用户是否登录，那么如果浏览器中禁止了 Cookie，如何保障整个机制的正常运转。 第一种方案，每次请求中都携带一个 SessionID 的参数，也可以 Post 的方式提交，也可以在请求的地址后面拼接 xxx?SessionID&#x3D;123456…。 第二种方案，Token 机制。Token 机制多用于 App 客户端和服务器交互的模式，也可以用于 Web 端做用户状态管理。 Token 的意思是“令牌”，是服务端生成的一串字符串，作为客户端进行请求的一个标识。Token 机制和 Cookie 和 Session 的使用机制比较类似。 当用户第一次登录后，服务器根据提交的用户信息生成一个 Token，响应时将 Token 返回给客户端，以后客户端只需带上这个 Token 前来请求数据即可，无需再次登录验证。 代理代理服务器特点： 本身不生产内容 处于中间位置转发上下游的请求和响应 面向下游的客户端：它是服务器 面向上游的服务器：它是客户端 正向代理、反向代理正向代理：代理的对象是客户端 反向代理：代理的对象是服务器 正向代理 作用： 隐藏客户端身份 绕过防火墙（突破访问限制） Internet访问控制 反向代理 隐藏服务器身份 安全防护 负载均衡 相关的头部字段1、via 追加经过的每一台代理服务器的主机名 2、x-Forwarded-For 追加请求方的IP地址 3、x-Real-IP 客户端的真实IP地址 CDN内容分发网络 利用最靠近每一位用户的服务器，更快更可靠的把音乐、视频、图片等资源文件传递给用户 缓存Memory Cache 、Disk Cache 通常会缓存的情况：GET请求+静态资源（HTML、CSS等） 响应头1、Pragma：作用类似于Cache-Control，HTTP&#x2F;1.0的产物 2、Expires：缓存的过期时间，HTTP&#x2F;1.0的产物 3、Cache-Control：设置缓存策略 no-storage：不允许缓存 public：允许用户、代理服务器缓存数据到本地 private：只允许用户缓存数据到本地 max-age：缓存的有效时间（多长时间不过期），单位秒 no-Cache：允许缓存，每次需要发请求询问是否是最新版本，再决定如何使用缓存 优先级：Pragme &gt; Cache-Control &gt; Expires 4、last-Modified：资源的最后一次修改时间 5、ETag：资源唯一标识，是一个摘要值 优先级：ETag &gt; last-Modified 请求头1、If-None-Match：如果上一次的响应头中有ETag，就会将ETag的值最为请求头的值 如果服务器发现资源的最新摘要值和If-None-Match不匹配就会返回新的资源（200） 否则，不会返回资源的具体数据（304） 2、If-Modified-since：与last-Modified配合使用 如果上一次的响应头中没有ETag，有last-Modified，就会把这个作为请求头的值 如果服务器发现最后一次修改时间晚（200） 否则（304） 为什么需要两个？ last-Modified的缺陷： 只能精确到秒级别 如果某些文件修改时间发生变化，但是内容没有变化 缓存的使用流程强制缓存：cache-control 对比缓存：no-cache 过程： 1、第一次 请求服务器 如果服务器响应的cache-control不是no-storage就将数据和缓存标识缓存到本地，否则不缓存 2、后续 本地有缓存，查看响应头的cache-control是不是no-cache 如果不是no-cache，就不需要进行对比缓存，判断缓存是否过期 如果缓存没有过期就可以直接使用本地缓存 如果缓存过期了或者响应头不是no-cache，就查看响应头是否有ETag，如果有就向服务器发起请求，请求头为if-none-match，如果服务器发现不匹配就返回200，匹配就返回304 如果响应头没有ETag，查看是否有last-modified，如果有就向服务器发起请求，请求头包括if-modified-since，如果服务器发现不匹配就200，匹配就返回3 04 面试题说一下一次完整的HTTP请求过程包括哪些内容？第一种回答 建立起客户机和服务器连接。 建立连接后，客户机发送一个请求给服务器。 服务器收到请求给予响应信息。 客户端浏览器将返回的内容解析并呈现，断开连接。 第二种回答域名解析 –&gt; 发起TCP的3次握手 –&gt; 建立TCP连接后发起http请求 –&gt; 服务器响应http请求，浏览器得到html代码 –&gt; 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） –&gt; 浏览器对页面进行渲染呈现给用户。 应用层（三）安全威胁网络层—ARP欺骗1、ARP欺骗，又称ARP毒化、ARP攻击 2、ARP欺骗可以造成的效果 让攻击者获取局域网上的数据包甚至篡改数据包 让网络上特定电脑之间无法通信 让送至特点IP地址的流量被错误发送到攻击者所取代的地方 3、核心步骤 DoS、DDoS1、DoS攻击：拒绝服务攻击 使目标电脑的网络或系统资源耗尽，使服务暂时中断或停止，导致其他正常用户无法访问 分为两大类 带宽消耗型：UDP洪水攻击、ICMP洪水攻击 资源消耗型：SYN洪水攻击、LAND洪水攻击 2、DDoS攻击：分布式拒绝服务攻击 黑客使用网络上两个或者以上被攻陷的电脑作为僵尸，向特定目标发动DoS攻击 2018年3月GitHub受到了最大的DDoS攻击 3、Dos攻击分为两大类 带宽消耗型：UDP洪水攻击（不断扔UDP数据包）、ICMP洪水攻击 资源消耗型：SYN洪水攻击、LAND攻击 SYN洪水攻击攻击者发送一系列的SYN请求到目标，然后让目标因为收不到ACK（第三次握手）而等待、消耗资源 攻击方法 跳过发送最后的ACK信息 修改源IP地址，让目标发送SYN-ACK到伪造的IP地址，因此目标永远不可能收到ACK（第三次握手） LAND攻击局域网拒绝服务攻击 通过持续发送相同源地址和目标地址的欺骗数据包，使目标试图和自己建立连接，消耗系统资源至崩溃 防御方式入侵检测、流量过滤、多重验证 堵塞网络带宽的流量将被过滤，正常流量可以通过 防火墙 设置规则，允许或者拒绝特定的通讯协议 黑洞引导 将所有受攻击计算机的通信全部发送到一个黑洞（空接口或者不存在的计算机地址） 应用层—DNS劫持攻击者篡改某个域名的解析结果，使得指向该域名的IP变成了另外一个IP 导致对相应网址的访问被劫持到另外一个不可达或者假冒的网址 从而实现非法窃取用户信息或者破坏正常网络服务的目的 HTTP协议的安全问题1、默认采用明文传输，因此会有很大的安全隐患 常见的提高安全性的方法：对通信内容进行加密后再进行传输 2、常见加密 不可逆 单向散列函数：MD5、SHA 可逆 对称加密 非对称加密 其他 混合密码系统 数字签名 证书 单向散列函数根据消息内容计算出散列值 散列值的长度和消息的长度无关，无论消息多大都会计算出固定长度的散列值 特点：根据任意长度的消息计算出固定长度的散列值 1、单向散列函数也被称为消息摘要函数、哈希函数 输出的散列值也被称为消息摘要、指纹 2、常见的几种单向散列函数 MD4、MD5 产生128bit的散列值，现在已经不安全 SHA-1 产生160bit散列值，现在已经不安全 SHA-2 SHA-256、SHA-384、SHA-512 SHA-3 3、应用：防止数据被篡改 4、应用：密码加密 对称加密（对称密码）对称密码中，加密用的密钥和解密用的密钥相同 常见的对称加密算法： DES 3DES AES DES 1、DES是一种将64bit明文加密成64bit密文的对称加密算法，密钥长度56bit 2、密钥长度64bit，但是每隔7bit会设置一个用于错误检查的bit，因此密钥长度实质上56bit 3、由于DES每次只能加密64bit数据，所以加密长数据需要反复加密 3DES将DES重复3次所得到的一种密码算法 三重DES并不少进行三次DES加密，而是加密、解密、加密的过程 3个密钥都是不同的，也被称为DES-EDE3 AES取代DES成为新标准的一种对称加密算法 AES密钥长度有128、192、256bit三种 非对称加密（公钥密码）公钥密码中，加密用的密钥和解密用的密钥不同 1、加密密钥：一般是公开的，因此该密钥称为公钥 因此，非对称加密也被称为公钥密码 解密密钥：不能公开，由消息接受者保管，不能公开，因此称为私钥 2、用对方的公钥进行加密，对方用自己的私钥解密 3、公钥和私钥是一一对应的，不能单独生成 一对公钥和私钥称为密钥对 4、由公钥加密的密文，必须使用对应的私钥才能解密 5、由私钥加密的密文，必须使用与该私钥对应的公钥才能加密（也可以使用私钥加密） 解决密钥配送问题1、由消息的接受者，生成一对公钥、私钥 2、将公钥发给消息的发送者 3、消息的发送者使用公钥加密消息 RSA对广泛使用的非对称加密算法 混合密码系统非对称加密：复杂、安全、加密解密速度慢 对称加密：简单、不安全、加密解密速度快 加密1、会话密钥 本次通信随机生成的临时密钥 作为对称加密的密钥，用于加密消息，提高速度 2、加密步骤 生成一个随机的会话密钥 用这个会话密钥对消息进行对称加密 使用接受者的公钥对会话密钥进行非对称加密 将非对称加密的会话密钥和对称加密的消息组合发给接受者 发出去的内容： 非对称加密的会话密钥 对称加密的消息 解密 过程： 使用私钥解密会话密钥 使用解密后的会话密钥解密消息 数字签名 问题：发送方发送的消息可能是被篡改的，或者是它发的但是它可以否认 数字签名不是用来加密的，是用来保证数据可靠性的 1、在数字签名技术中，有2种行为： 生成签名 由消息的发送者完成，通过“签名密钥”生成 验证签名 由消息的接收者完成，通过“验证密钥”生成 2、如何保证签名是消息发送者自己签的？ 用消息发送者的私钥进行签名 过程： 发送方发送消息的明文 发送方使用私钥加密消息生成签名 接收方使用公钥解密签名获得消息 将这个消息和明文消息进行比较 过程改进结合单向散列函数 过程： 使用单向散列函数将明文消息转为散列值 使用私钥加密散列值生成签名 发送签名和消息明文 接收方使用单向散列函数将消息转为散列值 接收方使用公钥解密签名生成散列值 比对散列值 疑惑 数字签名不能保证机密性？ 数字签名的作用不是为了保证机密性，是为了识别内容没有被篡改 数字签名的作用？ 确认消息的完整性 识别消息是否被篡改 防止消息发送人否认 证书 为了解决有人攻击发送的公钥，证书可以保证公钥一定是这个人的 公钥证书（PKC） 里面有姓名、邮箱等个人信息，以及此人的公钥 由认证机构（CA）施加数字签名（使用私钥进行数字签名，所以无法伪造） 过程： 接受者生成密钥对 接受者在CA注册自己的公钥，CA用自己的私钥对这个公钥施加数字签名并生成证书（生成证书） 消息的发送者使用CA的公钥进行验证数字签名，确认接受者发来的公钥是正确的（验证证书） 开始非对称加密 注册和下载 各大CA的公钥，默认被内置在浏览器和操作系统中，不需要考虑CA公钥的合法性 应用层（四）HTTPS1、超文本传输安全协议 2、常称为：HTTP over TLS、HTTP over SSL、HTTP Secure 3、现在在浏览器输入http://www.baidu.com会自动重定向到https://www.baidu.com SSL&#x2F;TLSHTTPS是在HTTP基础上使用SSL&#x2F;TLS来加密报文，对窃听和中间人攻击提供合理的防护 SSL&#x2F;TLS也可以使用到其他协议上，比如： FTP-&gt;FTPS SMTP-&gt;SMTPS 1、TLS（Transport Layer Security）：传输层安全协议 前身是SSL（Secure Socket Layers）：安全套接层 2、历史版本 SSL 1.0 SSL 2.0 SSL 1.3（2018年） SSL&#x2F;TLS工作在哪一层？ 在应用层和传输层之间 OpenSSL是SSL&#x2F;TLS协议的开源实现 Linux、MAC自带OpenSSL 常用指令： 生成私钥：openssl genres -out mj.key 生成公钥：openssl rsa -in mj.key -pubout HTTPS的成本1、证书的费用 2、加解密计算 3、降低访问速度 有些企业的做法：包含敏感数据的请求才使用HTTPS，其他保持使用HTTP HTTPS通信过程三大阶段： TCP的三次握手 TLS的连接 HTTP的请求和响应 TLS 1.2的连接大概10个步骤 1、Client Hello客户端发给服务器 TLS版本号 支持的加密组件列表（使用的加密算法及密钥长度等） 一个随机数 2、Server Hello服务器发给客户端 TLS版本 选择的加密组件（从第一步的组件列表挑选出来的） 一个随机数 3、certificate服务器发给客户端 服务器的公钥证书（被CA签名过） 4、server key exchange服务器发给客户端 用以实现DCDHE算法的其中一个参数（server Params） DCDHE是一种密钥交换算法 为了防止伪造，server Params经过私钥签名 5、Server Hello Done服务器发给客户端 告诉客户端：协商结束 目前为止，客户端和服务器之间通过明文共享了： 客户端：TLS版本、加密组件列表、随机数（Clinet Random） 服务器：TLS版本、选择的加密组件、随机数（Server Random）、公钥证书、实现密钥交换算法的参数（Server Params） 6、Client Key Exchange客户端发给服务器 用以实现DCDHE算法的其中一个参数（client Params） 目前为止，客户端和服务器都拥有了ECDHE算法需要的2个参数：Server Params、client Params 客户端、服务器都可以使用ECDHE算法 根据Server Params、client Params计算新的随机密钥串：Pre-master secret 然后结合Clinet Random、Server Random、Pre-master secret生成用来加密会话的会话密钥 7、change cipher spec客户端发给服务器 告知服务器：之后的通信会采用会话密钥进行加密 8、Finished客户端发给服务器 包含连接至今全部报文的整体校验值（摘要值），加密之后发送给服务器 这次握手协商是否成功，以服务器是否能够正确解密改报文为判定标准 9、Change Cipher spec服务器发给客户端 10、Finished服务器发给客户端 到此为止，客户端服务器验证加密解密没问题，握手正式结束 总结 1、客户端给服务器 TLS版本 支持的加密套件列表 随机数（Clinet Random） 2、服务器给客户端 TLS版本+选中的加密套件+随机数（Server Random） 公钥证书 密钥交换算法的参数（Server Params） 协商结束 3、客户端给服务器 验证证书是否有问题 client key exchange：密钥交换算法的参数（ClientParams），利用Server Params和Client Params生成随机数Pre-master secret，三个随机数生成会话密钥 change Cipher Spec ：告诉服务器我要使用会话密钥加密了 finished：发送一个加密的摘要值 4、服务器给客户端 告诉服务器加密解密成功","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"Linux","slug":"Linux","date":"2022-01-20T12:22:19.000Z","updated":"2022-02-07T13:47:07.732Z","comments":true,"path":"2022/01/20/Linux/","link":"","permalink":"http://example.com/2022/01/20/Linux/","excerpt":"","text":"综述基本概念 1、中断事件 输入设备驱动其实就是客户对接员。有时候新插上一个鼠标的时候，会弹出一个通知你安装驱动，这就是操作系统这家外包公司给你配备对接人员呢。当客户告诉对接员需求的时候，对于操作系统来讲，输入设备会发送一个中断。客户肯定希望外包公司把正在做的事情都停下来服务它。所以，这个时候客户发送的需求就被称为中断事件（Interrupt Event） 2、文件管理子系统 管理文件系统 3、程序 QQ的二进制文件 4、系统调用 把权限敏感的操作，放到操作系统内核中，只能由操作系统来执行。进程如果需要执行，就通过系统调用。这样的话，这些敏感操作就收拢到操作系统层面，方便安全的把控等 5、进程管理子系统 管理进程的执行 6、内存管理子系统 在操作系统中，不同的进程有不同的内存空间，但是整个电脑内存就这么点儿，所以需要统一的管理和分配，这就需要内存管理子系统（Memory Management Subsystem）。 基本命令 系统调用 进程管理1、创建进程：fork 在 Linux 里要创建一个新的进程，需要一个老的进程调用 fork 来实现，其中老的进程叫作父进程（Parent Process），新的进程叫作子进程（Child Process） 当父进程调用 fork 创建进程的时候，子进程将各个子系统为父进程创建的数据结构也全部拷贝了一份，甚至连程序代码也是拷贝过来的 既然fork是复制，就说明父进程和子进程在用户态的代码段是一模一样的，如果fork这个系统调用后面的语句都是A，则无论是父进程，还是子进程都是接下来要执行A的。 好在fork是一个系统调用，刚从内核返回的时候，由于内核是能够区分父进程和子进程的，因而用户态的程序代码里面，往往通过这个返回值来判断自己是父进程还是子进程，因为子进程如果不判断一下，是不知道自己是子进程的。这和CPU执行权也没有关系。就是代码执行完fork以后，由于父子进程的代码是一模一样的，父进程和子进程都不知道自己是哪一个，但是判断返回值就知道了。 2、操作系统在启动的时候先创建一个所有用户进程的“祖宗进程” 进程id为1的init进程是用户态所有进程的祖宗 进程id为2的kthread是内核态所有进程的祖宗 3、父进程查看子进程运行情况：waitpid 父进程可以调用它，将子进程的进程号作为参数传给它，这样父进程就知道子进程运行完了没有，成功与否。 内存管理1、每个进程都有自己的内存，互相之间不干扰，有独立的进程内存空间 代码段：对于进程的内存空间来讲，放程序代码的这部分，我们称为代码段（Code Segment） 数据段：对于进程的内存空间来讲，放进程运行中产生数据的这部分，我们称为数据段（Data Segment） 其中局部变量的部分，在当前函数执行的时候起作用，当进入另一个函数时，这个变量就释放了；也有动态分配的，会较长时间保存，指明才销毁的，这部分称为堆（Heap）。 2、进程自己不用的部分就不用管，只有进程要去使用部分内存的时候，才会使用内存管理的系统调用来登记，说自己马上就要用了，希望分配一部分内存给它，但是这还不代表真的就对应到了物理内存。只有真的写入数据的时候，发现没有对应物理内存，才会触发一个中断，现分配物理内存。 文件管理1、对于已经有的文件，可以使用open打开这个文件，close关闭这个文件； 2、对于没有的文件，可以使用creat创建文件； 3、打开文件以后，可以使用lseek跳到文件的某个位置； 4、可以对文件的内容进行读写，读的系统调用是read，写是write。 5、一切皆文件，每个文件，Linux 都会分配一个文件描述符（File Descriptor），这是一个整数。有了这个文件描述符，我们就可以使用系统调用，查看或者干预进程运行的方方面面。 进程通信1、消息队列 发送不需要一段很长的数据，这种方式称为消息队列（Message Queue）。由于一个公司内的多个项目组沟通时，这个消息队列是在内核里的，我们可以通过msgget创建一个新的队列，msgsnd将消息发送到消息队列，而消息接收方可以使用msgrcv从队列中取消息。 2、共享内存 当两个项目组需要交互的信息比较大的时候，可以使用共享内存的方式，也即两个项目组共享一个会议室（这样数据就不需要拷贝来拷贝去）。大家都到这个会议室来，就可以完成沟通了。这时候，我们可以通过shmget创建一个共享内存块，通过shmat将共享内存映射到自己的内存空间，然后就可以读写了。 3、信号量 如果大家同时修改同一块数据咋办？这就需要有一种方式，让不同的人能够排他地访问，这就是信号量的机制 Semaphore。 网络通信1、网络服务是通过套接字 Socket 来提供服务的。Socket 这个名字很有意思，可以作“插口”或者“插槽”讲。虽然我们是写软件程序，但是你可以想象成弄一根网线，一头插在客户端，一头插在服务端，然后进行通信。因此，在通信之前，双方都要建立一个 Socket。 2、我们可以通过 Socket 系统调用建立一个 Socket。Socket 也是一个文件，也有一个文件描述符，也可以通过读写函数进行通信。 系统初始化X86架构工作模式 1、计算机工作模式 CPU（Central Processing Unit，中央处理器） 总线（Bus） CPU 和其他设备连接，要靠总线（Bus），其实就是主板上密密麻麻的集成电路，这些东西组成了 CPU 和其他设备的高速通道 内存（Memory） 单靠 CPU 是没办法完成计算任务的，很多复杂的计算任务都需要将中间结果保存下来，然后基于中间结果进行进一步的计算。CPU 本身没办法保存这么多中间结果，这就要依赖内存了 其他设备 总线上还有一些其他设备，例如显卡会连接显示器、磁盘控制器会连接硬盘、USB 控制器会连接键盘和鼠标等等 2、CPU的构造 CPU包括三个部分：运算单元、数据单元、控制单元 运算单元：负责算，如加法、位移等，它不知道应该算哪些数据，运算结果放在哪里 数据单元：暂时存放数据和运算结果，包括CPU内部的缓存和寄存器组 控制单元：统一的指挥中心，获得下一条指令，然后执行下一条指令 3、进程的内存结构 进程一旦运行，如上图进程A和进程B会有独立的内存空间，互相隔离 代码段：程序会分别加载到进程A和进程B的内存空间，形成各自的代码段 数据段：程序运行过程中要操作的数据和产生的计算结果，放在数据段里 4、CPU和内存的配合 CPU的控制单元有一个指令指针寄存器，存放下一条指令在内存中的地址，控制单元会不停将代码段的指令拿进来先放入指令寄存器 当前指令分为两部分：做什么操作、操作哪些数据 想要执行这条指令，就要把第一部分交给运算单元，第二部分交给数据单元 数据单元根据数据的地址，从数据段读到数据寄存器内，就可以参与运算了，运算结果暂存在数据单元的数据寄存器内。最终会有指令将数据写回内存 进程切换 CPU寄存器保存当前处理进程的代码段起始地址和数据段起始地址，写的是进程A当前执行的就是线程A CPU和内存传数据，使用总线 总线上主要有两类数据： 地址数据：地址总线 真正的数据：数据总线 数据总线的位数决定了一次能拿多少个数据进来。 X86 8060处理器 1、数据单元 为了暂存数据，8086 处理器内部有 8 个 16 位的通用寄存器，也就是刚才说的 CPU 内部的数据单元，分别是 AX、BX、CX、DX、SP、BP、SI、DI。 这些寄存器主要用于在计算过程中暂存数据。 2、控制单元 IP 寄存器就是指令指针寄存器（Instruction Pointer Register)，指向代码段中下一条指令的位置。CPU 会根据它来不断地将指令从内存的代码段中，加载到 CPU 的指令队列中，然后交给运算单元去执行。 如果需要切换进程呢？ 每个进程都分代码段和数据段，为了指向不同进程的地址空间，有四个 16 位的段寄存器，分别是 CS、DS、SS、ES。 CS：代码段寄存器，找到代码在内存的位置 DS：数据段寄存器，找到数据在内存的位置 SS：栈寄存器，凡是和函数调用相关的操作都与栈相关 ES：附加段寄存器 如果运算中需要加载内存中的数据，需要通过 DS 找到内存中的数据，加载到通用寄存器中，应该如何加载呢？对于一个段，有一个起始的地址，而段内的具体位置，我们称为偏移量（Offset）。 在 CS 和 DS 中都存放着一个段的起始地址。 代码段的偏移量在 IP 寄存器中 数据段的偏移量会放在通用寄存器中。 32位处理器 在32位处理器中，有32根地址总线，可以访问2^32&#x3D;4G（(2^10)(2^10)(2^10)(2^2)&#x3D;4kkk&#x3D;4Gbit）内存 1、通用寄存器扩展 2、段寄存器 从BIOS到bootloaderBIOS时期1、ROM（Read Only Memory，只读存储器） 2、RAM（Random Access Memory，随机存取存储器） 3、BIOS（Basic Input and Output System，基本输入输出系统） ROM固化的初始化程序 在 x86 系统中，将 1M 空间最上面的 0xF0000 到 0xFFFFF 这 64K 映射给 ROM，也就是说，到这部分地址访问的时候，会访问 ROM。 4、BIOS的初始化 硬件检查 建立中断向量表和中断服务程序 bootloader时期内核初始化内核的启动从入口函数start_kernel()开始。在 init&#x2F;main.c 文件中，start_kernel 相当于内核的 main 函数。打开这个函数，你会发现，里面是各种各样初始化函数 XXXX_init。 初始化公司职能部门1、项目管理部门 创始进程：它是系统创建的第一个进程，我们称为 0 号进程。这是唯一一个没有通过 fork 或者 kernel_thread 产生的进程，是进程列表的第一个 进程列表：项目管理工具，列着所有的项目 2、办事大厅 中断门：处理各种中断 系统调用也是通过发送中断的方式进行的 3、会议室管理系统 初始化内存管理模块 4、项目管理流程 初始化调度模块 5、初始化基于内存的文件系统rootfs 初始化VFS（虚拟文件系统）：文件系统是项目资料库，为了兼容不同的文件系统，我们需要将文件的相关数据结构和操作抽象出来，形成抽象层对上提供统一的接口 初始化1号进程（用户态祖宗） kernel_thread(kernel_init;NULL,CLONE_FS) 有了很多的用户进程后，需要把原来的资源分成核心资源和非核心资源 x86提供了分层的权限机制，把区域分成了四个Ring，越往里面权限越高 内核态（Kernel Mode）：将能够访问关键资源的代码放在Ring0 用户态（User Mode）：普通程序放在Ring3 1、当用户态程序运行到一半，要访问一个核心资源，就需要暂停当前的运行，调用系统调用（发送中断） 2、用户态想要执行更高权限的指令，需要使用系统调用，用户态只需要等待返回结果即可 3、如何实现暂停？ 内存是用来保存程序运行时候的中间结果的，现在要暂时停下来，这些中间结果不能丢，因为再次运行的时候要基于这些中间结果；当前运行到代码的哪一行都是保存在寄存器内的 所以，在暂停的时候，CPU寄存器的值需要暂存到一个地方 过程：用户态-系统调用-保存寄存器-内核态执行系统调用-恢复寄存器-返回用户态 4、从内核态到用户态 执行kernel_thread这个函数的时候，系统处于内核态，需要切换到用户态去执行程序 初始化2号进程（内核态祖宗） kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES) 使用kernel_thread创建进程，但是为什么使用thread（线程）作为函数名呢？ 从用户态看：创建进程就是启动项目，这个项目需要多个人执行，就是多线程 从内核态看：无论是进程还是线程都统称为任务（Task），使用一样的数据结构 kthreadd函数：负责所有内核态的线程的调度和管理，是内核态所有线程的祖先 进程管理进程写代码：用系统调用创建进程1、创建文本文件，写入创建进程逻辑 fork系统调用，fork的返回值不同，父进程和子进程分道扬镳了 在子进程，需要通过execvp运行新的程序 123456789101112131415161718#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;extern int create_process (char* program, char** arg_list);int create_process (char* program, char** arg_list)&#123; pid_t child_pid; child_pid = fork (); if (child_pid != 0) return child_pid; else &#123; execvp (program, arg_list); abort (); &#125;&#125; 2、创建第二个文件，调用上面的函数 12345678910111213141516171819#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;extern int create_process (char* program, char** arg_list);int main ()&#123; char* arg_list[] = &#123; &quot;ls&quot;, &quot;-l&quot;, &quot;/etc/yum.repos.d/&quot;, NULL &#125;; # 调用函数运行ls命令 create_process (&quot;ls&quot;, arg_list); return 0;&#125; 编译：程序的二进制格式 CPU无法执行文本文件的指令，CPU能够执行的指令是二进制的，所以需要对指令进行翻译，翻译的过程为编译（Complie） 1、ELF（Executeable and Linkable Format，可执行与可链接格式） 在Linux下，二进制的程序需要有严格的格式ELF，这个格式可以根据编译的结果不同分为不同的格式 2、文本文件编译为二进制格式过程 头文件：上面代码的include部分 源文件：这个.c结尾的文件 .o文件：可重定位文件（Relocatable File） 头部：描述整个文件 .text：存放编译好的二进制可执行代码 .data：存放已经初始化的全局变量 .rodata：只读数据，例如字符串常量、const 的变量 .bss：未初始化全局变量，运行时会置 0 .symtab：符号表，记录的则是函数和变量 .strtab：字符串表、字符串常量和变量名 节头部标：存放节的元数据 为什么叫重定位文件？ 文件存放的地址都是相对地址 可执行文件：ELF的第二种格式 可以马上加载到内存里面执行 动态链接库：ELF的第三种格式，共享对象文件（Shared Object） 运行程序为进程 ELF这个格式的文件如何加载到内存？ 在内核中，有这样一个数据结构，用来定义加载二进制文件的方法。 12345678struct linux_binfmt &#123; struct list_head lh; struct module *module; int (*load_binary)(struct linux_binprm *); int (*load_shlib)(struct file *); int (*core_dump)(struct coredump_params *cprm); unsigned long min_coredump; /* minimal dump size */&#125; __randomize_layout; 对于 ELF 文件格式，有对应的实现。 1234567static struct linux_binfmt elf_format = &#123; .module = THIS_MODULE, .load_binary = load_elf_binary, .load_shlib = load_elf_library, .core_dump = elf_core_dump, .min_coredump = ELF_EXEC_PAGESIZE,&#125;; load_elf_binary是不是你很熟悉？没错，我们加载内核镜像的时候，用的也是这种格式。 还记得当时是谁调用的 load_elf_binary 函数吗？具体是这样的：do_execve-&gt;do_execveat_common-&gt;exec_binprm-&gt;search_binary_handler。 那 do_execve 又是被谁调用的呢？我们看下面的代码。 1234567SYSCALL_DEFINE3(execve, const char __user *, filename, const char __user *const __user *, argv, const char __user *const __user *, envp)&#123; return do_execve(getname(filename), argv, envp);&#125; 学过了系统调用一节，你会发现，原理是 exec 这个系统调用最终调用的 load_elf_binary。 exec 比较特殊，它是一组函数： 包含 p 的函数（execvp, execlp）会在 PATH 路径下面寻找程序； 不包含 p 的函数需要输入程序的全路径； 包含 v 的函数（execv, execvp, execve）以数组的形式接收参数； 包含 l 的函数（execl, execlp, execle）以列表的形式接收参数； 包含 e 的函数（execve, execle）以数组的形式接收环境变量。 在上面 process.c 的代码中，我们创建 ls 进程，也是通过 exec。 进程树既然所有的进程都是从父进程 fork 过来的，那总归有一个祖宗进程，这就是咱们系统启动的 init 进程。 总结这一节我们讲了一个进程从代码到二进制到运行时的一个过程，我们用一个图总结一下。 我们首先通过图右边的文件编译过程，生成 so 文件和可执行文件，放在硬盘上。下图左边的用户态的进程 A 执行 fork，创建进程 B，在进程 B 的处理逻辑中，执行 exec 系列系统调用。这个系统调用会通过 load_elf_binary 方法，将刚才生成的可执行文件，加载到进程 B 的内存中执行。 线程为什么需要线程？1、对于任何一个进程，即使没有主动创建线程，进程也默认拥有一个主线程 2、线程是负责执行二进制指令的，进程除了执行指令外，内存、文件系统都需要管 3、使用进程实现并行执行问题的问题： 创建进程占用资源太多 进程之间通信需要数据在不同的内存空间传来传去，无法共享 4、需要线程的原因 并行执行 需要处理应急的事情 分离前台任务和后台任务 如何创建线程？ 线程的数据 过程并行起来了，数据呢？ 将线程访问的数据分为三类： 线程中的局部变量 进程中的全局变量 线程中的全局变量 1、线程栈上的本地数据 栈的大小可以使用命令ulimit -a查看，默认情况下线程栈大小为8M 主线程在内存中有一个栈空间，其他线程也有独立的栈空间 为了避免线程之间的栈空间踩踏，线程栈之间会有小块区域来隔离保护各自的栈空间，一旦另外一个线程踏入到这个隔离区，会引发段错误 2、进程共享的全局数据 在不同进程间是隔离的，在一个进程中是共享的 多个线程一起修改同一个全局变量，需要一个机制来保护他们 3、线程私有数据（类似ThreadLocal） 弥补进程共享和线程内函数共享之间的空白 通过以下函数创建： 1int pthread_key_create(pthread_key_t *key, void (*destructor)(void*)) 创建一个key，伴随一个析构函数；key一旦被创建所有的线程都可以访问，但是各个线程可以根据自己的需要向key中填入不同的值，就提供了一个同名而不同值的全局变量 可以通过以下函数设置key对应的value 1int pthread_setspecific(pthread_key_t key, const void *value) 数据的保护Mutex（Mutual Exclusion，互斥） 进程数据结构（PCB） 在Linux里，无论是进程还是线程，到了内核中统一称为任务，由统一的结构task_struct管理 任务列表：使用链表将所有的task_struct串起来 任务任务ID1、每个任务都有一个ID作为这个任务的唯一标识 2、task_struct里面涉及任务ID的有下面几个： 123pid_t pid;pid_t tgid;struct task_struct *group_leader; 3、为什么需要这么多？进程和线程到内核中统一变成了任务，存在两个问题： 任务展示 如果按照任务列表将所有的线程都展示给用户，会比较复杂 用户无法找到那些自己创建的线程 给任务下发指令 比如需要终止某个任务，应该给进程下发信号，退出进程下的所有线程 4、在内核中需要对线程和进程进行区分 pid：process id tgid：thread group id 任何一个进程，如果只有主线程，那 pid 是自己，tgid 是自己，group_leader 指向的还是自己（pid&#x3D;tgid&#x3D;group_leader） 如果一个进程创建了其他线程，线程有自己的pid，tgid&#x3D;主线的的pid，group_leader指向主线程 信号处理1、关于信号处理的字段 12345678910/* Signal handlers: */struct signal_struct *signal;struct sighand_struct *sighand;sigset_t blocked;sigset_t real_blocked;sigset_t saved_sigmask;struct sigpending pending;unsigned long sas_ss_sp;size_t sas_ss_size;unsigned int sas_ss_flags; 这里定义了哪些信号被阻塞暂不处理（blocked），哪些信号尚等待处理（pending），哪些信号正在通过信号处理函数进行处理（sighand）。处理的结果可以是忽略，可以是结束进程等等。 信号处理函数默认使用用户态的函数栈，当然也可以开辟新的栈专门用于信号处理，这就是 sas_ss_xxx 这三个变量的作用。 上面我说了下发信号的时候，需要区分进程和线程。从这里我们其实也能看出一些端倪。 task_struct 里面有一个 struct sigpending pending。如果我们进入 struct signal_struct *signal 去看的话，还有一个 struct sigpending shared_pending。它们一个是本任务的，一个是线程组共享的。 任务状态1、涉及任务状态的字段 12volatile long state; /* -1 unrunnable, 0 runnable, &gt;0 stopped */ int exit_state; unsigned int flags; state是通过bitset的方式设置的，当前是什么状态哪一位就是1 2、TASK_RUNNING 进程在时刻准备运行（就绪状态） 当处于这个状态的进程获取时间片的时候就是在运行中，没有获取到就说明被其他进程抢占了，在等待再次分配时间片 运行的进程一旦需要进行IO操作，需要等待IO完毕，这个时候会释放CPU，进入睡眠状态 3、TASK_INTERRUPTIBLE 可中断的睡眠 浅睡眠的状态 这个时候一个信号来的时候进程要被唤醒，唤醒后不继续刚才的操作，而是进行信号处理 例如：收到某些信号就放弃等待这个I&#x2F;O操作完成，直接退出 4、TASK_UNINTERRUPTIBLE 不可中断的睡眠 深度睡眠状态 不能被信号唤醒，死等I&#x2F;O结束 kill信号也会被忽略 5、TASK_KILLABLE 可终止的睡眠 运行原理类似于TASK_UNINTERRUPTIBLE，但是可以响应致命信号 6、TASK_STOPPED 收到sigstop、sigttin、sigtstp、sigttou信号后进入该状态 7、EXIT_ZOMBIE 一旦一个进程要结束，先进入EXIT_ZOMBIE状态，但是这个时候它的父进程没有使用wait()等系统调用获取它的终止信息，此时进程变成了僵尸进程 进程调度1、进程的状态切换涉及调度，下面字段用于调度 12345678910111213141516171819//是否在运行队列上int on_rq;//优先级int prio;int static_prio;int normal_prio;unsigned int rt_priority;//调度器类const struct sched_class *sched_class;//调度实体struct sched_entity se;struct sched_rt_entity rt;struct sched_dl_entity dl;//调度策略unsigned int policy;//可以使用哪些CPUint nr_cpus_allowed;cpumask_t cpus_allowed;struct sched_info sched_info; 内核栈 程序执行过程中一旦调用到系统调用就需要进入内核继续执行，那么如何将用户态的执行和内核态的执行串起来呢？ 12struct thread_info thread_info;void *stack; 1、用户态函数栈 在进程的内存空间里面，栈是一个从高地址到低地址，往下增长的结构，也就是上面是栈底，下面是栈顶，入栈和出栈的操作都是从下面的栈顶开始的。 2、内核态函数栈 Linux给每个task都分配了内核栈，大小为8k thread_info：对task_struct结构的补充，存放与体系结构相关的东西 pg_regs：存放寄存器变量 系统调用从用户态到内核态，首先需要将用户态运行过程中的CPU上下文保存起来，保存到这个结构的寄存器变量里，这样系统调用返回的时候能够继续执行 总结 调度 CPU的数量是有限的，但是进程的数量远超过CPU的数目，因此就需要进行进程的调度，有效分配CPU的时间，保证进程的最快响应和进程之间的公平 调度策略和调度类1、Linux中进程可以分为两种 实时进程 需要尽快返回结果 普通进程 2、task_struct成员变量policy称为调度策略 12345678#define SCHED_NORMAL 0#define SCHED_FIFO 1#define SCHED_RR 2#define SCHED_BATCH 3#define SCHED_IDLE 5#define SCHED_DEADLINE 6unsigned int policy; 配合调度策略的包括优先级rt_priority; 12int prio, static_prio, normal_prio;unsigned int rt_priority; 对于实时进程，优先级范围是0-99；对于普通进程优先级范围是110-139。数值越小优先级越高 实时调度策略SCHED_FIFO、SCHED_RR、SCHED_DEADLINE 是实时进程的调度策略。 FIFO：先来先服务，但是可以分配更高的优先级来抢占 RR：轮流调度，采用时间片，相同优先级的任务用完时间片后放入队伍尾部，高优先级可以抢占 DEADLINE：按照任务的deadline进行调度，选择距离deadline最近的任务 普通调度策略对于普通进程的调度策略有，SCHED_NORMAL、SCHED_BATCH、SCHED_IDLE NORMAL：普通进程 BATCH：后台进程，不需要和前端交互 IDLE：特别空闲的时候才跑的进程 已经设置了调度策略和优先级，需要有变量执行 1const struct sched_class *sched_class; sched_class 有几种实现： stop_sched_class 优先级最高的任务会使用这种策略，会中断所有其他线程，且不会被其他任务打断； dl_sched_class 就对应上面的 deadline 调度策略； rt_sched_class 就对应 RR 算法或者 FIFO 算法的调度策略，具体调度策略由进程的 task_struct-&gt;policy 指定； fair_sched_class 就是普通进程的调度策略； idle_sched_class 就是空闲进程的调度策略。 完全公平调度算法Linux实现了一个基于CFS的调度算法 1、首先记录进程的运行时间vruntime CPU 会提供一个时钟，过一段时间就触发一个时钟中断叫 Tick CFS 会为每一个进程安排一个虚拟运行时间 vruntime。如果一个进程在运行，随着时间的增长，也就是一个个 tick 的到来，进程的 vruntime 将不断增大。没有得到执行的进程 vruntime 不变 vruntime少的受到了不公平的对待，需要优先执行 2、调度队列和调度实体 CFS需要一个数据结构对varuntime进行排序，找到最小的那个 查询：快速找到最小的 更新：快速调整排序 使用红黑树，节点称为调度实体 task_struct成员变量： 123456# 完全公平算法调度实体struct sched_entity se;# 实时调度实体struct sched_rt_entity rt;# DeadLine调度实体struct sched_dl_entity dl; 红黑树的例子： 所有可运行的进程通过不断地插入操作最终都存储在以时间为顺序的红黑树中，vruntime 最小的在树的左侧，vruntime 最多的在树的右侧。 CFS 调度策略会选择红黑树最左边的叶子节点作为下一个将获得 CPU 的任务。 红黑树放在哪里？ 每个CPU都有自己的struct rq结构，用于描述在此CPU上所运行的所有进程 包括实时进程队列rt_rq和一个CFS运行队列cfs_rq 在调度时调度器会首先去实时进程队列找是否有实时进程需要运行，如果没有去CFS运行队列找是否有进程需要运行 调度算法FCFS 算法 先来先服务算法，遵循先来后端原则，每次从就绪队列拿等待时间最久的，运行完毕后再拿下一个 该模式对长作业有利，适用 CPU 繁忙型作业的系统，不适用 I&#x2F;O 型作业，因为会导致进程CPU利用率很低。 SJF 算法 最短作业优先算法，该算法会优先选择运行所需时间最短的进程执行，可提高吞吐量。 跟FCFS正好相反，对长作业很不利。 SRTN 算法 最短剩余时间优先算法，可以认为是SJF的抢占式版本，当一个新就绪的进程比当前运行进程具有更短完成时间时，系统抢占当前进程，选择新就绪的进程执行。 有最短的平均周转时间，但不公平，源源不断的短任务到来，可能使长的任务长时间得不到运行。 HRRN 算法 高响应比优先算法，为了平衡前面俩而生，按照响应优先权从高到低依次执行。属于前面俩的折中权衡。 优先权 &#x3D; (等待时间 + 要求服务时间) &#x2F; 要求服务时间 RR 算法 时间片轮转算法，操作系统设定了个时间片Quantum，时间片导致每个进程只有在该时间片内才可以运行，这种方式导致每个进程都会均匀的获得执行权。 时间片一般20ms~50ms，如果太小会导致系统频繁进行上下文切换，太大又可能引起对短的交互请求的响应变差。 HPF 算法 最高优先级调度算法，从就绪队列中选择最高优先级的进程先执行。 优先级的设置有初始化固定死的那种，也有在代码运转过程中根据等待时间或性能动态调整 这两种思路。 缺点是可能导致低优先级的一直无法被执行。 MFQ 算法 多级反馈队列调度算法 ，可以认为是 RR 算法 跟 HPF 算法 的综合体。 系统会同时存在多个就绪队列，每个队列优先级从高到低排列，同时优先级越高获得是时间片越短。 新进程会先加入到最高优先级队列，如果新进程优先级高于当前在执行的进程，会停止当前进程转而去执行新进程。新进程如果在时间片内没执行完毕需下移到次优先级队列。 总结一个CPU上有一个队列，CFS的队列是一颗红黑树，每个节点是一个sched_entity，每个sched_entity都属于一个task_struct，task_struct里面有指针指向进程属于哪个调度类 协程1、大多数web服务本质上是IO密集型服务，瓶颈在于尽可能快速完成高并发下的数据读写，解决方案： 多进程：存在频繁调度切换的问题、每个进程资源不共享的问题，需要引入进程间通信机制 多线程：大量IO导致多线程被频繁挂起和切换，存在竞争问题 2、协程 Coroutines 比线程更加轻量级的微线程 理解成子程序调用，每个子程序都可以在单独的协程内执行 协程运行在线程之上，并没有增加线程数量，只是在线程基础上通过分时复用的方式运行多个协程 协程的切换在用户态完成 3、注意 协程运行在线程之上，并且协程调用了一个阻塞IO操作，此时操作系统并不知道协程的存在，它只知道线程，因此在协程调用阻塞IO操作时，操作系统会让线程进入阻塞状态，当前的协程和其它绑定在该线程之上的协程都会陷入阻塞而得不到调度。 在协程中不能调用导致线程阻塞的操作，比如打印、读取文件、Socket接口等。协程只有和异步IO结合起来才能发挥最大的威力。并且协程只有在IO密集型的任务中才会发挥作用。 内存管理内存管理独享内存空间1、每个项目的物理地址对于进程来说不可见，操作系统会给进程分配一个虚拟地址，所有进程看到的地址都是一样的，里面的内存都是从0开始的 2、在程序里面，指令写入的地址是虚拟地址。例如，位置为 10M 的内存区域，操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。 3、当程序要访问虚拟地址的时候，由内核的数据结构进行转换，转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。 规划虚拟地址空间1、操作系统的内存管理，主要分为三个方面： 物理内存的管理 虚拟地址的管理 虚拟地址和物理内存如何映射 2、物理内存的访问都是通过内存管理，不管是用户态还是内核态都是访问虚拟内存，通过内存管理映射到物理内存 3、站在一个进程的角度去看这个虚拟的空间： 如果是32位，那么有4G的内存空间是我的；如果是64位，在x86_64下，实际上只使用48位，对应256TB空间； OS将虚拟空间分为两部分：内核空间（地址在上）、用户空间（地址在下）；对于普通进程，内核空间不能访问 从最低位开始，先是 Text Segment（存放二进制可执行代码）、Data Segment（静态常量） 和 BSS Segment（未初始化的静态变量） 堆（Heap）：动态分配内存的区域 Memory Mapping Segment：把文件映射进内存，如果二进制的执行文件依赖于某个动态链接库，就是在这个区域里面将 so 文件映射到了内存中 栈（stack）：主线程的函数调用的函数栈 主线程函数调用，使用的是进程里的栈空间 主线程之外的线程，使用的函数栈是在进程的堆空间里分配的一段内存作为函数栈使用 对于内核空间，无论是哪个进程进来的都是看见同一个内核空间，同一个进程列表。虽然内核栈不同，但是如果想知道的话，还是能够知道每个进程的内核栈在哪里的。所以，如果要访问一些公共的数据结构，需要进行锁保护 虚拟地址映射物理地址分段机制 1、分段机制下虚拟地址由两部分组成：段选择子和段内偏移量 段选择子：保存在段寄存器，最重要的是段号，用作段表的索引 段内偏移量：位于0到段界限之间 2、段表：保存段的基地址、段的界限和特权等级等 段的物理内存地址&#x3D;基地址+段内偏移量 3、分段的问题： 内存碎片 内存交换效率低 4、在Linux中，段表称为段描述符表，放在全局描述符表GDT里面 表项包括基地址base、段界限limit、其他标识符 分析发现，所有段的起始地址都是一样的，都是0，所以在Linux系统中没有使用到全部的分段功能，分段可以做权限审核，例如用户态 DPL 是 3，内核态 DPL 是 0。当用户态试图访问内核态的时候，会因为权限不足而报错。 Linux只使用分段做权限审核 分页（paging）**1、对于物理内存，操作系统把它分成一块一块大小相同的页，这样更方便管理 换出：有的内存页面长时间不用了，可以暂时写到硬盘上 换入：一旦需要的时候，再加载进来，这样可以扩大可用物理内存的大小，提高物理内存的利用率 换入和换出都是以页为单位的，页面的大小一般为 4KB 2、虚拟地址分为两部分：页号、页内偏移量 3、页表：物理页每页所在物理内存的地址、基地址 页表中所有页表项需要提前建立并且连续 页表存储在内存管理单元（MMU） 4、分页如何解决分段的内存碎片、内存交换效率低的问题？ 释放内存都是以页为单位释放的 如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给换出（Swap Out）。一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高 分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。 5、简单的分页存在的问题？ 空间上的缺陷 操作系统可以同时运行非常多的进程，就意味着页表非常庞大；在32位环境下虚拟地址空间共有4GB，假设一个页大小为4KB，就需要100万个页，每个页表项需要4个字节大小存储，那么4G空间的映射需要4MB的内存来存储页表。每个进程都需要一个页表，那么这就很占用内存。 解决：多级页表 把这100万个页表项的单级页表再分页，分为1024个页表（二级），每个表（二级）包含1024个页表项，形成二级分页 如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表 页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项 对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是： 全局页目录项 PGD（Page Global Directory） 上层页目录项 PUD（Page Upper Directory） 中间页目录项 PMD（Page Middle Directory） 页表项 PTE（Page Table Entry） 虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销 解决：将常用页表项放入Cache（TLB），称为快表 有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个 CPU读取数据的流程： 进行上下文切换的时候，TLB放的是上一个进程的相关地址，刷新数据的方式： 全部刷新 部分刷新 段页式内存管理内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为段页式内存管理。 1、页式内存管理实现的方式： 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制； 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页； 地址结构就由段号、段内页号和页内位移三部分组成 用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示： 访问物理地址需要经过三次内存访问 第一次访问段表，得到页表起始地址 第二次访问页表，得到物理页号 第三次将物理页号与页内偏移组合，得到物理地址 Linux内存管理1、Intel处理器的发展历史 早期 Intel 的处理器从 80286 开始使用的是段式内存管理。但是很快发现，光有段式内存管理而没有页式内存管理是不够的，这会使它的 X86 系列会失去市场的竞争力。 因此，在不久以后的 80386 中就实现了对页式内存管理。也就是说，80386 除了完成并完善从 80286 开始的段式内存管理的同时还实现了页式内存管理。但是这个 80386 的页式内存管理设计时，没有绕开段式内存管理，而是建立在段式内存管理的基础上，这就意味着，页式内存管理的作用是在由段式内存管理所映射而成的的地址上再加上一层地址映射。由于此时段式内存管理映射而成的地址不再是“物理地址”了，Intel 就称之为“线性地址”（也称虚拟地址）。 于是，段式内存管理先将逻辑地址映射成线性地址，然后再由页式内存管理将线性地址映射成物理地址。 逻辑地址是「段式内存管理」转换前的地址，线性地址则是「页式内存管理」转换前的地址 2、Linux采用什么方式管理内存？ 主要采用页式内存管理，但是涉及了段机制 原因： Intel X86 CPU 一律对程序中使用的地址先进行段式映射，然后才能进行页式映射 对策：Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。 虚拟地址空间分布： 分为内核空间和用户空间 进程空间管理用户态和内核态的划分整个虚拟内存空间分为： 用户态地址空间 内核态地址空间 内核进程和用户进程所占的虚拟内存比例是 1:3 对于32位系统，最大寻址2^32&#x3D;4G，其中用户态虚拟地址空间3G，内核态1G 对于64位系统，虚拟地址使用48位 内核空间内核空间总是驻留在内存中，它是为操作系统的内核保留的。应用程序是不允许直接在该区域进行读写或直接调用内核代码定义的函数的。内核进程对应的虚拟内存，按访问权限可以分为进程私有和进程共享两块区域。 进程私有的虚拟内存：每个进程都有单独的内核栈、页表、task 结构以及 mem_map 结构等。 进程共享的虚拟内存：属于所有进程共享的内存区域，包括物理存储器、内核数据和内核代码区域。 用户空间用户态虚拟空间有几类数据，例如代码、全局变量、堆、栈、内存映射区等 运行时栈 由编译器自动释放，存放函数的参数值，局部变量和方法返回值等。 每当一个函数被调用时，该函数的返回类型和一些调用的信息被存储到栈顶，调用结束后调用信息会被弹出弹出并释放掉内存。 栈区是从高地址位向低地址位增长的，是一块连续的内在区域，最大容量是由系统预先定义好的，申请的栈空间超过这个界限时会提示溢出，用户能从栈中获取的空间较小。 运行时堆 存放进程运行中被动态分配的内存段，位于 BSS 和栈中间的地址位 由卡发人员申请分配（malloc）和释放（free） 堆是从低地址位向高地址位增长，采用链式存储结构。频繁地 malloc&#x2F;free 造成内存空间的不连续，产生大量碎片。 当申请堆空间时，库函数按照一定的算法搜索可用的足够大的空间。因此堆的效率比栈要低的多。 代码段 存放 CPU 可以执行的机器指令，该部分内存只能读不能写。 通常代码区是共享的，即其它执行程序可调用它。假如机器中有数个进程运行相同的一个程序，那么它们就可以使用同一个代码段。 未初始化的数据段 存放未初始化的全局变量，BSS 的数据在程序开始执行之前被初始化为 0 或 NULL。 已初始化的数据段 存放已初始化的全局变量，包括静态全局变量、静态局部变量以及常量。 内存映射区域 例如将动态库，共享内存等虚拟空间的内存映射到物理空间的内存，一般是 mmap 函数所分配的虚拟内存空间。 虚拟内存和物理内存物理内存1、物理内存（Physical memory）是相对于虚拟内存（Virtual Memory）而言的。 2、物理内存指通过物理内存条而获得的内存空间，而虚拟内存则是指将硬盘的一块区域划分来作为内存。 3、内存主要作用：在计算机运行时为操作系统和各种程序提供临时储存。物理上真实存在的插在主板内存槽上的内存条的容量的大小。 虚拟内存1、虚拟内存是计算机系统内存管理的一种技术。 它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间）。实际上，虚拟内存通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换，加载到物理内存中来。 2、虚拟内存地址 和用户进程紧密相关，一般来说不同进程里的同一个虚拟地址指向的物理地址是不一样的 每个进程所能使用的虚拟地址大小和 CPU 位数有关。在 32 位的系统上，虚拟地址空间大小是 2 ^ 32 &#x3D; 4G，在 64位系统上，虚拟地址空间大小是 2 ^ 64 &#x3D; 2 ^ 34G，而实际的物理内存可能远远小于虚拟内存的大小。 每个用户进程维护了一个单独的页表（Page Table），虚拟内存和物理内存就是通过这个页表实现地址空间的映射的。 3、用户进程申请并访问物理内存（或磁盘存储空间）的过程 用户进程向操作系统发出内存申请请求 系统会检查进程的虚拟地址空间是否被用完，如果有剩余，给进程分配虚拟地址 系统为这块虚拟地址创建的内存映射（Memory Mapping），并将它放进该进程的页表（Page Table） 系统返回虚拟地址给用户进程，用户进程开始访问该虚拟地址 CPU 根据虚拟地址在此进程的页表（Page Table）中找到了相应的内存映射（Memory Mapping），但是这个内存映射（Memory Mapping）没有和物理内存关联，于是产生缺页中断 操作系统收到缺页中断后，分配真正的物理内存并将它关联到页表相应的内存映射（Memory Mapping）。中断处理完成后 CPU 就可以访问内存了 当然缺页中断不是每次都会发生，只有系统觉得有必要延迟分配内存的时候才用的着，也即很多时候在上面的第 3 步系统会分配真正的物理内存并和内存映射（Memory Mapping）进行关联。 4、虚拟内存的优点 地址空间：提供更大的地址空间，并且地址空间是连续的，使得程序编写、链接更加简单 进程隔离：不同进程的虚拟地址之间没有关系，所以一个进程的操作不会对其它进程造成影响 数据保护：每块虚拟内存都有相应的读写属性，这样就能保护程序的代码段不被修改，数据块不能被执行等，增加了系统的安全性 内存映射：有了虚拟内存之后，可以直接映射磁盘上的文件（可执行文件或动态库）到虚拟地址空间。这样可以做到物理内存延时分配，只有在需要读相应的文件的时候，才将它真正的从磁盘上加载到内存中来，而在内存吃紧的时候又可以将这部分内存清空掉，提高物理内存利用效率，并且所有这些对应用程序是都透明的 共享内存：比如动态库只需要在内存中存储一份，然后将它映射到不同进程的虚拟地址空间中，让进程觉得自己独占了这个文件。进程间的内存共享也可以通过映射同一块物理内存到进程的不同虚拟地址空间来实现共享 物理内存管理：物理地址空间全部由操作系统管理，进程无法直接分配和回收，从而系统可以更好的利用内存，平衡进程间对内存的需求 文件系统文件系统文件系统的功能规划最常用的外部存储就是硬盘，数据以文件的形式保存在硬盘上，为了管理这些文件，在规划文件系统的时候需要考虑以下几点： 文件系统有严格的组织形式，使得文件能够以块为单位存储 文件系统也要有索引区，用来方便查找一个文件分成的多个块都存放在了什么位置 如果有热点文件，需要有缓存 文件应该使用文件夹的形式组织起来，方便管理查询 Linux内核需要在内存里面维护一套数据结构，保存哪些文件被哪些进程打开和使用 文件系统相关命令行格式化 将一块盘使用命令组织称一定格式的文件系统的过程 Windows常用格式化格式为NTFS，Linux常用的是ext3或者ext4 当一个 Linux 系统插入了一块没有格式化的硬盘的时候，我们可以通过命令 fdisk -l，查看格式化和没有格式化的分区 可以通过命令 mkfs.ext3 或者 mkfs.ext4 进行格式化 格式化后的硬盘需要挂载到某个目录下才能作为普通的文件系统访问 文件系统相关系统调用1、打开文件 当使用系统调用open打开一个文件时，操作系统会创建一些数据结构来表示这个被打开的文件。在进程中，为这个打开的文件分配一个文件描述符fd（File Descriptor） 2、文件描述符fd（File Descriptor） 区分一个进程打开的多个文件 只在当前进程有效 open返回的fd必须记录好，我们对这个文件的所有操作都需要这个fd 3、写入文件 参数 文件描述符（你是谁？） 表示写入的数据存放位置（你在哪里？） 表示希望写入的字节数 返回值：成功写入文件的字节数量 硬盘文件系统 主要讨论Linux下主流的文件系统格式——ext系列文件系统格式 inode与块的存储1、硬盘被分成相同大小的单元，称为块（block），一块的大小是扇区大小的整数倍（默认4k） 2、inode 存放文件的元数据，例如名字、权限等 每个文件都对应一个inode，文件夹也是文件 数据结构： 123456789101112131415161718192021struct ext4_inode &#123; __le16 i_mode; /* 读写权限 */ __le16 i_uid; /* 属于哪个用户 */ __le16 i_gid; /* 属于哪个组 */ __le32 i_size_lo; /* 大小 */ __le32 i_atime; /* 最近一次访问文件的时间 */ __le32 i_ctime; /* 最近一次更改inode的时间 */ __le32 i_mtime; /* 最近一次修改文件的时间，只有文件数据修改才会更新 */ __le32 i_dtime; /* Deletion Time */ __le16 i_links_count; /* Links count */ __le32 i_blocks_lo; /* 占多少个块 */ __le32 i_flags; /* File flags */...... __le32 i_block[EXT4_N_BLOCKS];/* 指向block */ __le32 i_generation; /* File version (for NFS) */ __le32 i_file_acl_lo; /* File ACL */ __le32 i_size_high;......&#125;; 3、block是如何保存的？ EXT4_N_BLOCKS有如下定义： 前12项保存块的位置，通过i_block[0-11]可以获取保存文件内容的块 如果一个文件放不下的时候，就需要让i_block[12]指向一个间接块，存放数据块的位置 如果文件再大一些，i_block[13]会指向一个块，可以用二次间接块，存放间接块的位置；再大就会使用i_block[14]指向三次间接块 12345#define EXT4_NDIR_BLOCKS 12#define EXT4_IND_BLOCK EXT4_NDIR_BLOCKS#define EXT4_DIND_BLOCK (EXT4_IND_BLOCK + 1)#define EXT4_TIND_BLOCK (EXT4_DIND_BLOCK + 1)#define EXT4_N_BLOCKS (EXT4_TIND_BLOCK + 1) 问题：对于大文件需要多次读取硬盘才能找到块，访问速度较慢 解决：ext4引入了Extents 存放连续的块，保存为一颗树 节点头ext4_extent_header：描述某个节点 1234567struct ext4_extent_header &#123; __le16 eh_magic; __le16 eh_entries; /* 表示这个节点有多少项，项分为两种，如果是叶子节点就直接指向硬盘上的连续块地址（ext4_extent），如果是分支节点就会指向下一层的节点（ext4_extent_idx） */ __le16 eh_max; __le16 eh_depth; __le32 eh_generation; &#125;; inode里面的i_block可以放下一个1个header和4个extent；这个时候eh_depth位0 如果文件比较大，4个extent放不下就需要分裂成一棵树，eh_depth&gt;0的节点就是索引节点最底层eh_depth&#x3D;0的是叶子节点 4、inode位图和块位图 文件系统中，专门有一个块来保存inode的位图，在这4k里面每一位对应一个inode。如果是1表示这个inode已经被使用了，如果是0就是没有被使用 文件系统的格式1、块组 数据块的位图是放在一个块里面的，共4k。每位代表一个块，共可以表示 4∗1024∗8&#x3D;215 个数据块。如果每个数据块也是按默认的 4K，最大可以表示空间为 215∗4∗1024&#x3D;227 个 byte，也就是 128M。 如果采用“一个块的位图 + 一系列的块”，外加“一个块的 inode 的位图 + 一系列的 inode 的结构”，最多能够表示 128M，称为一个块组 2、块组描述符表 这样一个个块组，就基本构成了我们整个文件系统的结构。因为块组有多个，块组描述符也同样组成一个列表，我们把这些称为块组描述符表。 3、超级块（ext4_super_block） 对整个文件系统的情况进行描述 这里面有整个文件系统一共有多少 inode，s_inodes_count；一共有多少块，s_blocks_count_lo，每个块组有多少 inode，s_inodes_per_group，每个块组有多少块，s_blocks_per_group 等。这些都是这类的全局信息。 4、文件系统的格式 引导块：系统启动时预留的一块区域 默认情况下，超级块和块组描述符表都有副本保存在每一个块组里面 问题：如果每个块组都保存一份完整的块组描述符，浪费空间，且块组描述符的个数就决定了整个文件系统的大小，就被限制住了 5、Meta Block Groups 块组描述符表不保存所有块组的描述符，而是将块组分为多个元块组（Meta Block Group），每个元块组里面的块描述符表仅包括自己的，一个元块组包含64个块组 目录的存储格式1、目录和普通文件 相同：本身也是一个文件，也有inode，inode里面也指向一些块。 不同：普通文件的块保存文件数据，目录文件的块保存目录里面一项一项的文件信息 文件信息：保存这个目录下一级文件的文件名和对应的inode，通过inode找到真正的文件 2、为避免频繁读取磁盘里的目录文件，内核会把已经读过的目录文件用目录项这个数据结构缓存在内存，方便用户下次读取目录信息，目录项可包含目录或文件，不要惊讶于可以保存目录，目录格式的目录项里面保存的是目录里面一项一项的文件信息。 软链接和硬连接 硬链接：老文件A被创建若干个硬链接B、C后。A、B、C三个文件的inode是相同的，所以不能跨文件系统。同时只有ABC全部删除，系统才会删除源文件。 软链接：相当于基于老文件A新建了个文件B，该文件B有新的inode，不过文件B内容是老文件A的路径。所以软链接可以跨文件系统。当老文件A删除后，文件B仍然存在，不过找不到指定文件了。 总结 虚拟文件系统多层合作 应用层：进程可通过系统调用进行文件读写操作 在内核，每个进程都需要为打开的文件维护一定的数据结构 在内核，整个系统打开的文件也需要维护一定的数据结构 虚拟文件系统：Linux可支持多种文件系统，他们的实现各不相同，因此Linux内核向用户空间提供了虚拟文件系统这个统一的接口对文件系统进行操作。它提供了常见的文件系统对象模型，例如 inode、directory entry、mount 等，以及操作这些对象的方法，例如 inode operations、directory operations、file operations 等 真正的文件系统：例如ext4 为了加快设备读写效率，需要缓存层 为了读写文件系统，需要通过块设备I&#x2F;O层，这是文件系统层和块设备驱动的接口 open 打开&#x2F;创建文件1、在进程里面通过open系统调用打开文件，最终调用系统调用实现sys_open 123456789101112131415161718192021222324SYSCALL_DEFINE3(open, const char __user *, filename, int, flags, umode_t, mode)&#123;...... return do_sys_open(AT_FDCWD, filename, flags, mode);&#125;long do_sys_open(int dfd, const char __user *filename, int flags, umode_t mode)&#123;...... fd = get_unused_fd_flags(flags); if (fd &gt;= 0) &#123; struct file *f = do_filp_open(dfd, tmp, &amp;op); if (IS_ERR(f)) &#123; put_unused_fd(fd); fd = PTR_ERR(f); &#125; else &#123; fsnotify_open(f); fd_install(fd, f); &#125; &#125; putname(tmp); return fd;&#125; 2、首先获取一个没有用的文件描述符 在每个进程的task_struct中，有一个指针files，类型是files_struct 1struct files_struct *files; files_struct里面最重要的是一个文件描述符表，每打开一个文件，会在这个列表分配一项，下标就是文件描述符 1234struct files_struct &#123; ...... struct file __rcu * fd_array[NR_OPEN_DEFAULT];&#125;; 对于任何一个进程，默认情况下，文件描述符0表示stdin标准输入，文件描述符1表示stdout标准输出，文件描述符2表示stedeer标准错误输出；再打开的文件会从这个列表找一个空闲位置分配给它（不是递增的） 文件描述符表每一项都是指向struct file的指针，也就是说每打开一个文件都会有一个struct file对应 3、do_filp_open创建struct file结构 4、fd_install将文件描述符和这个结构关联起来 Linux I&#x2F;O读写方式Linux 提供了 3 种磁盘与主存之间的数据传输机制： 轮询：基于死循环对 I&#x2F;O 端口进行不断检测 I&#x2F;O 中断：当数据到达时，磁盘主动向 CPU 发起中断请求，由 CPU 自身负责数据的传输过程 DMA 传输：在 I&#x2F;O 中断的基础上引入了 DMA 磁盘控制器，由 DMA 磁盘控制器负责数据的传输，降低了 I&#x2F;O 中断操作对 CPU 资源的大量消耗 DMA（Direct Memory Access，直接存储器访问)） 是所有现代电脑的重要特色，它允许不同速度的硬件装置来沟通，而不需要依赖于CPU的大量中断负载。否则，CPU 需要从来源把每一片段的资料复制到暂存器，然后把它们再次写回到新的地方。在这个时间中，CPU 对于其他的工作来说就无法使用。 I&#x2F;O中断每次用户进程读取磁盘数据时，都需要 CPU 中断，然后发起 I&#x2F;O 请求等待数据读取和拷贝完成，每次的 I&#x2F;O 中断都导致 CPU 的上下文切换。 用户进程向 CPU 发起 read 系统调用读取数据，由用户态切换为内核态，然后一直阻塞等待数据的返回 CPU 在接收到指令以后对磁盘发起 I&#x2F;O 请求，将磁盘数据先放入磁盘控制器缓冲区 数据准备完成以后，磁盘向 CPU 发起 I&#x2F;O 中断 CPU 收到 I&#x2F;O 中断以后将磁盘缓冲区中的数据拷贝到内核缓冲区，然后再从内核缓冲区拷贝到用户缓冲区 用户进程由内核态切换回用户态，解除阻塞状态，然后等待 CPU 的下一个执行时间钟 DMA传输1、DMA （Direct Memory Access），是一种允许外围设备（硬件子系统）直接访问系统主内存的机制。也就是说，基于 DMA 访问方式，系统主内存于硬盘或网卡之间的数据传输可以绕开 CPU 的全程调度。目前大多数的硬件设备，包括磁盘控制器、网卡、显卡以及声卡等都支持 DMA 技术。 2、整个数据传输操作在一个 DMA 控制器的控制下进行的。CPU 除了在数据传输开始和结束时做一点处理外（开始和结束时候要做中断处理），在传输过程中 CPU 可以继续进行其他的工作。这样在大部分时间里，CPU 计算和 I&#x2F;O 操作都处于并行操作，使整个计算机系统的效率大大提高。 用户进程向 CPU 发起 read 系统调用读取数据，由用户态切换为内核态，然后一直阻塞等待数据的返回 CPU 在接收到指令以后对 DMA 磁盘控制器发起调度指令（CPU第一次操作） DMA 磁盘控制器对磁盘发起 I&#x2F;O 请求，将磁盘数据先放入磁盘控制器缓冲区，CPU 全程不参与此过程。 数据读取完成后，DMA 磁盘控制器会接受到磁盘的通知，将数据从磁盘控制器缓冲区拷贝到内核缓冲区。 DMA 磁盘控制器向 CPU 发出数据读完的信号，由 CPU 负责将数据从内核缓冲区拷贝到用户缓冲区（CPU第二次操作） 用户进程由内核态切换回用户态，解除阻塞状态，然后等待 CPU 的下一个执行时间钟 传统I&#x2F;O方式1、在 Linux 系统中，传统的访问方式是通过write()和read()两个系统调用实现的，通过read()函数读取文件到到缓存区中，然后通过write()方法把缓存中的数据输出到网络端口 2、传统 I&#x2F;O 操作的数据读写流程，整个过程涉及 2 次 CPU 拷贝、2 次 DMA 拷贝总共 4 次拷贝，以及 4 次上下文切换 3、传统读操作 当应用程序执行read系统调用读取一块数据的时候，如果这块数据已经存在于用户进程的页内存中，就直接从内存中读取数据；如果数据不存在，则先将数据从磁盘加载数据到内核空间的读缓存（read buffer）中，再从读缓存拷贝到用户进程的页内存中。 1read(file_fd, tmp_buf, len); 基于传统的 I&#x2F;O 读取方式，read 系统调用会触发 2 次上下文切换，1 次 DMA 拷贝和 1 次 CPU 拷贝，发起数据读取的流程如下： 用户进程通过 read() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space） CPU利用DMA控制器将数据从主存或硬盘拷贝到内核空间的读缓冲区 CPU将读缓冲区中的数据拷贝到用户空间的用户缓冲区 上下文从内核态（kernel space）切换回用户态（user space），read 调用执行返回 4、传统写操作 当应用程序准备好数据，执行 write 系统调用发送网络数据时，先将数据从用户空间的页缓存拷贝到内核空间的网络缓冲区（socket buffer）中，然后再将写缓存中的数据拷贝到网卡设备完成数据发送。 1write(socket_fd, tmp_buf, len); 基于传统的 I&#x2F;O 写入方式，write() 系统调用会触发 2 次上下文切换，1 次 CPU 拷贝和 1 次 DMA 拷贝，用户程序发送网络数据的流程如下： 用户进程通过 write() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space） CPU 将用户缓冲区（user buffer）中的数据拷贝到内核空间（kernel space）的网络缓冲区（socket buffer） CPU 利用 DMA 控制器将数据从网络缓冲区（socket buffer）拷贝到网卡进行数据传输 上下文从内核态（kernel space）切换回用户态（user space），write 系统调用执行返回 零拷贝在 Linux 中零拷贝技术主要有 3 个实现思路：用户态直接 I&#x2F;O、减少数据拷贝次数以及写时复制技术 用户态直接 I&#x2F;O：应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输。这种方式依旧存在用户空间和内核空间的上下文切换，硬件上的数据直接拷贝至了用户空间，不经过内核空间。因此，直接 I&#x2F;O 不存在内核空间缓冲区和用户空间缓冲区之间的数据拷贝。 减少数据拷贝次数：在数据传输过程中，避免数据在用户空间缓冲区和系统内核空间缓冲区之间的CPU拷贝，以及数据在系统内核空间内的CPU拷贝，这也是当前主流零拷贝技术的实现思路。 写时复制技术：写时复制指的是当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么将其拷贝到自己的进程地址空间中，如果只是数据读取操作则不需要进行拷贝操作。 用户态直接I&#x2F;O1、用户态直接 I&#x2F;O 使得应用进程或运行在用户态（user space）下的库函数直接访问硬件设备，数据直接跨过内核进行传输，内核在数据传输过程除了进行必要的虚拟存储配置工作之外，不参与任何其他工作，这种方式能够直接绕过内核，极大提高了性能。 2、使用场景：用户态直接 I&#x2F;O 只能适用于不需要内核缓冲区处理的应用程序，这些应用程序通常在进程地址空间有自己的数据缓存机制，称为自缓存应用程序，如数据库管理系统就是一个代表。 3、缺点：这种零拷贝机制会直接操作磁盘 I&#x2F;O，由于 CPU 和磁盘 I&#x2F;O 之间的执行时间差距，会造成大量资源的浪费 解决方案：配合异步 I&#x2F;O 使用。 减少数据拷贝次数：mmap + write1、使用 mmap + write 代替原来的 read + write 方式，减少了 1 次 CPU 拷贝操作 2、mmap方法： mmap 是 Linux 提供的一种内存映射文件方法，即将一个进程的地址空间中的一段虚拟地址映射到磁盘文件地址，mmap + write 的伪代码如下： 12tmp_buf = mmap(file_fd, len);write(socket_fd, tmp_buf, len); 3、使用 mmap 的目的 将内核中读缓冲区（read buffer）的地址与用户空间的缓冲区（user buffer）进行映射，从而实现内核缓冲区与应用程序内存的共享，省去了将数据从内核读缓冲区（read buffer）拷贝到用户缓冲区（user buffer）的过程，然而内核读缓冲区（read buffer）仍需将数据拷贝到内核写缓冲区（socket buffer） 4、过程 基于 mmap + write 系统调用的零拷贝方式，整个拷贝过程会发生 4 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝，用户程序读写数据的流程如下： 用户进程通过 mmap() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。 将用户进程的内核空间的读缓冲区（read buffer）与用户空间的缓存区（user buffer）进行内存地址映射。 CPU利用DMA控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）。 上下文从内核态（kernel space）切换回用户态（user space），mmap 系统调用执行返回。 用户进程通过write()函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。 CPU将读缓冲区（read buffer）中的数据拷贝到的网络缓冲区（socket buffer）。 CPU利用DMA控制器将数据从网络缓冲区（socket buffer）拷贝到网卡进行数据传输。 上下文从内核态（kernel space）切换回用户态（user space），write 系统调用执行返回。 5、mmap 主要的用处是提高 I&#x2F;O 性能，特别是针对大文件。对于小文件，内存映射文件反而会导致碎片空间的浪费，因为内存映射总是要对齐页边界，最小单位是 4 KB，一个 5 KB 的文件将会映射占用 8 KB 内存，也就会浪费 3 KB 内存。 6、mmap 的拷贝虽然减少了 1 次拷贝，提升了效率，但也存在一些隐藏的问题 当 mmap 一个文件时，如果这个文件被另一个进程所截获，那么 write 系统调用会因为访问非法地址被 SIGBUS 信号终止，SIGBUS 默认会杀死进程并产生一个 coredump，服务器可能因此被终止。 减少数据拷贝次数：sendfile1、目的是简化通过网络在两个通道之间进行的数据传输过程。sendfile 系统调用的引入，不仅减少了 CPU 拷贝的次数，还减少了上下文切换的次数，它的伪代码如下： 1sendfile(socket_fd, file_fd, len); 2、通过 sendfile 系统调用，数据可以直接在内核空间内部进行 I&#x2F;O 传输，从而省去了数据在用户空间和内核空间之间的来回拷贝。 3、与 mmap 内存映射方式不同的是， sendfile 调用中 I&#x2F;O 数据对用户空间是完全不可见的。也就是说，这是一次完全意义上的数据传输过程。 4、过程 基于 sendfile 系统调用的零拷贝方式，整个拷贝过程会发生 2 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝，用户程序读写数据的流程如下： 用户进程通过sendfile()函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。 CPU 利用 DMA 控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）。 CPU 将读缓冲区（read buffer）中的数据拷贝到的网络缓冲区（socket buffer）。 CPU 利用 DMA 控制器将数据从网络缓冲区（socket buffer）拷贝到网卡进行数据传输。 上下文从内核态（kernel space）切换回用户态（user space），sendfile 系统调用执行返回。 5、相比较于 mmap 内存映射的方式，sendfile 少了 2 次上下文切换，但是仍然有 1 次 CPU 拷贝操作。sendfile 存在的问题是用户程序不能对数据进行修改，而只是单纯地完成了一次数据传输过程。 减少数据拷贝次数：sendfile + DMA gather copy1、Linux 2.4 版本的内核对 sendfile 系统调用进行修改，为 DMA 拷贝引入了 gather 操作。 它将内核空间（kernel space）的读缓冲区（read buffer）中对应的数据描述信息（内存地址、地址偏移量）记录到相应的网络缓冲区（ socket buffer）中，由 DMA 根据内存地址、地址偏移量将数据批量地从读缓冲区（read buffer）拷贝到网卡设备中 这样就省去了内核空间中仅剩的 1 次 CPU 拷贝操作，sendfile 的伪代码如下： 1sendfile(socket_fd, file_fd, len); 2、在硬件的支持下，sendfile 拷贝方式不再从内核缓冲区的数据拷贝到 socket 缓冲区，取而代之的仅仅是缓冲区文件描述符和数据长度的拷贝，这样 DMA 引擎直接利用 gather 操作将页缓存中数据打包发送到网络中即可，本质就是和虚拟内存映射的思路类似。 3、过程 基于 sendfile + DMA gather copy 系统调用的零拷贝方式，整个拷贝过程会发生 2 次上下文切换、0 次 CPU 拷贝以及 2 次 DMA 拷贝，用户程序读写数据的流程如下： 用户进程通过 sendfile() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。 CPU 利用 DMA 控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）。 CPU 把读缓冲区（read buffer）的文件描述符（file descriptor）和数据长度拷贝到网络缓冲区（socket buffer）。 基于已拷贝的文件描述符（file descriptor）和数据长度，CPU 利用 DMA 控制器的 gather&#x2F;scatter 操作直接批量地将数据从内核的读缓冲区（read buffer）拷贝到网卡进行数据传输。 上下文从内核态（kernel space）切换回用户态（user space），sendfile 系统调用执行返回。 4、sendfile + DMA gather copy 拷贝方式同样存在用户程序不能对数据进行修改的问题，而且本身需要硬件的支持，它只适用于将数据从文件拷贝到 socket 套接字上的传输过程。 减少数据拷贝次数：splice1、sendfile 只适用于将数据从文件拷贝到 socket 套接字上，同时需要硬件的支持，这也限定了它的使用范围。Linux 在 2.6.17 版本引入 splice 系统调用，不仅不需要硬件支持，还实现了两个文件描述符之间的数据零拷贝。splice 的伪代码如下： 1splice(fd_in, off_in, fd_out, off_out, len, flags); 2、splice 系统调用可以在内核空间的读缓冲区（read buffer）和网络缓冲区（socket buffer）之间建立管道（pipeline），从而避免了两者之间的 CPU 拷贝操作。 3、过程 基于 splice 系统调用的零拷贝方式，整个拷贝过程会发生 2 次上下文切换，0 次 CPU 拷贝以及 2 次 DMA 拷贝，用户程序读写数据的流程如下： 用户进程通过 splice() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。 CPU 利用 DMA 控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）。 CPU 在内核空间的读缓冲区（read buffer）和网络缓冲区（socket buffer）之间建立管道（pipeline）。 CPU 利用 DMA 控制器将数据从网络缓冲区（socket buffer）拷贝到网卡进行数据传输。 上下文从内核态（kernel space）切换回用户态（user space），splice 系统调用执行返回。 4、splice 拷贝方式也同样存在用户程序不能对数据进行修改的问题。除此之外，它使用了 Linux 的管道缓冲机制，可以用于任意两个文件描述符中传输数据，但是它的两个文件描述符参数中有一个必须是管道设备。 总结无论是传统 I&#x2F;O 拷贝方式还是引入零拷贝的方式，2 次 DMA Copy 是都少不了的，因为两次 DMA 都是依赖硬件完成的。 下面从 CPU 拷贝次数、DMA 拷贝次数以及系统调用几个方面总结一下上述几种 I&#x2F;O 拷贝方式的差别 传统（read+write） 发起read DMA拷贝：拷贝到cpu内核空间的读缓冲区 cpu拷贝：内核空间读缓冲区拷贝到用户空间用户缓冲区 发起write cpu拷贝：用户缓冲区拷贝到网络缓冲区 DMA拷贝：DMA将数据从网络缓冲区拷贝到网卡 内存映射（mmap+write） 发起mmap 用户缓冲区和读缓冲区进行内存地址映射 DMA拷贝：DMA将数据拷贝到读缓冲区 发起write cpu拷贝：读缓冲区拷贝到网络缓冲区 DMA拷贝：DMA将数据从网络缓冲区拷贝到网卡 sendfile 发起sendfile DMA拷贝：将数据拷贝到读缓冲区 cpu拷贝：数据拷贝到网络缓冲区 DMA拷贝：DMA将数据从网络缓冲区拷贝到网卡 sendfile+DMA gather copy 发起sendfile DMA拷贝：将数据拷贝到读缓冲区 CPU 把读缓冲区（read buffer）的文件描述符（file descriptor）和数据长度拷贝到网络缓冲区（socket buffer） DMA拷贝：基于已拷贝的文件描述符和数据长度，CPU 利用 DMA 控制器的 gather&#x2F;scatter 操作直接批量地将数据从内核的读缓冲区（read buffer）拷贝到网卡进行数据传输 splice 发起splice DMA拷贝：将数据拷贝到读缓冲区 CPU 在内核空间的读缓冲区（read buffer）和网络缓冲区（socket buffer）之间建立管道（pipeline） DMA拷贝：将数据从网络缓冲区（socket buffer）拷贝到网卡进行数据传输 消息队列的零拷贝RocketMQ 选择了 mmap + write 这种零拷贝方式，适用于业务级消息这种小块文件的数据持久化和传输； Kafka 采用的是 sendfile 这种零拷贝方式，适用于系统日志消息这种高吞吐量的大块文件的数据持久化和传输。但是值得注意的一点是，Kafka 的索引文件使用的是 mmap + write 方式，数据文件使用的是 sendfile 方式。 进程间通信进程间通信管道模型1ps -ef | grep 关键字 | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9 这里面的竖线|就是一个管道。它会将前一个命令的输出，作为后一个命令的输入。 从管道的这个名称可以看出来，管道是一种单向传输数据的机制，它其实是一段缓存，里面的数据只能从一端写入，从另一端读出。如果想互相通信，我们需要创建两个管道才行。 1、管道的两种类型 匿名管道 没有名字，用完就销毁了 命名管道 需要通过mkfifo命令创建，管道以文件的形式存在，文件类型是p 12# hello是管道的名称mkfifo hello 写入字符串，输入完命令之后命令会停住，需要读取才能结束 1echo &quot;hello world&quot; &gt; hello 消息队列模型 消息队列是保存在内核中的消息链表，会涉及到用户态跟内核态到来回切换，双方约定好消息体到数据结构，然后发送数据时将数据分成一个个独立的数据单元消息体，需注意消息队列及单个消息都有上限。 共享内存模型现代操作系统对内存管理采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程A和进程B虚拟地址是一样的，真正访问的也是不同的物理内存地址 该模式不涉及到用户态跟内核态来回切换，JVM 就是用的共享内存模式。并且并发编程也是个难点。 信号量1、如果多个进程使用同一个共享内存就会产生冲突，所以需要一个保护机制；在System V IPC进程间通信机制体系中使用信号量，因此，信号量和共享内存需要配合使用 2、信号量其实是一个计数器，用于实现进程间的互斥和同步 P操作：申请资源，将信号量的数值减去N，表示资源被申请了，其他人不能使用 V操作：归还资源，将信号量加上M，表示归还资源，其他人可以使用 信号1、Linux提供了几十种信号，分别代表不同的意义，信号之间依靠他们的值来区分 2、信号可以在任何时候发送给某个进程，进程需要为信号配置信号处理函数 3、信号是进程间通信机制中唯一的异步通信机制，可以在任何时候发送信号给某个进程 kill -9 1412：表示pid为1412的进程发送SIGKILL信号，用来立即结束该进程 Ctrl+C：表示SIGINT信号，表示终止该进程 4、有信号发生时，进程一般有三种方式响应： 执行默认操作 捕捉信号 忽略信号 Socket1、跨网络与不同主机上的进程之间通信 2、可以指定IPV4、IPV6、TCP、UDP类型，比如TCP协议通信的Socket模型如下： 管道","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}]},{"title":"设计模式","slug":"设计模式","date":"2022-01-20T07:28:31.000Z","updated":"2022-02-07T12:56:54.514Z","comments":true,"path":"2022/01/20/设计模式/","link":"","permalink":"http://example.com/2022/01/20/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"1、创建者模式（5种） 单例模式 原型模式 工厂方法模式 抽象工厂模式 建造者模式 2、结构型模式（7种） 代理模式 适配器模式 桥接模式 装饰者模式 外观模式 享元模式 组合模式 3、行为型模式（11种） 模版方法模式 策略模式 命令模式 指责链模式 状态模式 观察者模式 中介者模式 迭代器模式 访问者模式 备忘录模式 解释器模式 创建者模式 关注点是怎样创建对象？主要特点是将对象的创建和使用分离 降低系统的耦合度，使用者不需要关注对象的创建细节 单例模式这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建，这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。 结构主要有两种角色： 单例类：只能创建一个实例的类 访问类：使用单例类 实现 分为两种： 饿汉式：类加载就会导致该单实例对象被创建 懒汉式：类加载不会导致该单实例对象被创建，首次使用才创建 1、饿汉式（静态变量方式） 1234567891011121314151617181920212223242526272829/** * 饿汉式：静态成员变量 */public class Singleton &#123; //1、私有构造方法 private Singleton()&#123;&#125; //2、在本类中创建本类对象 private static Singleton instance = new Singleton(); //3、提供一个公共的访问方式让外界获取该对象 public static Singleton getInstance()&#123; return instance; &#125;&#125;public class Client &#123; public static void main(String[] args) &#123; //创建Singleton对象 Singleton instance = Singleton.getInstance(); Singleton instance1 = Singleton.getInstance(); //判断是否是同一个对象 System.out.println(instance==instance1); &#125;&#125; 2、饿汉式（静态代码块） 1234567891011121314151617181920/** * 饿汉式：静态代码块 */public class Singleton &#123; //1、私有构造方法 private Singleton()&#123;&#125; //2、声明Singleton类型的变量 private static Singleton instance; //3、在静态代码块中赋值 static &#123; instance = new Singleton(); &#125; //4、提供获取对象的方法 public static Singleton getInstance()&#123; return instance; &#125;&#125; 3、懒汉式（方式1—线程不安全） 123456789101112131415161718/** * 懒汉式：线程不安全 */public class Singleton &#123; //1、私有构造方法 private Singleton()&#123;&#125; //2、声明Singleton类型的变量 private static Singleton instance; //3、对外提供访问方式 public static Singleton getInstance()&#123; if(instance==null)&#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 4、懒汉式（方式2—线程安全） 使用synchronized 123456789101112131415161718/** * 懒汉式：线程不安全 */public class Singleton &#123; //1、私有构造方法 private Singleton()&#123;&#125; //2、声明Singleton类型的变量 private static Singleton instance; //3、对外提供访问方式 public synchronized static Singleton getInstance()&#123; if(instance==null)&#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 5、懒汉式（方式3—双重检查锁） 对于getInstance方法来说，绝大部分是读操作，使用synchronized会有损性能，没必要让每个线程都要持有锁，需要调整加锁的时机，产生了一种新的实现模式—双重检查 123456789101112131415161718192021public class Singleton &#123; //1、私有构造方法 private Singleton()&#123;&#125; //2、声明Singleton类型的成员变量 private static Singleton instance; //3、对外提供公共的访问方式 public static Singleton getInstance()&#123; //第一次判断 if(instance==null)&#123; synchronized (Singleton.class)&#123; //第二次判断 if(instance==null)&#123; instance=new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 双重检查锁模式解决了单例、性能、线程安全问题，但是存在问题，在多线程的情况下，可能会存在空指针，因为JVM在实例化对象的时候会进行优化和指令重排序操作，要解决双重检查锁模式带来的空指针异常，需要使用Volatile关键字 123456789101112131415161718192021public class Singleton &#123; //1、私有构造方法 private Singleton()&#123;&#125; //2、声明Singleton类型的成员变量 private static volatile Singleton instance; //3、对外提供公共的访问方式 public static Singleton getInstance()&#123; //第一次判断 if(instance==null)&#123; synchronized (Singleton.class)&#123; //第二次判断 if(instance==null)&#123; instance=new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 6、懒汉式（方式4—静态内部类） 由于JVM加载外部类的过程中不会加载静态内部类，只有内部类的属性&#x2F;方法被调用才会被加载，并初始化其静态属性 1234567891011121314public class Singleton &#123; private Singleton()&#123;&#125; //定义一个静态内部类 private static class SingletonHolder&#123; //在内部类声明并初始化外部类对象 private static final Singleton INSTANCE = new Singleton(); &#125; //提供访问方式 public static Singleton getInstance()&#123; return SingletonHolder.INSTANCE; &#125;&#125; 7、枚举方式 因为枚举类型是线程安全的，并且只会装载一次，是唯一一种不会被破坏的单例实现模式 123public enum Singleton &#123; INSTANCE;&#125; 存在的问题可以使用序列化、反射破坏单例模式 解决问题1、序列化 在Singleton类中添加readResolve方法，在反序列化时被反射调用，如果定义了这个方法就返回这个方法的值，否则就返回new出来的对象 123public Object readResolve()&#123; return SingletonHolder.instance;&#125; 2、反射 12345678910private static boolean flag = false;private Singleton()&#123; synchronized (Singleton.class)&#123; if(flag)&#123; throw new RuntimeException(&quot;不能创建多个对象&quot;); &#125; flag=true; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"Java并发","slug":"Java并发","date":"2022-01-19T13:21:46.000Z","updated":"2022-02-07T14:02:53.574Z","comments":true,"path":"2022/01/19/Java并发/","link":"","permalink":"http://example.com/2022/01/19/Java%E5%B9%B6%E5%8F%91/","excerpt":"","text":"线程并发编程的挑战上下文切换1、即使是单核处理器也支持多线程，CPU通过给每一个线程分配CPU时间片来实现这个机制。 2、上下文切换：CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务；但是在切换前会保存上一个任务的状态，以便切换回这个任务。任务从保存到再次加载的过程就是一次上下文切换 3、减少上下文切换的方法： 无锁并发编程：使用一些方法避免使用锁 CAS算法：使用CAS算法更新数据，不需要加锁 使用最少线程和使用线程：避免创建不需要的线程 使用协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换 死锁避免死锁的几个方法： 避免一个线程同时获取多个锁 避免一个线程在锁内同时占用多个资源 使用lock.trylock()来替代使用内部锁机制 对于数据库锁，加锁和解锁在一个数据库连接里 线程、进程、并发、并行1、进程：进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。 一个进程可以包含多个线程，至少包含一个 Java默认有几个线程？2个线程：main线程、GC线程 2、线程：线程是一个比进程更小的执行单位 对于java：Thread、Runnable、Callable Java可以开启线程吗？不可以，调用本地方法start0()，底层的C++，Java无法直接操作硬件 12345678910111213141516171819public synchronized void start() &#123; if (threadStatus != 0) throw new IllegalThreadStateException(); group.add(this); boolean started = false; try &#123; start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; &#125; &#125; &#125; private native void start0(); 3、并发 同一时间段，多个任务都在执行 (单位时间内不一定同时执行)； CPU 一核 ，模拟出来多条线程，快速交替 本质：充分利用CPU的资源 4、并行 单位时间内，多个任务同时执行 CPU 多核，多个线程同时进行；线程池 12345public static void main(String[] args) &#123; //获取CPU的核数 //CPU密集型，IO密集型 System.out.println(Runtime.getRuntime().availableProcessors()); &#125; 多线程线程的状态 线程状态（6个）： New（新建） Runnable（可运行） Blocked（阻塞）：进入阻塞状态的唯一前提是在等待获取同步锁。 只有两种情况可以使线程进入阻塞状态：一是等待进入synchronized块或方法，另一个是在调用wait()方法后重新进入synchronized块或方法。 Wating（等待，死等） 进入方法： 没有设置TimeOut参数的Object.wait()方法 没有设置 Timeout 参数的 Thread.join() 方法 LockSupport.park() 方法 退出方法： Object.notify() &#x2F; Object.notifyAll()（wait） 被调用的线程执行完毕（join） Timed waiting（计时等待，超时等待） 进入方法： sleep方法 设置了TimeOut参数的wait方法 设置了 Timeout 参数的 Thread.join() 方法 退出方法： sleep：时间结束 wait：时间结束 &#x2F; Object.notify() &#x2F; Object.notifyAll() join：时间结束 &#x2F; 被调用的线程执行完毕 Terminated（终止） wait、notify源代码1234567public final void wait() throws InterruptedException &#123; wait(0);&#125;//本地方法public final native void wait(long timeout) throws InterruptedException;public final native void notify(); wait方法需要try-catch，因为需要抛出异常 是否释放锁 wait方法会释放锁 notify方法不会释放锁 123456789101112131415161718class data&#123; Object o = new Object(); public void w() throws InterruptedException &#123; synchronized (o)&#123; System.out.println(&quot;wait进入临界区&quot;); o.wait(); System.out.println(&quot;不会输出&quot;); &#125; &#125; public void n() throws InterruptedException &#123; synchronized (o)&#123; System.out.println(&quot;notify进入临界区&quot;); o.notify(); System.out.println(&quot;调用了 notify() ，这里仍然会进行输出&quot;); &#125; &#125;&#125; 输出： 1234wait进入临界区notify进入临界区调用了 notify() ，这里仍然会进行输出不会输出 说明了 wait() 会释放锁， notify() 不会释放锁 考虑使用 ConditionCondition是Java中一个替代 wait notify的一个库，他可以**解决过早唤醒的问题，并且解决了 wait()不能区分其返回是否是因为超时的问题** 为什么要放在同步代码块中wait方法是一个本地方法，它是通过一个monitor对象锁（管程）来实现的，只有拥有了该对象的监视器锁才能调用wait方法，那么怎么调用wait方法呢？ 3、是通过增加synchronized关键字来实现的，这也是为什么wait必须在synchronized修饰的代码中运行的原因。但只要调用了wait方法，monitor锁就会被马上释放掉。 过程当调用wait()方法后，线程会进入WAITING(等待状态)，后续被notify()后，并没有立即被执行，而是进入等待获取锁的阻塞队列。 对于每个对象来说，都有自己的等待队列和阻塞队列。以前面的生产者、消费者为例，我们拿obj对象作为对象锁，配合图示。内部流程如下 当线程A（消费者）调用wait()方法后，线程A让出锁，自己进入等待状态，同时加入锁对象的等待队列。 线程B（生产者）获取锁后，调用notify方法通知锁对象的等待队列，使得线程A从等待队列进入阻塞队列。 线程A进入阻塞队列后，直至线程B释放锁后，线程A竞争得到锁继续从wait()方法后执行。 wait()和sleep()的区别1、来自不同的类 wait：Object，必须由锁对象进行调用 sleep：Thread，静态方法 1public static native void sleep(long millis) throws InterruptedException; 2、关于锁的释放 wait：会释放锁 sleep：抱着锁睡觉，不会释放锁 3、使用的范围不同 wait：只能在同步代码块中，常被用于线程间交互&#x2F;通信 sleep：可以在任何地方睡，通常被用于暂停执行 4、线程的苏醒 wait：方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。 sleep： 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout) 超时后线程会自动苏醒。 5、方法属性 wait：实例方法 sleep：静态方法 Join方法等待这个线程死亡再执行其他线程，其他线程阻塞 1234567891011121314151617181920212223242526public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException(&quot;timeout value is negative&quot;); &#125; if (millis == 0) &#123; while (isAlive()) &#123; //在获得通知前该线程将一直等待 wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; //wait方法 wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125; 例子： 123456789public static void main(String[] args) throws InterruptedException &#123; c t1 = new c(&quot;1&quot;); c t2 = new c(&quot;2&quot;); t1.start(); //t1结束后t2执行 t1.join(); t2.start(); &#125; 线程使用方式有三种使用线程的方法: 实现 Runnable 接口 1234567891011public class MyRunnable implements Runnable &#123; public void run() &#123; // ... &#125;&#125;public static void main(String[] args) &#123; MyRunnable instance = new MyRunnable(); Thread thread = new Thread(instance); thread.start();&#125; 实现 Callable 接口 123456789101112public class MyCallable implements Callable&lt;Integer&gt; &#123; public Integer call() &#123; return 123; &#125;&#125;public static void main(String[] args) throws ExecutionException, InterruptedException &#123; MyCallable mc = new MyCallable(); FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(mc); Thread thread = new Thread(ft); thread.start(); System.out.println(ft.get());&#125; 继承 Thread 类 123456789public class MyThread extends Thread &#123; public void run() &#123; // ... &#125;&#125;public static void main(String[] args) &#123; MyThread mt = new MyThread(); mt.start();&#125; 线程是如何启动的 基本核心过程包括 Java 创建线程和启动 调用本地方法 start0() JVM 中 JVM_StartThread 的创建和启动 设置线程状态等待被唤醒 根据不同的OS启动线程并唤醒 最后回调 run() 方法启动 Java 线程 Java 层面 Thread 启动start() 方法123456789101112131415161718192021222324new Thread(() -&gt; &#123; // todo&#125;).start();// JDK 源码public synchronized void start() &#123; if (threadStatus != 0) throw new IllegalThreadStateException(); group.add(this); boolean started = false; try &#123; start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123;&#125; &#125;&#125; start() 是一个 synchronized 方法，但为了避免多次调用，在方法中会由线程状态判断。threadStatus != 0。 group.add(this)，是把当前线程加入到线程组，ThreadGroup。 start0()，是一个本地方法，通过 JNI 方式调用执行。这一步的操作才是启动线程的核心步骤。 start0() 本地方法123456789101112// 本地方法 start0private native void start0();// 注册本地方法public class Thread implements Runnable &#123; /* Make sure registerNatives is the first thing &lt;clinit&gt; does. */ private static native void registerNatives(); static &#123; registerNatives(); &#125; // ...&#125; start0()，是一个本地方法，用于启动线程。 registerNatives()，这个方法是用于注册线程执行过程中需要的一些本地方法，比如：start0、isAlive、yield、sleep、interrupt0等。 JVM 创建线程JVM 启动线程JVM 线程回调thread-&gt;run()[JavaThread::run()]123456// The first routine called by a new Java threadvoid JavaThread::run() &#123; // ... 初始化线程操作 thread_main_inner();&#125; os_linux.cpp 类中的 java_start 里的 thread-&gt;run()，最终调用的就是 thread.cpp 的 JavaThread::run() 方法。 这部分还需要继续往下看，thread_main_inner(); 方法。 thread_main_inner1234567891011121314151617void JavaThread::thread_main_inner() &#123; if (!this-&gt;has_pending_exception() &amp;&amp; !java_lang_Thread::is_stillborn(this-&gt;threadObj())) &#123; &#123; ResourceMark rm(this); this-&gt;set_native_thread_name(this-&gt;get_thread_name()); &#125; HandleMark hm(this); this-&gt;entry_point()(this, this); &#125; DTRACE_THREAD_PROBE(stop, this); this-&gt;exit(false); delete this;&#125; this-&gt;entry_point()，实际调用的就是 3.1 中的 thread_entry 方法。 thread_entry，方法最终会调用到 JavaCalls::call_virtual 里的vmSymbols::run_method_name()。也就是 run() 方法，至此线程启动完成。 基础线程机制ExecutorExecutor 管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。 主要有三种 Executor: CachedThreadPool: 一个任务创建一个线程； FixedThreadPool: 所有任务只能使用固定大小的线程； SingleThreadExecutor: 相当于大小为 1 的 FixedThreadPool。 Daemon守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。 当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。 main() 属于非守护线程。 使用 setDaemon() 方法将一个线程设置为守护线程。 sleep()Thread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒。 sleep() 可能会抛出 InterruptedException，因为异常不能跨线程传播回 main() 中，因此必须在本地进行处理。线程中抛出的其它异常也同样需要在本地进行处理 yield()对静态方法 Thread.yield() 的调用声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。 线程池线程池：三大方法、7大参数、4中拒绝策略 池化技术 程序的运行，本质：占有系统的资源；优化资源的使用&#x3D;》池化技术 线程池、连接池、内存池、对象池 1、池化技术：事先准备好一些资源，有人要用就来我这里拿，用完之后还给我 2、线程池的好处： 降低资源消耗 提高响应的速度 方便管理 线程复用、可以控制最大并发数、管理线程 三大方法Executors：工具类、3大方法 1234567891011121314151617181920212223public static void main(String[] args) throws InterruptedException &#123; //单个线程 ExecutorService threadPool = Executors.newSingleThreadExecutor(); //创建一个固定的线程池大小 ExecutorService threadPool2 = Executors.newFixedThreadPool(5); //可伸缩的 ExecutorService threadPool3 = Executors.newCachedThreadPool(); try&#123; //使用线程池创建线程 for(int i = 0;i&lt;10;i++)&#123; threadPool3.execute(()-&gt;&#123; System.out.println(Thread.currentThread().getName()); &#125;); &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; //关闭线程池 threadPool3.shutdown(); &#125; &#125; 7大参数123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 本质：ThreadPoolExecutor 12345678910111213141516171819202122232425public ThreadPoolExecutor(int corePoolSize,//核心线程池大小 int maximumPoolSize,//最大容纳的同时执行线程数量 long keepAliveTime,//超时了，没有人调用就会释放 TimeUnit unit,//超时单位 BlockingQueue&lt;Runnable&gt; workQueue,//阻塞队列 ThreadFactory threadFactory,//线程工厂，创建线程的，一般不动 RejectedExecutionHandler handler//拒绝策略 ) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; **银行案例：** 手动创建线程池： 123456789ExecutorService service = new ThreadPoolExecutor( 2, 5, 3, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(3), Executors.defaultThreadFactory(), //银行满了，还有人进来，不处理这个人，抛出异常 new ThreadPoolExecutor.AbortPolicy()); 最大承载：队列+max值 4种策略1、CallerRunsPolicy：哪来的去哪里，用main线程来处理，将任务退回 12345public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125;&#125; 2、AbortPolicy：不处理，抛出异常（默认） 12345public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException(&quot;Task &quot; + r.toString() + &quot; rejected from &quot; + e.toString()); &#125; 3、DiscardPolicy：队列满了，丢掉任务，不会抛出异常 12//什么也不做public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;&#125; 4、DiscardOldestPolicy：队列满了，尝试和最早的线程竞争 123456public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; e.getQueue().poll(); e.execute(r); &#125; &#125; 小结和拓展1、池的最大大小如何定义？ CPU密集型：几核，就是几，可以保持CPU效率最高 12//获取CPU核数System.out.println(Runtime.getRuntime().availableProcessors()); IO密集型：判断你的程序中十分耗IO的线程有多少个，大于这个数就可以了（一般两倍） 底层工作原理 callable接口1、与Runnable的区别： Runnable没有返回值，callable有返回值 run方法不会抛异常，call会抛异常 2、Callable接口代表一段可以调用并返回结果的代码; Future接口表示异步任务，是还没有完成的任务给出的未来结果。 所以说Callable用于产生结果，Future用于获取结果。 3、FutureTask 12public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt;public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; 123456789101112131415public class add&#123; public static void main(String[] args)&#123; FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(new MyThread()); Thread t1 = new Thread(futureTask,&quot;AA&quot;); t1.start(); &#125;&#125;class MyThread implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; System.out.println(&quot;1&quot;); return 1024; &#125;&#125; ThreadLocal概述ThreadLocal类用来提供线程内部的局部变量，不同线程之间不会相互干扰，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或组件之间一些公共变量传递的复杂度。 线程隔离 基本使用 12345678910111213141516171819202122public static void main(String[] args) throws ExecutionException, InterruptedException &#123; get g = new get(); for(int i=0;i&lt;5;i++)&#123; new Thread(()-&gt;&#123; g.setA(Thread.currentThread().getName()+&quot;set&quot;); System.out.println(Thread.currentThread().getName()+&quot;----&quot;+g.getA()); &#125;).start(); &#125;&#125;class get&#123; ThreadLocal&lt;String&gt; t = new ThreadLocal(); String a; public String getA() &#123; return t.get(); &#125; public void setA(String a) &#123; t.set(a); &#125;&#125; 输出： 12345Thread-0----Thread-0setThread-4----Thread-4setThread-3----Thread-3setThread-2----Thread-2setThread-1----Thread-1set 与synchronized的区别ThreadLocal和synchronized都是用来处理多线程并发访问变量的问题 1、synchronized 原理：以时间换空间，只提供了一个变量，让不同的线程排队访问 侧重点：多个线程之间访问资源的同步 2、ThreadLocal 原理：以空间换时间，每一个线程都有一份变量的副本，从而实现同时访问不干扰 侧重点：多线程中让每个线程直接的数据相互隔离 总结：在上述案例中虽然使用两者都可以解决问题，但是使用ThreadLocal会有更高的并发性 运用场景转账案例 内部结构在JDK8中，每个Thread维护一个ThreadLocalMap，这个Map的key是ThreadLocal本身，value是真正要存储的值Object 对比 JDK8的设计方案好处： 每个Map存储的Entry数量变少（之前Entry的数量是由Thread数量决定的，现在是由ThreadLocal数量决定的，尽量避免哈希冲突的发生） 当Thread销毁的时候，ThreadLocalMap也会销毁，减少内存的使用 核心方法源码set方法12345678910111213141516171819202122public void set(T value) &#123; //获取当前线程对象 Thread t = Thread.currentThread(); //获取当前线程对象中维护的ThreadLocalMap ThreadLocalMap map = getMap(t); //判断Map是否存在 if (map != null) //存在就调用map.set方法设置此实体Entry map.set(this, value); else //不存在就进行ThreadLocalMap的初始化 createMap(t, value);&#125;ThreadLocalMap getMap(Thread t) &#123; //Thread类：ThreadLocal.ThreadLocalMap threadLocals = null; return t.threadLocals;&#125;void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; get方法123456789101112131415161718192021222324252627public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; //情况1:map不存在 //情况2:map存在，但是不存在与当前ThreadLocal关联的entry return setInitialValue();&#125;private T setInitialValue() &#123; //调用initialValue获取初始化的值 T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; remove方法12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125; 流程： 获取当前线程，根据当前线程获取一个Map 获取的Map不为空就移除对应的entry initialValue方法123protected T initialValue() &#123; return null;&#125; 返回该线程局部变量的初始值 这个方法是一个延迟调用方法，set方法没有调用就调用了get方法才会执行，并且只执行一次 这个方法缺省值返回null 如果想要一个除null之外的初始值，可以重写此方法 ThreadLocalMap源码没有实现Map接口，内部的Entry也是独立实现的 成员变量12345678//初始容量，必须是2的次幂private static final int INITIAL_CAPACITY = 16;//存放数据的tableprivate Entry[] table;//数组里面entry的个数，用来判断是否超过阈值private int size = 0;//进行扩容的阈值private int threshold; // Default to 0 存储结构123456789//继承WeakReference，用ThreadLocal作为key，key是弱引用，目的是将ThreadLocal对象的生命周期和线程生命周期解绑static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 弱引用和内存泄漏1、内存泄露 Memory overflow：内存溢出，没有足够的内存供申请者使用 Memory leak：内存泄漏，已动态分配的堆内存因为某种原因无法释放，造成内存浪费 2、弱引用 Java的引用有4种类型：强、软、弱、虚 强引用：最常见的普通对象引用，垃圾回收器不会回收这种对象 弱引用：垃圾回收器一旦发现只具有弱引用的对象，不管内存是否足够，都会回收它的内存 3、如果key使用强引用 如果ThreadLocalMap的key使用强引用，会出现内存泄露吗？ 4、如果key使用弱引用 hash冲突的解决threadLocal的set方法 12345678910111213141516171819202122public void set(T value) &#123; //获取当前线程对象 Thread t = Thread.currentThread(); //获取当前线程对象中维护的ThreadLocalMap ThreadLocalMap map = getMap(t); //判断Map是否存在 if (map != null) //存在就调用map.set方法设置此实体Entry map.set(this, value); else //不存在就进行ThreadLocalMap的初始化 createMap(t, value);&#125;ThreadLocalMap getMap(Thread t) &#123; //Thread类：ThreadLocal.ThreadLocalMap threadLocals = null; return t.threadLocals;&#125;void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 首先获得当前线程，根据线程获取map 获取的map不为空，则调用threadlocalmap的set方法 获取的map为空，则调用threadlocalmap的构造方法 构造方法1234567891011ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; //默认容量16 table = new Entry[INITIAL_CAPACITY]; //计算索引 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); //设置值 table[i] = new Entry(firstKey, firstValue); size = 1; //设置阈值 setThreshold(INITIAL_CAPACITY);&#125; 阈值是初始容量的2&#x2F;3 1234567891011121314private final int threadLocalHashCode = nextHashCode();private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125;private static AtomicInteger nextHashCode = new AtomicInteger();//与斐波那契数列有关，尽量避免哈希冲突private static final int HASH_INCREMENT = 0x61c88647;//AtomicInteger的一个方法public final int getAndAdd(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta);&#125; set方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); //线性探测法 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; //获得key ThreadLocal&lt;?&gt; k = e.get(); //如果key存在且相同 if (k == key) &#123; //覆盖 e.value = value; return; &#125; //如果key是空的，value不为空，说明之前的对象已经被回收了 if (k == null) &#123; //替换，包括垃圾清理动作，防止内存泄漏 replaceStaleEntry(key, value, i); return; &#125; &#125; //如果没有遍历成功，就创建新值 tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125;private void rehash() &#123; expungeStaleEntries(); //如果size大于3/4的阈值，扩容 if (size &gt;= threshold - threshold / 4) resize();&#125;private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; //扩容两倍 int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; //遍历旧数组 for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; // Help the GC &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; setThreshold(newLen); size = count; table = newTab;&#125; 使用信息探测法解决哈希冲突： 该方法一次探测下一个地址，直到有空的地址后插入，如果整个空间都没有空余地址，则溢出 假设当前table为16，key计算出的hash值为14，如果位置上已经有值，并且key与当前key不一样，就发生了哈希冲突，这时候将14加1得到15，判断15的位置，如果有冲突就会回到0，以此类推，直到可以插入 Java内存模型Java内存模型硬件的效率和一致性1、高速缓存（Cache）：内存与CPU之间的缓冲，将运算所需要使用的数据复制到缓冲中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就不需要等待缓慢的内存读写了 引出了新的问题：缓存一致性，为了解决该问题，需要各个处理器访问缓存时遵循一些协议（MSI、MESI、MOSI等） 2、乱序执行优化：为了使处理器内部的运算单元能够被尽量充分利用，处理器可能会对输入代码进行乱序执行优化，处理器会在计算之后将乱序执行的结果重组，保证结果与顺序执行的结果一致，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致。因此，如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其顺序性不能靠代码的先后顺序保证。 Java虚拟机类似的操作：指令重排序优化 JMM1、JMM 即 Java Memory Model，它定义了主存、工作内存抽象概念，底层对应着CPU寄存器、缓存、硬件内存、CPU指令优化等 2、JMM的主要目的：定义程序中各种变量的访问规则，即关注在虚拟机中把变量存储到内存和从内存中取出变量值这样的底层细节 主内存与工作内存1、变量：实例字段、静态字段、构成数组对象的元素，不包含局部变量和方法参数（线程私有的，不会被共享） 2、主内存：存储所有的变量 与物理上的主内存对比？在物理上，这里的主内存只是虚拟机内存的一部分 3、工作内存：每个线程都有自己的工作内存 与高速缓存类比 保存了被该线程使用的变量的主内存副本 线程对变量的所有操作都在工作内存中进行，而不能直接读写主内存的数据 内存间交互操作主内存与工作内存之间的具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存这一类的实现细节 8个操作： 1、lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态 2、unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量可以被其他线程锁定 3、read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load操作 4、load（载入）：作用于工作内存的变量，它把read操作从主内存得到的变量值放入工作内存的变量副本中 5、use（使用）：作用于工作内存的变量，它把工作内存中的一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作 6、assign（赋值）：作用于工作内存的变量，它把执行引擎接受的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时将会执行这个操作 7、store（存储）：作用于工作内存的变量，它把工作内存中的一个变量的值传送到主内存中，以便随后的write操作使用 8、write（写入）：作用于主内存的变量，它把store操作从工作内存得到的变量值放到主内存的变量中 8个需要满足的规则： 1、不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者工作内存发起store，主内存不write的情况出现 2、不允许一个线程丢弃最近的assign操作，即变量在工作内存改变了之后必须把变化同步回主内存 3、不允许一个线程没有原因（没有assign操作）的把数据从工作内存同步回主内存 4、一个变量只能在主内存诞生，不允许在工作内存直接使用一个没有被初始化的变量，也就是说在对一个变量实施use、store之前必须执行assign和load 5、一个变量在同一时刻只运行一个线程lock 6、对一个变量执行lock，会清空工作内存此变量的值，在执行引擎使用这个变量前，需要重新load或者assign操作以初始化 7、unlock前必须lock 8、执行unlock前必须store、write 特性一：可见性问题 1234567891011private static int number = 0; public static void main(String[] args) throws InterruptedException &#123; new Thread(()-&gt;&#123; while (number==0)&#123; &#125; &#125;,&quot;t&quot;).start(); TimeUnit.SECONDS.sleep(1); number=1; System.out.println(number); &#125; 上面的程序存在一个问题：线程t不会停下来 为什么呢？分析一下： 1、初始状态，t线程刚开始从主内存读取了number的值到工作内存 2、因为t线程要频繁从主内存中读取number的值，JIT编译器会将number的值缓存至自己的工作内存中的高速缓存中，减少对run的访问，提高效率 3、1s之后，main线程更改了number的值，并同步回主内存，而t是从自己的工作内存中的高速缓存中读取这个变量的值，结果永远是旧值 解决：Volatile关键字为了解决上面的这个问题，就需要把变量声明为Volatile 修饰成员变量和静态成员变量 指示JVM这个变量是共享的且不稳定的，每次使用它都要去主存中读取 1private volatile static int number = 0; 当然，也可以使用synchronized解决这个问题： 123456789101112131415private static int number = 0;final static Object lock = new Object();public static void main(String[] args) throws InterruptedException &#123; new Thread(()-&gt;&#123; synchronized(lock)&#123; while (number==0)&#123; &#125; &#125; &#125;,&quot;t&quot;).start(); TimeUnit.SECONDS.sleep(1); number=1; System.out.println(number);&#125; 特性二：原子性什么是原子性？ 不可分割，完整性，也即某个线程正在做具体业务时，中间不可以被分割或者加塞，需要整体完整 要么同时成功，要么同时失败 特性三：有序性VolatileVolatile是JVM提供的轻量级同步机制 保证可见性1、可见性：当一个线程修改了这个变量的值，新值对于其他线程都是立即可知的 1234567891011private volatile static int number = 0;public static void main(String[] args) throws InterruptedException &#123; new Thread(()-&gt;&#123; while (number==0)&#123; &#125; &#125;,&quot;t&quot;).start(); TimeUnit.SECONDS.sleep(1); number=1; System.out.println(number);&#125; 3、如何保证可见性的？ Java代码： 1instance = new Singlenton(); //instance是volatile变量 转为汇编代码，如下： 120x01a3deld: movd $0x0,0x1104800(%esi);0x01a3de24:lock add1 $0x0,(%esp); 对volatile变量修饰的共享变量进行写操作时会多出第二行汇编代码，lock前缀的指令在多核处理器下会引发两件事情： 将当前处理器缓存行的数据写回系统内存 这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效 不保证原子性 有人说：“volatile变量对所有线程是立即可见的，对volatile变量所有的写操作都能够立即反映到其他线程之中。也就是说volatile变量的运算在并发下是线程安全的” 事实上，volatile变量在各个线程的工作内存中是不存在一致性问题的，但是Java的运算操作符是非原子操作，这导致volatile变量的运算在并发下一样是不安全的 对Voliate变量的单次读写是可以保证原子性的，如long和double类型变量，但是不能保证自增自减这种操作，因为本质上是读、写两次操作 也就是说，volatile是不保证原子性的！！ 案例演示123456789101112131415161718192021private volatile static int number = 0;public static void test_add()&#123; number++;&#125;public static void main(String[] args) throws InterruptedException &#123; //20个线程 for(int i=0;i&lt;20;i++)&#123; new Thread(()-&gt;&#123; for(int j=0;j&lt;1000;j++)&#123; test_add(); &#125; &#125;).start(); &#125; //需要等待上面20个线程都计算完成后再用main线程取得最后的结果 //如果线程数量大于2，说明上面20个线程没有计算完 while (Thread.activeCount()&gt;2)&#123; Thread.yield(); &#125; System.out.println(Thread.currentThread().getName()+number);&#125; 输出结果： 1main19325 原理number++被拆分成3个指令 执行GETFIELD：拿到主内存中的原始值number 执行IADD：进行加1操作 执行PUTFIELD：把工作内存中的值写回主内存中 当多个线程并发执行PUTFIELD指令的时候，会出现写回主内存覆盖问题，所以才会导致最终结果不为20000，volatile不能保证原子性。 解决 加Synchronized或者lock 使用原子类保证原子性 12345private volatile static AtomicInteger number = new AtomicInteger(0);public static void test_add()&#123; number.getAndIncrement();&#125; 禁止指令重排1、重排序分类 计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令进行重排，分为以下三种： 编译器优化的重排序：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序 指令级并行的重排序：现代处理器采用了指令级并行技术（ILP）将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序 内存系统的重排序：由于处理器使用缓存和读&#x2F;写缓冲区，这使得加载和存储操作看上去是在乱序执行 第一个属于编译器重排序，第二个和第三个属于处理器重排序 对于处理器重排序，JMM的处理器重排序会要求java编译器在生成指令序列时，插入特定类型的内存屏障指令，通过内存屏障指令来禁止特定类型的处理器重排序 2、分析 单线程环境下，确保程序最终执行结果和代码顺序执行的结果一致 处理器在进行重排序要考虑指令之间的数据依赖性 多线程环境下，线程交替执行，由于编译器重排的存在，两个线程使用的变量能否保证一致性是无法确定的，结果无法预测 数据依赖性 如果两个操作访问同一个变量，且两个操作中有一个写操作，此时两个操作存在数据依赖性，分为三个类型 写后读 12a=1b=a 写后写 12a=1;a=2; 读后写 12a=b;b=1; 以上三种情况，只要进行重排序，结果就会发生改变 编译器和处理器在重排序时，会遵守数据依赖性 as-if-serial语义1、as-if-serial语义：不管怎么重排序，单线程程序的执行结果不能被改变；编译器、runtime和处理器都必须尊重as-if-serial语义。 2、为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果 happens-before语义先行发生原则，JMM 定义的两项操作间的偏序关系，是判断数据是否存在竞争的重要手段。 JMM 将 happens-before 要求禁止的重排序按是否会改变程序执行结果分为两类。对于会改变结果的重排序 JMM 要求编译器和处理器必须禁止，对于不会改变结果的重排序，JMM 不做要求。 JMM 存在一些天然的 happens-before 关系，无需任何同步器协助就已经存在。如果两个操作的关系不在此列，并且无法从这些规则推导出来，它们就没有顺序性保障，虚拟机可以对它们随意进行重排序。 程序次序规则：一个线程内写在前面的操作先行发生于后面的。 管程锁定规则： unlock 操作先行发生于后面对同一个锁的 lock 操作。 volatile 规则：对 volatile 变量的写操作先行发生于后面的读操作。 线程启动规则：线程的 start 方法先行发生于线程的每个动作。 线程终止规则：线程中所有操作先行发生于对线程的终止检测。 对象终结规则：对象的初始化先行发生于 finalize 方法。 传递性：如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C 。 区别as-if-serial 保证单线程程序的执行结果不变，happens-before 保证正确同步的多线程程序的执行结果不变。 这两种语义的目的都是为了在不改变程序执行结果的前提下尽可能提高程序执行并行度。 1、内存屏障（Memory Barriers） 又称为内存栅栏，是一个CPU指令 作用： 保证特定操作的执行顺序 强制刷出各种CPU的缓存数据，保证某些变量的内存可见性（利用这个特性实现volatile的内存可见性） 编译器和处理器会对指令进行重排序，JMM 为了保证在不同的编译器和 CPU 上有相同的结果，通过插入特定类型的内存屏障禁止在内存屏障前后的指令执行重排序优化，插入一条内存屏障会告诉编译器和 CPU：不管什么指令都不能和这条 Memory Barrier 指令重排序。 对Voliate变量进行写操作时，会在写操作后加入一条store屏障指令，将工作内存中的共享变量值刷新回主内存 对Voliate变量进行读操作时，会在读操作前加入一条load屏障指令，从主内存中读取共享变量 你在哪里用过Volatile？单例模式DCL代码共6种 DCL机制不一定线程安全，因为有指令重排序的存在，加入volatile可以禁止指令重排 原因：某一个线程执行到第一次检测，读取到instance不为null时，instance的引用对象可能没有完成初始化。 instance = new add();分为3步完成： 123456//1、分配对象内存空间memory = add();//2、初始化对象instance(memory)；//3、设置instance指向刚分配的内存地址instance = memory; 步骤2和步骤3不存在数据依赖关系，而且无论重排前还是重排后程序的执行结果在单线程没有改变 因此，这种重排优化是允许的 123456//1、分配对象内存空间memory = add();//3、设置instance指向刚分配的内存地址 但是对象还没有初始化完成！instance = memory;//2、初始化对象instance(memory)； 1234567891011121314151617181920212223242526public class add&#123; private static volatile add instance = null; private add()&#123; System.out.println(Thread.currentThread().getName()+&quot;\\t构造方法&quot;); &#125; //DCL(双重检查) public static add getInstance()&#123; if(instance==null)&#123; synchronized (add.class)&#123; if(instance==null)&#123; instance = new add(); &#125; &#125; &#125; return instance; &#125; public static void main(String[] args)&#123; //并发多线程 for (int i =0;i&lt;10;i++)&#123; new Thread(()-&gt;&#123; add.getInstance(); &#125;).start(); &#125; &#125;&#125; 锁synchronized锁阻塞式的解决方案：synchronized、Lock 非阻塞式的解决方案：原子变量 语法： 123synchronized(对象)&#123; 临界区&#125; 1、因此，synchronized是用对象锁保证了临界区内代码的原子性，临界区内的代码对外是不可分割的，不会被其他线程打断 2、保证可见性的原理：执行synchronized时，会对应lock原子操作，会刷新工作内存中共享变量的值 3、有序性：依然会发生重排序，但是可以保证只有一个线程在同步代码块 三种使用方式 修饰代码块 ：指定加锁对象，对给定对象&#x2F;类加锁。synchronized(this object) 表示进入同步代码库前要获得给定对象的锁。synchronized(类.class) 表示进入同步代码前要获得当前class的锁 123456Object o = new Object();public void test()&#123; synchronized(o)&#123; 临界区 &#125;&#125; 修饰实例方法: 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁 1234// 相当于以下代码synchronized(this)&#123; 临界区&#125; 修饰静态方法: 也就是给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得当前class 的锁。 123456// 相当于以下代码class test&#123; synchronized(test.class)&#123; 临界区 &#125;&#125; 八锁问题关于锁的8个问题： 1、标准情况下，两个线程都打印输出（中间sleep 1s），哪个先打印？ 第一个线程先打印，因为锁的存在，两个方法用的是同一个锁，谁先拿到谁执行 2、第一个线程的锁方法延迟4s，哪个先？ 第一个线程先打印 3、增加一个普通方法后，先执行普通方法还是锁方法（sleep 4s）？ 先执行普通方法，不受锁的影响 4、两个对象，先打印哪个？ 先打印没有延迟的那个 5、两个静态的同步方法，一个对象，先打印哪一个？ 先打印第一个线程 6、两个静态的同步方法，两个对象，先打印哪一个？ 先打印第一个线程，static锁的是class，class全局唯一 7、一个静态同步方法（有延迟），一个普通同步方法，一个对象，先打印哪一个？ 先打印普通同步方法，两个方法锁的不是一个（一个是class，一个是对象） 8、一个静态同步方法（有延迟），一个普通同步方法，两个对象，先打印哪一个？ 先打印普通同步方法，两个方法锁的不是一个（一个是class，一个是对象） 小结： new：this 具体的一个对象 static：class 唯一的模版 线程安全问题成员变量和静态变量是否线程安全？1、如果没有被共享，则线程安全 2、如果被共享了，根据它们的状态能否被改变，又分两种情况： 如果只有读操作：线程安全 如果有读写操作，则这段代码是临界区，需要考虑线程安全 局部变量是否线程安全？1、局部变量是线程安全的 2、局部变量引用的对象不一定线程安全： 如果该对象没有逃离方法的作用范围，它是线程安全的 如果该对象逃离方法的作用范围，需要考虑线程安全 局部变量线程安全分析1234public static void test1()&#123; int i=0; i++;&#125; 每个线程调用test1方法时局部变量i，会在每个线程的栈帧内存中被创建多份，因此不存在共享 如图： 局部变量的引用稍有不同： 123456789101112131415class test1&#123; public void method1(int num)&#123; ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); for(int i=0;i&lt;num;i++)&#123; method2(list); method3(list); &#125;&#125; private void method2(ArrayList&lt;String&gt; list)&#123; list.add(&quot;1&quot;); &#125; private void method3(ArrayList&lt;String&gt; list)&#123; list.remove(0); &#125;&#125; 同样不存在共享，各不干扰 如果将method改为public，出现以下情况： 12345678class test2 extends test1&#123; @Override public void method3(ArrayList&lt;String&gt; list)&#123; new Thread(()-&gt;&#123; list.remove(0); &#125;).start(); &#125;&#125; 这样，两个线程就会访问一个对象，会出现线程安全问题 因此，使用private或者final提供了安全 常见线程安全类 String Integer等包装类 StringBuffer Random Vector Hashtable java.util.concurrent包下的类 线程安全是指：多个线程调用它们的同一个实例的某个方法时，是线程安全的。 1234567891011Hashtable a = new Hashtable();new Thread(()-&gt;&#123; a.put(1,2)&#125;).start();new Thread(()-&gt;&#123; a.put(1,2)&#125;).start();public synchronized V put(K key, V value) &#123;&#125; 也可以说： 它们的每一个方法是原子的 但注意：它们多个方法的组合不是原子的 线程安全类方法的组合分析下面这个代码： 12345Hashtable a = new Hashtable();//线程1，线程2if(a.get(&quot;key&quot;)==null)&#123; a.put(&quot;key&quot;,value);&#125; 不可变类线程安全性String、Integer等都是不可变类，因为其内部的状态不可改变，因此是线程安全的 实例分析 map：不是线程安全的 s1：线程安全 s2：线程安全 D1：不是线程安全的 D2：不是线程安全的 userService：不是线程安全的，多个线程共享使用 count：不是线程安全的，共享资源 特性可重入一个线程可以多次执行synchronized，重复获取一把锁 原理：synchronized的锁对象中有一个计数器（recursions变量），会记录线程获得几次锁，在执行完同步代码块时，计数器的数量会减1，计数器数量为0就释放锁 好处：可以避免死锁、可以让我们更好的封装代码 不可中断一个线程获得锁后另外一个线程想要获得锁必须处于阻塞或者等待状态，如果第一个线程不释放锁，第二个线程会一直阻塞或等待，不可被中断。 synchronized属于不可被中断 Lock的lock方法不可被中断，trylock方法可中断的 Monitor原理同步代码块底层原理 对应的字节码： monitorenter 指令 monitor才是真正的锁，JVM会创建一个monitor C++对象 两个成员变量 owner：拥有锁的线程 recursions：记录获取锁的次数（允许重入），为0释放锁 monitorexit 指令 能执行这个指令的一定是拥有当前对象锁的线程 为什么会有两个monitorexit？ 出现异常会走第二个monitorexit，释放锁 同步方法底层原理同步方法在反汇编后，会增加ACC_SYNCHRONIZED修饰，隐式调用monitorenter和monitorexit，执行前调用monitorenter，执行后调用monitorexit synchronized和lock的区别1、synchronized是关键字，lock是一个接口（接口有相应的实现类） 2、synchronized会自动释放锁，lock需要手动释放锁 3、synchronized是不可中断的，lock可以中断（trylock方法）可以不中断（lock方法） 4、lock可以知道线程有没有拿到锁（trylock），synchronized不可以 5、lock可以提高读的效率（读写锁） 6、synchronized是非公平锁，lock可以控制公平还是非公平 深入JVM源代码monitor监视器锁 waitSet：处于wait状态的线程 _cxq：多个线程竞争锁的单向链表（保存没有抢到锁的线程） entrylist：上一次在cxq等待没有抢到锁的线程 monitor竞争monitorenter 对于重量级锁，会调用slow_enter 最终调用ObjectMonitor::enter，如下： 流程如下： 通过CAS把monitor设置为当前线程 如果设置之前的owner指向当前线程，说明线程重入，执行recursions++ 如果第一次进入monitor，设置recursions为1，onwer为当前线程，该线程成功获得锁并返回 如果获取锁失败，则等待锁的释放 monitor等待 流程： 当前线程封装，状态设置为TS_CXQ 在for循环中，通过CAS把节点push到_cxq中，同一时刻可能有多个线程把自己的节点push到 _cxq列表中 进入cxq中之后，尝试自旋获取锁，如果还没有获取就挂起，等待被唤醒 当该线程被唤醒时，会从刮起的点继续执行，使用trylock尝试获取锁 monitor释放1、推出同步代码块会让recursions减1，减为0说明线程释放了锁 2、根据不同的策略，唤醒cxq或者entrylist中的线程 monitor是重量级锁因为用户态和内核态的切换会消耗大量的系统资源 linux操作系统的体系架构分为：用户空间和内核 内核：本质上可以理解为一种软件，控制计算机的硬件资源，并提供上层应用程序运行的环境 用户空间：上层应用程序活动的空间，必须依托内核提供的资源 系统调用：为了使上层应用能够访问到这些资源，内核必须为上层应用提供访问的接口，即系统调用 所有进程初始都运行于用户空间，此时为用户态 当调用系统调用执行某些操作时，例如I&#x2F;O调用，此时需要内核，就称为进程处于内核运行态 JDK6 synchronized优化CAS作用：将比较和交换转换为原子操作，这个原子操作由CPU保证，依赖于三个值：内存中的值V、旧的预估值X，要修改的新值B Unsafe类：Unsafe对象不能直接调用，只能通过反射获得 这是一种完全依赖于硬件的功能，通过它实现了原子操作。原语的执行时连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，不会造成数据不一致。 锁升级过程无锁–》偏向锁–〉轻量级锁–》重量级锁 Java对象布局JVM中，对象在内存中的布局分为三块区域：对象头、实例数据、对齐填充 普通对象头 数组对象头 其中，Mark Word的结构为： 偏向锁第三位是1 klass Word 偏向锁锁会偏向于第一个获得它的线程，会在对象头存储偏向锁的线程ID，以后该线程进入和退出同步块只需要检查是否是偏向锁、锁标志位、ThreadID即可 一旦出现多个线程竞争就必须撤销偏向锁，所以撤销偏向锁消耗的性能必须小于之前节省的CAS原子操作的性能 原理：当锁对象第一次被线程获取，虚拟机会把对象头中的标志位设为01，即偏向模式，同时使用CAS操作把获取的这个线程ID记录在对象头中，如果CAS操作成功，以后这个线程进入和这个锁相关的同步块时，虚拟机不需要进行任何操作 轻量级锁目的：在多线程交替执行同步块的情况下，尽量避免重量级锁引起的性能消耗，但是如果多个线程在同一时刻进入临界区，会导致轻量级锁膨胀升级重量级锁 原理栈帧：一个进入栈的方法 关闭了偏向锁或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁，则为尝试获取轻量级锁，步骤如下： 轻量级锁是为了在没有竞争的前提下减少重量级锁使用操作系统互斥量产生的性能消耗。 在代码即将进入同步块时，如果同步对象没有被锁定，虚拟机将在当前线程的栈帧中建立一个锁记录空间，存储锁对象目前 Mark Word 的拷贝。然后虚拟机使用 CAS 尝试把对象的 Mark Word 更新为指向锁记录的指针，如果更新成功即代表该线程拥有了锁，锁标志位将转变为 00，表示处于轻量级锁定状态。 如果更新失败就意味着至少存在一条线程与当前线程竞争。虚拟机检查对象的 Mark Word 是否指向当前线程的栈帧，如果是则说明当前线程已经拥有了锁，直接进入同步块继续执行，否则说明锁对象已经被其他线程抢占。如果出现两条以上线程争用同一个锁，轻量级锁就不再有效，将膨胀为重量级锁，锁标志状态变为 10，此时Mark Word 存储的就是指向重量级锁的指针，后面等待锁的线程也必须阻塞。 解锁同样通过 CAS 进行，如果对象 Mark Word 仍然指向线程的锁记录，就用 CAS 把对象当前的 Mark Word 和线程复制的 Mark Word 替换回来。假如替换成功同步过程就顺利完成了，如果失败则说明有其他线程尝试过获取该锁，就要在释放锁的同时唤醒被挂起的线程。 自旋锁因为执行同步代码块的时间是比较短的，但是第二个线程获取不到锁会立刻阻塞，这是不划算的，为了让线程等待，只需要让这个线程执行自旋，就实现了自旋锁 自旋锁在 JDK1.4 就已引入，默认关闭，在 JDK6 中改为默认开启。 自旋不能代替阻塞，虽然避免了线程切换开销，但要占用处理器时间，如果锁被占用的时间很短，自旋的效果就会非常好，反之只会白白消耗处理器资源。如果自旋超过了限定的次数仍然没有成功获得锁，就应挂起线程，自旋默认限定次数是 10。 适应性自旋锁JDK6 对自旋锁进行了优化，自旋时间不再固定，而是由前一次的自旋时间及锁拥有者的状态决定。 如果在同一个锁上，自旋刚刚成功获得过锁且持有锁的线程正在运行，虚拟机会认为这次自旋也很可能成功，进而允许自旋持续更久。如果自旋很少成功，以后获取锁时将可能直接省略掉自旋，避免浪费处理器资源。 有了自适应自旋，随着程序运行时间的增长，虚拟机对程序锁的状况预测就会越来越精准。 锁消除锁消除指即时编译器对检测到不可能存在共享数据竞争的锁进行消除。 主要判定依据来源于逃逸分析，如果判断一段代码中堆上的所有数据都只被一个线程访问，就可以当作栈上的数据对待，认为它们是线程私有的而无须同步。 锁粗化原则需要将同步块的作用范围限制得尽量小，只在共享数据的实际作用域中进行同步，这是为了使等待锁的线程尽快拿到锁。 但如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体之外的，即使没有线程竞争也会导致不必要的性能消耗。因此如果虚拟机探测到有一串零碎的操作都对同一个对象加锁，将会把同步的范围扩展到整个操作序列的外部。 Lock锁1、格式： 123456789Lock l = ...;//加锁l.lock();try &#123; // access the resource protected by this lock&#125; finally &#123; //解锁 l.unlock();&#125; 2、实现类： ReentrantLock：可重入锁 ReentrantReadWriteLock.ReadLock ReentrantReadWriteLock.WriteLock 3、ReentrantLock 构造方法： 123456public ReentrantLock() &#123; sync = new NonfairSync();&#125;public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 公平锁：十分公平，先来后到 非公平锁：不公平，可以插队（默认） 例子： 12345678910111213141516171819class ticket&#123; private int number = 30; //创建锁 Lock lock = new ReentrantLock(); public void sale()&#123; //加锁 lock.lock(); //尝试获取锁 lock.tryLock(); try&#123; ..... &#125;catch(Exception e)&#123; &#125;finally&#123; //解锁 lock.unlock(); &#125; &#125;&#125; Synchronized和Lock区别1、原始构成 Synchronized 是内置的Java关键字，属于JVM层面，底层通过monitor对象完成，其实wait&#x2F;notify也依赖于monitor对象 Lock 是一个Java类，是api层面的锁 2、Synchronized 无法判断获取锁的状态，Lock 可以判断是否取到了锁 3、Synchronized 会自动释放锁，Lock 必须要手动释放锁（不释放会死锁） 4、Synchronized 线程1（获得锁，阻塞）线程2（等待）；Lock锁不一定会等待下去，线程可以不用一直等待就结束了； 5、Synchronized 可重入锁，不可以中断的，非公平的；Lock 可重入锁，可以判断锁，可以自己设置公不公平 6、Synchronized 适合锁少量的代码同步问题，Lock适合大量的代码块同步 ReentrantLock聚合关系总结: ReentrantLock实现了Lock,Serializable接口 ReentrantLock.Sync(内部类)继承了AQS ReentrantLock.NonfairSync和ReentrantLock.FairSync继承了ReentrantLock.Sync ReentrantLock持有ReentrantLock.Sync对象(实现锁功能) 锁实现总结: 由Node节点组成一条同步队列(有head,tail两个指针,并且head初始化时指向空节点) int state标记锁使用数量(独占锁时,通常为1,发生重入时&gt;1) lock()时加到队列尾部 unlock()时,释放head节点,并指向下一个节点head&#x3D;head.next,然后唤醒当前head节点 构造方法123456789//默认非公平锁public ReentrantLock() &#123; sync = new NonfairSync();&#125;//设置为公平锁public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; lock方法123456public void lock() &#123; sync.lock();&#125;//sync内部类abstract void lock(); 分为公平锁、非公平锁 unlock方法123public void unlock() &#123; sync.release(1);&#125; tryLock方法123public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125; 各种类型的锁公平锁和非公平锁1、基本概念 公平锁：多个线程按照申请锁的顺序获取锁，先来后到 非公平锁：多个线程获取锁的顺序不是按照申请锁的顺序，有可能会优先获取锁，有可能造成优先级反转或者饥饿现象 2、区别 ReentrantLock默认是非公平锁 公平锁就是很公平，每个线程在获取锁的时候会查看此锁维护的等待队列，如果为空或者当前线程是等待队列的第一个就占有锁，否则加入等待队列中 非公平锁直接尝试占有锁，如果尝试失败就采用类似公平锁的方式 可重入锁（递归锁）1、概念 指同一线程外层函数获得锁之后，内层递归函数仍然可以获取该锁的代码，在同一线程在外层方法获取锁的时候，在进入内层方法会自动获取锁 也就是说，线程可以进入任何一个它已经拥有的锁所同步的代码块 作用：防止死锁 2、ReentrantLock和Synchronized就是典型的可重入锁 Synchronized123456789101112131415161718192021222324public class hellotest &#123; public static void main(String[] args) throws Exception&#123; Phone p = new Phone(); new Thread(()-&gt;&#123; try &#123; p.sendSMS(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125;class Phone&#123; //外层 public synchronized void sendSMS()throws Exception&#123; System.out.println(Thread.currentThread().getName()+&quot;\\t invoked sendSMS()&quot;); senEmail(); &#125; //内层 public synchronized void senEmail()&#123; System.out.println(Thread.currentThread().getName()+&quot;\\t invoked sendEmail()&quot;); &#125;&#125; 输出： 12Thread-0 invoked sendSMS()Thread-0 invoked sendEmail() ReentrantLock123456789101112131415161718192021222324252627282930313233343536373839404142434445public class hellotest &#123; public static void main(String[] args) throws Exception&#123; Phone p = new Phone(); new Thread(()-&gt;&#123; try &#123; p.sendSMS(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;).start(); new Thread(()-&gt;&#123; try &#123; p.sendSMS(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125;class Phone&#123; Lock lock = new ReentrantLock(); public void sendSMS()throws Exception&#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName()+&quot;\\t invoked sendSMS()&quot;); senEmail(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; public void senEmail()&#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName()+&quot;\\t invoked sendEmail()&quot;); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125;&#125; 输出： 1234Thread-0 invoked sendSMS()Thread-0 invoked sendEmail()Thread-1 invoked sendSMS()Thread-1 invoked sendEmail() 区别1、都是可重入锁 “可重入锁” 指的是自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增 1，所以要等到锁的计数器下降为 0 时才能释放锁。 2、synchronized依赖于JVM，ReentrantLock依赖于API synchronized 是依赖于 JVM 实现的， JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。 ReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try&#x2F;finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。 3、ReentrantLock比synchronized增加了一些高级功能 相比synchronized，ReentrantLock增加了一些高级功能，主要来说主要有三点： 等待可中断 : ReentrantLock提供了一种能够中断等待锁的线程的机制，通过 lock.lockInterruptibly() 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。 可实现公平锁 : ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。 可实现选择性通知（锁可以绑定多个条件）: synchronized关键字与wait()和notify()&#x2F;notifyAll()方法相结合可以实现等待&#x2F;通知机制。ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition()方法。 自旋锁尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁 好处：减少线程上下文切换的损耗，不用阻塞 缺点：如果长时间无法获得，性能下降 自己写一个自旋锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class hellotest &#123; //原子引用线程 AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference(); public void myLock()&#123; Thread thread = Thread.currentThread(); System.out.println(Thread.currentThread().getName()+&quot;\\t come in&quot;); while (!atomicReference.compareAndSet(null,thread))&#123; &#125; System.out.println(Thread.currentThread().getName()+&quot;\\t lock&quot;); &#125; public void myUnlock()&#123; Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread, null); System.out.println(Thread.currentThread().getName()+&quot;\\t unlock()&quot;); &#125; public static void main(String[] args) throws Exception&#123; hellotest g = new hellotest(); new Thread(()-&gt;&#123; g.myLock(); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; g.myUnlock(); &#125;,&quot;AA&quot;).start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; new Thread(()-&gt;&#123; g.myLock(); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; g.myUnlock(); &#125;,&quot;BB&quot;).start(); &#125;&#125; 独占锁（写锁）&#x2F;共享锁（读锁）&#x2F;互斥锁1、独占锁：该锁一次只能被一个线程所持有（ReentrantLock和Synchronized都是独占锁） 2、共享锁：指该锁可以被多个线程持有 一个 ReadWriteLock保持一对关联的lock，一个用于读操作，一个用于写操作。 read lock：可能被多个线程同时进行的读者，只要没有作家。 write lock：一次只能被一个线程占有 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class test4 &#123; public static void main(String[] args)&#123; MyCache cache = new MyCache(); //写入 for (int i =1;i&lt;6;i++)&#123; final int temp = i; new Thread(()-&gt;&#123; cache.put(temp+&quot;&quot;,temp+&quot;&quot;); &#125;,String.valueOf(i)).start(); &#125; //读取 for (int i =1;i&lt;6;i++)&#123; final int temp = i; new Thread(()-&gt;&#123; cache.get(temp+&quot;&quot;); &#125;,String.valueOf(i)).start(); &#125; &#125;&#125;class MyCache&#123; private volatile Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); //读写锁：更加细粒度的控制 private ReadWriteLock lock = new ReentrantReadWriteLock(); //写，写入的时候只希望同时只有一个线程写 public void put(String key,Object value)&#123; //加锁 lock.writeLock().lock(); try&#123; System.out.println(Thread.currentThread().getName()+&quot;写入&quot;+key); map.put(key,value); System.out.println(Thread.currentThread().getName()+&quot;写入OK&quot;); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.writeLock().unlock(); &#125; &#125; //读 public void get(String key)&#123; lock.readLock().lock(); try &#123; System.out.println(Thread.currentThread().getName()+&quot;读取&quot;+key); map.get(key); System.out.println(Thread.currentThread().getName()+&quot;读取OK&quot;); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.readLock().unlock(); &#125; &#125;&#125; 生产者消费者问题Synchronized版本1、Object类上的几个方法： public final native void notify();唤醒等待在此对象上的线程，如果有个线程等待，随机唤醒一个线程 public final native void notifyAll();唤醒等待此对象上的所有线程 public final void wait() ;让当前运行线程等待 public final native void wait(long timeout);让当前线运行程等待timeout毫，直到其他线程调用notify()方法或notifyAll()方法的对象，或一个指定的时间已经过去 public final void wait(long timeout, int nanos);让当前运行线程等待timeout++毫秒，直到其他线程调用notify()方法或notifyAll()方法的对象，或一个指定的时间已经过去 1234567891011121314151617181920212223242526public class test1 &#123; public static void main(String[] args) &#123; Data data = new Data(); new Thread(()-&gt;&#123; for(int i=0;i&lt;10;i++)&#123; try &#123; data.increment(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;,&quot;A&quot;).start(); new Thread(()-&gt;&#123; for(int i = 0;i&lt;10;i++)&#123; try &#123; data.decrement(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;,&quot;B&quot;).start(); &#125; &#125; 12345678910111213141516171819202122232425262728// 等待+业务+通知class Data&#123; private int number=0; //+1 public synchronized void increment() throws InterruptedException &#123; if(number!=0)&#123; //等待 this.wait(); &#125; number++; System.out.println(Thread.currentThread().getName()+&quot;=&gt;&quot;+number); //通知其他线程，+1完毕 this.notifyAll(); &#125; //-1 public synchronized void decrement() throws InterruptedException &#123; if(number == 0)&#123; //等待 this.wait(); &#125; number--; System.out.println(Thread.currentThread().getName()+&quot;=&gt;&quot;+number); //通知其他线程，-1完毕 this.notifyAll(); &#125;&#125; 问题：4个线程还安全吗？ 使用if判断（只判断一次），存在虚假唤醒 一个线程可以同时醒来，没有被通知，中断，或时，所谓的空虚假唤醒。虽然这将很少发生在实践中，应用程序必须防止它通过测试的条件，应该引起线程被唤醒，并继续等待，如果条件不满意。换句话说，等待应该总是发生在循环中 解决：将if判断改成while即可 JUC版本（condition）代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class test2 &#123; public static void main(String[] args) &#123; Data data = new Data(); new Thread(()-&gt;&#123; for(int i=0;i&lt;10;i++)&#123; try &#123; data.increment(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;,&quot;A&quot;).start(); new Thread(()-&gt;&#123; for(int i = 0;i&lt;10;i++)&#123; try &#123; data.decrement(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;,&quot;B&quot;).start(); new Thread(()-&gt;&#123; for(int i=0;i&lt;10;i++)&#123; try &#123; data.increment(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;,&quot;C&quot;).start(); new Thread(()-&gt;&#123; for(int i = 0;i&lt;10;i++)&#123; try &#123; data.decrement(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;,&quot;D&quot;).start(); &#125;&#125;// 等待+业务+通知class Data2&#123; private int number=0; Lock lock = new ReentrantLock(); Condition condition = lock.newCondition(); //+1 public void increment()&#123; lock.lock(); try &#123; while (number!=0)&#123; //等待 condition.await(); &#125; number++; System.out.println(Thread.currentThread().getName()+&quot;=&gt;&quot;+number); //通知其他线程，+1完毕 condition.signalAll(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; //-1 public void decrement()&#123; lock.lock(); try &#123; while(number == 0)&#123; //等待 condition.await(); &#125; number--; System.out.println(Thread.currentThread().getName()+&quot;=&gt;&quot;+number); //通知其他线程，-1完毕 condition.signalAll(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125;&#125; JUC版本（精准通知和唤醒） Condition：精准的通知和唤醒线程 需求：有序，A执行完调用B，B执行完调用A，C执行完调用A 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public class test3 &#123; public static void main(String[] args) &#123; Data3 d = new Data3(); //A执行完调用B，B执行完调用A，C执行完调用A new Thread(()-&gt;&#123; for (int i=0;i&lt;10;i++) &#123; d.printA(); &#125; &#125;,&quot;A&quot;).start(); new Thread(()-&gt;&#123; for (int i=0;i&lt;10;i++) &#123; d.printB(); &#125; &#125;,&quot;B&quot;).start(); new Thread(()-&gt;&#123; for (int i=0;i&lt;10;i++) &#123; d.printC(); &#125; &#125;,&quot;C&quot;).start(); &#125;&#125;// 等待+业务+通知class Data3&#123; private Lock lock = new ReentrantLock(); private Condition condition1 = lock.newCondition(); private Condition condition2 = lock.newCondition(); private Condition condition3 = lock.newCondition(); public int number=1;//1:A;2:B;3:C public void printA()&#123; lock.lock(); try &#123; while (number!=1)&#123; //等待 condition1.await(); &#125; System.out.println(Thread.currentThread().getName()+&quot;AAAAA&quot;); //唤醒指定的人 number=2; condition2.signal(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; public void printB()&#123; lock.lock(); try &#123; while (number!=2)&#123; //等待 condition2.await(); &#125; System.out.println(Thread.currentThread().getName()+&quot;BBBBB&quot;); //唤醒指定的人 number=3; condition3.signal(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; public void printC()&#123; lock.lock(); try &#123; while (number!=3)&#123; //等待 condition3.await(); &#125; System.out.println(Thread.currentThread().getName()+&quot;CCCCC&quot;); //唤醒指定的人 number=1; condition1.signal(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125;&#125; Condition和Object的区别 Lost wake up问题1、通俗理解：线程 A 调用 wait() 方法进入阻塞状态，接下来没有其他线程去唤醒线程 A，或者其他线程唤醒时机不对(早于线程 A 的 wait() )，导致线程 A 永远阻塞下去。 2、现在有一个生产者线程和消费者线程： 先定义一个 obj 对象，并将其 count 属性的初始值设置为 0： 12Object obj = new Object();obj.count = 0; 生产者伪代码： 12obj.count++;obj.notify(); 消费者伪代码： 123while(obj.count&lt;=0) obj.wait();obj.count--; 两个线程启动，消费者检查 obj.count 的值，发现 obj.count &lt;= 0 条件成立，但这时由于 CPU 的调度，发生上下文切换，生产者开始工作，执行了 count+1 和 obj.notify()，也就是发出通知，准备唤醒一个阻塞的线程。然后 CPU 调度到消费者，此时消费者开始执行 obj.wait()，线程进入阻塞。但生产者已经早在消费者阻塞前执行了唤醒动作，也就导致消费者永远无法醒来了。 随便加个锁能解决「lost wake up 问题」吗不能，举个例子: 定义一把锁： 1Lock lock1 = new Lock(); 生产者伪代码： 1234lock1.lock();obj.count++;obj.notify();lock1.unlock(); 消费者伪代码： 12345lock1.lock();while(count&lt;=0) obj.wait();obj.count--;lock1.unlock(); 两个线程启动，obj.count 初始值为 0。假设消费者先竞争到锁，while 中的 obj.count&lt;=0 条件满足，执行 obj.wait() 使线程进入阻塞状态，lock1 锁没有被释放，所以生产者拿不到锁，也就无法 obj.notify() 通知消费者醒来，消费者将永远阻塞下去。 Java 中什么锁才能解决「lost wake up 问题」只有上述例子中的 obj 对象锁才能避免这个问题，也就是将 obj.wait() 和 obj.notify() 放进 obj 对象锁的同步块中。如果锁的不是例子中的 obj 对象，Java 就会抛出 IllegalMonitorStateException 异常 生产者伪代码： 1234synchronized (obj) &#123; obj.count++; obj.notify();&#125; 消费者伪代码： 12345synchronized (obj) &#123; while(count&lt;=0) obj.wait(); obj.count--;&#125; Java 中对 wait() 方法的注释中提到：线程在调用 obj.wait() 前必须要拿到当前 obj 对象的监视器 monitor 对象，即 obj 的锁。只有这样，当执行到 obj.wait() 时，该线程才可以暂时让出 obj 的同步锁并停止对锁的竞争，让其他正在等待此锁的线程可以得到同步锁并运行。 在上述例子中，消费者执行到 obj.wait() 时，让出了 obj 锁，停止了对锁的竞争，进入阻塞状态，紧接着生产者竞争到 obj 锁，执行了 obj.notify() 方法，唤醒了消费者，使消费者线程从阻塞状态重新回到就绪状态。 这里要注意的是，obj.notify() 并不是让生产者马上释放锁，也不是让消费者马上得到锁，而是通知消费者线程可以重新去参与锁的竞争了。 阻塞队列版本1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class hellotest &#123; public static void main(String[] args) throws Exception&#123; milk m = new milk(new ArrayBlockingQueue&lt;&gt;(1)); new Thread(()-&gt;&#123; System.out.println(&quot;生产开始&quot;); try &#123; m.produce(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); new Thread(()-&gt;&#123; System.out.println(&quot;消费开始&quot;); try &#123; m.consume(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); TimeUnit.SECONDS.sleep(5); m.stop(); &#125;&#125;class milk&#123; //默认开启，进行生产和消费 private volatile boolean FLAG = true; private AtomicInteger atomicInteger = new AtomicInteger(); BlockingQueue&lt;String&gt; blockingQueue = null; public milk(BlockingQueue&lt;String&gt; blockingQueue)&#123; this.blockingQueue=blockingQueue; System.out.println(blockingQueue.getClass().getName()); &#125; public void produce() throws InterruptedException &#123; String data = null; boolean retValue; while (FLAG)&#123; data = atomicInteger.incrementAndGet()+&quot;&quot;; retValue = blockingQueue.offer(data,2L,TimeUnit.SECONDS); if(retValue)&#123; System.out.println(Thread.currentThread().getName()+&quot;\\t 插入队列&quot;+data+&quot;成功&quot;); &#125;else &#123; System.out.println(Thread.currentThread().getName()+&quot;\\t 插入队列&quot;+data+&quot;失败&quot;); &#125; TimeUnit.SECONDS.sleep(1); &#125; &#125; public void consume() throws InterruptedException &#123; String result = null; while (FLAG)&#123; result = blockingQueue.poll(2L,TimeUnit.SECONDS); if(result==null||result.equalsIgnoreCase(&quot;&quot;))&#123; FLAG=false; System.out.println(Thread.currentThread().getName()+&quot;\\t 消费退出&quot;); &#125;else &#123; System.out.println(Thread.currentThread().getName()+&quot;\\t 消费队列&quot;+result+&quot;成功&quot;); &#125; TimeUnit.SECONDS.sleep(1); &#125; &#125; public void stop()&#123; FLAG=false; &#125;&#125; AQSLockSupport LockSupport是用来创建锁和其他同步类的基本线程阻塞原语。 1、线程阻塞工具类，都是静态方法，调用底层native代码 2、LockSupport和每一个使用它的线程都有一个许可关联，permit相当于1、0开关，默认是0 调用unpark变为1 调用park变为0，通过park立即返回 如果再次调用park会阻塞，直到permit变为1 每个线程都只有一个相关的permit，最多一个，重复调用unpark不会积累凭证 park123public static void park() &#123; UNSAFE.park(false, 0L);&#125; permit默认为0，所以一开始调用park方法，当前线程就会阻塞，直到别的线程将当前线程的permit设置为1，park会被唤醒，然后将permit设置为0并返回 unpark1234public static void unpark(Thread thread) &#123; if (thread != null) UNSAFE.unpark(thread);&#125; 例子123456789101112131415public static void main(String[] args) throws InterruptedException &#123; Thread a = new Thread(()-&gt;&#123; System.out.println(Thread.currentThread().getName()+&quot;-&gt; &quot;+&quot;come in&quot;); LockSupport.park(); System.out.println(Thread.currentThread().getName()+&quot;-&gt; 被唤醒&quot;); &#125;); a.start(); TimeUnit.SECONDS.sleep(3); new Thread(()-&gt;&#123; LockSupport.unpark(a); System.out.println(Thread.currentThread().getName()+&quot;-&gt; 通知&quot;); &#125;).start();&#125; AQS AQS是JUC框架中重要的类，通过它来实现独占锁和共享锁的，内部很多类都是通过AQS来实现的，比如CountDownLatch、ReentrantLock、ReentrantReadWriteLock、Semaphore。 AQS：抽象的队列同步器（AbstractQueuedSynchronized） 是用来构建锁或者其他同步器组件的重量级基础框架及整个JUC体系的基石，通过内置的FIFO队列来完成资源获取线程的排队工作，并通过一个int类型变量表示持有锁的状态 用处：加锁会导致堵塞，有阻塞就需要排队，实现排队就需要有某种形式的队列进行管理 CLH队列：将请求共享资源的线程封装为队列的结点Node，通过CAS、自旋、LockSupport.park的方式维护state的状态，使并发达到同步的控制效果 AQS源码体系 内部体系架构： 1、AQS自身： int变量：state（1表示被占用，只能去排队） CLH队列：双向队列（有首节点、尾节点） 2、内部类Node 有两个模式：共享、排它 有前节点和后节点（pre、next） 有一个重要的int变量：waitStatus，表示当前节点在队列中的状态 0：默认 1：表示线程获取锁的请求取消 -2：表示节点在等待队列中等待被唤醒 -3：当前线程在共享情况下 -1：表示线程已经准备好了，就等待释放资源了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152static final class Node &#123; //共享 static final Node SHARED = new Node(); //独占 static final Node EXCLUSIVE = null; static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; // 当前节点在队列中的状态 // 默认0 // 1：取消 // -1：线程准备好了 // -2：等待唤醒 // -3：当前线程在共享情况下 volatile int waitStatus; //前指针 volatile Node prev; //后指针 volatile Node next; //线程 volatile Thread thread; Node nextWaiter; final boolean isShared() &#123; return nextWaiter == SHARED; &#125; final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; //构造方法 Node() &#123;&#125; Node(Thread thread, Node mode) &#123; this.nextWaiter = mode; this.thread = thread; &#125; Node(Thread thread, int waitStatus) &#123; this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; 源码 Lock接口的实现了基本上都是通过聚合了一个队列同步器的子类完成线程的访问控制的 ReentrantLock: 公平锁和非公平锁 区别：公平锁需要判断队列中是否存在有效节点 公平锁讲究先来先到，如果这个锁的等待队列中已经有线程在等待，那么当前线程就会进入等待队列 非公平锁如果可以获取锁，就立刻占有 1234567891011121314151617181920//公平锁final void lock() &#123; acquire(1);&#125;//非公平锁final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125;//最终都会调用acquire方法public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; lock加锁三个阶段： 尝试加锁 加锁失败，进入队列 线程入队列后，进入阻塞状态 123//main方法代码ReentrantLock lock = new ReentrantLock();lock.lock(); 12345678910111213141516171819//ReentrankLock类：lock方法public void lock() &#123; sync.lock();&#125;//ReentrankLock类中的sync内部类的抽象方法：lockabstract void lock();//ReentrankLock类中的非公平锁内部类的方法：lockfinal void lock() &#123; //CAS：更改AQS的state //如果state为0，就将state设置为1 if (compareAndSetState(0, 1)) //设置队列的当前线程为这个线程 setExclusiveOwnerThread(Thread.currentThread()); else //如果CAS失败，说明已经有线程抢占了锁，那么就需要进入acquire方法 acquire(1);&#125; acuqire123456//AQS类的acquire方法：传入的参数为1，arg为1public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; //返回false，取反为true；如果返回true（重入），因为是短路与，所以后面就不会进行 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; tryAcquire—抢占、重入 1234567891011121314151617181920212223242526272829303132333435//AQS的方法protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125;//ReentrankLock类中的非公平锁内部类的方法：tryAcquireprotected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125;//ReentrankLock类中的sync内部类的方法，acquires为1final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); //获取state int c = getState(); //如果state为0，直接AQS，抢占锁 if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //如果请求的线程和当前的线程相同，说明重入 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); //设置state为重入的次数 setState(nextc); //返回true return true; &#125; //如果都不是，就返回false return false;&#125; ReentrantLock重入的原理 在第二次获取锁的时候，CAS失败，进入tryacquire方法，会进行判断请求的线程和当前拥有资源的线程是否相同，如果相同，state+1 addwaiter—创建node并加入到队列123456789101112131415161718192021222324252627282930313233343536373839404142private Node addWaiter(Node mode) &#123; //创建一个新的node Node node = new Node(Thread.currentThread(), mode); // 获取tail，如果是第一个线程，就为null Node pred = tail; // 如果tail不是null if (pred != null) &#123; //CAS交换 node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); //返回线程 return node;&#125;//Node的enq方法private Node enq(final Node node) &#123; //自旋 for (;;) &#123; Node t = tail; //如果tail为null，就进行初始化 if (t == null) &#123; //使用CAS进行初始化，new一个空node作为头节点（Thread=null，waitStatus=0）：傀儡节点/哨兵节点，只是用来占位 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; //如果tail不为null，将传入的需要增加的节点加入到队列中 node.prev = t; //CAS设置tail为需要增加的节点 if (compareAndSetTail(t, node)) &#123; //设置t的next为需要增加的节点 t.next = node; //返回t return t; &#125; &#125; &#125;&#125; 步骤： 1、addWriter方法会首先新建这个node 2、如果当前队列不为空，就将自己放到尾节点，去6； 3、如果当前队列为空，就需要进入Node的enq方法；去4； 4、再次判断队列是否为空，如果为空就进行初始化（傀儡节点），等待队列的第一个节点是傀儡节点 5、初始化后，tail不为null了，就可以使用CAS传入线程（同2） 6、返回这个节点 acquireQueued—使用locksupport阻塞节点12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//node：插入的新node//arg：1final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; //被打断 boolean interrupted = false; for (;;) &#123; //获得上一个节点 final Node p = node.predecessor(); //如果p=head，再抢一次（看看state是不是0） if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; //抢占失败，进入shouldParkAfterFailedAcquire方法，将上一个节点的waitstatus变为-1 //再次进入，进入parkAndCheckInterrupt方法，使用locksupport挂起当前节点，直到unpark才结束 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; //默认为0 int ws = pred.waitStatus; if (ws == Node.SIGNAL) return true; if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; //更改上一个节点的waitStatus变为-1 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 步骤： 将上一个节点的waitstatus改为-1 使用locksupport将自己进行阻塞 后面的线程都在park，在parkAndCheckInterrupt()方法这里等待unpark() unlock123public void unlock() &#123; sync.release(1);&#125; release12345678910111213//AQS类public final boolean release(int arg) &#123; //如果是true，说明state=0 if (tryRelease(arg)) &#123; //获取head Node h = head; //如果head不为null，waitstatus不等于0 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; tryRelease—state减1，为0free就是true1234567891011121314151617181920protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125;//ReentrankLock的内部类protected final boolean tryRelease(int releases) &#123; //当前状态-1 int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; //如果c=0 if (c == 0) &#123; free = true; //设置当前thread为null setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 123protected final void setState(int newState) &#123; state = newState;&#125; unparkSuccessor12345678910111213141516171819private void unparkSuccessor(Node node) &#123; //获取waitStatus int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); //获取下一个节点 Node s = node.next; //如果下一个节点等于null且waitstatus大于0 if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; //如果下一个节点不等于null if (s != null) //唤醒下一个节点 LockSupport.unpark(s.thread);&#125; 总结1、AQS的加锁操作 首先调用lock方法 lock方法调用了sync的lock方法 sync的lock方法调用了非公平锁的lock方法，使用CAS更改state状态 更改成功，就将当前占有锁的线程更改为这个线程 更改不成功（说明没有线程占有锁）进入AQS类的acquire方法 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; //返回false，取反为true；如果返回true（重入），因为是短路与，所以后面就不会进行 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 首先进入ReentrankLock类中非公平锁的tryAcquire方法，接着进入sync的nonfairTryAcquire方法 使用CAS转换state，转换成功就占有锁，返回true，整个流程结束 转换不成功，如果两个线程相同，说明是重入，那么就state加1，返回true，整个流程结束 以上情况都不是，返回false，进入addWaite方法 接着进入addWaiter方法 根据线程创建新的节点 如果tail不是null，使用CAS转换，将当前线程设置为tail，返回这个节点 如果tail为null，进入Node的enq方法 再次判断队列是否为空，如果为空就进行初始化（傀儡节点），等待队列的第一个节点是傀儡节点 初始化后，tail不为null了，就可以使用CAS将这个线程转为tail 返回这个节点 再进入acquireQueued方法 将上一个节点的waitstatus改为-1（傀儡节点，除了初始化的傀儡节点，获得锁的线程node会将node的thread设置为null，也是傀儡节点） 使用locksupport将自己进行阻塞（park） 后面的线程都在park，在parkAndCheckInterrupt()方法这里等待unpark() 2、AQS的unlock 进入sync的release方法 首先进行tryRelease方法 将state减1，如果为0，就返回true 如果不为0，说明是重入了，返回false，流程结束 如果不是重入，进入unparkSuccessor方法 unpark队列的下一个节点 如果实现非公平？ 非公平锁相比较公平锁的 tryAcquire方法，少了一步判断 AQS 队列中是否有等待的线程的操作。 JUCCAS 对于并发控制而言，锁是一种悲观的策略，它总是假设每一次的临界区操作会产生冲突，因此会对每一次的操作都小心翼翼。如果有多个线程访问临界区资源，就宁可牺牲性能也不会让线程等待，所以说锁会阻塞线程执行。 无锁是一种乐观的策略，它会假设对资源的访问是没有冲突的。遇到冲突怎么办？无锁的策略使用一种比较交换的技术（CAS，Compare And Swap）来鉴别线程冲突，一旦检测到冲突产生，就重试当前的操作直到没有冲突为止。 什么是CASCAS 表示 Compare And Swap，比较并交换，需要三个操作数 包含三个参数CAS（V，A，B） V：表示要更新的变量，内存位置 A：表示旧的预期值 B：表示新值 CAS 指令执行时，当且仅当 V 符合 A 时，处理器才会用 B 更新 V 的值，否则它就不执行更新。但不管是否更新都会返回 V 的旧值，这些处理过程是原子操作，执行期间不会被其他线程打断。 这是一种完全依赖于硬件的功能，通过它实现了原子操作。原语的执行时连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，不会造成数据不一致。 在 JDK 5 后，Java 类库中才开始使用 CAS 操作，该操作由 Unsafe 类里的 compareAndSwapInt 等几个方法包装提供。HotSpot 在内部对这些方法做了特殊处理，即时编译的结果是一条平台相关的处理器 CAS 指令。Unsafe 类不是给用户程序调用的类，因此 JDK9 前只有 Java 类库可以使用 CAS，譬如 juc 包里的 AtomicInteger类中 compareAndSet等方法都使用了Unsafe 类的 CAS 操作实现。 12345678910111213141516main&#123; AtomicInteger number = new AtomicInteger(2020); number.compareAndSet(2020,2021);&#125;public class AtomicInteger extends Number implements java.io.Serializable &#123; //如果达到期望的值，就更新，否则就不更新 public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125;&#125;public final class Unsafe &#123; //处理器 CAS 指令 public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);&#125; CAS底层原理1234main&#123; AtomicInteger number = new AtomicInteger(2020); number.getAndIncrement();&#125; 1、Unsafe类 是CAS的核心类，由于Java方法无法直接访问底层系统，需要通过本地方法来访问，Unsafe相当于一个后门，基于该类可以直接操作特定内存的数据。 Unsafe类存在于sun.misc包中，其内部方法操作可以像C的指针（通过内存偏移量）一样操作内存，因为Java中CAS操作的执行依赖于Unsafe类的方法。 2、valueOffset 表示该变量值在内存中的偏移地址，因为Unsafe就是根据内存偏移地址来获取数据的。 123456789101112public class AtomicInteger extends Number implements java.io.Serializable &#123; private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; //获取内存偏移量 valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value;&#125; 3、变量value使用volatile修饰，保证了多线程之间的内存可见性 问：CAS是什么？ CAS是一条**CPU并发原语**，它判断内存某个位置的值是否为预期值，如果是更改为新的值，这个过程是原子的 CAS并发原语体现在JAVA语言中就是Unsafe类中的各个方法。调用这些方法，JVM可以帮我们实现CAS汇编指令，这是一种完全依赖于硬件的功能，通过它实现了原子操作。 再次强调，CAS是一种系统原语，原语属于操作系统用语范畴，是由若干条指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，执行过程中不允许被打断，也就是说CAS是一条CPU的原子指令，不会造成数据不一致的问题。 例一源码分析主函数： 1234main&#123; AtomicInteger number = new AtomicInteger(2020); number.getAndIncrement();&#125; 可以看到调用了getAndIncrement()方法，如下： 12345678public class AtomicInteger&#123; public final int getAndIncrement() &#123; //this：代表当前对象 //valueOffset：内存偏移量 //1：自增 return unsafe.getAndAddInt(this, valueOffset, 1); &#125;&#125; 这个方法又调用了Unsafe类的一个方法getAndAddInt()方法，如下： 12345678910111213141516171819202122232425262728public final class Unsafe &#123; //先获取，再加 //var1:this //var2:内存地址偏移量 //var4:1 public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; //获取当前这个对象这个地址上的值 var5 = this.getIntVolatile(var1, var2); &#125; //比较并交换 //var1:this，var2:内存地址偏移量，var5:当前值，var5+var4:新值 //修改成功跳出循环；不成功就返回false，一直循环 while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; &#125; //获取这个值的方法 public native int getIntVolatile(Object var1, long var2); //处理器 CAS 指令 //var1和var2：要更新的变量 //var4：旧的预期值 //var5：新的值 public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);&#125; 例二假设线程A和线程B同时执行getAndAddInt()操作（分别跑在不同的CPU上）： AutomicInteger里面的value原始值是3，即主内存中AutomicInteger的value为3，根据JMM模型，线程A和线程B各自持有一份值为3的value的副本分别到各自的工作内存 线程A通过getIntVolatile(var1,var2)拿到value值为3，这时线程A被挂起 线程B通过getIntVolatile(var1,var2)拿到value值为3，刚好B没有被挂起，并执行compareAndSwapInt方法，比较内存值也是3，成功修改内存值为4，线程B收工 这时A恢复，执行compareAndSwapInt方法，发现自己的值和主内存的值不一致，说明这个值已经被修改过了，那A修改失败，只能重新读取 线程A重新获取value值，因为变量value被volatile修饰，所以其他线程对它的修改，线程A总是可以看见，线程A继续执行compareAndSwapInt方法进行比较替换，直到成功 Unsafe类+CAS思想（自旋） CAS缺点1、循环时间长，开销大 这个方法的do while，如果CAS失败，会一直尝试，如果长时间不成功会带来很大的开销 1234567public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125;while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; &#125; 2、只能保证一个共享变量的原子操作 对于多个共享变量操作，循环CAS无法保证一致性，只能使用加锁 3、ABA问题 ABA问题 原子类AutomicInteger的ABA问题？原子更新引用知道吗？ ABA问题：狸猫换太子 CAS算法实现一个重要前提：取出内存中某时刻的数据并在当下时刻比较并替换，那么这个时间差会导致数据的变化。 1、ABA问题如何产生的？ 比如：一个线程1从内存位置V取出A，这时候另外一个线程2也从内存中取出A，并且线程2进行了一些操作将值变成了B，然后线程2又将V位置的数据变回了A；这时候线程1进行CAS操作，发现内存中仍然是A，线程1操作成功。 虽然线程1的CAS操作成功，但是这不代表这个过程没有问题 原子引用Atomic：原子 在java.util.concurrent.atomic下有这些类： 其中，AtomicReference&lt;V&gt;为原子引用： 例子： 1234567891011121314class User&#123; String userName; int age;&#125;main&#123; User u1 = new User(&quot;zhangsan&quot;,18); User u2 = new User(&quot;lisi&quot;,20); AtomicReference&lt;User&gt; at = new AtomicReference&lt;&gt;(); at.set(u1); System.out.println(at.compareAndSet(u1,u2));//true System.out.println(at.compareAndSet(u1,u2));//false&#125; ABA解决原子引用+新增机制（修改版本号，类似于时间戳） 1234线程 工作内存 1s 2s 线程1 100 1 2019 2线程2 100 1 101 2 102 3 时间戳原子引用类： 一个 AtomicStampedReference保持随着整数“邮票”一个对象的引用，可以自动更新。 实现说明：此实现通过创建表示“框”[参考，整数]对的内部对象来保持标记的引用。 对比： 1、 AtomicReference产生ABA问题 1234567891011121314151617static AtomicReference&lt;Integer&gt; a1 = new AtomicReference&lt;&gt;(100);public static void main(String[] args) throws InterruptedException &#123; new Thread(()-&gt;&#123; a1.compareAndSet(100,101); a1.compareAndSet(101,100); &#125;,&quot;t1&quot;).start(); new Thread(()-&gt;&#123; //暂停1s，保证t1线程完成了一次ABA操作 try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(a1.compareAndSet(100, 2019)+&quot;\\t&quot;+a1.get()); &#125;,&quot;t2&quot;).start();&#125; 输出： 1true 2019 2、使用 AtomicStampedReference解决问题 12345678910111213141516171819202122232425262728293031static AtomicStampedReference&lt;Integer&gt; a2 = new AtomicStampedReference&lt;&gt;(100,1);public static void main(String[] args) throws InterruptedException &#123; new Thread(()-&gt;&#123; //获得初始版本号 int stamp = a2.getStamp(); System.out.println(Thread.currentThread().getName()+&quot;\\t第一次版本号：&quot;+stamp); //暂停1s,保证t2获取的版本号和t1一致 try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; a2.compareAndSet(100,101,a2.getStamp(),a2.getStamp()+1); System.out.println(Thread.currentThread().getName()+&quot;\\t第二次版本号：&quot;+a2.getStamp()); a2.compareAndSet(101,100,a2.getStamp(),a2.getStamp()+1); System.out.println(Thread.currentThread().getName()+&quot;\\t第三次版本号：&quot;+a2.getStamp()); &#125;,&quot;t1&quot;).start(); new Thread(()-&gt;&#123; //获得初始版本号 int stamp = a2.getStamp(); System.out.println(Thread.currentThread().getName()+&quot;\\t第一次版本号：&quot;+stamp); //暂停3s，保证t3完成一次ABA操作 try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(a2.compareAndSet(100, 2019,stamp,stamp+1)); &#125;,&quot;t2&quot;).start();&#125; 输出： 12345t1 第一次版本号：1t2 第一次版本号：1t1 第二次版本号：2t1 第三次版本号：3false 常用的辅助类CountDownLatch 1234567891011121314public static void main(String[] args) throws InterruptedException &#123; //总数是6 CountDownLatch countDownLatch = new CountDownLatch(6); for(int i =0;i&lt;6;i++)&#123; new Thread(()-&gt;&#123; System.out.println(Thread.currentThread().getName()+&quot;Go out&quot;); //计数器数量减1 countDownLatch.countDown(); &#125;).start(); &#125; //等待计数器归0，然后向下执行 countDownLatch.await(); System.out.println(&quot;close door&quot;); &#125; 原理： countDownLatch.countDown();：计数器数量减1 countDownLatch.await();：等待计数器归0，然后向下执行 每次有线程调用countDown()数量-1，假设计数器变为0，countDownLatch.await();就会被唤醒，继续向下执行 CyclicBarrier 123456789101112131415161718192021public static void main(String[] args)&#123; //总数是7 CyclicBarrier cyclicBarrier = new CyclicBarrier(7,()-&gt;&#123; System.out.println(&quot;召唤神龙！&quot;); &#125;); for(int i =0;i&lt;7;i++)&#123; final int temp = i; new Thread(()-&gt;&#123; System.out.println(Thread.currentThread().getName()+temp); //等待计数器变成7 try &#123; cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125; &#125; Semaphore信号量 123456789101112131415161718192021public static void main(String[] args)&#123; //线程数量：停车位 限流 Semaphore semaphore = new Semaphore(3); for (int i = 0;i&lt;6;i++)&#123; new Thread(()-&gt;&#123; // acquire()得到 try &#123; semaphore.acquire(); System.out.println(Thread.currentThread().getName()+&quot;抢到车位&quot;); TimeUnit.SECONDS.sleep(2); System.out.println(Thread.currentThread().getName()+&quot;离开车位&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; // release()释放 semaphore.release(); &#125; &#125;).start(); &#125; &#125; 原理： acquire()：获得，如果满了就等待被释放为止 release()：释放当前信号量 作用：多个共享资源互斥的使用、并发限流（控制最大的线程数） 线程安全集合类 线程安全集合类分为三大类： 遗留的安全集合：Hashtable、Vector 使用Collections装饰的线程安全集合（加Synchronized修饰），如： Collections.synchronizedList() Collections.synchronizedCollection() Collections.synchronizedMap() Collections.synchronizedSet() Collections.synchronizedNavigableMap() Collections.synchronizedNavigableSet() Collections.synchronizedSortedMap() Collections.synchronizedSortedSet() java.util.concurrent.* 包含三类关键词：Blocking、CopyOnWrite、Concurrent Blocking：大部分实现基于锁，并提供用来阻塞的方法 CopyOnWrite：修改时拷贝，修改的开销较重 Concurrent类型的容器：内部很多操作使用cas优化，提供较高的吞吐量；但是存在弱一致性的问题（遍历时弱一致性、求大小弱一致性、读取弱一致性） CopyOnWriteArrayList 问题： 出现java.util.ConcurrentModificationException并发修改异常 解决方案： 1、List&lt;String&gt; list = new Vector&lt;&gt;(); 2、List&lt;String&gt; list = Collections.synchronizedList(new ArrayList&lt;&gt;()); 3、List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); 1、CopyOnWrite：写入时复制，COW：计算机程序设计领域的一种优化策略。 2、**CopyOnWriteArrayList比Vector好在哪里？** CopyOnWriteArrayList 使用的lock锁的机制，Vector使用synchronized锁的机制 Vector 的增删改查方法都加上了synchronized锁，保证同步的情况下，因为每个方法都要去获得锁，所以性能就会大大下降。 CopyOnWriteArrayList 方法只是在增删改方法上增加了ReentrantLock锁，但是他的读方法不加锁，所以在读的方面就要比Vector性能要好，CopyOnWriteArrayList适合读多写少的并发情况，读写分离，在写的时候复制出一个新的数组，完成插入、修改、删除操作，在完成操作后，将这个新的数组赋值给一个array。 1private transient volatile Object[] array; 123456789101112131415161718192021public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; // 复制一个数组 Object[] newElements = Arrays.copyOf(elements, len + 1); //完成操作 newElements[len] = e; //赋值给Array setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125;final void setArray(Object[] a) &#123; array = a;&#125; CopyOnWriteArraySet解决方案： 1234//1、Collections工具类Set&lt;String&gt; set1 = Collections.synchronizedSet(new HashSet&lt;&gt;());//2、CopyOnWriteArraySetSet&lt;String&gt; set2 = new CopyOnWriteArraySet&lt;&gt;(); HashSet的底层是什么？ HashMap（容量16，负载因子0.75） 既然是HashMap，为什么只添加一个元素呢？ 123456789101112//底层是hashmappublic HashSet() &#123; map = new HashMap&lt;&gt;();&#125;//add方法//set的本质就是map，key是无法重复的public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125;//常量private static final Object PRESENT = new Object(); CopyOnWriteArraySet底层是什么？ 12345public class CopyOnWriteArraySet&lt;E&gt; extends AbstractSet&lt;E&gt; implements java.io.Serializable &#123; //底层是CopyOnWriteArrayList private final CopyOnWriteArrayList&lt;E&gt; al;&#125; ConcurrentHashMap1、知识回顾： map是这样用的吗？不是，工作不用HashMap 默认等价于：new HashMap&lt;&gt;(16,0.75f); 123static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;static final float DEFAULT_LOAD_FACTOR = 0.75f; 2、解决方案 12Map&lt;String, String&gt; map1 = new ConcurrentHashMap&lt;&gt;();SynchronizedMap 3、SynchronizedMap 内部维护了一个普通对象Map，还有排斥锁mutex 1234SynchronizedMap(Map&lt;K,V&gt; m) &#123; this.m = Objects.requireNonNull(m); mutex = this;&#125; 我们在调用构造方法的时候就需要传入一个Map，可以看到有两个构造器，如果你传入了mutex参数，则将对象排斥锁赋值为传入的对象。 4、HashTable 跟HashMap相比Hashtable是线程安全的，适合在多线程的情况下使用，但是效率可不太乐观。 他在对数据操作的时候都会上锁，所以效率比较低下 和HashMap的不同： Hashtable 是不允许键或值为 null 的，HashMap 的键值则都可以为 null。 实现方式不同：Hashtable 继承了 Dictionary类，而 HashMap 继承的是 AbstractMap 类。 初始化容量不同：HashMap 的初始容量为：16，Hashtable 初始容量为：11，两者的负载因子默认都是：0.75。 扩容机制不同：当现有容量大于总容量 * 负载因子时，HashMap 扩容规则为当前容量翻倍，Hashtable 扩容规则为当前容量翻倍 + 1。 迭代器不同：HashMap 中的 Iterator 迭代器是 fail-fast 的，而 Hashtable 的 Enumerator 不是 fail-fast 的。 为啥 Hashtable 是不允许 KEY 和 VALUE 为 null, 而 HashMap 则可以呢？ 因为Hashtable在我们put 空值的时候会直接抛空指针异常，但是HashMap却做了特殊处理。 Hashtable使用的是安全失败机制（fail-safe），这种机制会使你此次读到的数据不一定是最新的数据。 如果你使用null值，就会使得其无法判断对应的key是不存在还是为空，因为你无法再调用一次contain(key）来对key是否存在进行判断，ConcurrentHashMap同理。 fail-fast是啥？ 快速失败（fail—fast）是java集合中的一种机制， 在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception。 他的原理是啥？ 迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。 集合在被遍历期间如果内容发生变化，就会改变modCount的值。 每当迭代器使用hashNext()&#x2F;next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。 5、ConcurrentHashMap ConcurrentHashMap 底层是基于 数组 + 链表 组成的，不过在 jdk1.7 和 1.8 中具体实现稍有不同。 我先说一下他在1.7中的数据结构吧： 如图所示，是由 Segment 数组、HashEntry 组成，和 HashMap 一样，仍然是数组加链表。 HashEntry跟HashMap差不多的，但是不同点是，他使用volatile去修饰了他的数据Value还有下一个节点next。 那你能说说他并发度高的原因么？ 原理上来说，ConcurrentHashMap 采用了分段锁技术，其中 Segment 继承于 ReentrantLock。 不会像 HashTable 那样不管是 put 还是 get 操作都需要做同步处理，理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。 每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment。 就是说如果容量大小是16他的并发度就是16，可以同时允许16个线程操作16个Segment而且还是线程安全的。 1 阻塞队列1、阻塞队列的典型使用场景就是 生产者&#x2F;消费者模式 之前需要使用synchronized+wait+notify 不得不阻塞： 写入：如果队列满了，就必须阻塞等待 取：如果队列为空的，就必须阻塞等待生产 2、为什么需要阻塞队列？ 我们不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程 架构 1、架构图： 2、种类分析： ArrayBlockingQueue：由数组结构组成的有界阻塞队列 LinkedBlockingQueue：由链表结构组成的有界（大小默认Integer.Max_VALUE）阻塞队列，也可以看作无界 PriorityBlockingQueue：支持优先级排序的无界阻塞队列 DelayQueue：使用优先级队列实现的延迟无界阻塞队列 SynchronizedQueue：不存储元素的阻塞队列，也即单个元素的队列 LinkedTransferQueue：由链表结构组成的无界阻塞队列 LinkedBlockingDeque：由链表结构组成的双向阻塞队列 核心方法1、抛出异常2、不会抛出异常3、阻塞等待4、超时等待 方式 抛出异常 有返回值，不会抛出异常 阻塞等待 超时等待 添加 add offer(元素) put offer(元素，时间，时间格式) 移除 remove poll() take poll(时间，时间格式) 判断队列首元素 element peek 不可用 不可用 抛出异常 队列满抛出异常：Queue full 队列空删除元素抛出异常：NoSuchElementException 队列空判断队列第一个元素抛出异常：NoSuchElementException 12345678910111213141516171819public static void test1()&#123; //队列的大小 ArrayBlockingQueue&lt;String&gt; blockingQueue = new ArrayBlockingQueue&lt;&gt;(3); blockingQueue.add(&quot;a&quot;); blockingQueue.add(&quot;a&quot;); blockingQueue.add(&quot;a&quot;); //异常：Queue full blockingQueue.add(&quot;a&quot;); blockingQueue.remove(); blockingQueue.remove(); blockingQueue.remove(); //异常：NoSuchElementException blockingQueue.remove(); //异常：NoSuchElementException blockingQueue.element();&#125; 有返回值，不会抛出异常123456789101112131415161718public static void test2()&#123; ArrayBlockingQueue blockingQueue = new ArrayBlockingQueue&lt;&gt;(3); System.out.println(blockingQueue.offer(&quot;a&quot;)); System.out.println(blockingQueue.offer(&quot;a&quot;)); System.out.println(blockingQueue.offer(&quot;a&quot;)); //不抛出异常，返回false System.out.println(blockingQueue.offer(&quot;a&quot;)); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll()); //不抛出异常，返回null System.out.println(blockingQueue.poll()); //不抛出异常，返回null System.out.println(blockingQueue.peek());&#125; 等待，阻塞（一直阻塞）1234567891011121314151617public static void test3() throws InterruptedException &#123; ArrayBlockingQueue blockingQueue = new ArrayBlockingQueue&lt;&gt;(3); blockingQueue.put(&quot;a&quot;); blockingQueue.put(&quot;a&quot;); blockingQueue.put(&quot;a&quot;); //队列没有位置，一直等待 blockingQueue.put(&quot;a&quot;); System.out.println(blockingQueue.take()); System.out.println(blockingQueue.take()); System.out.println(blockingQueue.take()); //一直等待 System.out.println(blockingQueue.take());&#125; 等待，阻塞（等待超时）1234567891011121314151617public static void test4() throws InterruptedException &#123; ArrayBlockingQueue blockingQueue = new ArrayBlockingQueue&lt;&gt;(3); blockingQueue.offer(&quot;a&quot;); blockingQueue.offer(&quot;a&quot;); blockingQueue.offer(&quot;a&quot;); //队列没有位置，等待2s,如果没有位置就超时退出 blockingQueue.offer(&quot;a&quot;,2, TimeUnit.SECONDS); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll()); //一直等待 blockingQueue.poll(2,TimeUnit.SECONDS);&#125; 同步队列SynchronousQueue&lt;E&gt; 没有容量 进去一个元素必须等待取出来之后，才能往里面放一个元素 put、take 12345678910111213141516171819202122232425262728293031public static void main(String[] args) throws InterruptedException &#123; //put了一个元素，必须先take出来，不然不能put其他元素 SynchronousQueue&lt;String&gt; blockingQueue = new SynchronousQueue&lt;&gt;(); new Thread(()-&gt;&#123; try &#123; System.out.println(Thread.currentThread().getName()+&quot;put 1&quot;); blockingQueue.put(&quot;1&quot;); System.out.println(Thread.currentThread().getName()+&quot;put 2&quot;); blockingQueue.put(&quot;2&quot;); System.out.println(Thread.currentThread().getName()+&quot;put 3&quot;); blockingQueue.put(&quot;3&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;,&quot;t1&quot;).start(); new Thread(()-&gt;&#123; try &#123; TimeUnit.SECONDS.sleep(3); System.out.println(Thread.currentThread().getName()+blockingQueue.take()); TimeUnit.SECONDS.sleep(3); System.out.println(Thread.currentThread().getName()+blockingQueue.take()); TimeUnit.SECONDS.sleep(3); System.out.println(Thread.currentThread().getName()+blockingQueue.take()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;,&quot;t2&quot;).start();&#125; Fork&#x2F;Join框架 什么是ForkJoin？ JDK1.7提出，用于并行执行任务，提高效率，大数据量 &#x3D;&#x3D;把大任务分割成若干个小任务，最终汇总每个小任务的结果后得到大任务结果的框架&#x3D;&#x3D; Fork：把大任务切分为若干个字任务并行的执行 Join：合并这些子任务的执行结果 工作窃取 ForkJoin的特点：工作窃取（work-stealing） 1、概念：指某个线程从其他队列里窃取任务来执行 2、比如：A线程负责A队列的任务，B线程的任务已经结束后去A队列中窃取一个任务来执行，这时访问同一个队列，因此为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用&#x3D;&#x3D;双端队列&#x3D;&#x3D;，被窃取的任务线程永远从头部拿任务，窃取任务的线程从尾部拿线程 3、优点和缺点 优点：充分利用线程进行并行计算，减少了线程之间的竞争 缺点：在某些情况下还是存在竞争，比如双端队列只有一个任务时。并且该算法消耗大量的稀土资源，比如创建多个线程、创建多个双端队列 Fork&#x2F;Join框架设计步骤1：分割任务 步骤2：执行任务并合并结果 使用两个类来完成以上两件事情： ForkJoinTask：使用Fork&#x2F;join框架，必须先创建一个Fork&#x2F;Join任务。它提供在任务中执行fork和join操作的机制。通常情况下，我们只需要继承它的子类:RecursiveAction：用于没有返回结果的任务RecursiveTask：用于有返回结果的任务 ForkJoinPool：ForkJoinTask需要通过ForkJoinPool来执行 使用Fork&#x2F;Join12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class add extends RecursiveTask&lt;Long&gt;&#123; private long start; private long end; //临界值 private long temp = 10000L; public add(long start, long end) &#123; this.start = start; this.end = end; &#125; @Override protected Long compute() &#123; long sum=0L; if((end-start)&lt;temp)&#123; for(long i=start;i&lt;=end;i++)&#123; sum+=i; &#125; &#125;else &#123; //forkjoin long middle = (start+end)/2; add task1 = new add(start,middle); add task2 = new add(middle+1,end); //执行子任务 task1.fork(); task2.fork(); //等待结果 long result1 = task1.join(); long result2 = task2.join(); sum = result1+result2; &#125; return sum; &#125; public static void main(String[] args) &#123; //1、ForkJoinPool：通过它来执行 ForkJoinPool forkJoinPool = new ForkJoinPool(); //2、生产一个计算任务 add test = new add(1,12345); //3、执行一个任务 Future&lt;Long&gt; result = forkJoinPool.submit(test); try &#123; System.out.println(result.get()); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; 框架的实现原理ForkJoinPool由ForkJoinTask数组和ForkJoinWorkerThread数组组成： ForkJoinTask数组：负责将存放程序&#x3D;&#x3D;提交&#x3D;&#x3D;给ForkJoinPool任务 ForkJoinWorkerThread数组负责&#x3D;&#x3D;执行&#x3D;&#x3D;这些任务 1、ForkJoinTask的fork方法实现原理 12345678public final ForkJoinTask&lt;V&gt; fork() &#123; Thread t; if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ((ForkJoinWorkerThread)t).workQueue.push(this); else ForkJoinPool.common.externalPush(this); return this;&#125; 2、ForkJoinTask的join方法实现原理 join方法主要作用：阻塞当前线程并等待获取结果 12345678910111213public final V join() &#123; int s; if ((s = doJoin() &amp; DONE_MASK) != NORMAL) reportException(s); return getRawResult(); &#125; private void reportException(int s) &#123; if (s == CANCELLED) throw new CancellationException(); if (s == EXCEPTIONAL) rethrow(getThrowableException());&#125; 1、首先使用dojoin()方法得到当前任务的状态 已完成（NORMAL）：直接返回任务结果 被取消（CANCELLED）：抛出异常 信号（SIGNAL） 出现异常（EXCEPTIONAL）：抛出相应的异常 123456789private int doJoin() &#123; int s; Thread t; ForkJoinWorkerThread wt; ForkJoinPool.WorkQueue w; return (s = status) &lt; 0 ? s : ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ? (w = (wt = (ForkJoinWorkerThread)t).workQueue). tryUnpush(this) &amp;&amp; (s = doExec()) &lt; 0 ? s : wt.pool.awaitJoin(w, this, 0L) : externalAwaitDone();&#125; 查看任务状态，看任务是否已经完成，如果完成则返回任务状态；如果没有完成，则从任务数组中取出任务并执行。 如果任务顺利完成，状态为NORMAL；如果出现异常则记录异常，状态为EXCEPTIONAL 其他四大函数式接口 函数式接口：只有一个方法的接口 1234567@FunctionalInterfacepublic interface Runnable &#123; public abstract void run();&#125;//简化编程模型，在底层大量使用//forEach(消费者类的函数式接口) 四大函数式接口：Consumer、Function、Predicate、Supplier 函数式接口：Function1234public interface Function&lt;T, R&gt; &#123; //传入T，返回R R apply(T t);&#125; 有一个输入参数，有一个输出 1234567891011public static void main(String[] args) throws InterruptedException &#123; //工具类：输出输入的值 Function function = new Function&lt;String, String&gt;() &#123; @Override public String apply(String o) &#123; return o; &#125; &#125;; System.out.println(function.apply(&quot;asd&quot;));&#125; Lambda表达式简化： 123456public static void main(String[] args) throws InterruptedException &#123; //工具类：输出输入的值 Function function = (str)-&gt;&#123;return str;&#125;; System.out.println(function.apply(&quot;asd&quot;));&#125; 断定型接口：Predicate1234@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123; boolean test(T t);&#125; 有一个输入参数，返回布尔值 1234567891011public static void main(String[] args) throws InterruptedException &#123; //判断字符串是否为空 Predicate&lt;String&gt; predicate = new Predicate&lt;String&gt;()&#123; @Override public boolean test(String s) &#123; return s.isEmpty(); &#125; &#125;; System.out.println(predicate.test(&quot;&quot;));&#125; 供给型接口：Supplier1234@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; T get();&#125; 只有返回 12345678public static void main(String[] args) throws InterruptedException &#123; Supplier supplier = new Supplier&lt;String&gt;() &#123; @Override public String get() &#123; return &quot;1024&quot;; &#125; &#125;; &#125; 消费型接口：Consumer1234@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123; void accept(T t);&#125; 只有输入，没有返回值 123456789public static void main(String[] args) throws InterruptedException &#123; Consumer&lt;String&gt; consumer = new Consumer&lt;String&gt;() &#123; @Override public void accept(String o) &#123; System.out.println(o); &#125; &#125;; consumer.accept(&quot;111&quot;);&#125; 总结基础知识 CAS 比较并交换 无锁、自旋锁 ABA问题：加版本号 底层：lock cmpxchg 指令，不是原子的，所以比较之后数据依然会发生改变 对象内存布局 对象（4个部分）： markword（8个字节）：锁信息、GC信息、hashcode 类型指针：指向方法区的class 实例数据 对齐填充 Mark Word的结构为： 锁升级过程 偏向锁 1、背景：多数情况下只有一个线程在运行（StringBuffer的一些sync方法、vector的一些sync方法） 2、获取锁的过程 匿名偏向(Anonymously biased) 在此状态下thread pointer为NULL(0)，意味着还没有线程偏向于这个锁对象。第一个试图获取该锁的线程将会面临这个情况，使用原子CAS指令可将该锁对象绑定于当前线程。这是允许偏向锁的类对象的初始状态。 检查对象的Mark Word是否为可偏向锁状态 如果不是可偏向状态（0），CAS修改本线程id，修改成功就执行同步代码块（线程id 1 01） 如果是可偏向锁状态（1），检查Mark Word存储的线程id是否为当前线程id，如果是则执行同步代码块；如果不是，使用CAS修改线程id为本线程id，修改成功则执行同步代码块；修改不成功，当持有锁的线程到达全局安全点后，挂起该进程，进行锁升级 3、释放锁的过程 有其他线程来获取这个锁，偏向锁的释放采用了一种只有竞争才会释放锁的机制，线程是不会主动去释放偏向锁，需要等待其他线程来竞争。 一个进程使用CAS修改线程id失败就开始偏向锁的撤销 等待全局安全点(在这个是时间点上没有字节码正在执行)。 暂停拥有偏向锁的线程，检查持有偏向锁的线程是否活着 如果不处于活动状态，则将对象头设置为无锁状态（空 0 01） 如果处于活动状态，则挂起持有偏向锁的线程，并将对象头Mark Word的锁记录指针改成当前线程的锁记录，锁**升级为轻量级锁状态(00)**。 轻量级锁 1、背景：大多数情况下线程交替执行，不存在线程并行执行（无法解决线程的竞争问题） 2、偏向锁升级（锁的mark word内偏向线程A） 3、获取锁的过程 在线程进入同步方法、同步块的时候，如果同步对象锁状态为无锁状态(锁标志位为”01”状态，是否为偏向锁为”0”)，虚拟机首先将在当前线程的栈帧中建立一个名为锁记录(Lock Recored)的空间，用于储存锁对象目前的Mark Word的拷贝(官方把这份拷贝加了个Displaced前缀，即Displaced Mark Word)。 将对象头的Mark Word拷贝到线程的锁记录(Lock Recored)中。 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针。如果这个更新成功了，则执行步骤4，否则执行步骤5。 更新成功，这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位将转变为”00”，即表示此对象处于轻量级锁的状态。 更新失败，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，可以直接进入同步块继续执行（将displaced置为null），否则说明这个锁对象已经被其其它线程抢占了。进行自旋执行步骤3，如果自旋结束仍然没有获得锁，轻量级锁就需要膨胀为重量级锁，锁标志位状态值变为”10”，Mark Word中储存就是指向monitor对象的指针，当前线程以及后面等待锁的线程也要进入阻塞状态。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"Redis","slug":"Redis","date":"2022-01-10T08:44:09.000Z","updated":"2022-02-07T14:43:39.354Z","comments":true,"path":"2022/01/10/Redis/","link":"","permalink":"http://example.com/2022/01/10/Redis/","excerpt":"","text":"Redis问题如何保证mysql与缓存一致性？读取缓存读取缓存的方案都是按照下面的流程进行操作的： 更新一致性方案——设置缓存过期时间所有的写操作都以数据库为准，如果数据库写入成功但是缓存更新失败，只要缓存到期时间之后后面读缓存时自然会去数据库读取新的缓存然后更新 更新一致性方案——先更新数据库再更新缓存 被普遍反对！ 原因： 数据安全角度：如果请求A和请求B同时进行操作，A先更新了数据库的一条数据，随后B马上有更新了该条数据，但是可能因为网络延迟等原因，B却比A先更新了缓存，就会出现一种什么情况呢？缓存中的数据并不最新的B更新过的数据，就导致了数据不一致的情况。 业务场景角度：如果是写多读少的业务，这种方案会导致数据还没读缓存就被频繁更新，浪费性能 更新一致性方案——先删除缓存再更新数据库1、问题：脏数据 A进行更新操作，B进行查询操作；A进行写操作前删除了缓存，B读的时候发现没有缓存就会查询数据库，如果A事务没有提交B就会查询到旧值存储到缓存中，就会导致数据不一致问题 2、解决：延时双删 过程： 删除Redis缓存 更新数据库 等待一段时间，删除Redis缓存（等待时间：读数据业务逻辑耗时+几百ms） 目的：确保B读请求结束A写请求能够删除B读请求存储的脏数据 3、问题：第二次删除缓存失败，还是会造成缓存和数据库的不一致 更新一致性方案——先更新数据库再删除缓存缓存更新方案：Cache-Aside Pattern 应用程序应该从缓存中获取数据，获取成功就直接返回，获取失败就从数据库中读取，成功后放入缓存 更新数据时先把数据库存储到数据库中成功后再让缓存失效 问题： 有两个请求A和B，A进行查询同时B进行更新，假设发生下述情况： ①此时缓存刚好失效 ②请求A 就会去查询数据库得到一个旧的值 ③请求B将新的值写入数据库 ④请求B写入成功后删除缓存 ⑤请求A将查到的机制写入缓存，产生脏数据… 但是这种情况的概率很小 如果删除缓存失败怎么办？解决：重试机制 解决：读取binlog异步删除缓存 单线程为什么快？1、为什么不使用多线程？ 减少多线程带来的额外开销和多线程同时访问共享资源的并发问题 2、为什么单线程快？ Redis大部分操作在内存实现 采用高效的数据结构 多路I&#x2F;O复用，能够并发处理大量客户端请求 3、多路I&#x2F;O复用 一个线程处理多个IO流，select&#x2F;epoll机制 该机制允许内核中同时存在多个监听socket和已连接socket；内核会一直监听这些socket上的连接请求或数据请求；一旦有请求到达就交给redis线程处理 select&#x2F;epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。 回调机制：select&#x2F;epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件；这些事件会被放进一个事件队列，redis对事件队列不断处理，Redis处理的时候会调用相应的处理函数，这就实现了基于事件的回调 select、poll、epoll基本的socket编程模型1、服务端和客户端进行通信时，在服务器端通过以下三步来创建监听客户端连接的监听套接字（listening socket） 调用socket函数，创建一个套接字（主动套接字） 调用bind函数，将主动套接字和当前服务器的IP和监听端口进行绑定 调用listen函数，将主动套接字转为监听套接字，开始监听客户端的连接 在完成上述三步之后，服务器端就可以接收客户端的连接请求了，可以运行一个循环流程，在流程中调用accept函数，用于接收客户端连接请求 accept函数是阻塞函数，如果此时一直没有客户端连接请求，那么服务器端执行流程会一直阻塞在accept函数 最后，服务器端可以通过调用recv或者send函数在刚刚返回的已连接套接字上，接收并处理读写请求，或者将数据发送给客户端 12345678listenSocket = socket(); //调用socket系统调用创建一个主动套接字bind(listenSocket); //绑定地址和端口listen(listenSocket); //将默认的主动套接字转换为服务器使用的被动套接字，也就是监听套接字while (1) &#123; //循环监听是否有客户端连接请求到来 connSocket = accept(listenSocket); //接受客户端连接 recv(connsocket); //从客户端读取数据，只能同时处理一个客户端 send(connsocket); //给客户端返回数据，只能同时处理一个客户端&#125; 2、在基本的 Socket 编程模型中，accept 函数只能在一个监听套接字上监听客户端的连接，recv 函数也只能在一个已连接套接字上，等待客户端发送的请求。 3、IO多路复用机制 可以让程序通过调用多路复用函数，同时监听多个套接字上的请求，既包括监听套接字上的请求也包括已连接套接字的请求 select和poll机制实现IO多路复用1、select机制 参数： __nfds：监听的文件描述符数量 *__readfds、*__writefds、*__exceptfds：被监听描述符的三个集合（fd_set结构） *__timeout：监听时阻塞等待的超时时长 监听的事件：读数据事件、写数据事件、异常事件 对于每一个描述符集合，都可以监听1024个描述符 如何使用select机制实现网络通信 调用前，创建好传递给select函数的描述符集合，再创建监听套接字，将套接字的描述符加入到创建好的描述符集合中 调用select函数，把创建好的描述符集合作为参数传递给select函数；程序调用后会发生阻塞，当select函数检测到有描述符就绪后，就会结束阻塞，并返回就绪的文件描述符数量 在描述符集合中查找哪些描述符就绪了，对这些描述符对应的套接字进行处理，在该套接字上进行读写操作 123456789101112131415161718192021222324252627282930313233343536373839int sock_fd,conn_fd; //监听套接字和已连接套接字的变量sock_fd = socket() //创建套接字bind(sock_fd) //绑定套接字listen(sock_fd) //在套接字上进行监听，将套接字转为监听套接字fd_set rset; //被监听的描述符集合，关注描述符上的读事件 int max_fd = sock_fd//初始化rset数组，使用FD_ZERO宏设置每个元素为0 FD_ZERO(&amp;rset);//使用FD_SET宏设置rset数组中位置为sock_fd的文件描述符为1，表示需要监听该文件描述符FD_SET(sock_fd,&amp;rset);//设置超时时间 struct timeval timeout;timeout.tv_sec = 3;timeout.tv_usec = 0; while(1) &#123; //调用select函数，检测rset数组保存的文件描述符是否已有读事件就绪，返回就绪的文件描述符个数 n = select(max_fd+1, &amp;rset, NULL, NULL, &amp;timeout); //调用FD_ISSET宏，在rset数组中检测sock_fd对应的文件描述符是否就绪 if (FD_ISSET(sock_fd, &amp;rset)) &#123; //如果sock_fd已经就绪，表明已有客户端连接；调用accept函数建立连接 conn_fd = accept(); //设置rset数组中位置为conn_fd的文件描述符为1，表示需要监听该文件描述符 FD_SET(conn_fd, &amp;rset); &#125; //依次检查已连接套接字的文件描述符 for (i = 0; i &lt; maxfd; i++) &#123; //调用FD_ISSET宏，在rset数组中检测文件描述符是否就绪 if (FD_ISSET(i, &amp;rset)) &#123; //有数据可读，进行读数据处理 &#125; &#125;&#125; 缺点： 对单个进程监听的文件描述符数量有限 当select函数返回后需要遍历描述符集合找到具体就绪的描述符 2、poll机制 参数： *__fds：pollfd 结构体数组，包含要监听的描述符，以及描述符上要监听的事件类型 12345struct pollfd &#123; int fd; //进行监听的文件描述符 short int events; //要监听的事件类型 short int revents; //实际发生的事件类型&#125;; _nfds：表示*__fds数据元素的个数 _timeout：表示poll函数阻塞的超时事件 通信流程 创建pollfd数组和监听套接字，进行绑定 将监听套接字加入pollfd数组，并设置其监听读事件，也就是客户端的连接请求 循环调用poll函数，检测pollfd数组就绪的文件描述符 如果是连接套接字就绪，表明有客户端连接，使用accept接收连接，并创建已连接套接字，加入pollfd数组，监听读事件 如果是已连接套接字就绪，表明客户端有读写请求，调用recv&#x2F;send函数处理 12345678910111213141516171819202122232425262728293031323334353637383940414243444546int sock_fd,conn_fd; //监听套接字和已连接套接字的变量sock_fd = socket() //创建套接字bind(sock_fd) //绑定套接字listen(sock_fd) //在套接字上进行监听，将套接字转为监听套接字//poll函数可以监听的文件描述符数量，可以大于1024#define MAX_OPEN = 2048//pollfd结构体数组，对应文件描述符struct pollfd client[MAX_OPEN];//将创建的监听套接字加入pollfd数组，并监听其可读事件client[0].fd = sock_fd;client[0].events = POLLRDNORM; maxfd = 0;//初始化client数组其他元素为-1for (i = 1; i &lt; MAX_OPEN; i++) client[i].fd = -1; while(1) &#123; //调用poll函数，检测client数组里的文件描述符是否有就绪的，返回就绪的文件描述符个数 n = poll(client, maxfd+1, &amp;timeout); //如果监听套件字的文件描述符有可读事件，则进行处理 if (client[0].revents &amp; POLLRDNORM) &#123; //有客户端连接；调用accept函数建立连接 conn_fd = accept(); //保存已建立连接套接字 for (i = 1; i &lt; MAX_OPEN; i++)&#123; if (client[i].fd &lt; 0) &#123; client[i].fd = conn_fd; //将已建立连接的文件描述符保存到client数组 client[i].events = POLLRDNORM; //设置该文件描述符监听可读事件 break; &#125; &#125; maxfd = i; &#125; //依次检查已连接套接字的文件描述符 for (i = 1; i &lt; MAX_OPEN; i++) &#123; if (client[i].revents &amp; (POLLRDNORM | POLLERR)) &#123; //有数据可读或发生错误，进行读数据处理或错误处理 &#125; &#125;&#125; 和select函数相比，poll函数允许一次监听超过1024个文件描述符，但是仍然需要遍历每个文件描述符 epoll机制实现IO多路复用1、epoll机制使用epoll_event结构体来记录待监听的文件描述符及其监听的事件类型 events：整数类型变量，取值使用不同的宏定义值 epoll_data_t：联合体变量 fd：记录文件描述符 12345678910111213typedef union epoll_data&#123; ... int fd; //记录文件描述符 ...&#125; epoll_data_t;struct epoll_event&#123; uint32_t events; //epoll监听的事件类型 epoll_data_t data; //应用程序数据&#125;; 2、epoll_create函数 创建一个epoll实例，维护两个结构，分别是记录要监听的文件描述符和已经就绪的文件描述符，对于已经就绪的文件描述符会被返回给用户程序处理 所以就不需要遍历查询哪些文件描述符已经就绪 3、epoll_ctl函数 给被监听的文件描述符添加事件类型 4、epoll_wait函数 获取就绪的文件描述符 12345678910111213141516171819202122232425262728293031323334353637int sock_fd,conn_fd; //监听套接字和已连接套接字的变量sock_fd = socket() //创建套接字bind(sock_fd) //绑定套接字listen(sock_fd) //在套接字上进行监听，将套接字转为监听套接字 epfd = epoll_create(EPOLL_SIZE); //创建epoll实例，//创建epoll_event结构体数组，保存套接字对应文件描述符和监听事件类型 ep_events = (epoll_event*)malloc(sizeof(epoll_event) * EPOLL_SIZE);//创建epoll_event变量struct epoll_event ee//监听读事件ee.events = EPOLLIN;//监听的文件描述符是刚创建的监听套接字ee.data.fd = sock_fd;//将监听套接字加入到监听列表中 epoll_ctl(epfd, EPOLL_CTL_ADD, sock_fd, &amp;ee); while (1) &#123; //等待返回已经就绪的描述符 n = epoll_wait(epfd, ep_events, EPOLL_SIZE, -1); //遍历所有就绪的描述符 for (int i = 0; i &lt; n; i++) &#123; //如果是监听套接字描述符就绪，表明有一个新客户端连接到来 if (ep_events[i].data.fd == sock_fd) &#123; conn_fd = accept(sock_fd); //调用accept()建立连接 ee.events = EPOLLIN; ee.data.fd = conn_fd; //添加对新创建的已连接套接字描述符的监听，监听后续在已连接套接字上的读事件 epoll_ctl(epfd, EPOLL_CTL_ADD, conn_fd, &amp;ee); &#125; else &#123; //如果是已连接套接字描述符就绪，则可以读数据 ...//读取数据并处理 &#125; &#125;&#125; 复习 8大数据类型 string、hash、list、set、sortedSet、Bitmap、HyperLogLog、GEO String类型使用场景 1、命令 最常用：set key value、get key 设置多个：mset k1 v1 k2 v2、mget k1 k2 数值增减： 递增：incr k1 增加指定：incrby k1 2 递减：decr k1 减少指定：decrby k1 2 获取字符串长度：strlen k1 setnx k1 v1、set key value [EX seconds][PX milliseconds] [NX|XX]、setex key seconds value EX：key在多少秒后过期 PX：key在多少毫秒后过期 NX：当key不存在时，才创建key，效果等同于setnx XX：当key存在时，覆盖key 2、应用场景 商品编号、订单号采用incr命令生成 hash应用场景 Map&lt;String,Map&lt;Object,Object&gt;&gt; 1、命令 一次设置一个字段值：hset k1 f1 v1 一次获取一个字段值：hget k1 f1 一次设置多个字段值：hmset k1 f1 v1 f2 v2 一次获取多个字段值：hmget k1 f1 f2 获取所有字段值：hgetall k1 获取某个key内全部数量：hlen k1 删除一个key：hdel k1 增加：hincrby k1 f1 2 2、应用场景 购物车 list应用场景 1、命令 左边添加：lpush k1 1 2 3 4 右边添加：rpush k1 1 2 3 4 查看列表（类似于分页）：lrange k1 0 -1 获取元素个数：llen k1 2、应用场景 点赞 set应用场景 1、命令 添加元素：sadd k1 m1 m2... 删除元素：srem k1 m1 m2... 获取集合中的所有元素：smembers k1 判断元素是否在集合中：sismember k1 m1 获取集合中元素的个数：scard k1 从集合中随机弹出一个元素，元素不删除：srandmember k1 [数字] 从集合中随机弹出一个元素，出一个删一个：spop k1 [数字] 2、集合运算 交：sinter key1 key2 并：sunion key1 key2 差（属于k1不属于k2）：sdiff key1 key2 3、应用场景 微信抽奖小程序 参与：sadd key 用户ID 显示参与人数：scard key 抽奖：spop k1 1 朋友圈点赞 新增点赞：sadd pub:msgID 点赞用户1 点赞用户2 取消点赞：srem pub:msgID 点赞用户1 展示所有点赞过的用户：smembers pub:msgID 点赞用户统计：scard pub:msgID 好友社交关系 共同关注：sinter s1 s2 qq可能认识的人 sdiff s1 s2 zset应用场景 向有序集合中加入元素和分数 1、命令 添加元素：zadd k1 score m1 按照元素分数从小到大顺序返回索引从start到stop之间的所有元素：zrange k1 start stop [withscores] 获取元素的分数：zscore k1 m1 获取排名：zrank k1 m1、zrevrank k1 m1 增加：zincrby key 1 m1 2、场景 热搜 排序显示 分布式锁 入门问题现象 海量用户 高并发 关系型数据库 性能瓶颈：磁盘IO性能低下 扩展瓶颈：数据关系复杂、扩展性差、不便于大规模集群 解决思路 降低磁盘IO次数 去除数据间关系，越简单越好 Nosql1、Nosql：非关系型数据库，作为关系型数据库的补充 2、作用：应对基于海量用户和海量数据前提下的数据处理问题 3、特征： 可扩容、可伸缩 大数据量下高性能 灵活的数据模型 高可用 不支持ACID 4、常见Nosql数据库： Redis 数据在内存，支持持久化 支持多种数据结构的存储 memcache 数据在内存，不支持持久化 MongoDB 文档型数据库 对value（尤其是json）提供丰富的查询功能 Redis简介概念：用C语言开发的一个开源的高性能键值对数据库 特征： 数据间没有必然的关联关系 内部使用单线程 高性能 多数据类型支持 字符串类型 string 列表类型 list 散列类型 hash 集合类型 set 有序集合类型 zset 数据类型都支持丰富操作，且是原子性的 持久化支持，可以进行数据灾难恢复 实现主从同步操作 Redis应用 Redis安装1234567redis-benchmark：性能测试工具redis-check-aof ：修复有问题的AOF文件redis-check-rdb：修复有问题的RDB文件redis-sentinel：Redis集群使用redis-server：Redis服务器启动命令redis-cli：客户端，操作入口 启动： 1redis-server Redis相关知识1、端口：6379 2、默认16个数据库，select 0&#x2F;1&#x2F;2 3、Redis是 单线程+多路IO复用技术 多路复用：使用一个线程检查多个文件描述符（socket）的就绪状态，比如调用select和poll函数，传入多个文件描述符，如果有一个文件描述符就绪，则返回，否则阻塞直到超时。得到就绪状态后进行真正的操作可以在同一个线程里执行，也可以启用线程执行 数据类型介绍业务数据的特殊性 1、作为缓存使用 原始业务功能设计：秒杀、双11、12306 运营平台监控到的突发高频访问数据：突发时政要闻 高频、复杂的统计数据：在线人数、投票排行榜 2、附加功能 系统功能优化或升级：单服务器升级集群、Session管理 3、redis数据存储格式 redis是一个Map，其中所有的数据都是采用key-value的形式存储 数据类型指的是存储的数据类型，也就是value部分的类型，key永远是字符串 对key的操作1234567891011key * ：查看当前库所有的keyexists key ：判断某个key是否存在type key ：查看key的类型 del key ：删除key的数据unlink key ：根据value选择非阻塞删除，仅将keys从元数据中删除，真正的删除在后续异步完成expire key 10 ：为给定key设置过期时间（单位：秒），不设置时间表示永远不过期ttl key：查看剩余时间,-2表示过期，-1表示永不过期dbsize：查看当前数据库key的数量 string1、存储的数据：单个数据，最简单的数据存储类型，最常用 2、存储数据的格式：一个存储空间保存一个数据 3、存储内容：通常使用字符串，如果以整数形式展示，也可以作为数字操作，value最大512M 4、基本操作 添加&#x2F;修改数据：set key value 获取数据：get key 删除数据：del key 1234127.0.0.1:6379&gt; del name (integer) 1 # 操作成功127.0.0.1:6379&gt; del name (integer) 0 # 操作失败 添加&#x2F;修改多个数据：mset key1 value1 key2 value2 获取多个数据：mget key1 key2 获取数据字符串个数（字符串长度）：strlen key 追加信息到原始信息后部（如果原始信息存在就追加，否则新建）：append key value 单数据操作和多数据操作？ 比如：操作三个数据 单数据操作：3次发送、3次回复、运行三次 多数据操作：1次发送，1次回复，运行三次 结论：没有固定结论，对于多数据操作，可能需要切割 5、String类型数据的扩展操作 业务场景：分布式ID 对于大型企业级应用，分表操作是基本操作，使用多张表存储同类型数据，但是对应的主键id必须保证统一性，不能重复，如何解决这个问题？ 解决方案 设置数值数据增加指定范围的值 12345# 加1incr key# 加指定数incrby key incrementincrbyfloat key increment 设置数值减少指定范围的值 12decr keydecrby key increment Sting作为数值操作 string在redis内部存储默认就是一个字符串，当遇到增减类操作incr、dec时会转为数值型进行计算 redis所有操作都是原子性的，采用单线程处理所有的业务，命令一个个执行 注意：如果原始数据不能转为数值或者超越了数值上限，就会报错 redis用于控制数据库主键id，为数据库表主键提供生成策略，保障数据库表的主键唯一性 业务场景：控制时效性 解决方案 设置数据具有指定的生命周期 12setex key seconds valuepsetex key milliseconds value redis控制数据的生命周期，通过数据是否失效控制业务行为，适用于所有具有时效性限定控制的操作 6、数据结构 String的数据结构为简单动态字符串（SDS），是可以修改的字符串，内部结构实现类似于java的arraylist，采用预分配冗余空间的方式来减少内存的频繁分配。 内部为当前字符串实际分配的空间capacity，一般高于实际字符串长度len，当字符串长度小于1M时，扩容都是2倍，如果超过1M，扩容一次只多扩容1M空间。（最长512M） 为什么redis不使用char*？ char*的结构设计 一块连续的内存空间，依次存放字符串的每一个字符；最后一个字符是\\0，标识字符串的结束 影响：如果保存的数据本身含有\\0，那么数据会被截断，这就不符合redis希望能够保持任意数据的需求了 操作函数的复杂度： 求数组长度，需要遍历每一个字符，复杂度是O（n） 追加字符，需要遍历字符串获得末尾完成追加，还需要保证空间足够 原因：不符合redis对字符串高效操作的需求 SDS结构 主要由len（buf数据所保存字符串的长度）、free（未使用的字节数量）、buf[]（保存字符串的数组）三个属性组成 本质还是数据，只是增加了额外的元数据 追加操作： 获取目标字符串长度，根据当前长度和需要追加的长度判断空间是否足够 将数据拷贝到字符串结尾 设置字符串的最新长度 优点 效率高：使用strlen获取字符串长度在SDS中len属性记录了字符串长度，获取字符串长度的时间复杂度为O(1) 数据溢出：SDS会自动扩容 内存重分配策略：解决了字符串在增长和缩短时内存分配问题 空间预分配策略：当修改字符串时，会为SDS分配修改所必要的空间，还会为SDS分配额外使用的空间free，如果字符串修改后len小于1M，那么free和len相等，len值大于等于1M，那么free为1M 惰性空间释放：优化字符串缩短操作，使用free记录剩余空间 List：单键多值1、简介 Redis列表是简单的字符串列表，按照插入顺序排序 可以添加一个元素到列表的头部或者尾部 底层实际上是个双向列表，对两端操作性能很高 2、基本操作 添加数据&#x2F;修改数据 12lpush key value1 [value2]...rpush key value1 [value2]... 获取数据 123lrange key start stop (lrange list1 0 -1) lindex key indexllen key 获取并移除数据 12lpop keyrpop key 3、扩展操作 规定时间内获取并移除数据，阻塞式数据获取 12blpop key1 [key2] timeoutbrpop key1 [key2] timeout 业务场景：微信朋友圈点赞，要求按照点赞顺序显示点赞好友信息 从中间取消元素，移除指定元素 1234lrem key count value例子：lrem list01 1 d 4、注意事项 list中保存的数据是string类型 具有索引概念，但是操作数据通常以队列形式进行入队出队，或者栈的形式 list可以对数据进行分页操作，通常第一页信息来自list，第2页及更多信息通过数据库形式加载 5、数据结构 List的数据结构为快速链表（quickList） 列表元素较少的情况下会使用一块连续的内存存储，这个结构是zipList，它将所有的元素紧挨着一起存储，分配的是一块连续的内存 数据量较多的情况下会使用quickList 因为普通链表需要的附加指针空间太大，会比较浪费空间 Redis将链表和zipList结合起来组成quickList，将多个ziplist使用双向指针串起来使用 Set 对外提供功能与list类似的一个列表的功能，特殊之处在于set可以自动排重，当需要一个列表数据但不希望出现重复时，set是一个很好的选择，并且set提供了判断某个成员是否在集合内的接口 Redis的set时string类型的无序集合，底层是value为null的hash表，复杂度为O（1 ） 1、基本操作 添加数据 1sadd key m1 m2... 获取全部数据 1smembers key 删除数据 1srem key m1 m2 获取集合数据总量 1scard key 判断集合中是否包含指定数据 1sismember key member 2、扩展操作 每位用户首次使用今日头条会设置3个爱好的内容，后期为了增加用户的活跃度，需要让用户对其他信息类别逐渐产生兴趣，如何实现？ 业务分析 系统分析出各个分类的最新或最热点信息条目并组织成set集合 随机挑选其中部分信息 配合用户关注信息分类中的热点信息组织成展示的全信息集合 解决方案 随机获取集合中指定数量的数据 1srandmember key count 随机获取集合中某个数据并将数据移出集合 1spop key 随机推荐类信息检索，如热点歌单推荐 qq好友推荐（共同好友）、微博推荐 解决方案 求两个集合的交、并、差 123sinter key1 key2sunion key1 key2sdiff key1 key2 求两个集合的交、并、差并存储到指定集合 123sinterstore targetkey key1 key2sunionstore targetkey key1 key2sdiffstore targetkey key1 key2 将指定数据从原始集合移动到目标集合 1smove source targetkey member redis应用于同类信息的关联搜索，二度关联搜索、深度关联搜索 显示共同好友、共同关注 3、注意事项 set类型不允许数据重复 set虽然和hash存储结构相同，无法启用hash中的存储值的空间 4、应用场景 集团有1000名员工，内部系统有700多个角色，3000多个业务操作，23000多种数据每位员工具有一个或多个角色，如何进行权限校验？ 解决方案： 根据用户id获取用户所有角色 根据用户所有角色获取用户所有操作权限放入set集合（合并并存储） 根据用户所有角色获取用户所有数据全选放入set集合 统计网站的PV（访问量）、UV（独立访客）、IP（独立IP） PV：被访问的次数 UV：不同用户访问次数 IP：不同IP地址访问次数 解决方案： 建立string类型数据，利用incr统计日访问量（PV） 建立set模型，记录不同cookie数量（UV） 建立set模型，记录不同ip数量（IP） 黑白名单 解决方案： 周期性更新用户黑名单，加入set集合 用户行为信息到达后和黑名单进行比对，确认行为去向 黑名单过滤IP地址：应用于开放游客访问权限的信息源 黑名单过滤设备信息：应用于限定访问设备的信息源 黑名单过滤用户：应用于基于访问权限的信息源 5、数据结构 set的数据结构是dict字典，字典是用哈希表实现的 Java中的HashSet的内部实现使用HashMap，Redis的set结构也是一样的，内部使用hash结构，所有的value指向同一个内部值 Hash1、简介 键值对集合 是一个string类型的field和value的映射表，hash特别适合存储对象 2、基本操作 添加&#x2F;修改数据：hset key field value 获取数据： 12hget key fieldhgetall key 添加&#x2F;修改多个数据：hmset key field1 value1 field2 value2 获取多个数据：hmget key field1 field2 获取哈希表中字段的数量：hlen key 获取哈希表中是否存在指定字段：hexists key field 3、扩展操作 获取哈希表所有的字段名或字段值 12hkeys keyhvals key 设置指定字段的数值数据增加指定范围的值 12hincrby key field incrementhincrbyfloat key field increment 4、注意事项 hash类型的value只能存储字符串 每个hash可以存储2^32-1个 hgetall操作可以获取全部属性，如果field过多，遍历效率会很低，有可能成为数据访问瓶颈 4、应用场景 购物车设计和实现 业务分析 添加、浏览、更改数量、删除、清空 解决方案 用户id为key，每位客户创建一个hash存储结构存储对应的购物车信息 商品编号为field，购买数量为value 添加商品：追加全新的field和数量value 浏览：遍历hash 更改数量：自增&#x2F;自减，设置value值 删除商品：删除field 清空：删除key 问题：当前只是将数据存储到了redis中，并没有起到加速的作用，商品信息还需要二次查询数据库 每条商品记录保存为两条field field1用于保存购买数量 命名格式：商品id：nums 数据：数值 field2用于保存购物车显示的信息，包括文字描述、图片地址等 命名格式：商品id：info 数据：json 12345678127.0.0.1:6379&gt; hmset 004 g01:nums 100 g01:info &#123;...&#125; OK 127.0.0.1:6379&gt; hgetall 004 1) &quot;g01:nums&quot; 2) &quot;100&quot; 3) &quot;g01:info&quot; 4) &quot;&#123;...&#125;&quot; 127.0.0.1:6379&gt; 优化：商品相同，会出现信息重复，可以将field2独立成hash 12# 如果key中对应的field有vlaue，什么都不做，没有值就加进去hsetnx key field value 抢购商品 解决方案： 以商家id作为key 参与抢购的商品id作为field 数量为value 使用降值的方式控制 5、数据结构 Hash对应的数据结构有两种：ziplist、hashtable field-value长度较短且个数较少，使用ziplist field-value长度较长且个数较多，使用hashtable Hash数据结构 两个问题：哈希冲突、rehash Redis解决方案： 哈希冲突：链式哈希 rehash：渐进式rehash 1、链式哈希 用链表把映射到hash表同一个桶中的键连接起来 2、rehash redis准备了两个哈希表用于rehash时交替保存数据 Zset有序集合 新的存储需求：数据排序有利于数据有效展示，需要提供一种可以根据自身特征进行排序的方式 需要的存储结构：新的存储模型，可以保存可排序的数据 zset类型：在set的存储结构基础上添加可排序字段 score 1、基本操作 添加数据 1zadd key score1 m1 score2 m2 获取全部数据，已经排序 1234# 从小到大zrange key start stop 【withscores】# 从大到小zrevrange key start stop 【withscores】 删除数据 1zrem key m1 m2 m3... 按条件获取数据 12zrangebyscore key min max [withscores][limit]zrevrangebyscore key max min [withscores] 条件删除数据 12zremrangebyrank key start stopzremrangebyscore key min max 获取集合数据总量 12zcard keyzcount key min max 集合交、并操作 12zinterstore target numkeys key1 key2zunionstore target numkeys key1 key2 2、扩展操作 电影TOP10 对资源建立排序依据 解决方案 获取数据对应的索引（排名） 12zrank key memberzrevrank key member score值获取与修改 12zscore key memberzincrby key increment member 3、注意事项 score有范围，64位 score保存的数据可以是一个双精度double值，基于双精度浮点数的特征可能会丢失精度，使用时要慎重 zset底层存储还是基于set结构，因此数据不能重复，如果重复添加相同数据，score会被覆盖，保留最后一次修改的结果 4、应用场景 基于时效性任务管理 试用VIP，VIP到期之后，如果有效管理此类信息，即便对于正式VIP用户也存在对应的管理方式 解决方案 将处理时间记录为score值 记录下一个要处理的时间，当到期后处理对应任务，移除redis中的记录，记录下一个要处理的时间 新任务加入时，判定并更新当前下一个要处理的任务时间 为了提升性能，通常将任务根据特征存储成若干个zset，例如1小时内、1天内等，操作时逐级提升，将即将操作的若干个任务纳入1小时内处理的队列中 获取当前系统时间：time 权重任务队列&#x2F;消息队列 解决方案 对于带权重的任务，优先处理权重高的任务，采用score记录权重 多条件任务权重 如果权限过多，需要对排序score值进行处理 5、数据结构 zset是Redis提供的一个非常特别的数据结构，一方面等价于java的Map&lt;String,Double&gt;，可以给每个元素value赋予一个权重score，另一方面又类似于TreeSet，内部的元素会按照score进行排序，得到每个元素的名次，还可以根据score的范围获取元素的列表 底层使用了两个数据结构： hash，hash的作用是关联value和score，保障元素value的唯一性，可以通过元素value找到对应的score 跳表，目的是给value排序，根据score的范围获取元素列表 为什么不用平衡二叉树？ 更加节省内存 遍历更加友好 更容易实现和维护 跳表1、可以实现二分查找的有序链表 2、查找的时间复杂度 过程：从最高级索引开始，一层一层遍历最后下沉到原始链表 时间复杂度&#x3D;索引高度*每层索引遍历元素的个数 O（Logn） 3、空间复杂度 假设每两个结点会抽出一个结点作为上一级索引的结点，原始的链表有n个元素，则一级索引元素个数为n&#x2F;2，二级索引元素个数n&#x2F;4，所以索引节点的总和是：n&#x2F;2 + n&#x2F;4 + n&#x2F;8 + … + 8 + 4 + 2 &#x3D; n-2，**空间复杂度是 O(n)**。 如果每三个结点抽一个结点做为索引，索引总和数就是 n&#x2F;3 + n&#x2F;9 + n&#x2F;27 + … + 9 + 3 + 1&#x3D; n&#x2F;2，减少了一半 因此，可以通过减少索引数来减少空间复杂度 O（n） 4、插入数据 概率算法：告诉我们这个元素需要插入到几级索引中 最坏时间复杂度：O（logn） Redis配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136################################## NETWORK ###################################### 表示只能本地访问bind 127.0.0.1 ::1# 表示开启保护模式protected-mode yesport 6379# 设置tcp的backlog，backlog是一个连接队列，队列总和=未完成三次握手队列+已经完成三次握手队列tcp-backlog 511# 超时时间 0表示永不超时timeout 0# 表示检查心跳的时间tcp-keepalive 300################################# TLS/SSL ###################################################################### GENERAL ###################################### redis后台启动daemonize no# 保存进程号pidfile /var/run/redis_6379.pid# 日志级别：# debug (a lot of information, useful for development/testing)# verbose (many rarely useful info, but not a mess like the debug level)# notice (moderately verbose, what you want in production probably)# warning (only very important / critical messages are logged)loglevel notice# 日志输出文件路径logfile &quot;&quot;# 数据库个数databases 16always-show-logo noset-proc-title yes################################ SNAPSHOTTING ################################stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename dump.rdbdir /usr/local/var/db/redis/################################# REPLICATION #################################replica-serve-stale-data yesreplica-read-only yesrepl-diskless-sync norepl-diskless-sync-delay 5############################### KEYS TRACKING ################################################################### SECURITY ###################################################################### CLIENTS ################################################################## MEMORY MANAGEMENT ############################################################# LAZY FREEING ####################################lazyfree-lazy-eviction nolazyfree-lazy-expire nolazyfree-lazy-server-del noreplica-lazy-flush nolazyfree-lazy-user-del nolazyfree-lazy-user-flush no################################ THREADED I/O ############################################################# KERNEL OOM CONTROL ##############################oom-score-adj nooom-score-adj-values 0 200 800#################### KERNEL transparent hugepage CONTROL ######################disable-thp yes############################## APPEND ONLY MODE ###############################appendonly nono-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yesaof-use-rdb-preamble yes################################ LUA SCRIPTING ###############################lua-time-limit 5000################################ REDIS CLUSTER ######################################################### CLUSTER DOCKER/NAT support ########################################################## SLOW LOG ###################################slowlog-max-len 128################################ LATENCY MONITOR ############################################################# GOPHER SERVER ################################################################ ADVANCED CONFIG ############################### 发布和订阅1、Reds发布订阅是一种消息通信模式 2、Redis客户端可以订阅任意数量的频道 3、命令行实现 打开一个客户端订阅channel1 1subscribe channel1 打开另外一个客户端，给channel1发布消息 1publish channel1 hello Bitmaps1、简介 本身不是一种数据类型，实际上是字符串，但是可以对字符串的位进行操作 单独提供一套命令，在redis中使用bitmaps和 使用字符串的方法不同。可以把bitmaps想象成一个以位为单位的数组，数组的每个单元存储0和1 HyperLogLogGeospatital案例 微信接收消息默认将最近接收的消息置顶，多个好友及订阅号同时发消息，该排序会不停进行交替，同时还可以将重要的会话设置为置顶，一旦用户离线后，再次打开微信时消息怎么按顺序展示？ 依赖list的数据具有顺序的特征 对置顶好友和普通好友分别创建独立的list 当某个list接受到用户消息后，将消息发送方的id从list的一侧加入list 多个相同id加入需要先删除 先推送置顶会话list 通用命令key通用命令key特征1、key是一个字符串，通过key获取redis保存的数据 key应该设计哪些操作？ 对于key自身状态相关操作 对于key有效性控制相关操作 对于key快速查询 key基本操作1、删除指定key 1del key 2、获取key是否存在 1exists key 3、获取key类型 1type key key扩展操作（时效性）1、为指定key设置有效期 1234expire key secondspexpire key millisecondsexpireat key timestamppexpireat key milliseconds-timestamp 2、获取key有效期 -2：不存在 -1：存在 当前有效时长 12ttl keypttl key 3、切换key转换到永久性 1persist key key扩展操作（查询模式）1、查询key Keys * 查询索引 Keys it* 查询所有以it开头的 keys ??h 查询前面两个字符任意，后面以h结尾 keys user:? 查询所有以user：开头，最后一个字符任意 1keys pattern key其他操作1、为key改名字 1234# 同名就覆盖rename key newkey# 如果不存在改名renamenx key newkey 2、对所有key排序 1sort 3、其他key 通用操作 1help @generic 数据库通用命令 key重复问题 1、切换数据库 1select index 2、其他操作 123quitping echo message 3、数据移动 1move key db_index Jedis12345678910public void testJedis()&#123; //1、连接redis Jedis jedis = new Jedis(&quot;192.168.164.134&quot;,6379); //2、操作redis jedis.select(2); jedis.set(&quot;name&quot;,&quot;zhang&quot;); System.out.println(jedis.get(&quot;name&quot;)); //3、关闭连接 jedis.close();&#125; 事务和锁 Redis事务是一个单独的隔离操作，事务中的所有命令都会序列化、按顺序执行。事务在执行的过程中，不会被其他客户端发送的命令请求打断 Redis事务的主要作用是串联多个命令防止别的命令插队 Multi、Exec、discard从输入multi命令开始，输入的命令都会依次进入命令队列中，但不会执行，直到输入exec奇偶，redis将之前的命令依次执行。 组队过程中可以使用discard放弃组队 如果组队中命令出现错误，那么所有的命令都不会执行； 如果执行出现运行错误，那么正确的命令会被执行，只有错误的命令不执行。 事务冲突 悲观锁每次拿数据的时候认为别人会修改，所以每次在拿数据的时候会加上锁，这样别人想去拿数据就会阻塞。 乐观锁使用版本号机制 适用于多读的应用类型，这样可以提高吞吐量，redis就是使用这种check-and-set机制实现事务的 watch key在执行multi之前，先执行watch key1 [key2]，可以监视一个或多个key。 如果在事务执行之前这些key被其他命令改动，那么事务被打断，监控一直持续到EXEC命令 事务三特性1、单独的隔离操作 事务的所有命令都会序列化、按顺序的执行。事务在执行过程中不会被其他客户端发送的命令请求打断 2、没有隔离级别的概念 队列的命令在提交之前都不会执行 3、不保证原子性 事务中如果有一条命令执行失败，后面的命令仍然会执行，不回滚 秒杀案例 set集合判断用户是否重复秒杀操作：sismember 库存-1：decr 问题： 连接超时问题：使用连接池解决 超卖问题 解决方案： 乐观锁 1234567891011121314151617//watchjedis.watch(kcKey);//获取库存，如果库存为null，秒杀开没有开始//如果商品数量小于1，秒杀结束//开始秒杀//使用事务Transaction multi = jedis.multi();//组队操作multi.decr(kcKey);multi.sadd(userKey,uid);//执行List&lt;Object&gt; results = multi.exec();if(results==null || results.size()==0)&#123; jedis.close(); &#125; 库存遗留问题 乐观锁造成库存遗留问题 解决： LUA脚本 将复杂的或者多步的redis操作，写为一个脚本，一次提交给redis执行，减少反复连接redis的次数 lua脚本类似redis的事务，有一定的原子性，不会被其他命令插队 利用lua脚本淘汰用户，解决超卖问题 通过lua解决争抢问题，实际上是redis利用单线程的特性，用任务队列的方式解决多任务并发问题 分布式锁 超卖问题，避免一件商品被多个人修改 业务分析： 使用watch监控一个key有没有改变不能解决问题，需要监控的是具体数据 虽然redis是单线程的，但是多个客户端对同一数据进行操作，如何避免不被同时修改？ 解决方案 使用setnx设置一个公共锁：利用setnx命令返回值特征，有值就返回设置失败（无控制权），无值则返回设置成功（有控制权），操作完毕通过del操作释放锁 1setnx lock-key value 业务场景 依赖分布式锁的机制，某个用户操作时对应客户端当即，且此时已经获取到锁，如何解决？ 业务分析： 由于锁操作由用户控制加锁解锁，必定会存在加锁后不解锁的风险 需要解锁操作不能仅依赖用户控制，系统级别要给出保底处理方案 解决方案 使用expire为锁key添加时间限制 12expire lock-key secondpexpire lock-key milliseconds 持久化 什么是持久化？ 持久化：利用永久性存储介质将数据进行保存，在特定的时间将保存的数据进行恢复的工作机制 为什么要进行持久化？ 防止数据的意外丢失，确保数据安全 持久化过程保存什么？ 1、RDB：将当前数据状态进行保存，快照形式，存储数据结果，存储格式简单，关注点在数据（全量快照） 2、AOF：将数据的操作过程进行保存，日志形式，存储操作过程，存储格式复杂，关注点在数据的操作过程 RDB 谁？什么时间？干什么事情？ 谁：redis操作者 什么时间：即时 干什么事情：保存数据 save、bgsave1、命令： 1save 2、save指令相关配置 3、save工作原理 save指令会阻塞当前Redis服务器，线上环境不建议使用 数据量过大，单线程执行方式造成效率过低如何处理？ 后台执行 谁：使用者 什么时间：合理的时间 干什么事：保存数据 1、命令 1bgsave 2、作用 手动启动后台保存操作，但是不是立即执行的 12127.0.0.1:6379&gt; bgsave Background saving started 3、工作原理 bgsave是针对save阻塞问题做的优化，Redis内部所涉及的RDB操作都采用bgsave方式 快照时数据能够修改吗？ Redis借助操作系统提供的写时复制（COW），在执行快照的时候能够正常处理些操作 bgsave子进程是由主线程fork生成的，可以共享主线程的内存数据；如果主线程要修改一块数据，那么这个数据块就会被复制一份，主线程在这个数据副本上进行修改。bgsave可以继续把原来的数据写入rdb 这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响 自动执行 反复执行保存指令，忘记了怎么办？不知道数据产生了多少变化？何时保存？ 自动执行 谁：redis服务器发起指令（基于条件） 什么时间：满足条件 干什么事情：保存数据 1、配置 1save second changes 作用：满足限定时间范围内（second）key的变化数量达到指定数量（changes）即进行持久化 2、工作原理 4、原理 save配置要根据实际业务设置，随意设置会出现问题 使用的是bgsave 对比 优点和缺点1、优点 存储效率高 内部存储的是redis在某个时间点的数据快照 速度比AOF快 应用：服务器中每X个小时执行bgsave备份，将rdb文件拷贝到远程机器中，用于灾难恢复 2、缺点 无法做到实时持久化，具有较大可能丢失数据 bgsave需要fork操作创建子进程，要牺牲一些性能 redis众多版本没有进行rdb的格式统一，可能出现兼容问题 AOF RDB的弊端： 数据量大，效率低、IO性能低 基于fork创建子进程，内存产生额外消耗 宕机带来的数据丢失风险 解决思路 不写全数据，仅记录部分数据 改记录数据为记录操作过程 对所有操作均进行记录，排除丢失数据的风险 1、AOF概念：以独立日志的方式记录每次写命令，重启时再重新执行AOF中命令来恢复数据，与RDB相比可以简单描述为改记录数据为记录操作过程 2、主要作用：解决了数据持久化的实时性，目前已经是Redis持久化的主流方式 写数据的过程 4、AOF功能开启 配置：开启AOF持久化功能 1appendonly yes 配置：AOF写数据策略 1appendfsync always|everysec|no 风险1、如果刚执行完一个命令就宕机了，这个命令和数据会有丢失的风险 2、AOF日志在主线程执行，在把日志写入磁盘时，磁盘写压力大，导致写盘很慢，导致后面操作无法执行 回写策略三个写数据的策略 always：每次写入操作均同步到AOF文件中，数据零误差，性能较低 everysec：每秒将缓冲区的指令同步到AOF文件中，数据准确性较高，性能较高，在系统突然宕机的情况下丢失1s的数据 no：操作系统控制每次同步到AOF文件的周期，过程不可控制 AOF重写随着命令不断写入AOF，文件会越来越大，为了解决这个问题，Redis引入了AOF重写机制压缩文件体积，AOF文件重写是将Redis进程内的数据转化为写命令同步到新AOF文件的过程。 简单的说，就是将同一个数据的若干执行结果转化为最终结果数据对应的指令进行记录 作用： 降低磁盘占用量 提高持久化效率 降低恢复数据的效率 规则： 进程内已超时的数据不再写入文件 忽略无效指令，重写时使用进程内数据直接生成，新的AOF只保留最终数据的写入命令 对同一个数据的多条命令进行合并 把rdb快照以二进制的形式附在新的aof头部 重写会阻塞吗？ 重写过程由后台子进程来完成，这也是为了避免阻塞主线程，导致数据库性能下降 一个拷贝，两处日志 一个拷贝：每次执行重写时候，主线程fork出后台的bgrewriteaof子进程。此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志 两处日志：如果有写操作，第一处日志就是指正在使用的AOF日志，Redis会把这个操作写到它的缓冲区；第二处日志指的是重写日志 RDB和AOF区别 如何选择1、对数据非常敏感，建议使用默认的AOF持久化方案 AOF持久化策略使用everysecond，每秒钟fsync一次，该策略redis仍可以保持很好的处理性能，当出现问题，最多丢失1s数据 注意：AOF文件存储体积大，且恢复速度慢 2、数据呈现阶段有效性，建议使用RDB持久化方案 数据可以良好的做到阶段内无丢失，且恢复速度较快 注意：利用RDB实现紧凑数据持久化会降低Redis性能 3、综合比对 RDB和AOF是一种权衡 不能承受分钟以内的数据丢失，对业务数据敏感，使用AOF 能够承受分钟以内的数据丢失，且追求大数据集的恢复速度，使用RDB 灾难恢复使用RDB 双保险策略，同时开启RDB和AOF，重启后Redis优先使用AOF恢复数据 持久化应用场景 不需要持久化：1、3、4、9、12（长期）、15 持久化：5、6、7、12（短期）、13、16 删除策略过期数据Redis是一种内存级的数据库，所有数据均存放在内存中，内存中的数据可以通过TTL指令获取其状态 XX：具有时效性的数据 -1：永久有效的数据 -2：已经过期的数据或被删除的数据或未定义的数据 删除策略时效性数据的存储结构 删除策略的目标 在内存占用和cpu占用之间寻找平衡点 定时删除1、创建一个定时器，当key设置有过期时间，且过期时间到达，由定时器任务立即执行对键的删除操作 2、优点：节约内存，快速释放 3、缺点：cpu压力很大，会影响redis服务器的响应时长、吞吐量 4、总结：时间换空间 惰性删除1、数据到达过期时间不处理，等下次访问该数据时如果已经过期就删除 2、expirelfNeeded()：检查数据过期 3、优点：节约cpu性能 4、缺点：内存压力很大，出现长期占用内存的数据 5、总结：存储空间换处理器性能 定期删除1、过程 Redis服务器初始化时，读取配置server.hz的值，默认为10； 每秒钟执行server.hz次serverCron()-&gt;databasesCron()-&gt; activeExpireCycle() activeExpireCycle()对每个expires[*]逐一检测，随机挑选w个key检测 如果key超时就删除 如果一轮中删除的key数量&gt;w * 0.25循环该过程 如果小于等于就检查下一个expires[*]，0-15循环 w值在配置文件中设置 参数current_db用于记录activeExpireCycle()进入哪一个expires[*]执行 如果activeExpireCycle()执行时间到期，下次从current_对比继续执行 2、周期性轮询redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频率 3、特点： cpu性能占用设置有峰值，检测频率可以自定义设置 内存压力不是很大，长期占用内存的冷数据会被持续清理 4、总结：周期性抽查 比对1、定时删除 定义计时器，过期就删除 节约内存，无占用 不分时间占用cpu 2、惰性删除 下次访问就删除 内存占用严重 cpu利用率高 3、定期删除 轮询redis库，随机抽查 每秒花费固定的cpu资源维护 内存淘汰机制 如果新数据进入redis时，如果内存不足怎么办？ redis使用内存存储数据，执行每一个命令前，会调用freeMemoryifNeeded()检测内存是否充足 如果内存不满足新加入数据的最低存储要求，redis要临时删除一些数据，清理数据的策略为逐出算法 配置最大可用内存 1maxmemory 每次选取待删除数据个数 1maxmemory-samples 删除策略 1maxmemory-policy 检测易失数据可能会过期的key voliate-lru：挑选最近最少使用（时间上）的数据进行数据淘汰（LRU） voliate-lfu：挑选最近使用次数最少（次数上）的数据淘汰（LFU） volatile-ttl：挑选将要过期的数据淘汰 volatile-random：任意选择数据淘汰 检测全库数据所有key allkeys-lru allkeys-lfu allkeys-random：任意选择数据淘汰 放弃数据驱逐 noenviction：禁止驱逐 LRU算法 是什么？ Least Recently used，常用页面置换算法 选择最近最久未使用的数据淘汰 https://leetcode-cn.com/problems/lru-cache/ 核心：哈希链表 本质：HashMap+DoubleLinkedList 手写LRU1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public class LRUCache&#123; //Node节点作为数据载体 class Node&lt;k,v&gt;&#123; k key; v value; Node&lt;k,v&gt; prev; Node&lt;k,v&gt; next; public Node()&#123; this.prev=this.next=null; &#125; public Node(k key,v value)&#123; this.key=key; this.value=value; this.prev=this.next=null; &#125; &#125; //双向链表，里面放node class DoubleLinkedList&lt;k,v&gt;&#123; Node&lt;k,v&gt; head; Node&lt;k,v&gt; tail; public DoubleLinkedList() &#123; head=new Node&lt;&gt;(); tail=new Node&lt;&gt;(); head.next=tail; tail.prev=head; &#125; //添加到头 public void addHead(Node&lt;k,v&gt; node)&#123; node.prev=head; node.next=tail.next; head.next.prev=node; head.next=node; &#125; //删除节点 public void removeNode(Node&lt;k,v&gt; node)&#123; node.next.prev=node.prev; node.prev.next=node.next; node.next=null; node.prev=null; &#125; //获得最后一个节点 public Node&lt;k,v&gt; getLast()&#123; return tail.prev; &#125; &#125; //缓存坑位 private int capacity; Map&lt;Integer,Node&lt;Integer,Integer&gt;&gt; map; DoubleLinkedList&lt;Integer,Integer&gt; doubleLinkedList; public LRUCache(int capacity)&#123; this.capacity=capacity; map=new HashMap&lt;&gt;(); doubleLinkedList=new DoubleLinkedList&lt;&gt;(); &#125; public int get(int key)&#123; if(!map.containsKey(key))&#123; return -1; &#125; Node&lt;Integer, Integer&gt; node = map.get(key); doubleLinkedList.removeNode(node); doubleLinkedList.addHead(node); return node.value; &#125; public void put(int key,int value)&#123; if(map.containsKey(key))&#123; Node&lt;Integer, Integer&gt; node = map.get(key); node.value=value; map.put(key,node); doubleLinkedList.removeNode(node); doubleLinkedList.addHead(node); &#125;else &#123; if(map.size()==capacity)&#123; Node&lt;Integer, Integer&gt; last = doubleLinkedList.getLast(); map.remove(last.key); doubleLinkedList.removeNode(last); &#125;else &#123; Node&lt;Integer,Integer&gt; newNode = new Node&lt;&gt;(key,value); map.put(key,newNode); doubleLinkedList.addHead(newNode); &#125; &#125; &#125;&#125; 主从复制1、是什么？ 主机数据更新后根据配置和策略，自动同步到备机的master&#x2F;slaver机制，master以写为主，slave以读为主 2、用处 读写分离 容灾恢复 主从复制原理1、从服务器连接上主服务器之后，从服务器向主服务器发送进行数据同步消息 2、主服务器接到从服务器发送过来的同步消息之后，把主服务器数据进行持久化，rdb文件，把rdb文件发送给从服务器，从服务器读取rdb文件 3、每次主服务器进行写操作后，和从服务器进行数据同步 主从库如何进行第一次同步1、第一阶段：主从库间建立连接、协商同步的过程。从库和主库建立起来连接，告诉主库即将进行同步，主库确认回复后主从库就可以开始同步了 从库给主库发送psync命令，表示要进行数据同步 主库收到psync命令后会用FULLRESYNC响应命令带上两个参数（表示第一次复制采用全量复制） 2、第二阶段：主库将所有数据同步给从库，从库收到数据后在本地完成数据加载 主库执行bgsave命令生成rdb文件，将文件发送给从库 从库清空数据库，加载rdb文件 同步过程中的写操作主库会在内存中用buffer记录写操作 3、第三阶段：主库把第二阶段执行过程中新收到的写命令发送给从库 主-从-从模式 如果从库数量很多，都需要和主库进行全量复制，就会导致主库忙于fork子进程生成RDB文件，进行数据全量同步，“主-从-从”可以分担主库压力 redis cluster模式下，无法使用主-从-从的级联模式 主从库间网络断了怎么办1、网络断后，主从库会采用增量复制的方式继续同步 2、主库会把断连期间收到的写操作命令写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。 3、repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。 哨兵机制 能够后台监控主机是否故障，如果故障了根据投票数量自动将从库转换为主库 主要功能包括： 主节点生存检测，通过ping监控 自动故障转移：当主节点无法正常工作时，Sentinel将启动自动故障转移操作。它将与发生故障的主节点处于主从关系的从节点之一升级到新的主节点，并将其他从节点指向新的主节点； 通知：通知其他从库和客户端新的主库 监控：主观下线和客观下线1、哨兵进程会使用ping命令检测它自己和主、从库的网络连接情况，用来判断实例的状态 2、主观下线：发现从库超时了就标记为主观下线 3、误判一般会发生在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况，如何减少误判？ 哨兵集群：通常采用多实例组成的集群模式进行部署，引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状态不好而误判主库下线的情况。 4、客观下线：只有大多数的哨兵实例，都判断主库已经“主观下线”了，主库才会被标记为“客观下线” 选定新的主库1、过程：筛选+打分 先按一定的照筛选条件把不符合条件的从库去掉，再按照一定的规则给剩下的从库打分 2、筛选条件 检查从库的在线状态、判断之前的网络连接状态 3、打分 第一轮：优先级高的从库得分高（slave-priority配置项） 第二轮：和旧主库同步程度最接近的从库得分高 第三轮：ID号小的从库得分高（最早连接上） 哨兵集群在配置哨兵集群的时候，配置哨兵的信息需要设置主库的IP和端口，并没有配置其他哨兵的连接信息 基于pub&#x2F;sub机制的哨兵集群组成1、哨兵实例之间可以相互发现，归功于Redis提供的发布&#x2F;订阅机制 2、哨兵间如何互相知道彼此地址？ 哨兵只要和主库建立起了连接，就可以在主库上发布消息（比如发布自己的连接信息），同时也可以从主库上订阅消息，获得其他哨兵发布的连接信息 频道：__sentinel__:hello 3、哨兵如何知道从库的IP地址和端口？ 哨兵向主库发送INFO命令，主库返回从库列表给哨兵 基于pub&#x2F;sub机制的客户端事件通知1、哨兵是特殊的redis实例 每个哨兵也提供发布&#x2F;订阅机制，客户端可以从哨兵订阅信息 2、哨兵提供不同的消息订阅频道 由哪个哨兵执行主从切换？1、判断客观观下线 任何一个哨兵只要判断主库“主观下线”后就会给其他哨兵发送is-master-down-by-addr 命令，其他哨兵也会根据自己和主库的连接情况做出响应 一个哨兵获得了所需要的赞同票数后可以标记主库“客观下线” 此时这个哨兵会给其他哨兵发送命令，表示希望自己来执行主从切换，并让其他哨兵投票（Leader选取） 2、Leader选取 需要满足两个条件： 拿到半数以上的赞成票 拿到的票数大于等于哨兵配置文件的quorum值 3、需要注意的是，如果哨兵集群只有 2 个实例，此时，一个哨兵要想成为 Leader，必须获得 2 票，而不是 1 票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切换的。因此，通常我们至少会配置 3 个哨兵实例。这一点很重要，你在实际应用时可不能忽略了。 切片集群1、概念 切片集群也叫分片集群，指启动多个Redis实例组成一个集群，然后按照一定的规则将收到的数据划分成多份，每一份用一个实例来保存 如何保存更多数据？1、为了保存大量的数据，使用大内存云主机（纵向扩展）和切片集群（横向扩展）两种方法 纵向扩展：升级单个redis实例的资源配置，包括增加内存容量、增加磁盘容量等 横向扩展：增加redis实例的个数 2、使用横向扩展要解决的两个问题： 数据在多个实例如何分布？ 客户端怎么确定想要访问的数据在哪里？ 数据切片和实例的对应分布关系Redis Cluster1、在redis 3.0之后，官方提供了Redis Cluster的方案用于实现切片集群，规定了数据和实例的对应规则 2、Slot Redis Cluster一个切片集群由16384个哈希槽 哈希槽类似于数据分区，每个键值对都会根据key被映射到一个哈希槽中 3、映射过程 根据key按照CRC16算法计算一个16bit的值 用这个值对16384取模，得到哈希槽 4、哈希槽的映射 使用cluster create创建集群，此时redis会自动把这些槽平均分布在集群实例上 客户端如何定位数据？一般来说，客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。但是，在集群刚刚创建的时候，每个实例只知道自己被分配了哪些哈希槽，是不知道其他实例拥有的哈希槽信息的 应用问题缓存穿透 1、背景 应用服务器压力变大了 redis命中率降低，一直查询数据库 2、现象 redis查询不到数据 出现大量非正常url访问 3、解决方案 **对空值缓存 **：如果一个查询返回的数据为空，把这个结果进行缓存 设置可访问的白名单：使用bitmaps定义一个可访问的名单，名单id作为bitmaps的偏移量，每次访问和bitmap里面的id做比较 采用布隆过滤器 缓存击穿 1、现象 数据库访问压力瞬间增加 redis没有出现大量key过期 redis正常运行 2、原因 redis的某个key过期，大量访问使用这个key 3、解决方案 预先设置热门数据 事时调整：监控热门数据，实时调整key的过期时长 使用锁： 缓存失效的时候，不是立即去load db 先使用缓存工具的某些成功操作返回值的操作（redis的setnx）去set一个mutex key 操作返回成功时，再进行load db的操作，并回设缓存，删除mutex key 操作返回失败，说明有线程在load db，当前线程睡眠一段时间重试 缓存雪崩 1、现象 数据库压力变大，服务器崩溃 大量key集中过期 2、解决方案 构建多级缓存架构：ngnix缓存+redis缓存+其他缓存 使用锁：保证不会有大量线程对数据库一次性进行读写，从而避免失效时出现大量并发请求 设置过期标志更新缓存：记录缓存数据是否过期，如果过期会触发通知另外的线程在后台更新实际key的缓存 分散过期时间 分布式锁1、使用setnx上锁，使用del释放锁 2、锁一直没有释放，设置key的过期时间，自动释放 12setnx user 1expire 10 3、上锁之后突然出现异常，无法设置过期时间 12上锁，设置过期时间set 10 nx ex 10","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"MySQL","slug":"mysql","date":"2022-01-08T11:55:11.000Z","updated":"2022-02-07T14:44:09.349Z","comments":true,"path":"2022/01/08/mysql/","link":"","permalink":"http://example.com/2022/01/08/mysql/","excerpt":"","text":"MySQL 问题 关系型数据库和非关系型数据库 关系型数据库最典型的数据结构是表，由二维表及其之间的联系所组成的一个数据组织。 优点： 1、易于维护：都是使用表结构，格式一致； 2、使用方便：SQL语言通用，可用于复杂查询； 3、复杂操作：支持SQL，可用于一个表以及多个表之间非常复杂的查询。 缺点： 1、读写性能比较差，尤其是海量数据的高效率读写； 2、固定的表结构，灵活度稍欠； 3、高并发读写需求，传统关系型数据库来说，硬盘I&#x2F;O是一个很大的瓶颈。 非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合，可以是文档或者键值对等。 优点： 1、格式灵活：存储数据的格式可以是key,value形式、文档形式、图片形式等等，文档形式、图片形式等等，使用灵活，应用场景广泛，而关系型数据库则只支持基础类型。 2、速度快：nosql可以使用硬盘或者随机存储器作为载体，而关系型数据库只能使用硬盘； 3、高扩展性； 4、成本低：nosql数据库部署简单，基本都是开源软件。 缺点： 1、不提供sql支持，学习和使用成本较高； 2、无事务处理； 3、数据结构相对复杂，复杂查询方面稍欠。 为什么使用B+树？ 1、哈希表：只有精确匹配索引所有列的查询才有效，不适合范围查询 自适应哈希索引：如果 InnoDB 注意到某些索引列值被频繁使用时，它会在内存基于 B+ 树索引之上再创建一个哈希索引，这样就能让 B+ 树也具有哈希索引的优点。 2、平衡二叉树：每个节点只存储一个键值和数据，数量非常多时树会非常高 3、B树：每个节点可以存储多个关键字，一定程度上解决了上文提到的存储尽量多的索引的问题，也一定程度上的解决了存储尽量多的有效索引的问题 4、B+树： 非节点不存储数据：InnoDB 中页的默认大小是 16 KB，如果不存储数据，那么节点就可以存储更多的键值 B+ 树的叶子节点中的索引数据是按顺序排列的，并且叶子节点间是通过双向链表进行连接的：实现范围查找，排序查找，分组查找等操作时变得异常简单 如果没有主键索引？ 在InnoDB中,只有主键索引是聚簇索引,如果没有主键,则挑选一个唯一键建立聚簇索引.如果没有唯一键,则隐式的生成一个键来建立聚簇索引 为什么推荐使用自增索引？ 自增的话就是依次插入，否则就需要在已经有的节点插入，可能会有叶子节点的分裂 为什么不能使用红黑树？ 读取磁盘的次数过多，读取浪费太多 B+树的阶 https://juejin.cn/post/6973647815473889311 16K &#x2F; 字段大小 int：4byte bigint：8byte 指针：6B 日志redo Log（重做日志）1、当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log里面，并更新内存，这个时候更新就算完成了 2、InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做 3、InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。 crash-safe：保证即使数据库发生异常重启，之前提交的记录都不会丢失 binLog（归档日志）1、Server层日志 为什么会有两个日志？ 最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力 区别： redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 2、Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。 3、概念 binlog cache：它是用于缓存binlog event的内存，大小由binlog_cache_size控制 binlog cache 临时文件：是一个临时磁盘文件，存储由于binlog cache不足溢出的binlog event，该文件名字由”ML”打头，由参数max_binlog_cache_size控制该文件大小 binlog file：代表binglog 文件，由max_binlog_size指定大小 binlog event：代表binlog中的记录，如MAP_EVENT&#x2F;QUERY EVENT&#x2F;XID EVENT&#x2F;WRITE EVENT等 binlog cache和binlog临时文件都是在事务运行过程中写入，一旦事务提交，binlog cache和binlog临时文件都会释放掉。而且如果事务中包含多个DML语句，他们共享binlog cache和binlog 临时文件 更新语句的执行流程1、事务开启 2、执行器先找引擎取 ID&#x3D;2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID&#x3D;2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 3、执行DML语句：执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 更新redolog：将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。 写入binglog cache：如果binlog cache的空间已经满了，则将binlog cache的数据写入到binlog临时文件，同时清空binlog cache。 第一次执行DML语句时分配内存空间binlogcache 4、提交事务： 将binlog cache和binlog临时文件写入到binlog file中，释放binlog cache和binlog临时文件 redo log 改成提交（commit）状态 当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，怎么做？ 建立临时库 寻找最近一次的全量备份 从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。 redo log的两阶段提交 为了保证一致性 如果先写redolog，后写bin log 假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。 如果先写bindolog，后写redo log 如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。 两阶段提交 redolog只是完成了prepare， 而binlog又失败，那么事务本身会回滚，所以这个库里面status的值是0，如果通过binlog 恢复出一个库，status值也是0。 undo Log（回滚日志） 事务的原子性： 保证一个事务中的增删改操作要么都成功，要么都不做。这时就需要 undo log，在对数据库进行修改前，会先记录对应的 undo log，然后在事务失败或回滚的时候，就可以用这些 undo log 来将数据回滚到修改之前的样子。 行记录中会有三个隐藏列： DB_ROW_ID：如果没有为表显式的定义主键，并且表中也没有定义唯一索引，那么InnoDB会自动为表添加一个row_id的隐藏列作为主键。 DB_TRX_ID：事务中对某条记录做增删改时，就会将这个事务的事务ID写入trx_id中。 DB_ROLL_PTR：回滚指针，本质上就是指向 undo log 的指针。 MVCC多版本控制中使用undo log 锁机制 面试官：你知道MySQL的锁机制吗？ 答：知道的。MySQL锁按加锁粒度可以分为行锁表锁和页锁。按锁的使用方式可以分为共享锁和排他锁。按加锁思想可以分为悲观锁和乐观锁。 1、行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。有可能会出现死锁的情况。 2、表级锁是表示当前的操作对整张表加锁，资源开销比行锁少，不会出现死锁的情况，但是发生锁冲突的概率很大。 3、在 MySQL 中，行级锁并不是直接锁记录，而是锁索引。索引分为主键索引和非主键索引两种，如果一条sql 语句操作了主键索引，MySQL 就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。 InnoDB 行锁是通过给索引项加锁实现的，如果没有索引，InnoDB 会通过隐藏的聚簇索引来对记录加锁。也就是说：如果不通过索引条件检索数据，那么InnoDB将对表中所有数据加锁，实际效果跟表锁一样。因为没有了索引，找到某一条记录就得扫描全表，要扫描全表，就得锁定表。 4、乐观锁和悲观锁 悲观锁和乐观锁是两种加锁的思想。乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。 乐观锁在操作数据时非常乐观，认为别人不会同时修改数据。因此乐观锁不会上锁，只是在执行更新的时候判断一下在此期间别人是否修改了数据：如果别人修改了数据则放弃操作，否则执行操作。 乐观锁主要是基于数据版本机制来实现，实现方式有两种：CAS和版本号机制。MVCC也是乐观锁的一种实现方式。(注：与MVCC相对的，是基于锁的并发控制，Lock-Based Concurrency Control。MVCC最大的好处是：读不加锁，读写不冲突。读分为快照读和当前读，快照读基于数据的可见版本不加锁。） 面试官：那乐观锁加锁吗？ 答：（1）乐观锁本身是不加锁的，只是在更新时判断一下数据是否被其他线程更新了；（2）有时乐观锁可能与加锁操作合作，但不能改变“乐观锁本身不加锁”这一事实。 面试官：那你知道死锁吗？是怎么产生的又怎么样解决呢？ MySQL中的死锁一般是事务相互等待对方资源，最后形成环路造成的。若无外力作用,它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁,这些永远在互相等待的进程称为死锁进程。 死锁的产生主要有以下几种情况：不同表相同记录行锁冲突，相同表记录行锁冲突，不同索引锁冲突，gap锁冲突。 死锁的发生与否，并不在于事务中有多少条SQL语句，死锁的关键在于：两个(或以上)的Session加锁的顺序不一致。 所以当出现死锁时要分析MySQL每条SQL语句的加锁规则，分析出每条语句的加锁顺序，然后检查多个并发SQL间是否存在以相反的顺序加锁的情况，就可以分析出各种潜在的死锁情况，也可以分析出线上死锁发生的原因。同时可以通过应用业务日志定位到问题代码，找到相应的事务对应的sql。 死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。 避免死锁的方法： 1）以固定的顺序访问表和行。 2）大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小。 3）在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁概率。 4）降低隔离级别。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁。 5）为表添加合理的索引。可以看到如果不走索引将会为表的每一行记录添加上锁，死锁的概率大大增大。 基础 数据类型 1、varchar：可变长度的字符串，可以根据传输的数据长度动态分配空间 优点：节省空间 缺点：速度慢 适用场景：字符串列的最大长度比平均长度大很多、列的更新很少、使用了 UTF8 这种复杂字符集，每个字符都使用不同的字节数存储。 2、char：定长字符串，不管实际的数据长度是多少，分配固定长度的空间，使用不恰当的时候可能会导致空间的浪费 优点：速度快 缺点：使用不当可能会导致空间的浪费 适合存储很短的字符串，或所有值都接近同一个长度，例如存储密码的 MD5 值。 对于经常变更的数据，CHAR 也比 VARCHAR更好，因为定长的 CHAR 不容易产生碎片。对于非常短的列，CHAR 在存储空间上也更有效率，例如用 CHAR 来存储只有 Y 和 N 的值只需要一个字节，但是 VARCHAR 需要两个字节，因为还有一个记录长度的额外字节。 3、int：整数型，等同于java中的int 4、bigint：长整型，等同于java中的long 5、float：单精度浮点型数据 6、double：双精度浮点型数据 7、date：短日期类型 8、datetime：长日期类型 DATETIME 和 TIMESTAMP 的区别？ DATETIME 能保存大范围的值，从 1001~9999 年，精度为秒。把日期和时间封装到了一个整数中，与时区无关，使用 8 字节存储空间。 TIMESTAMP 和 UNIX 时间戳相同，只使用 4 字节的存储空间，范围比 DATETIME 小得多，只能表示 1970 ~2038 年，并且依赖于时区。 MySQL支持的字符集和排序规则 utf8mb3（在mysql中就是utf8）：阉割过的utf8字符集，使用1-3个字节表示字符 utf8mb4（emoji表情）：正宗的utf8字符集，使用1-4个字节表示字符 SQL语句执行顺序 编写步骤 select from join on where group by having order by limit 执行步骤 from on join where group by having select Order by limit 事务 什么是事务？ 一个事务其实就是一个完整的业务逻辑 答：事务是一组原子性的 SQL 查询，或者说一个独立的工作单元。如果数据库引擎能够成功地对数据库应用该组查询的全部语句，那么就执行该组查询。如果其中有任何一条语句因为崩溃或其他原因无法执行，那么所有的语句都不会执行，也就是说事务内的语句要么全部执行成功，要么全部执行失败。 什么是完整的业务逻辑？ 假设从A账户向B账户转账100元，将A账户的钱减去100，将B账户的钱加100 以上的操作是一个最小的工作单元，要么同时成功，要么同时失败，不可再分 1、只有DML（insert、delete、update）语句才有事务，其他的语句和事务无关 只有这三个操作对数据库表的数据进行增删改，需要考虑安全问题 假设所有业务只需要一条DML语句就能完成，还需要事务机制吗？ 正是因为做某件事的时候需要多条DML语句共同联合完成，所以才需要事务的存在；一条DML语句不需要事务 到底什么是事务？ 本质上，一个事务其实就是多条DML语句同时成功，或者同时失败 事务是怎么做到同时成功同时失败的呢？ InnoDB存储引擎：提供一组用来记录事务性活动的日志文件 在事务的执行过程中，每一条DML语句的操作都会记录到事务性活动日志文件中 在事务的执行过程中，可以提交事务，也可以回滚事务 提交事务：清空事务性活动日志文件，将数据持久化到数据库表中，标志着事务的成功结束 回滚事务：清空事务性活动日志文件，撤销所有的操作，事务结束，全部失败 如何提交事务？如何回滚事务？ 提交事务：commit语句 回滚事务：rollback语句，回滚到上一次的提交点 事务：transaction mysql默认情况下是什么样的事务行为？ 自动提交，每执行一条DML语句提交一次（回滚无效） 关闭自动提交机制： 1start transaction; 自动提交不符合开发习惯，为了保证数据的安全，所以需要使用事务 事务有什么特性？ACID？ 原子性 atomicity 一个事务在逻辑上是必须不可分割的最小工作单元，不可再分 一致性 consistency 同一个事物中所有操作同时成功或者同时失败 隔离性 isolation A事务和B事务之间有一定的隔离 A事务在操作一张表时在提交之前对另一个事务B的隔离性 针对并发事务而言，隔离性就是要隔离并发运行的多个事务之间的相互影响，一般来说一个事务所做的修改在最终提交以前，对其他事务是不可见的。 持久性 durability 一旦事务提交成功，其修改就会永久保存到数据库中，此时即使系统崩溃，修改的数据也不会丢失。 事务的隔离级别 A教室和B教室之间的墙可以很厚也可以很薄，这就是事务的隔离级别，墙越厚表示隔离级别越高 事务和事务之间的隔离级别包括： 读未提交 READ UNCOMMITTED：没有提交就读到了 事务A可以读取到事务B未提交的数据 脏读现象：读到了脏数据 这种隔离级别一般都是理论上的，大多数数据库不使用 读已提交 READ COMMITTED：提交之后才能读到 事务A只能读取到事务B提交后的数据 解决了脏读现象 问题：不可重复读取数据、幻读 事务开启之后，第一次读到的数据是3条，当前事务还没有结束，可能第二次再次读取的时候读到了4条，3不等于4称为不可重复读取 幻读：如果一个事务先根据某些条件查询出一些记录，之后另外一个事务向表中添加了一些记录，原先的事务再次按照该条件查询的时候，读到了另外一个事务插入的数据。针对多行 幻读的重点在于新增或者删除 不可重复读：如果事务A 按一定条件搜索， 期间事务B 修改了符合条件的某一条数据，导致事务A 再次读取时数据发生改变，针对一行 不可重复读的重点是修改 每次读到的数据是真实的 Orcale默认 可重复读 REPEATABLE READ：提交之后也读不到，只能读取事务开始的数据 事务A开启之后，不管多久每一次读取的数据都是一致的，即使数据已经改变 解决了不可重复读取数据的问题 问题：可能出现幻读 数据不够绝对真实 MySQL默认，mysql是不会出现幻读的 串行化 SERIALIZABLE（最高隔离级别） 效率低 解决了所有问题 事务不能并发 每一次读取到的数据都是最真实的 1234设置隔离级别set global transaction isolation level read uncommitted;查看全局隔离级别select @@transaction_isolation; 版本链 对于InnoDB存储引擎，他的聚簇索引记录中都包含两个必要的隐藏列： trx_id：每次对某条记录进行改动时，都会把对应的事务id赋值给trx_id Roll_pointer：每次对某条记录进行改动时，这个隐藏列会存储一个指针，可以通过指针获取该记录修改前的信息 ReadView 对于使用读未提交的事务来说，直接读取记录的最新版本就好了，对于使用串行的事务来说，使用枷锁方式访问记录，对于读已提交和可重复读的事务来说，就需要版本链，核心问题是需要判断版本链哪个版本对事务可见： ReadView中4个重要的内容： m_ids：一个列表, 存储当前系统活跃的事务id（没有提交的事务），通过对照版本链找到已经提交的事务 min_trx_id：存m_ids的最小值 max_trx_id：系统分配给下一个事务的id creator_trx_id:：生成readView事务的事务id 1、如果被访问版本的trx_id属性值小于m_ids列表中最小的事务id，表明生成该版本的事务在生成ReadView前已经提交，所以该版本可以被当前事务访问。 2、如果被访问版本的trx_id属性值大于m_ids列表中最大的事务id，表明生成该版本的事务在生成ReadView后才生成，所以该版本不可以被当前事务访问。 3、如果被访问版本的trx_id属性值在m_ids列表中最大的事务id和最小事务id之间，那就需要判断一下trx_id属性值是不是在m_ids列表中，如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。 已提交读和可重复读的区别就在于它们生成ReadView的策略不同 也就是说已提交读隔离级别下的事务在每次查询的开始都会生成一个独立的ReadView 可重复读隔离级别则在第一次读的时候生成一个ReadView，之后的读都复用之前的ReadView。 MVCC MVCC （多版本并发控制），指的是在使用读已提交和重复读两个隔离级别的事务进行执行select操作时访问记录的版本链的过程 MVCC 只能在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作，因为 READ UNCOMMITTED 总是读取最新的数据行，而不是符合当前事务版本的数据行，而 SERIALIZABLE 则会对所有读取的行都加锁。 锁操作粒度： 表锁：操作时，会锁定整个表 行锁：操作时，会锁定当前操作行 对数据操作的类型分： 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响 写锁（排它锁）：当前操作没有完成之前，它会阻断其他写锁和读锁 MyISAM表锁MyISAM在执行查询语句前，会自动给涉及的所有表加读锁，在执行更新操作（update、delete、insert）前，会自动给涉及的表加写锁，这个过程不需要用户干预。 12显式加读锁：lock table tb_book read; 1、对一个表使用表读锁后，不能读取另外一个表 2、读锁和写操作冲突 12显示加写锁：lock table tb_book write; 1、在当前客户端：加写锁可以读 2、在当前客户端：加写锁可以更新、插入 3、在其他客户端：加写锁不可以读、不可以更新和插入 小结 1、加读锁，不会阻塞其他用户的读，会阻塞写 2、加写锁，会阻塞其他用户的读和写 MyISAM的读写锁调度是写优先，不适合作为写为主的存储引擎 InnoDB锁行锁：偏向InnoDB存储引擎，开销大，加锁慢，会出现死锁；锁定的粒度很小，发生锁冲突的概率最低，并发读也最高 InnoDB和MyISAM最大的不同就是支持事务、行锁 行锁的种类1、记录锁：加在索引上的，不加索引就会升级为表锁 2、间隙锁：为了避免幻读，引入了间隙锁，锁定的是范围，只有在事务隔离级别 RR 中才会产生 当我们用范围条件而不是使用相等条件检索数据，并请求共享或排它锁时，InnoDB会给符合条件的已有数据进行加锁，对于键值在条件范围内但并不存在的记录叫做间隙（GAP），InnoDB会对间隙加锁 非唯一索引等值判断、范围查询都会产生间隙锁 主键索引等值判断存在不会产生间隙锁（不存在就会产生间隙锁，锁住上面最近的一个到下面最近的一个），返回查询会产生间隙锁 如：查找id&lt;8，id有1、2、3、4、6、7，会对5也进行加锁 123456事务1:update city set city_name=&quot;zhang&quot; where country_id&lt;4;事务2:insert into city values(2,&quot;hello&quot;,3);无法执行 3、记录锁和间隙锁组合（临键锁） 封锁范围包含索引记录，又包含索引区间，主要目的是为了避免幻读 锁定一段左开右闭的索引区间 临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。 1、加锁语句，使用主键或唯一键进行定值查询，查询对象存在时，使用的是记录锁（行锁），查询对象不存在时，使用的是间隙锁。 2、加锁语句，使用主键或唯一键进行范围查询，使用的是间隙锁 3、加锁语句，使用普通索引进行定值或者范围查询，均使用的是间隙锁 4、间隙锁可以看做是左右开区间“（）”，而临键锁是记录锁+间隙锁，所以看做是左开右闭区间“（]”，且InnoDB默认加锁为临键锁 5、间隙锁和临建锁都是为解决幻读问题 6、记录锁、间隙锁、临键锁，都属于排它锁； 4、表锁 锁的类型1、读锁 对于普通select语句，InnoDB不会加任何锁 将查到的数据加S锁，允许其他事务继续获取这些记录的S锁，不能获取这些记录的X锁（会阻塞） 使用场景：读出数据后，其他事务不能修改，自己也不一定能修改，因为其他事务也可以加读锁 1select ... lock in share mode 将查到的数据加上X锁，不允许其他事务获取这些记录的S锁和X锁 使用场景：读出数据后，其他事务即不能写也不能读，只有自己可以修改数据 1select ... for update 2、写锁 delete：删除一条数据时，先对记录加X锁，再执行删除操作 insert：插入一条记录时，会先加隐式锁来保护这条新插入的记录在本事务提交前不被别的事务访问到 update： 如果被更新的列，修改前后没有导致存储空间变化，会先加X锁，再进行修改 如果被更新的列，修改前后导致存储空间产生变化，会先加X锁，然后删除记录，再insert一条新的记录 在MySQL，写锁是可以读的——MVCC 3、MDL锁 元数据锁 表开启了一个查询事务后（select），会自动获得MDL锁，保证表的结构不会发生改变（添加列等） 4、意向锁 在mysql的innodb引擎中，意向锁是表级锁 意向共享锁（IS）：加共享锁之前必须获取该表的意向共享锁 意向排它锁（IX）：加排它锁之前。。。。 意向锁和MDL锁都是为了防止事务进行中，执行DDL语句导致数据不一致 乐观锁和悲观锁共享锁和排它锁都是悲观锁 乐观锁：大多数基于数据版本记录机制实现，一般给数据库表增加一个version 锁等待和死锁1、锁等待：一个事务过程中产生的锁，其他事务需要等待上一个事务释放他的锁，才能占用该资源 2、死锁 死锁的条件 两行记录，至少两个事务 事务A操作第n行数据，并加锁 事务B操作第m行数据，并加锁 事务A操作第m行数据 事务B操作第n行数据 形成死锁 InnoDB可以自动检测死锁并回滚该事务（将持有最少行级排他锁的事务进行回滚） 尽量不要产生死锁～～～ 死锁检测 当出现死锁以后，有两种策略： 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。 怎么解决由这种热点行更新导致的性能问题呢？（假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。） 一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。 另一个思路是控制并发度。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。 但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。 因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。 避免死锁 以固定的顺序访问表和行。 大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小。 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁概率。 降低隔离级别。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁。 为表添加合理的索引。可以看到如果不走索引将会为表的每一行记录添加上锁，死锁的概率大大增大。 总结InnoDB存储引擎由于实现了行级锁定，虽然性能损耗较高，但是在整体并发处理能力方面优于MyISAM表锁，当系统高并发的情况下，InnoDB整体性能有优势。 优化建议： 尽可能让检索数据通过索引完成，避免行锁升级为表锁 合理设计索引，减少锁的范围 减少索引条件及索引范围，避免间隙锁 尽量控制事务大小，减少锁定资源量和时间长度 尽可能使用低级别事务隔离 索引概述1、索引是帮助mysql高效获取数据的数据结构（有序） 在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用数据，这样就可以在这些数据结构上实现高级查找算法，这种数据结构就是索引。 建立索引 VS 没有建立索引 没有建立索引：需要遍历 建立索引：快速定位 sql语句select * from user where name &#x3D; ‘jack’； 以上sql语句回去name字段上扫描 如果没有添加所以就会进行全局扫描，一个一个比对，效率较低 mysql在查询方面主要两种方式： 全局扫描 根据索引检索 注意 在实际中，书的目录都是排序的，因为只有排序了才能进行区间查找，因此mysql中索引也是排序的，并且和treeset的数据结构相同（自平衡二叉树） 任何数据库中，主键会自动添加索引对象，在mysql中，一个字段如果有unique约束的话，也会自动创建索引对象 任何数据库中，任何一张表的任何一条记录在硬盘存储上都有一个硬盘的物理存储编号 在mysql中，索引是一个单独的对象，不同的存储引擎以不同的形式存在，在MyISAM存储引擎中，索引存储在一个.MYI文件中，在InnoDB存储引擎中，存储在一个逻辑名称为tablespace当中，在MEMORY存储引擎当中存储在内存中。不管存储在哪里，索引在mysql中都是一个数的形式存在 1、优势 快速定位，降低数据库IO成本 通过索引列对数据进行排序，降低数据排序成本 2、劣势 索引也是一种表，需要占用磁盘空间 虽然索引能够提高查询效率，同时也降低更新表的速度（mysql不仅需要保存数据，还需要保存索引文件每次更新添加了索引列的字段，都会调整因为更新带来的键值变化后的索引信息） 什么条件下考虑给字段添加索引？ 条件一：数据量庞大（因为硬件环境不同，需要测试） 条件二：该字段经常出现在where后面，以条件的形式存在，也就是说这个字段总是被扫描 条件三：该字段很少的DML操作（因为DML之后索引需要重新排序） 建议不要随意添加索引，因为索引也是需要维护的，太多的话反而会影响系统性能 数据结构索引是在MySQL的存储引擎层中实现的，所以不同的存储引擎的索引不一定完全相同，MySQL目前提供以下4种索引： BTREE：最常见的索引类型，大部分索引都支持B树索引 Hash：只有Memory引擎支持，使用场景简单 R-tree：是MyISAM引擎的一种特殊索引类型 Full-tree：全文索引也是MyISAM的一种特殊索引类型 如果没有特别指明，都是指B+树（多路搜索树，并不一定是二叉树） 其中聚集索引、复合索引、前缀索引、唯一索引默认都是使用B+tree索引，统称为索引 BTree 结构BTree又叫多路平衡搜索树，一颗m叉的Btree特性如下： 树中每个节点最多包含m个孩子 除根节点与叶子节点以外，每个节点至少有[ceil(m/2)]个孩子（ceil：向上取整） 若根节点不是叶子节点，则至少有两个孩子 所有的叶子节点都在同一层 每个非叶子节点由n个key和n+1个指针组成，其中[ceil(m/2)-1] &lt;= n &lt;= m-1 当key的数量大于m-1时，中间key向上分裂到父节点，两边key分裂 例子：5叉BTree 插入 C N G A H E K Q M F W L T Z D P R X Y S 过程如下： BTREE和二叉树相比，层级更浅，查找数据更快 B+Tree 结构插入操作B+树插入要记住这几个步骤： B+树插入都是在叶子结点进行的，就是插入前，需要先找到要插入的叶子结点。 如果被插入关键字的叶子节点，当前含有的关键字数量是小于阶数m，则直接插入。 如果插入关键字后，叶子节点当前含有的关键字数目等于阶数m，则插，该节点开始分裂为两个新的节点，一个节点包含⌊m&#x2F;2⌋ 个关键字，另外一个关键字包含⌈m&#x2F;2⌉个关键值。（⌊m&#x2F;2⌋表示向下取整，⌈m&#x2F;2⌉表示向上取整，如⌈3&#x2F;2⌉&#x3D;2）。 分裂后，需要将第⌈m&#x2F;2⌉的关键字上移到父结点。如果这时候父结点中包含的关键字个数小于m，则插入操作完成。 分裂后，需要将⌈m&#x2F;2⌉的关键字上移到父结点。如果父结点中包含的关键字个数等于m，则继续分裂父结点。 以一颗4阶的B+树为例子吧，4阶的话，关键值最多3（m-1）个。假设插入以下数据43，48，36，32,37,49,28. 在空树中插入43 这时候根结点就一个关键值，此时它是根结点也是叶子结点。 依次插入48，36 这时候跟节点拥有3个关键字，已经满了 继续插入 32，发现当前节点关键字已经不小于阶数4了，于是分裂 第⌈4&#x2F;2⌉&#x3D;2（下标0,1,2）个，也即43上移到父节点。 继续插入37，49，前节点关键字都是还没满的，直接插入，如下： 最后插入28，发现当前节点关键字也是不小于阶数4了，于是分裂，第⌈4&#x2F;2⌉&#x3D;2个，也就是36上移到父节点，因父子节点只有2个关键值，还是小于4的，所以不用继续分裂，插入完成 查找操作因为B+树的数据都是在叶子节点上的，内部节点只是指针索引的作用，因此，查找过程需要搜索到叶子节点上。还是以这颗B+树为例吧： 单值查询 假设我们要查的值为32. 第一次磁盘 I&#x2F;O，查找磁盘块1，即根节点（36,43）,因为32小于36，因此访问根节点的左边第一个孩子节点 第二次磁盘 I&#x2F;O, 查找磁盘块2，即根节点的第一个孩子节点，获得区间(28,32),遍历即可得32. 范围查询 假设我们要查找区间 [32,40]区间的值. 第一步先访问根节点，发现区间的左端点32小于36,则访问根节点的第一个左子树(28,32); 第二步访问节点（28,32），找到32，于是开始遍历链表，把[32,40]区间值找出来，这也是B+树比B-树高效的地方。 删除操作B+树删除关键字，分这几种情况 找到包含关键值的结点，如果关键字个数大于m&#x2F;2，直接删除即可； 假设当前有这么一颗5阶的B+树 如果删除22，因为关键字个数为3 &gt; 5&#x2F;2&#x3D;2， 直接删除（⌈⌉表示向上取整的意思） 找到包含关键值的结点,如果关键字个数大于m&#x2F;2，并且关键值是当前节点的最大（小）值，并且该关键值存在父子节点中，那么删除该关键字，同时需要相应调整父节点的值。 如果删除20，因为关键字个数为3 &gt; 5&#x2F;2&#x3D;2，并且20是当前节点的边界值，且存在父子节点中，所以删除后，其父子节点也要响应调整。 找到包含关键值的结点，如果删除该关键字后，关键字个数小于⌈m&#x2F;2⌉，并且其兄弟结点有多余的关键字，则从其兄弟结点借用关键字 以下这颗5阶的B+树， 如果删除15,删除关键字的结点只剩1个关键字，小于5&#x2F;2&#x3D;2，不满足B+树特点，但是其兄弟节点拥有3个元素（7,8,9），可以借用9过来，如图： 找到包含关键值的结点，如果删除该关键字后，关键字个数小于⌈m&#x2F;2⌉，并且其兄弟结点没有多余的关键字，则与兄弟结点合并。 以下这颗5阶的B+树： 如果删除关键字7，删除关键字的结点只剩1个关键字，小于5&#x2F;2&#x3D;2，不满足B+树特点，并且兄弟结点没法借用，因此发生合并，如下： 主要流程酱紫： 因为7被删掉后，只剩一个8的关键字，不满足B+树特点（m&#x2F;2&lt;&#x3D;关键字&lt;&#x3D;m-1）。 并且没有兄弟结点关键字借用，因此8与前面的兄弟结点结合。 被删关键字结点的父节点，7索引也被删掉了，只剩一个9，并且其右兄弟结点（18,20）只有两个关键字，也是没得借，因此在此合并。 被删关键字结点的父子节点，也和其兄弟结点合并后，只剩一个子树分支，因此根节点（16）也下移了。 所以删除关键字7后的结果如下： 内存结构 在InnoDB中，索引默认使用的数据结构为B+树，而B+树里的每个节点都是一个页，默认的页大小为16KB。 非叶子节点存的是索引值以及页的偏移量，而叶子节点上存放的则是完整的每行记录 B+树能够存多少数据？ 非叶子节点 页默认16KB File Header、Page Header等一共占102个字节 Infimum + Supremum分别占13个字节 记录头占5个字节 id占为int，占4个字节 页目录的偏移量占4个字节 所以，非叶子节点能存多少条索引记录呢 12345 非叶子节点能存放的索引记录= (页大小 - File Header - Page Header - ...) / ( 主键 + 页偏移量 + 下一条记录的偏移量)= （16KB - 128B) / (5B + 4B + 4B) = 16256 / 13= 1250 条 叶子节点 变长列表占1个字节 null标志位忽略 记录头占5个字节 id占为int，占4个字节 name为VARCHAR，编码为UTF8，为了好算，所有行记录我都只用两个中文，那就是 2 * 3B &#x3D; 6个字节 事务ID列占6个字节 回滚指针列占7个字节 12345 叶子节点能存放的数据记录= (页大小 - File Header - Page Header - ...) / ( 主键 + 字段 + 下一条记录的偏移量)= （16KB - 128B) / (1B + 5B + 4B + 6B + 6B + 7B) = 16256 / 29= 560 条 高度为3的B+树 根节点能放1250条索引记录 第二层能放1250 * 1250 &#x3D; 1,562,500条索引记录 叶子节点 1250 * 1250 * 560 &#x3D; 875,000,000条数据记录，八亿多条数据 B树和B+树的区别1、B 树的所有节点既存放 键(key) 也存放 数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。 2、B 树的叶子节点都是独立的，B+树的叶子节点有一条引用链指向与它相邻的叶子节点。 3、B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。 Hash索引和B+树Hash 索引定位快 Hash 索引指的就是 Hash 表，最大的优点就是能够在很短的时间内，根据 Hash 函数定位到数据所在的位置，这是 B+树所不能比的。 Hash 冲突问题 知道 HashMap 或 HashTable 的同学，相信都知道它们最大的缺点就是 Hash 冲突了。不过对于数据库来说这还不算最大的缺点。 Hash 索引不支持顺序和范围查询(Hash 索引不支持顺序和范围查询是它最大的缺点。 聚集索引和非聚集索引 聚集索引 聚集索引即索引结构和数据一起存放的索引。主键索引属于聚集索引。 在 Mysql 中，InnoDB 引擎的表的 .ibd文件就包含了该表的索引和数据，对于 InnoDB 引擎表来说，该表的索引(B+树)的每个非叶子节点存储索引，叶子节点存储索引和索引对应的数据。 聚集索引的优点 聚集索引的查询速度非常的快，因为整个 B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。 聚集索引的缺点 依赖于有序的数据 ：因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。 更新代价大 ： 如果对索引列的数据被修改时，那么对应的索引也将会被修改， 而且况聚集索引的叶子节点还存放着数据，修改代价肯定是较大的， 所以对于主键索引来说，主键一般都是不可被修改的。 非聚集索引 非聚集索引即索引结构和数据分开存放的索引。 二级索引属于非聚集索引 MYISAM 引擎的表的.MYI 文件包含了表的索引， 该表的索引(B+树)的每个叶子非叶子节点存储索引， 叶子节点存储索引和索引对应数据的指针，指向.MYD 文件的数据。 非聚集索引的叶子节点并不一定存放数据的指针， 因为二级索引的叶子节点就存放的是主键，根据主键再回表查数据。 非聚集索引的优点 更新代价比聚集索引要小 。非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的 非聚集索引的缺点 跟聚集索引一样，非聚集索引也依赖于有序的数据 可能会二次查询(回表) :这应该是非聚集索引最大的缺点了。 当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询。 这是 Mysql 的表的文件截图: .frm文件：表结构 .ibd文件：索引和数据 .MYD文件：数据 .MYI文件：索引 非聚集索引一定要回表吗？ 非聚集索引不一定回表查询。 试想一种情况，用户准备使用 SQL 查询用户名，而用户名字段正好建立了索引。 1SELECT name FROM table WHERE name=&#x27;guang19&#x27;;Copy to clipboardErrorCopied 那么这个索引的 key 本身就是 name，查到对应的 name 直接返回就行了，无需回表查询。 即使是 MYISAM 也是这样，虽然 MYISAM 的主键索引确实需要回表， 因为它的主键索引的叶子节点存放的是指针。但是如果 SQL 查的就是主键呢? 1SELECT id FROM table WHERE id=1;Copy to clipboardErrorCopied 主键索引本身的 key 就是主键，查到返回就行了。这种情况就称之为覆盖索引了。 覆盖索引如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”。 我们知道在 InnoDB 存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次。这样就会比较慢覆盖索引就是把要查询出的列和索引是对应的，不做回表操作！ 覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了， 而无需回表查询。 如主键索引，如果一条 SQL 需要查询主键，那么正好根据主键索引就可以查到主键。 再如普通索引，如果一条 SQL 需要查询 name，name 字段正好有索引， 那么直接根据这个索引就可以查到数据，也无需回表。 索引语法和分类可以在创建表的时候创建，也可以随时增加新的索引 创建索引 语法： 1create [] index 索引名称 on 表名(字段名,...) 为city表的city_name创建索引： 1create index idx_city_name on city(city_name); 查看索引 1show index from city\\G; 1234567891011121314151617explain select * from city where city_name=&#x27;123&#x27;;添加索引前：+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| 1 | SIMPLE | city | NULL | ALL | NULL | NULL | NULL | NULL | 5 | 20.00 | Using where |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+1 row in set, 1 warning (0.00 sec)添加索引后：+----+-------------+-------+------------+------+---------------+---------------+---------+-------+------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+---------------+---------+-------+------+----------+-------+| 1 | SIMPLE | city | NULL | ref | idx_city_name | idx_city_name | 203 | const | 1 | 100.00 | NULL |+----+-------------+-------+------------+------+---------------+---------------+---------+-------+------+----------+-------+1 row in set, 1 warning (0.01 sec) 删除索引 1drop index idx_city_name on city; 索引分类 1、单值索引：一个字段上添加索引 2、唯一索引：unique字段上添加索引，唯一性比较弱的字段上添加索引用处不大 3、复合索引：多个字段上添加索引 4、主键索引：主键上添加索引 索引失效1、select * from city where city_name like &#39;%T&#39;; 即使添加了索引也不会走索引，因为模糊匹配中以%开头，无法使用索引进行检索 2、隐式类型转换 如果索引列出现了隐式类型转换，则 MySQL 不会使用索引。 常见的情况是在 SQL 的 WHERE 条件中字段类型为字符串，其值为数值，如果没有加引号那么 MySQL 不会使用索引。 3、索引文件具有 B-Tree 的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引 4、使用or的时候索引会失效，如果使用or要求两边的条件字段都有索引 12345678910explain select * from city where city_name = &#x27;zhang&#x27; or country_id=1;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| 1 | SIMPLE | city | NULL | ALL | idx_city_name | NULL | NULL | NULL | 5 | 40.00 | Using where |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+1 row in set, 1 warning (0.00 sec)没有使用索引 5、使用复合索引没有使用左侧的列查找 复合索引：两个字段或者更多字段联合起来 1create index c_index on city(city_name,country_id); 只能使用city_name进行查找 6、在where当中索引列参加了运算，索引失效 7、在where当中索引列使用了函数 1explain select * from city where lower(city_name)=&#x27;london&#x27;; 索引设计原则建立索引 对查询频次较高且数据量比较大的表建立索引。 索引字段的选择，最佳候选列应当从 WHERE 子句的条件中提取，如果 WHERE 子句中的组合比较多，应当挑选最常用、过滤效果最好的列的组合。业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引。 使用前缀索引 索引列开始的部分字符，索引创建后也是使用硬盘来存储的，因此短索引可以提升索引访问的 IO 效率。对于 BLOB、TEXT 或很长的 VARCHAR 列必须使用前缀索引，MySQL 不允许索引这些列的完整长度。前缀索引是一种能使索引更小更快的有效方法，但缺点是 MySQL 无法使用前缀索引做 ORDER BY 和 GROUP BY，也无法使用前缀索引做覆盖扫描。 选择合适的索引顺序 当不需要考虑排序和分组时，将选择性最高的列放在前面。索引的选择性是指不重复的索引值和数据表的记录总数之比，索引的选择性越高则查询效率越高，唯一索引的选择性是 1，因此也可以使用唯一索引提升查询效率。 删除无用索引 MySQL 允许在相同列上创建多个索引，重复的索引需要单独维护，并且优化器在优化查询时也需要逐个考虑，这会影响性能。重复索引是指在相同的列上按照相同的顺序创建的相同类型的索引，应该避免创建重复索引。如果创建了索引 (A,B) 再创建索引 (A) 就是冗余索引，因为这只是前一个索引的前缀索引，对于 B-Tree 索引来说是冗余的。解决重复索引和冗余索引的方法就是删除这些索引。除了重复索引和冗余索引，可能还会有一些服务器永远不用的索引，也应该考虑删除。 索引下推满足最左前缀原则的时候，最左前缀可以用于在索引中定位记录。那些不符合最左前缀的部分，会怎么样呢？ 以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的： 1mysql&gt; select * from tuser where name like &#x27;张%&#x27; and age=10 and ismale=1; 你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。 当然，这还不错，总比全表扫描要好。 然后呢？当然是判断其他条件是否满足。 在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。 而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 😊 存储过程和函数1、事先经过编译并存储在数据库中的一段SQL语句的集合 2、优势：减少应用程序和数据库之间的交互 3、存储过程：一个没有返回值的函数 1234create proceduce procedure_name ([proc_parameter])begin -- sql语句end; 声明语句结束符，可以自定义: 123DELIMITER $$或DELIMITER // 4、存储函数：一个有返回值的过程 12345create FUNCTION name()returns typebegin...end; 视图 什么是视图？ view：站在不同的角度看待同一份数据 怎么创建视图对象？怎么删除？ 12345678910mysql&gt; select * from city;+---------+-----------+------------+| city_id | city_name | country_id |+---------+-----------+------------+| 1 | 武汉 | 1 || 2 | 沈阳 | 1 || 3 | NewYork | 2 || 4 | London | 2 |+---------+-----------+------------+4 rows in set (0.00 sec) 1234创建视图create view myView as select * from city;删除视图drop view myView; 注意：只有DQL查询语句才能以view形式创建 视图作用？ 方便、简化开发、利于维护 可以面向视图对象进行增删改查，对视图对象进行增删改查会对原表进行操作 1234567891011// 面向视图查询mysql&gt; select * from myView;+---------+-----------+------------+| city_id | city_name | country_id |+---------+-----------+------------+| 1 | 武汉 | 1 || 2 | 沈阳 | 1 || 3 | NewYork | 2 || 4 | London | 2 |+---------+-----------+------------+4 rows in set (0.01 sec) 在实际开发中，将一个特别长且多处使用的sql语句转为视图对象，会方便增删改查，并且有利于后期的维护 试图对象也是一个文件，在数据库中也是以文件的形式存在的，和table一样 数据库设计三范式 函数依赖？码？ 函数依赖：X函数确定Y，例如：姓名-&gt;年龄这个函数依赖只在姓名唯一的情况下成立 码：k-&gt;u，k称为超码 什么是数据库设计范式？ 数据库表的设计依据，教你怎么进行数据库表的设计 设计数据库表的时候按照以上范式进行可以避免表数据的冗余 什么是规范化？ 通过模式分解将低级范式的关系模式转为若干高级范式关系模式的集合 范式直接的关系 1NF 包含 2NF 包含 3NF 包含 BCNF 第一范式 1、要求任何一张表必须有主键，每一个字段原子性不可再分 2、最基本的要求 第二范式 建立在第一范式的基础之上，要求所有非主键字段完全依赖主键，不要产生部分依赖 12345学生编号+教师编号 学生姓名 教师姓名1001 001 A D1002 002 B E1003 001 C D1001 002 A E 不满足第二范式，A依赖1001，D依赖001，产生了部分依赖 有什么缺点？ 1、插入异常：如果该学生没有对应的教师，插入不进去 2、删除异常：如果一个学生换了老师，那么删除的时候学生信息也被删除了 3、修改异常：修改一个需要多修改很多个 4、数据冗余，空间浪费 如何修改？ 解决方法：分解 为了满足第二范式，需要这样设计： 使用三张表表示多对多关系：学生表、教师表、学生教师关系表 12345学生编号（主键） 学生姓名老师编号（主键） 老师信息id（主键）学生编号（外键）老师编号（外键） 口诀：多对多，三张表，关系表两个外键 第三范式 建立在第二范式的基础之上，要求所有非主键字段直接依赖主键，不要产生传递依赖 1234学生编号(pk) 学生姓名 班级编号 班级名称 1001 A 01 一年一班 1002 B 02 一年二班 1003 C 02 一年二班 以上表设计描述班级和学生的关系，一对多关系（一个教师多个学生） 是否满足第三范式？ 班级依赖班级编号，班级编号依赖学生编号，产生传递依赖 不符合第三范式，产生数据的冗余 如何设计一对多？ 拆分两张表：学生表、班级表 123班级编号 班级名称学生编号 学生姓名 班级编号（外键） 口诀：一对多，两张表，多的表加外键 总结 1、一对多：两张表，多的表加外键 2、多对多：三张表，关系表两个外键 3、一对一：在实际开发可能出现一张表字段过多，这个时候需要拆分表 没有拆分表之前，一张表，比如用户信息表 拆分为用户登陆信息表、用户详细信息表 体系结构 1、connection Pool：连接池组件，接收客户端发起的请求 2、management service &amp; utilities：管理服务和工具组件 SQL interface：封装sql语句 Parser：解析器，解析客户端的请求 optimizer：优化器 cache &amp; buffers：缓存 3、Plggable storage engines：插件式存储引擎（innoDB） 4、存储层：操作文件系统、日志等信息 1、连接层 客户端和链接服务，包括本地socket通信和大多数基于客户端&#x2F;服务端工具实现的类似于TCP&#x2F;IP的通信 连接池，为通过安全接入的客户端提供线程 2、服务层 完成大多数核心功能，包括查询解析、分析、优化、缓存以及日期和时间等所有内置函数，所有跨存储引擎的功能都在这一层实现，例如存储过程、触发器、视图等 所有的跨存储引擎的功能也在这一层实现，在该层服务器解析查询并创建内部解析书，完成优化，最后生成执行操作；select语句还会查询内部的缓存 3、引擎层 4、存储层 MySQL可以分为server层和存储引擎层 客户端和server端tcp握手进行连接 如果你是一条查询语句，mysql8.0之前回查询缓存，mysql8.0之后就删掉了 server端收到你发送的sql语句，会进行分析判断你这条sql的语法属于增删改查等等 分析完要执行的sql之后，就是对sql进行一些成本估计和优化 执行器拿到优化完的sql，会调用存储引擎提供的接口查询具体的数据，并将满足条件的数据返回给客户端。 存储引擎概述1、针对不同的存储需求可以选择最优的存储引擎，存储引擎就是存储数据、建立索引、更新查询数据等技术的实现方式。 2、存储引擎是作用在表上的 3、默认使用innoDB，5.5版本之前使用MyISAM 从上图我们可以查看出 MySQL 当前默认的存储引擎是 InnoDB,并且在 5.7 版本所有的存储引擎中只有 InnoDB 是事务性存储引擎，也就是说只有 InnoDB 支持事务。 InnoDB支持事务 行锁 唯一支持外键 存储方式不同 InnoDB页 InnoDB是一个将表数据存储到磁盘上的存储引擎，真正处理数据的过程发生在内存中，所以需要把硬盘的数据加载到内存，但是读写磁盘的数据远低于内存 InnoDB将数据划分为若干页，以页作为磁盘和内存之间交互的基本单位，一般是16KB。 也就是说，一次最少从磁盘读取16KB内容到内存，一次最少将内存16KB内容刷新到磁盘中 InnoDB页目录 记录在页中按照主键值由小到大顺序串联成一个单链表，那如果我们想根据主键值查找页中的某条记录该咋办呢？ 最笨的办法：从Infimum记录（最小记录）开始，沿着链表一直往后找，总有一天会找到（或者找不到），在找的时候还能投机取巧，因为链表中各个记录的值是按照从小到大顺序排列的，所以当链表的某个节点代表的记录的主键值大于你想要查找的主键值时，你就可以停止查找了，因为该节点后边的节点的主键值依次递增。 这个方法在页中存储的记录数量比较少的情况用起来也没啥问题，但是如果一个页中存储了非常多的记录，这么查找对性能来说还是有损耗的，所以我们说这种遍历查找这是一个笨办法 那么就可以使用类似书的目录 存取多行数据之后，就会出现多个页，就需要另外的部分——目录页 目录页：记录页号，key为该页的最小值，value为页数 B+树： 主键：聚簇索引特点： 按照主键大小进行记录和页的排序 数据页（叶子节点）里的记录是按照主键从小到大排序的单向链表 数据页之间是按照主键大小排列的双向链表 B+树中同一层的页目录也是按照主键值从小到大排序的双向链表 B+树的叶子节点存储的是完整的用户记录，就是指这个记录中存储了所有列的值 具体这两种特性的B+树称为聚簇索引，所有完整的用户记录都存放在这个聚簇索引的叶子节点 在InnoDB中，聚簇索引就是数据的存储方式，所有的用户记录都存储在了叶子节点 优点： 可以把相关数据保存在一起 数据访问更快，聚簇索引将索引和数据保存在同一个 B-Tree 中，因此获取数据比非聚簇索引要更快。 用覆盖索引扫描的查询可以直接使用页节点中的主键值。 缺点： 聚簇索引最大限度提高了 IO 密集型应用的性能，如果数据全部在内存中将会失去优势。 更新聚簇索引列的代价很高，因为会强制每个被更新的行移动到新位置。 基于聚簇索引的表插入新行或主键被更新导致行移动时，可能导致页分裂，表会占用更多磁盘空间。 当行稀疏或由于页分裂导致数据存储不连续时，全表扫描可能很慢。 其他索引列：二级索引聚簇索引只能在搜索条件是主键时才能发挥作用，因为B+树的数据是按照主键进行排序的，当我们想以别的列作为搜索条件时，可以多建几棵B+树，不同的B+树采用不同的排序规则 二级索引和聚簇索引的不同： 按照指定索引列进行排序 叶子节点存储的不是完整的用户记录，而是索引列+主键 目录项记录中不适主键+页号，变成了索引列+页号 对二级索引进行查找数据的时候，需要根据主键值区聚簇索引中再查找完整的用户记录，这个过程叫回表 和聚簇索引的区别？回表？ 叶子节点存储索引列+主键，然后再去聚簇索引找完整的数据 多个索引列：联合索引以多个列的大小作为排序规则建立的B+树称为联合索引，本质上是二级索引 索引的适用条件1、全值匹配：搜索条件中的列和索引列一致的话 2、匹配左边的列：不用包含全部联合索引中的列，只包含左边的就行 如果我们想使用联合索引中尽可能多的列，搜索条件中的各个列必须是联合索引中从最左边连续的列 3、匹配列前缀：使用like语句进行模糊匹配，需要匹配前缀，例如“AS%” 4、匹配范围值 例1：name为索引，下面的操作会使用到索引，先查找name值为Asa的记录，再查找name为Barlow的记录，因为记录之间有链表，所以可以进行查询 1SELECT * FROM person_info WHERE name &gt; &#x27;Asa&#x27; AND name &lt; &#x27;Barlow&#x27;; 例2：使用联合索引name、age，下面的操作，会对name进行索引查询，对于age是用不到索引的，因为name不同，无法排序 1SELECT * FROM person_info WHERE name &gt; &#x27;Asa&#x27; AND name &lt; &#x27;Barlow&#x27; AND age &gt; 10; 如果对多个列同时进行范围查找的话，只有对索引最左边的那个列进行范围查找的时候才能用到B+树索引 5、精确匹配某一列并范围匹配另外一列：对于联合索引，如果查找左边的列是精确查找，那么后面的查找就会使用到索引 6、排序 规则：按照从左到右的顺序，先按照name值排序，如果记录的name值相同，则需要按照birthday来排序，如果birthday的值相同，则需要按照phone_number排序，然后进行回表操作取出该索引中不包含的列就好了 1SELECT * FROM person_info ORDER BY name, birthday, phone_number LIMIT 10; 注意： 需要匹配左索引列 不可以顺序逆序混用 where子句中不能出现非索引列 7、分组 覆盖查询需要回表的记录越多，使用二级索引的性能就越低，甚至让某些查询宁愿使用全表扫描也不使用二级索引 那什么时候采用全表扫描的方式，什么时候使用采用二级索引 + 回表的方式去执行查询呢？ 这个就是传说中的查询优化器做的工作，查询优化器会事先对表中的记录计算一些统计数据，然后再利用这些统计数据根据查询的条件来计算一下需要回表的记录数，需要回表的记录数越多，就越倾向于使用全表扫描，反之倾向于使用二级索引 + 回表的方式。 当然优化器做的分析工作不仅仅是这么简单，但是大致上是个这个过程。一般情况下，限制查询获取较少的记录数会让优化器更倾向于选择使用二级索引 + 回表的方式进行查询，因为回表的记录越少，性能提升就越高。 覆盖索引 为了彻底告别回表操作带来的性能损耗，我们建议：最好在查询列表里只包含索引列 Buffer PoolInnoDB结构： InnoDB的缓冲池缓存什么？有什么用？ 缓存表数据与索引数据，把磁盘上的数据加载到缓冲池，避免每次访问都进行磁盘IO，起到加速访问的作用。 速度快，那为啥不把所有数据都放到缓冲池里？ 凡事都具备两面性，抛开数据易失性不说，访问快速的反面是存储容量小： （1）缓存访问快，但容量小，数据库存储了200G数据，缓存容量可能只有64G； （2）内存访问快，但容量小，买一台笔记本磁盘有2T，内存可能只有16G； 因此，只能把“最热”的数据放到“最近”的地方，以“最大限度”的降低磁盘访问。 MyISAM1、不支持事务 2、不支持外键 3、非聚集索引 4、MySQL5.1及之前，MyISAM 是默认存储引擎 5、支持全文索引 6、不支持行锁，支持表锁 MyISAM和InnoDB实现BTree索引方式的区别 MyISAM B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。 InnoDB 其数据文件本身就是索引文件，其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”，而其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，在走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。 总结： MyISAM的B+Tree叶子节点存放的是数据记录的地址，InnoDB的叶子节点存放的是完整的数据记录 MyISAM是非聚集索引，InnoDB是聚集索引（数据文件本身就是主索引，主键就是索引的key） InnoDB的其他索引都是辅助索引，叶子节点存放主键的值 一个表中只能有一个聚集索引，一个表中可以有多个非聚集索引 存储引擎的选择1、InnoDB：默认存储引擎，用于事务处理应用程序，支持外键。如果对事务的完整性有较高要求，在并发条件下要求数据的一致性，数据操作包含很多更新、删除操作，那么就选择InnoDB 2、MyISAM：如果操作以读操作和插入操作为主，对事务的完整性和并发性要求不高，就选择MyISAM 3、MEMORY：叫所有数据存在在RAM中，在需要快速定位记录的环境下可以提供快速访问。常用于更新不频繁的小表 4、MERGE：将一系列等同于MyISAM表以逻辑方式组合在一起，作为一个对象引用。优点是突破对单个MyISAM表的大小限制 优化SQL步骤查看SQL执行频率show [session|global]status提供服务器状态信息 session 当前链接 global 数据库上次启动至今 123456789101112131415161718192021222324252627282930mysql&gt; show status like &#x27;com_______&#x27;;+---------------+-------+| Variable_name | Value |+---------------+-------+| Com_binlog | 0 || Com_commit | 0 || Com_delete | 0 || Com_import | 0 || Com_insert | 2 || Com_repair | 0 || Com_revoke | 0 || Com_select | 3 || Com_signal | 0 || Com_update | 0 || Com_xa_end | 0 |+---------------+-------+11 rows in set (0.00 sec)mysql&gt; show global status like &#x27;Innodb_rows_%&#x27;;+----------------------+-------+| Variable_name | Value |+----------------------+-------+| Innodb_rows_deleted | 0 || Innodb_rows_inserted | 10 || Innodb_rows_read | 64 || Innodb_rows_updated | 4 |+----------------------+-------+4 rows in set (0.00 sec) 定位低效的SQL语句1、慢查询日志 可以通过慢查询日志定位那些已经执行完毕的 SQL 语句 2、show processlist 查看当前 MySQL 正在进行的线程，包括线程的状态、是否锁表等，可以实时查看 SQL 的执行情况，同时对一些锁表操作进行优化 12345678mysql&gt; show processlist;+----+-----------------+-----------+---------+---------+--------+------------------------+------------------+| Id | User | Host | db | Command | Time | State | Info |+----+-----------------+-----------+---------+---------+--------+------------------------+------------------+| 5 | event_scheduler | localhost | NULL | Daemon | 395042 | Waiting on empty queue | NULL || 22 | root | localhost | demo_01 | Query | 0 | init | show processlist |+----+-----------------+-----------+---------+---------+--------+------------------------+------------------+2 rows in set (0.00 sec) 当查询非常多的数据时，可以看到： explain通过上面的步骤查询到效率低的sql语句后，可以通过explain或者desc命令获取MySQL如何执行SELECT语句的信息，包括执行过程中表是如何连接的、链接的顺序： 查询SQL语句的执行计划 1234567mysql&gt; explain select * from city;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+| 1 | SIMPLE | city | NULL | ALL | NULL | NULL | NULL | NULL | 4 | 100.00 | NULL |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+1 row in set, 1 warning (0.00 sec) id 表示查询中执行select子句或者操作表的顺序 1、id相同代表加载表的顺序从上到下 123456789mysql&gt; explain select * from city,country where city.country_id = country.country_id;+----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+--------------------------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+--------------------------------------------+| 1 | SIMPLE | country | NULL | ALL | PRIMARY | NULL | NULL | NULL | 2 | 100.00 | NULL || 1 | SIMPLE | city | NULL | ALL | NULL | NULL | NULL | NULL | 4 | 25.00 | Using where; Using join buffer (hash join) |+----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+--------------------------------------------+2 rows in set, 1 warning (0.01 sec) 2、id不同，id值越大优先级越高，越先被执行 3、id有相同，也有不同；相同的可以认为是一组，从上到下顺序执行；在所有的组中id值越大优先级越高 select_type 名称 描述 SIMPLE 简单的select查询，不包含子查询或者union PRIMARY 查询中包括任何复杂的子查询，最外层查询标记为该标记 UNION 第二个select出现在union之后标记为union，如果union包含在from子句的子查询外外层标记为derived DERIVED 在from列表中包含的子查询 SUBQUERY 在select或where列表中包含子查询 table 数据来源表 type 表的访问类型 null 不访问任何表、索引，直接返回结果 system 表只有一行记录，这是const类型的特殊例子，一般不会出现 const 通过索引一次就找到了，用于比较主键或者unique索引，因为只匹配一行数据，所以很快。 eq_ref 类似于ref，区别在于使用的是唯一索引，使用主键的关联查询，关联查询出的记录只有一条。常见于主键或唯一索引扫描 ref 非唯一性索引扫描，返回匹配某个单独值的所有行，本质上也是一种索引访问 range 只检索给定返回的行，使用一个索引来选择行 index 和all的区别为index类型只是遍历了索引树，all是遍历数据文件 all 遍历全表 possible_keys 可能用到的索引 key 实际用到的索引 key_len 索引字段的长度 rows 扫描行的数量 extra 1、using filesort：使用文件排序，使用非索引字段进行order by 2、using temporary：使用临时表保存中间结果，常见于order by 和groupby 3、using index show profiles 分析SQL帮助我们了解时间耗费都去哪里了 1234567891011121314151617181920212223242526272829303132mysql&gt; show profiles;+----------+------------+-------------------------+| Query_ID | Duration | Query |+----------+------------+-------------------------+| 1 | 0.00195000 | select @@have_profiling || 2 | 0.00123100 | select * from city |+----------+------------+-------------------------+2 rows in set, 1 warning (0.00 sec)mysql&gt; show profile for query 2;+--------------------------------+----------+| Status | Duration |+--------------------------------+----------+| starting | 0.000888 || Executing hook on transaction | 0.000021 || starting | 0.000006 || checking permissions | 0.000008 || Opening tables | 0.000050 || init | 0.000005 || System lock | 0.000015 || optimizing | 0.000012 || statistics | 0.000023 || preparing | 0.000020 || executing | 0.000131 || end | 0.000004 || query end | 0.000002 || waiting for handler commit | 0.000007 || closing tables | 0.000006 || freeing items | 0.000011 || cleaning up | 0.000022 |+--------------------------------+----------+17 rows in set, 1 warning (0.00 sec) trace分析优化器执行计划开启trace，设置格式为JSON，并设置trace最大能够使用的内存大小 12SET optimizer_trace=&quot;enabled=on&quot;,end_markers_in_json=on;set optimizer_trace_max_mem_size=1000000; 执行sql语句 1234select * from city where country_id &gt;0;查看执行计划：select * from information_schema.optimizer_trace\\G; 优化SQL优化大批量插入数据使用load指令大量导入数据，可以提高导入的效率 对于InnoDB类型的表，有以下几种方式可以提高导入的效率： 1、主键顺序插入 2、关闭唯一性校验：set unique_checks=0，导入后设置为1 3、手动提交事务：set autocommit=0，导入后设置为1 优化insert语句1、多次inset合并为一条 1inser into test values(1,1),(2,1),(3,1); 2、手动提交事务：set autocommit=0，插入后设置为1 优化order by语句尽量使用use index，减少额外的排序，通过索引直接返回数据 应用优化使用连接池对于访问数据库来说，建立连接的代价比较昂贵，因为我们频繁创建关闭连接是比较消耗资源的，所以有必要建立数据库连接池来提高访问的性能 减少对MySQL的访问1、避免对数据的重复检索 2、增加cache层 增加缓存层来减轻数据库的负担，部分数据从数据库抽取出来放到应用端以文本方式存储，或者使用MyBatis提供的一级缓存&#x2F;二级缓存，或者使用redis数据库来缓存数据 负载均衡将固定的负载量分布到不同的服务器上，从而降低单台服务器的负载 1、利用MySQL复制分流查询 通过MySQL的主从复制，实现读写分离，使增删改操作走主节点，查询操作走从节点，降低单台服务器的读写压力 2、使用分布式数据库架构 适合大数据量、负载高的情况，有良好的拓展性和可用性，通过在多台服务器之间分布数据可以实现在多台服务器之间的负载均衡 MySQL查询缓存优化（Mysql 8已经没有了） 开启MySQL查询缓存，当执行完全相同的SQL语句时，服务器就会直接从缓存中读取结果，之前的缓存会失效 操作流程 1、客户端发送一条查询给服务器 2、服务器检查查询缓存，如果命中缓存，则立即返回存储在缓存中的结果，否则进入下一个阶段 3、服务端进行SQL解析、预处理、再由优化器生成对应的执行计划 4、查询执行引擎 5、返回结果 参数配置 1、查看当前数据库是否支持查询缓存 1show variables like &#x27;have_query_cache&#x27;; 2、查看是否开启查询缓存 日志在MySQL中，有4种日志：错误日志、二进制日志、查询日志、慢查询日志 错误日志记录了mysqld启动和停止时，已经服务器在运行过程中发生任何严重错误时的相关信息 二进制日志记录了所有DDL（数据定义）语句和DML（操作）语句，不包含select查询语句 对数据的恢复有极其重要的作用，MySQL的主从复制就是根据这个日志 默认没有开启 123456配置文件位置：/usr/my.cnf开启log_bin=mysqlbin配置二进制日志的格式binlog_format=statement 日志格式statement 该日志格式在日志文件中记录SQL语句，每一条对数据进行修改的SQL都会记录在日志文件中，通过Mysql提供的mysqlbinlog工具，可以清晰查看每条语句的文本 主从复制的时候，从库会将日志解析为原文本，并在从库重新执行一次 row 记录每一行数据的变更 mixed 默认日志格式，混合statement和row，默认使用statement，但是特殊情况下使用row 查询日志记录所有操作语句 慢查询日志记录了执行时间超过long_query_time设置值并且扫描记录数不小于min_examined_row_limit的所有SQL语句的日志，默认10s。 MySQL主备一致 将主数据库的DDL和DML操作通过二进制日志传输到从库的数据库中，然后在从库上对这些日志重新执行 MySQL支持一台主库同时向多台从库进行复制，从库同时也可以作为其他从服务器的主库，实现链状复制 基本原理1、主备切换的流程 状态1：客户端读写都访问节点A，节点B是A的备库，只是将A的更新同步过来在本地执行，可以保持节点B和A数据相同 状态2：当需要切换时就切换成状态2，这时候客户端访问B，节点A为节点B的备库 节点A到节点B的内部流程 下图是update语句在A执行同步到B的完整流程 主库收到客户端更新请求后写入undolog、redolog、binlog B和A之间维持了一个长连接，主库A内部有一个线程专门用于服务B的这个长连接 事务日志同步的完整流程： 在B上通过change master命令，设置主库A的IP、端口、用户名、密码以及从哪个位置开始请求binlog（文件名、日志偏移量） 在B上执行start slave命令，这时候备库会启动两个线程，如上图io_thread、sql_thread，其中io_thread负责与主库建立连接 A校验信息，开始按照B传来的位置信息从本地读取binlog，发送给B B拿到binlog后写入本地文件，称为中转日志(relay log) sql_thread读取中转日志后解析出日志里的命令并执行 2、循环复制问题 双M结构：A和B互为主备 问题：B执行relay log会生成binlog，又发给了A，循环执行更新语句 解决： 规定两个库的server id（mysql在binlog中记录了这个命令第一次执行所在实例的server id）不同 一个备库接到binlog进行重放后，生成与原binlog的server id相同的binlog 每个库收到binlog后先判断serverid，如果和自己相同表示这个日志是自己生产的，丢弃 Mysql保证高可用1、最终一致性 主库的binlog都可以传到备库并被正确执行，备库就能达到和主库一致的状态 2、主备延迟 主备切换的场景：主动运维、被动 主备延迟：备库执行完成的时间—主库执行完成的时间 如果两个机器时间不一致会导致时主备延迟的值不准吗？ 备库连接到主库时会获取主库的时间，在计算主备延迟时会进行扣除 主备延迟的最直接表现：备库消费relay log的速度比主库生产binlog的速度慢 3、主备延迟的来源 备库机器性能 备库压力大 大事务：用delete语句删除很多数据、大表DDL 备库的并行复制能力 4、可靠性优先策略 双M结构下，从状态1到状态2切换的过程： 判断备库B的seconds_behind_master（主备延迟时间），如果小于某个值继续下一步，否则持续重试 把主库A改成只读状态（当前系统不可用，都是只读的） 判断B的seconds_behind_master值，直到这个值变成0 把B改成可读写状态 把业务请求切换到B 系统的不可用时间由数据可靠性优先的策略决定 5、可用性优先策略 不等主备数据同步，直接把连接切到备库 问题：数据不一致 主从切换1、基本的一主多从结构 A和A’互为主备 从库B、C、D指向主库A 主备切换：A’成为新的主库，从库B、C、D接到A‘ 2、基于位点的主备切换 把节点B设置为节点A‘的从库时需要执行change master命令 参数： MASTER_HOST、MASTER_PORT、MASTER_USER 和 MASTER_PASSWORD 四个参数，分别代表了主库 A’的 IP、端口、用户名和密码 MASTER_LOG_FILE 和 MASTER_LOG_POS 表示，要从主库的 master_log_name 文件的 master_log_pos 这个位置的日志继续同步。而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"Java进阶","slug":"Java进阶","date":"2022-01-06T11:15:35.000Z","updated":"2022-02-08T04:05:17.107Z","comments":true,"path":"2022/01/06/Java进阶/","link":"","permalink":"http://example.com/2022/01/06/Java%E8%BF%9B%E9%98%B6/","excerpt":"","text":"常用APIMath1、Math包含执行基本数字运算的方法 2、Math没有构造方法，如何使用类中的成员呢？ 看类的成员是否都是静态的，如果是，通过类名就可以直接调用 SystemSystem类包含几个有用的类字段和方法，它不能被实例化 Object1、Object是类层次结构的根，每个类都可以将Object作为超类，所有类都直接或者间接的继承自Object 2、构造方法： public Object() 在面向对象中，为什么说子类的构造方法默认访问父类的无参构造方法？ 因为他们的顶级父类只有无参构造方法 toString()1234//返回类的名字@实例的哈希码的16进制的字符串。建议Object所有的子类都重写这个方法。public String toString() &#123; return getClass().getName() + &quot;@&quot; + Integer.toHexString(hashCode());&#125; equals()12345//用于比较2个对象的内存地址是否相等//String类对该方法进行了重写用户比较字符串的值是否相等。public boolean equals(Object obj) &#123; return (this == obj); &#125; Arrays冒泡排序1、排序：将一组数据按照固定的规则进行排列 2、冒泡排序：一种排序的方式，对要进行排序的数据中相邻的数据进行两两比较，将较大的数据放在后面，依次对所有的数据进行操作，直至所有数据按要求完成排序 如果有n个数据进行排序，总共需要比较n-1次 每一次比较完毕，下一次的比较就会少一个数据参与 3、动画演示： 4、代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374main&#123; //定义一个数组 int[] arr = &#123;24,69,80,57,13&#125;; System.out.println(arrayToString(arr)); //第一次比较 for(int i=0;i&lt;arr.length-1;i++)&#123; if(arr[i] &gt; arr[i+1])&#123; int temp = arr[i]; arr[i] = arr[i+1]; arr[i+1] = temp; &#125; &#125; System.out.println(arrayToString(arr)); //第二次比较 for(int i=0;i&lt;arr.length-1-1;i++)&#123; if(arr[i] &gt; arr[i+1])&#123; int temp = arr[i]; arr[i] = arr[i+1]; arr[i+1] = temp; &#125; &#125; System.out.println(arrayToString(arr)); //第三次比较 for(int i=0;i&lt;arr.length-1-2;i++)&#123; if(arr[i] &gt; arr[i+1])&#123; int temp = arr[i]; arr[i] = arr[i+1]; arr[i+1] = temp; &#125; &#125; System.out.println(arrayToString(arr)); //第四次比较 for(int i=0;i&lt;arr.length-1-3;i++)&#123; if(arr[i] &gt; arr[i+1])&#123; int temp = arr[i]; arr[i] = arr[i+1]; arr[i+1] = temp; &#125; &#125; System.out.println(arrayToString(arr)); //优化 for(int x = 0;x &lt; arr.length-1;x++)&#123; for(int i = 0;i &lt; arr.length-1-x;i++)&#123; if(arr[i] &gt; arr[i+1])&#123; int temp = arr[i]; arr[i] = arr[i+1]; arr[i+1] = temp; &#125; &#125; &#125; System.out.println(arrayToString(arr));&#125;//把数组中的元素按照指定的规则组成一个字符串public static String arrayToString(int[] arr)&#123; StringBuilder sb = new StringBuilder(); sb.append(&quot;[&quot;); for(int i = 0;i&lt;arr.length;i++)&#123; if(i == arr.length-1)&#123; sb.append(arr[i]); &#125;else&#123; sb.append(arr[i]).append(&quot;,&quot;); &#125; &#125; sb.append(&quot;]&quot;); String s = sb.toString(); return s;&#125; 最终冒泡排序的代码： 1234567891011//优化for(int x = 0;x &lt; arr.length-1;x++)&#123; for(int i = 0;i &lt; arr.length-1-x;i++)&#123; if(arr[i] &gt; arr[i+1])&#123; int temp = arr[i]; arr[i] = arr[i+1]; arr[i+1] = temp; &#125; &#125;&#125;System.out.println(arrayToString(arr)); Arrays类的概述和常用方法Arrays类包含用于操作数组的各种方法 12345// toString(int[] a)int[] arr = &#123;24,69,80,57,13&#125;;System.out.println(Arrays.toString(arr));Arrays.sort(arr);System.out.println(Arrays.toString(arr)); 输出: 12[24,69,80,57,13][13,24,57,69,80] 有构造方法：private Arrays()&#123;&#125; 工具类的设计思想： 构造方法用private修饰 成员用public static修饰 基本类型包装类概述引入： 需求：判断一个数据是否在int范围内 12System.out.println(Integer.MIN_VALUE);System.out.println(Integer.MAX_VALUE); java.lang.Integer继承于java.lang.Number继承于java.lang.Object 1、将基本数据类型封装成对象的好处：可以在对象中定义更多的功能方法操作该数据 2、常用操作之一：用于基本数据类型与字符串之间的转换 Integer类的概述和使用1、Integer：包装一个对象中的原始类型int的值 2、方法： public static Integer valueOf(int i)：返回表示指定int值的Integer实例 public static Integer valueOf(String s)：返回保存指定值的Integer对象String int和String的相互转换123456789101112int number = 100;//int-&gt;stringString s1 = &quot;&quot; + number;//int-&gt;stringString s2 = String.valueOf(number);String s = &quot;100&quot;;//string-&gt;intInteger i = Integer.valueOf(s);int i1 = i.intValue();//string-&gt;intint i2 = Integer.parseInt(s); 1、int转为String public static String valueOf(int i) 2、String转为int public static int parseInt(String s) 日期类Date类Date代表特定的时间，精确到毫秒 public class Date extends Object implements Serializable,Cloneable,Comparable&lt;Date&gt; 1、构造方法： public Date()：分配一个Date对象，并初始化，以便它代表它被分配的时间，精确到毫秒 public Date(long date) 分配一个Date对象，将其初始化为从标准基准时间（January 1, 1970, 00:00:00 GMT.）起指定的毫秒数 例： 12345678910main&#123; //public Date():分配一个Date对象，并初始化，以便它代表它被分配的时间，精确到毫秒 Date d1 = new Date() // Fri Mar 12 20:39:41 CST 2021 //public Date(long date):分配一个Date对象，并将其初始化为从标准基准时间起指定的毫秒数 long date = 1000*60*60; Date d2 = new Date(date);// Thu Jan 01 09:00:00 CST 1970 &#125; 2、常用方法 public long getTime()：获取日期对象从1970年1月1日0点到现在的毫秒值 public void setTime(long time)：设置时间，给的是毫秒值 例： 12345678910main&#123; //创建日期对象 Date d = new Date(); //public long getTime() d.getTime(); // 1615553049497毫秒 //public void setTime(long time) d.setTime(0); //Thu Jan 01 08:00:00 CST 1970 由于时区不一样，所以结果不一样&#125; SimpleDateFormat类public class SimpleDateFormat extends DateFormat 1、SimpleDateFormat是一个具体类，用于以区域设置敏感的方式格式化和解析日期 2、常用的模式字母及对应关系： y 年 M 月 d 日 H 时 m 分 s 秒 3、构造方法： public SimpleDateFormat()：使用默认模式和日期格式 public SimpleDateFormat(String pattern)：使用给的的模式和日期格式 4、格式化和解析日期方法 格式化（Date到String）：public final String format(Date date) 解析（String到Date）：public Date parse(String source) 例： 12345678910111213141516//格式化Date d = new Date();SimpleDateFormat sdf = new SimpleDateFormat();String s = sdf.format(d);System.out.println(s); //21-3-12 下午8:54SimpleDateFormat sdf1 = new SimpleDateFormat(&quot;yyyy-MM-dd-HH-mm-ss&quot;);String s = sdf1.format(d);System.out.println(s); //2021-03-12-20-55-49//从String到DateString ss = &quot;2021-03-12-20-55-49&quot;;SimpleDateFormat sdf2 = new SimpleDateFormat(&quot;yyyy-MM-dd-HH-mm-ss&quot;);Date dd = sdf2.parse(ss); //这里需要处理异常 throws ParseExceptionSystem.out.println(dd); //Fri Mar 12 20:55:49 CST 2021 Calendar类Calendar类为某一时刻和一组日历字段之间的转换提供了一些方法，并为操作日历字段提供了一些方法 1234567//获取对象Calendar c = Calendar.getInstance(); //多态的形式//public int get(int field)int year = c.get(Calendar.YEAR);int month = c.get(Calendar.MONTH)+1;//从0开始的int day = c.get(Calendar.DATE); 1、常用方法： public int get(int field)：返回给定日历字段的值 public abstract void add(int field,int amount)：根据日历的规则，将指定的时间量添加或减去给定的日历字段 public final void set(int year,int month,int date)：设置当前日历的年月日 12345678910111213//获取对象Calendar c = Calendar.getInstance(); //public abstract void add(int field,int amount)c.add(Calendar.YEAR,1);//年份+1System.out.println(c.get(Calendar.YEAR)); // 2022//public final void set(int year,int month,int date)c.set(2020,1,1);int year = c.get(Calendar.YEAR);int month = c.get(Calendar.MONTH)+1;//从0开始的int day = c.get(Calendar.DATE);System.out.println(year+&quot;-&quot;+month+&quot;-&quot;+day) // 2020-2-1 异常概述1、Throwable类是所有错误（error类）和异常（exception类）的超类 2、异常：就是程序出现了不正常的情况 3、异常体系 Error：严重问题，不需要处理（非检查型异常） Exception：异常类，表示程序本身可以处理的问题 RuntimeException：编译期不检查，出现问题之后需要回来修改代码（非检查型异常）包括：错误的强制类型转换、数组访问越界、访问null指针 非RuntimeException：编译期必须处理，否则不能通过编译（检查型异常）包括：试图超越文件末尾继续添加数据、试图打开一个不存在的文件、试图根据指定的字符串查找class对象，而这个类并不存在 JVM的默认处理方案如果程序出现了问题，我们没有做任何处理，最终JVM会做默认的处理： 把异常的名称、原因、位置等信息输出在控制台 程序停止运行 异常处理两种方案： 使用try..catch.. 使用throws 捕获异常：try-catch格式： 1234567891011try&#123; 可能出现的代码&#125;catch(异常类名 变量名)&#123; 异常处理&#125;执行流程：1、程序从try里面的代码开始执行2、出现异常，会自动生成一个异常类对象，该异常类对象将被提交给Java运行系统3、当java运行时，吸引接收到异常对象，回到catch中去找匹配的异常对象，找到后进行异常的处理4、执行完毕后，程序还可以继续往下执行 例子： 123456try&#123; int[] arr = &#123;1,2,3&#125;; System.out.println(arr[3]);&#125;catch(ArrayIndexOutOfBoundsException e)&#123; e.printStackTrace();&#125; Throwable成员方法1、public String getMessage()：返回此throwable的详细消息字符串 2、public String toString()：返回此可抛出的简短描述 3、public void printStackTrace()：把异常的错误信息输出在控制台 getMessage()源代码： 12345678910public class Throwable&#123; private String detailMessage; public Throwable(String message)&#123; detailMessage = message; &#125; public String getMessage() &#123; return detailMessage; &#125;&#125; 例子： 123456try&#123; int[] arr = &#123;1,2,3&#125;; System.out.println(arr[10]);&#125;catch(ArrayIndexOutOfBoundsException e)&#123; System.out.println(e.getMessage());&#125; toString()12345678try&#123; int[] arr = &#123;1,2,3&#125;; System.out.println(arr[10]);&#125;catch(ArrayIndexOutOfBoundsException e)&#123; System.out.println(e.toString());&#125;输出：java.lang.ArrayIndexOutOfBoundsException: 10 printStackTrace()123456789try&#123; int[] arr = &#123;1,2,3&#125;; System.out.println(arr[10]);&#125;catch(ArrayIndexOutOfBoundsException e)&#123; e.printStackTrace();&#125;输出:java.lang.ArrayIndexOutOfBoundsException: 10 at Test.main(Test.java:13) 抛出异常：throws格式： 1throws 异常类名 例子： 123456789101112131415161718//运行时异常public void method()throws ArrayIndexOutOfBoundsException&#123; int[] arr = &#123;1,2,3&#125;; System.out.println(arr[3]);&#125;//编译时异常public void method2()thorws ParseException&#123; String s = &quot;2020-01-01&quot;; SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); Date d = sdf.parse(s); System.out.println(d);&#125;main&#123; method();//不能往下运行 method2();//使用try-catch即可往下运行&#125; 注意： 编译时异常必须要处理，有两种方案：try-catch或者throws，如果采用throws，将来谁调用谁处理 运行时异常可以不处理，出现问题后需要修改代码 自定义异常格式： 1234public class 异常类名 extends Exception&#123; 无参构造 带参构造&#125; 例子： 123456789101112131415161718public class scoreException extends Exception&#123; public scoreException()&#123;&#125; public scoreException(String message)&#123; super(message); &#125;&#125;public class teacher&#123; public void check(int score)throws scoreException&#123; if(score&lt;0||score&gt;100)&#123; //抛出异常 throw new scoreException(&quot;error&quot;); &#125;else&#123; System.out.println(&quot;normal&quot;); &#125; &#125;&#125; throws和throw的区别1、throws： 用在方法声明后面，跟的是异常类名 表示抛出异常，由该方法的调用者处理 表示出现异常的一种可能性，并不一定会发生这些异常 2、throw： 用在方法体内，跟的是异常对象名 表示抛出异常，由方法体内的语句处理 执行throw一定抛出了某种异常 finally子句 代码抛出一个异常后，就会停止处理这个方法中剩余的代码，并退出这个方法；如果这个方法已经获取了一些本地资源，而且这些资源必须处理，这就会存在问题。 不管是否有异常被捕获，finally子句中的代码都会执行。 例子： 1234567891011121314var in = new FileInputStream(...);try&#123;//1导致异常的执行代码//2&#125;catch(IOexception e)&#123;//3show error message//4&#125;finally&#123;//5in.close();&#125;//6 有三种情况会执行finally子句： 代码没有抛出异常，1、2、5、6 代码抛出一个异常，并在catch中捕获。如果catch中没有抛出异常，程序将会执行finally子句之后的第一条语句（1、3、4、5、6）；如果抛出异常了，异常被抛回这个方法的调用者（1、3、5） 代码抛出了一个异常，但没有catch子句捕获这个异常，（1、5） 在以下 3 种特殊情况下，finally 块不会被执行： 在 try 或 finally 块中用了 System.exit(int)退出程序。但是，如果 System.exit(int) 在异常语句之后，finally 还是会被执行 程序所在的线程死亡。 关闭 CPU。 注意： 当 try 语句和 finally 语句中都有 return 语句时，在方法返回之前，finally 语句的内容将被执行，并且 finally 语句的返回值将会覆盖原始的返回值。 try-with-resources格式： 123try(Resource res=...)&#123; work with res&#125; try退出时，会自动调用res.close() 1、适用范围（资源的定义）： 任何实现 java.lang.AutoCloseable或者 java.io.Closeable 的对象，即&#x3D;&#x3D;需要关闭资源&#x3D;&#x3D; 面对必须要关闭的资源，我们总是应该优先使用 try-with-resources而不是try-finally。随之产生的代码更简短，更清晰，产生的异常对我们也更有用。try-with-resources语句让我们更容易编写必须要关闭的资源的代码，若采用try-finally则几乎做不到这点。 Java 中类似于InputStream、OutputStream 、Scanner 、PrintWriter等的资源都需要我们调用close()方法来手动关闭，一般情况下我们都是通过try-catch-finally语句来实现这个需求，如下： 1234567891011121314//读取文本文件的内容 Scanner scanner = null; try &#123; scanner = new Scanner(new File(&quot;D://read.txt&quot;)); while (scanner.hasNext()) &#123; System.out.println(scanner.nextLine()); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; finally &#123; if (scanner != null) &#123; scanner.close(); &#125; &#125; 使用 Java 7 之后的 try-with-resources 语句改造上面的代码: 1234567try (Scanner scanner = new Scanner(new File(&quot;test.txt&quot;))) &#123; while (scanner.hasNext()) &#123; System.out.println(scanner.nextLine()); &#125;&#125; catch (FileNotFoundException fnfe) &#123; fnfe.printStackTrace();&#125; 当然多个资源需要关闭的时候，使用 try-with-resources 实现起来也非常简单，如果你还是用try-catch-finally可能会带来很多问题。 通过使用分号分隔，可以在try-with-resources块中声明多个资源。 123456789101112try (BufferedInputStream bin = new BufferedInputStream(new FileInputStream(new File(&quot;test.txt&quot;)));BufferedOutputStream bout = new BufferedOutputStream(new FileOutputStream(new File(&quot;out.txt&quot;)))) &#123; int b; while ((b = bin.read()) != -1) &#123; bout.write(b); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; try-with-resource语句自身也可以有catch，甚至可以有finally，这些子句会在关闭资源之后执行 集合进阶集合概述1、概念：对象的容器，实现了对对象常用的操作，类似数组功能 2、集合类的特点：提供一种存储空间可变的存储模型，存储的数据容量可以发生改变 3、和数组的区别： 数组长度固定，集合长度不固定 数组可以存储基本类型和引用类型，集合只能存储引用类型（装箱操作） 4、位置：java.util.* Collection概述和使用1、概述 单列集合的顶层接口，表示一组对象，这些对象称为Collection的元素 JDK不提供此接口的任何直接实现，它提供更具体的子接口（set和list）实现 2、创建Collection集合的对象 多态的方式 具体的实现类ArrayList 例子： 1234567891011main&#123; //创建Collection集合的对象 Collection&lt;String&gt; c = new ArrayList&lt;String&gt;(); //添加元素:boolean add(E e) c.add(&quot;hello&quot;); c.add(&quot;world&quot;) //输出集合对象 System.out.println(c);&#125; 常用方法1、boolean add(E e)：添加元素，永远返回true 2、boolean remove(Object o)：从集合中移除指定的元素 3、void clear()：清空集合中的元素 4、boolean contains(Object o)：判断集合中是否存在指定元素 5、boolean isEmpty()：判断集合是否为空 6、int size()：集合的长度 使用Iterator迭代器遍历1、Iterator：迭代器，集合的专用遍历方式 Iterator&lt;E&gt; iterator()：返回此集合中元素的迭代器，通过集合的iterator()方法得到 迭代器是通过集合的方法得到的，所以说它是依赖于集合存在的 2、Iterator中的常用方法： E next()：返回迭代的下一个元素 boolean hasNext()：如果迭代具有更多元素，则返回true 例子： 1234567891011121314151617181920212223242526Collection&lt;String&gt; c = new ArrayList&lt;String&gt;();c.add(&quot;a&quot;);c.add(&quot;b&quot;);c.add(&quot;c&quot;);//生成迭代器Iterator&lt;String&gt; it = c.iterator();/* //iterator方法 public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; //Itr:内部类 private class Itr implements Iterator&lt;E&gt;&#123;....&#125;*///next：返回迭代的下一个元素System.out.println(it.next());//aSystem.out.println(it.next());//bSystem.out.println(it.next());//cSystem.out.println(it.next());//多调用会抛出异常NoSuchElementException，表示被请求的元素不存在//优化：hasNext(),多次调用不会抛出异常while(it.hasNext())&#123; System.out.println(it.next());&#125; 集合的使用步骤 步骤： 创建集合对象 添加元素 遍历集合 通过集合对象获取迭代器对象 通过迭代器对象的hasNext()方法判断是否还有元素 通过迭代器对象的next()方法获取下一个元素 List概述和特点概述： 有序集合（也称为序列），用户可以精确控制列表中每个元素的插入位置，用户可以通过整数索引访问元素，并搜索列表中的元素 与set集合不同，列表通常允许重复的元素 特点： 有序：存储和取出的元素顺序一致 可重复：存储的元素可以重复 例子： 12345678910111213141516//创建集合对象List&lt;String&gt; list = new ArrayList&lt;String&gt;();//添加元素list.add(&quot;1&quot;);list.add(&quot;2&quot;);list.add(&quot;3&quot;);list.add(&quot;3&quot;);//输出集合对象System.out.println(list)//[1,2,3,3]//遍历集合Iterator&lt;String&gt; iterator = list.iterator();while(iterator.hasNext())&#123; System.out.println(iterator.next());&#125;//1 2 3 3 list集合的特有方法1、void add(int index,Element)：插入指定位置的元素 2、E remove(int index)：删除指定索引处的元素，返回被删除的元素 3、E set(int index,E element)：修改指定索引处的元素，返回被修改的元素 4、E get(int index)：返回指定索引处的元素 并发修改异常 需求：有一个集合list，里面三个元素：hello、world、java，遍历集合得到每一个元素，看看有没有world，如果有就添加一个javaee元素 12345678910111213List&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;hello&quot;);list.add(&quot;world&quot;);list.add(&quot;java&quot;);Iterator&lt;String&gt; it = list.iterator();while(it.hasNext())&#123; String s = it.next(); if(s.equals(&quot;world&quot;))&#123; list.add(&quot;javaee&quot;); &#125;&#125; 1、结果： 1报错：Exception in thread &quot;main&quot; java.util.ConcurrentModificationException 2、源码分析： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public interface List&lt;E&gt;&#123; boolean add(E e); Iterator&lt;E&gt; iterator();&#125;public abstract class AbstractList&lt;E&gt;&#123; int modCount = 0;&#125;public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;&#123; //获取迭代器 public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; private class Itr implements Iterator&lt;E&gt; &#123; //光标 默认0 int cursor; //记录 -1 int lastRet = -1; //将集合实际修改次数赋值给预期修改次数 int expectedModCount = modCount; //判断集合是否有元素 public boolean hasNext() &#123; return cursor != size; &#125; //获取下一个元素 public E next() &#123; checkForComodification(); //将光标赋值给i int i = cursor; //判断，如果大于size说明没有元素了 if (i &gt;= size) throw new NoSuchElementException(); //把集合存储数组的地址复制给该方法的局部变量 Object[] elementData = ArrayList.this.elementData; //进行判断，条件满足抛出并发修改异常 if (i &gt;= elementData.length) throw new ConcurrentModificationException(); //光标自增 cursor = i + 1; //返回局部变量数组的元素 return (E) elementData[lastRet = i]; &#125; //校验预期修改次数和实际修改次数是否一致 final void checkForComodification() &#123; if (modCount != expectedModCount) //抛出并发修改异常 throw new ConcurrentModificationException(); &#125; &#125; &#125; 分析： 12345报错行：String s = it.next();由于ArrayList的内部类Itr的next方法中首先调用了checkForComodification方法，而这个方法中如果modCount不等于expectedModCount的话就会抛出异常；在add操作中，会在ensureExplicitCapacity方法中对modCount进行++，因此，modeCount不等于expectedModCount了，所以会抛出异常 结论： 当要删除的元素在集合的倒数第二个元素的位置，不会发生并发修改异常 原因：调用hasnext方法时，光标的值和集合的长度一样，就会返回false，因此不会再去调用next方法，不会产生并发修改异常 解决方案：使用Itr的remove方法即可 listIterator列表迭代器1、通过list集合的listIterator()方法得到，所以说它是list集合特有的迭代器 2、用于允许程序员沿任一方向遍历列表的列表迭代器，在迭代期间修改列表，并获取列表中迭代器的当前位置 3、常用方法： E next()：返回迭代中的下一个元素 boolean hasNext() E previous()：返回迭代中的上一个元素 boolean hasPrevious()：如果此列表迭代器在相反方向遍历列表时具有更多元素，则返回true void add(E e)：插入列表 例子： 1234567891011121314151617181920212223List&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;1&quot;);list.add(&quot;2&quot;);list.add(&quot;3&quot;);list.add(&quot;3&quot;);ListIterator&lt;String&gt; lit = list.listIterator();//正向迭代while(lit.hasNext())&#123; System.out.println(lit.next());&#125;//逆向迭代while(lit.hasPrevious())&#123; System.out.println(lit.previous());&#125;//增加元素while(lit.hasNext())&#123; String s = lit.next(); if(s.eauals(&quot;world&quot;))&#123; lit.add(&quot;javaee&quot;); &#125;&#125; 注意：这里使用迭代器添加元素，不会报错～～ 源码分析123456789101112131415161718192021222324252627public interface List&lt;E&gt;&#123; ListIterator&lt;E&gt; listIterator();&#125;public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;&#123; public ListIterator&lt;E&gt; listIterator() &#123; return new ListItr(0); &#125; //Itr private class Itr implements Iterator&lt;E&gt; &#123;....&#125; //ListItr private class ListItr extends Itr implements ListIterator&lt;E&gt; &#123; public void add(E e) &#123; checkForComodification(); try &#123; int i = cursor; ArrayList.this.add(i, e); cursor = i + 1; lastRet = -1; //实际修改值赋值给预期修改值！！！！ expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125;&#125; 不会出现并发修改异常的原因：重写了add方法，添加了expectedModCount = modCount; 增强for循环简化数组和Collection集合的遍历 实现Iterable接口的实现类，允许其对象称为增强for语句的目标 是JDK5之后出现的，内部原理是一个Iterator迭代器 格式： 1for(元素数据类型 变量名 : 数组或者Collection集合)&#123;...&#125; 例子： 12345678910List&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;1&quot;);list.add(&quot;2&quot;);list.add(&quot;3&quot;);list.add(&quot;3&quot;);for(String s : list)&#123; System.out.println(s);&#125; 数据结构数据结构是计算机存储、组织数据的方式，是指相互之间一种或多种特定关系的数据元素的集合，通常情况下精心挑选的数据结构可以带来更高的效率 栈1、结构： 2、压栈操作 压栈顺序：A、B、C、D 3、出栈 出栈顺序：D、C、B、A 先进后出 队列1、结构 2、入队列：从后端进入队列 3、出队列：从前端出队列 先进先出 数组1、结构 2、查询数据通过索引定位，查询任意数据耗时相同，查询效率高 3、删除数据时，要将原始数据删除，同时后面的每个数据后移，删除效率低 4、添加数据时，添加位置后的每个数据后移，再添加元素，添加效率低 链表1、结点的结构： 2、结构： 3、在链表中添加数据 4、删除数据 链表是一个增加、删除快的模型（对比数组） 5、查询数据必须要从头开始查询，所以是一种查询慢的模型（对比数组） list集合子类的特点list集合常用子类：ArrayList、LinkedList ArrayList：底层数据结构是数组，查询慢，增删慢 LinkedList：底层数据结构是链表，查询慢，增删快 LinkedList： 1、public void addFirst(E e)：在该链表开头插入指定元素 2、public void addLast(E e)：在指定元素追加到此链表结尾 3、public E getFirst()：返回第一个元素 4、public E getLast()：返回最后一个元素 5、public E removeFirst()：删除并返回第一个元素 6、public E removeLast()：删除并返回最后一个元素 例子： 123456789101112131415161718192021222324252627LinkedList&lt;String&gt; l = new LinkedList&lt;String&gt;();l.add(&quot;0&quot;);l.add(&quot;1&quot;);l.add(&quot;2&quot;);//public void addFirst(E e)l.addFirst(&quot;3&quot;)System.out.println(l);//[3,0,1,2]//public void addLast(E e)l.addLast(&quot;4&quot;)System.out.println(l);//[3,0,1,2,4]//public E getFirst()l.getFirst();//3//public E getLast()l.getLast();//4//public E removeFirst()l.removeFirst();//3System.out.println(l);//[0,1,2,4]// public E removeLast()l.removeLast();//4System.out.println(l);//[0,1,2] Set概述和特点1、特点 不包含重复元素 没有索引，不能使用普通的for循环遍历 例子： 1234567891011121314151617需求：存储字符串并遍历Set&lt;String&gt; s = new HashSet&lt;String&gt;();s.add(&quot;hello&quot;);s.add(&quot;java&quot;);s.add(&quot;world&quot;);//增强forfor(String i:s)&#123; System.out.println(i);&#125;//输出结果javaworldhello 哈希值哈希值：JDK根据对象的地址或者字符串或者数字算出来的int类型数值 Object类中的public int hashCode()方法可以获取对象的哈希值 例子： 123456789101112131415161718192021public class student&#123; private String name; private int age;&#125;main&#123; //创建学生对象 student s = new student(&quot;a&quot;,10); //同一个对象的哈希值相同 System.out.println(s.hashCode()); //默认情况下（不重写hashCode()方法的情况下），不同对象的哈希值不同 student s1 = new student(&quot;a&quot;,10); System.out.println(s1.hashCode()); System.out.println(&quot;a&quot;.hashCode());//97 System.out.println(&quot;b&quot;.hashCode());//98 System.out.println(&quot;c&quot;.hashCode());//99 System.out.println(&quot;重地&quot;.hashCode());//1179395 System.out.println(&quot;通话&quot;.hashCode());//1179395 对象的哈希值的特点： 同一对象多次调用hashCode()方法返回的哈希值相同 默认情况下，不同对象的哈希值不同 HashSetHashSet集合特点 底层数据结构是哈希表 对集合的迭代顺序不保证 不带索引 不饱和重复元素 HashSet保证元素唯一的源码分析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class HashSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;&#123; //add方法 public boolean add(E e) &#123; return map.put(e, PRESENT)==null; &#125; &#125;public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; //hash值与hashCode方法相关 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果哈希表未初始化，就对齐初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //根据对象的哈希值计算对象的存储位置，如果该位置没有元素，就存储元素 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // p.hash == hash：存入的元素和以前的元素比较哈希值 // 如果不同就继续向下执行，把元素添加到集合；如果相同，会调用对象的equals方法来进行比较 // 如果equals返回false，把元素添加到集合；如果返回true说明元素重复、不存储 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125;&#125; HashSet集合添加元素的过程 要保证元素的唯一性，就需要重写hashCode()和equals() 哈希表哈希表： JDK8之前，底层采用数组+链表实现，可以说是元素为链表的数组 JDK8之后，在长度比较长之后，底层做出了优化 1、哈希表如何保证元素唯一性的？ LinkedHashSet1、特点： 哈希表和链表实现set接口，具有可预测的迭代次序 由链表保证元素有序，也就是说元素的存储和取出顺序一致 由哈希表保证元素唯一，也就是说没有重复的元素 TreeSet1、特点： 元素有序，按照一定的顺序进行排序，取决于构造方法TreeSet()：根据元素的自然排序进行排序TreeSet(Comparator comparator)：根据指定的比较器进行排序 没有带索引的方法 不含重复元素 例子： 123456789TreeSet&lt;Integer&gt; ts = new TreeSet&lt;Integer&gt;();ts.add(&quot;3&quot;);ts.add(&quot;2&quot;);ts.add(&quot;1&quot;);for(String s:ts)&#123; System.out.println(s);//1,2,3 自然排序&#125; 自然排序Comparable存储学生对象并遍历，创建TreeSet集合使用无参构造方法 需求：按照年龄从小到大，年龄相同按照名字字母排序 123456789101112131415161718192021222324252627282930public class stu implements Comparable&lt;stu&gt;&#123; String name; Int age; @Override public int compareTo(stu s)&#123; //相等：return 0; //升序：return 1； //降序：return -1； int num = this.age-s.age num == 0 ? this.name.compareTo(s.name):num return num; &#125;&#125;main&#123; TreeSet&lt;stu&gt; ts = new TreeSet&lt;stu&gt;(); stu s1 = new stu(&quot;aa&quot;,1); stu s2 = new stu(&quot;bb&quot;,2); stu s3 = new stu(&quot;ab&quot;,1); stu s4 = new stu(&quot;cc&quot;,3); ts.add(s1); ts.add(s2); ts.add(s3); ts.add(s4); for(stu s:ts)&#123; System.out.println(s); &#125;&#125; 结论： 用TreeSet集合存储自定义对象，无参构造方法使用的是自然排序对元素进行排序 自然排序：元素所属的类实现Comparable接口，重写compareTo方法 比较器排序Comparator存储学生对象并遍历，创建TreeSet集合使用带参构造方法 需求：按照年龄从小到大，年龄相同按照名字字母排序 123456789101112131415161718192021222324252627public class stu implements Comparable&lt;stu&gt;&#123; String name; Int age;&#125;main&#123; TreeSet&lt;stu&gt; ts = new TreeSet&lt;stu&gt;(new Comparator&lt;stu&gt;()&#123; @Override public int compare(stu s1,stu s2)&#123; int num = s1.age-s2.age num == 0 ? this.name.compareTo(s.name):num return num; &#125; &#125;); stu s1 = new stu(&quot;aa&quot;,1); stu s2 = new stu(&quot;bb&quot;,2); stu s3 = new stu(&quot;ab&quot;,1); stu s4 = new stu(&quot;cc&quot;,3); ts.add(s1); ts.add(s2); ts.add(s3); ts.add(s4); for(stu s:ts)&#123; System.out.println(s); &#125;&#125; 结论： 用TreeSet集合存储自定义对象，有参构造方法使用的是比较器排序对元素进行排序 比较器排序：让集合构造方法接收Comparator的实现类对象，重写compare方法 泛型1、泛型：是JDK5引入的特性，提供了编译时类型安全监测机制，该机制允许在编译时检测到非法的类型 2、本质：参数化类型，也就是说所操作的数据类型被指定为一个参数 参数化类型：将类型由原来的具体的类型参数化，然后在调用&#x2F;使用的时候传入具体的类型 参数化类型可以用在类（泛型类）、方法（泛型方法）、接口（范型接口）中 3、格式： 123&lt;类型&gt;：指定一种类型的歌手，这里的类型可以看作形参&lt;类型1，类型2...&gt;：指定多种类型的格式，多种类型之间由逗号隔开，可以看作形参将来具体调用时给定的类型可以看作实参，并且实参只能是引用数据类型 4、好处 把运行期间的问题提前到了编译期间 避免了强制类型转换 泛型类123456789101112131415public class stu&#123; private String name;&#125;public class teacher&#123; private Integer age;&#125;main&#123; stu s = new stu(); s.setName(&quot;a&quot;); teacher t = new teacher(); t.setAge(30); //t.setAge(&quot;30&quot;); 会报错，只能接受integer&#125; 泛型类的定义格式： 12修饰符 class 类名&lt;类型&gt;&#123;&#125;类型：T、E、K、V... 新建泛型类： 1234567891011public class generic&lt;T&gt;&#123; private T t; get/set...&#125;main&#123; generic&lt;String&gt; g1 = new generic&lt;String&gt;(); g1.setT(&quot;a&quot;);//只能填String generic&lt;Integer&gt; g2 = new generic&lt;Integer&gt;(); g1.setT(1);//只能填Integer&#125; 泛型方法12345678910111213141516171819public class gen&#123; public void show(String s)&#123;System.out.println(s);&#125; public void show(Integer s)&#123;System.out.println(s);&#125; public void show(Boolean s)&#123;System.out.println(s);&#125;&#125;main&#123; gen g = new gen(); g.show(&quot;a&quot;); g.show(30); g.show(true);&#125;问题：方法必须一一对应，太麻烦解决1:使用范型类进行改进public class gen&lt;T&gt;&#123; public void show(T s)&#123;System.out.println(s);&#125;&#125;问题：想要使用不同方法必须创建一个新的类，麻烦 范型方法格式： 1修饰符 &lt;类型&gt; 返回值类型 方法名(类型 变量名)&#123;&#125; 改进： 123public class gen&#123; public &lt;T&gt; void show(T s)&#123;System.out.println(s);&#125;&#125; 泛型接口1、定义格式： 1修饰符 interface 接口名&lt;类型&gt;&#123;&#125; 例子： 123456789101112131415public interface gen&lt;T&gt;&#123; void show(T t);&#125;public class gen1&lt;T&gt; implements gen&lt;T&gt;&#123; @Override public void show(T t)&#123; System.out.println(t); &#125;&#125;main&#123; gen&lt;String&gt; g = new gen1&lt;String&gt;(); g.show(&quot;1&quot;);&#125; 类型擦除Java 的泛型是伪泛型，这是因为 Java 在编译期间，所有的泛型信息都会被擦掉，这也就是通常所说类型擦除。 Java的泛型基本上都是在编译器这个层次上实现的，在生成的字节码中是不包含泛型中的类型信息的，使用泛型的时候加上类型参数，在编译器编译的时候会去掉，这个过程成为类型擦除。 为什么使用？为了兼容jdk老版本的编码 使用反射验证 123456789public static void main(String[] args) throws Exception&#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(&quot;AA&quot;); Class&lt;? extends List&gt; aClass = list.getClass(); Method add = aClass.getMethod(&quot;add&quot;, Object.class); add.setAccessible(true); add.invoke(list,123); System.out.println(list);&#125; 类型通配符java中的父子类在泛型不被认可，所以要使用通配符进行处理；接下来会使用通配符在泛型在将java中的继承关系重新绑定 通配符一般使用？来表示，可以理解？是泛型中所有类的父类 如果我们不希望list&lt;?&gt;是任何泛型list的父类，只希望它代表某一种泛型list的父类，可以使用类型通配符的上限： 类型通配符上限：&lt;?extends 类型&gt; list&lt;?extends Number&gt;：表示的类型是Number或者其子类型 指定下限： 类型通配符下限：&lt;?super 类型&gt; list&lt;?super Number&gt;：表示的类型是Number或者其父类型 12345678910111213141516171819202122232425262728//类型通配符：`&lt;?&gt;`List&lt;?&gt; l1 = new ArrayList&lt;Object&gt;();List&lt;?&gt; l2 = new ArrayList&lt;Number&gt;();//上限public void show(List&lt;? extends Number&gt; p)&#123; System.out.println(&quot;1&quot;);&#125;main&#123; List&lt;String&gt; a = new ArrayList&lt;&gt;(); List&lt;Integer&gt; b = new ArrayList&lt;&gt;(); show(a)//报错 show(b)//不报错&#125;//下限public void show(List&lt;? super Integer&gt; p)&#123; System.out.println(&quot;1&quot;);&#125;main&#123; List&lt;Object&gt; a = new ArrayList&lt;&gt;(); List&lt;Integer&gt; b = new ArrayList&lt;&gt;(); show(a)//不报错 show(b)//不报错&#125; 问题：什么时候用上边界，什么时候用下边界？ 答：上边界在读取T这个类型数据的时候，但不写入数据的时候使用；下边界在需要写入数据时，但不需要读取的时候使用 常用的通配符为： T，E，K，V，？ ？ 表示不确定的 java 类型 T (type) 表示具体的一个 java 类型 K V (key value) 分别代表 java 键值中的 Key Value E (element) 代表 Element Map1、概述和使用 Interface Map&lt;K,V&gt; K：键；V：值 将键映射到值的对象；不能包含重复的键；每个键可以映射到最多一个值 2、创建Map集合对象 多态的方式 HashMap 例子： 12345678910main&#123; Map&lt;String,String&gt; a = new HashMap&lt;String,String&gt;(); //put：添加方法，第一次出现添加元素，多次出现更改元素 a.put(&quot;a&quot;,&quot;a1&quot;); a.put(&quot;b&quot;,&quot;b1&quot;); a.put(&quot;b&quot;,&quot;b2&quot;); System.out.println(a);//&#123;a=a1, b=b2&#125;&#125; 基本功能 获取功能 遍历1、方式1： 获取所有键的集合，用keySet方法实现 遍历键的集合，获取每一个键，用增强for循环实现 根据键找值，用get方法实现 2、方式2： 获取键值对对象集合，用entrySet方法 遍历键值对对象集合，得到每一个键值对对象，用增强for循环实现 根据键值对对象获取键和值，getKey获取键，getValue获取值 Collections1、概述：是对集合操作的工具类 2、常用方法： public static &lt;T extends Comparable&lt;? super T&gt;&gt; void sort(List&lt;T&gt; list)：将指定的列表按照升序排列 public static void reverse(List&lt;?&gt; list)：反转指定列表中元素的顺序 public static void shuffle(list&lt;?&gt; list)：使用默认的随机源随机排序列表 12345678910111213141516List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();list.add(10);list.add(30);list.add(20);list.add(50);list.add(40);Collections.sort(list);System.out.println(list);//10、20、30、40、50Collections.reverse(list);System.out.println(list);//40、50、20、30、10Collections.shuffle(list);System.out.println(list);//每次运行都不一样 对于排序，使用比较器进行排序 123456Collections.sort(array,new Comparator&lt;stu&gt;()&#123; @Override public int compare(stu s1,stu s2)&#123; ..... &#125;&#125;) IO流File概述和构造方法File：是文件和目录路径名的抽象表示 文件和目录是可以通过File封装成对象的 对于File而言，其封装的并不是一个真正存在的文件，仅仅是一个路径名而已，它可以是存在的，也可以不存在。将来要通过具体的操作把这个路径的内容转换为具体的存在。 1、方法 File(String pathname)：通过将给定的路径名字符串转换为抽象路径名来创建新的File实例 File(String parent,String child)：从父路径名字符串和子路径字符串创建新的File实例 File(File parent,String child)：从父抽象路径名和子路径名字符串创建新的File实例 例子： 123456789File l1 = new File(&quot;/Users/zhangtao/Desktop/2/1.txt&quot;);System.out.println(l1);///Users/zhangtao/Desktop/2/1.txtFile l2 = new File(&quot;/Users/zhangtao/Desktop/2&quot;,&quot;1.txt&quot;);System.out.println(l2);///Users/zhangtao/Desktop/2/1.txtFile l3 = new File(&quot;/Users/zhangtao/Desktop/2&quot;);File l4 = new File(l3,&quot;1.txt&quot;);System.out.println(l4);///Users/zhangtao/Desktop/2/1.txt File类的创建功能方法： public boolean creatNewFile()：文件不存在时，创建新的空文件 public boolean mkdir()：创建目录 public boolean mkdirs()：创建目录，包括不存在的父目录（多级目录） 例子： 12345678910111213public static void main(String[] args) throws IOException &#123; //需求1：创建/Users/zhangtao/Desktop/2/目录下java.txt文件 File l1 = new File(&quot;/Users/zhangtao/Desktop/2/java.txt&quot;); System.out.println(l1.createNewFile());//再次创建会出现false //需求2:创建/Users/zhangtao/Desktop/2/目录下的一个目录javase File l2 = new File(&quot;/Users/zhangtao/Desktop/2/javase&quot;); System.out.println(l2.mkdir());//再次创建会出现false //需求3：创建多级目录java/javase/ File l3 = new File(&quot;/Users/zhangtao/Desktop/2/java/javase&quot;); System.out.println(l3.mkdirs());//再次创建会出现false&#125; File类的判断和获取功能 File类的删除功能方法： public boolean delete()：删除文件或者目录 绝对路径和相对路径的区别： 绝对路径：完整的路径名，不需要其他信息就可以定位文件 相对路径：使用其他路径名的信息进行解释 注意：如果一个目录中有内容，就必须逐层删除 递归递归概述：方法定义中调用方法本身 例子： 每个月的兔子：1、1、2、3、5、8….，从第三个月开始每个月的数量是前两个月之和 12345678910111213141516public static void main(String[] args) throws IOException &#123; System.out.println(get(20)); &#125; /** * 首先定义一个方法 * 定一个方法f(n)表示第n个月的兔子 * 如何表示n-1个月的兔子？f(n-1) * 如何表示n-2个月的兔子？f(n-2) * */ public static int get(int n)&#123; if(n==1||n==2)&#123; return 1; &#125;else &#123; return get(n - 1) + get(n - 2); &#125; &#125; 递归 思路： 把一个复杂的问题层层转化为一个与原问题相似的规模较小的问题来求解 递归策略只需少量的程序就可以描述出解题过程所需要的多次重复计算 递归解决问题要找到两个内容： 递归出口：否则会出现内存溢出 递归规则：与原问题相似的规模较小的问题 案例1：递归求阶乘 1234567public static int get(int n)&#123; if(n==1)&#123; return 1; &#125;else&#123; return get(n-1)*n; &#125; &#125; 案例2：遍历目录并打印所有文件的路径 123456789101112public static void get(File n)&#123; File [] files = n.listFiles(); if(files!=null)&#123; for(File file:files)&#123; if(file.isDirectory())&#123; get(file); &#125;else&#123; System.out.println(file.getAbsolutePath()); &#125; &#125; &#125; &#125; 字节流IO流概述和分类1、概述： IO：输入&#x2F;输出 流：一种抽象概念，是对数据传输的总称，也就是说数据在设备间的传输统称为流，流的本质是数据传输 IO流就是用来处理设备间数据传输问题的常见应用：文件复制、文件上传、文件下载 2、分类： 按照数据的流向分类输入流：读数据输出流：写数据 按照数据类型分类字节流：字节输入流、字节输出流（记事本打开，读不懂的内容，不知道选什么就选字节流）字符流：字符输入流、字符输出流（记事本打开，读得懂的内容） 一般来说，IO流的分类按照数据类型分类 字节流写数据字节流抽象基类： InputStream：表示字节输入流的类的超类 OutputStream：表示字节输出流的所有类的超类 子类名特点：子类名称都是以其父类名作为子类名的后缀 FileOutputStream：文件输出流用于将数据写入File FileOutputStream (String name)：创建文件输出流以指定的名称写入文件 public void write(int b)：根据输入转为字符，写入文件中 例： 123456//创建字节输出流对象，能够自动生成文件FileOutputStream a = new FileOutputStream(&quot;a.txt&quot;);a.write(97);//aa.write(57);//9//释放资源a.close(); 字节流写数据的三种方式例子： 123456789101112131415161718//创建字节输出流对象，能够自动生成文件FileOutputStream a = new FileOutputStream(&quot;a.txt&quot;);//public void write(int b)a.write(97);//aa.write(57);//9//public void write(byte b[])byte[] by = &#123;97,98,99,100&#125;;a.write(by);//abcde//String.getBytes()：返回字符串的字节数组a.write(&quot;zhang&quot;.getBytes());//public void write(byte b[], int off, int len)a.write(by,1,3);//bcd//释放资源a.close(); 字节流写数据的两个小问题1、如何实现换行？ 12345使用换行符号换行win：\\r\\nmac：\\rlinux：\\n 2、如何实现追加写入？ 12//使用true表示文件写入到末尾FileOutputStream a = new FileOutputStream(&quot;a.txt&quot;,true); 字节流写数据加异常处理(finally)finally：在异常处理时提供finally来执行所有清楚操作，比如说IO流的释放资源 特点：被finally控制的语句一定会执行，除非JVM退出 格式： 1234567try&#123; 可能导致异常的执行代码&#125;catch(IOexception e)&#123; 异常处理&#125;finally&#123; 执行所有清除操作&#125; 例子： 123456789101112131415FileOutputStream a = null;try&#123; a = new FileOutputStream(&quot;a.txt&quot;); a.write(&quot;zhang&quot;.getBytes());&#125;catch (IOException e)&#123; e.printStackTrace();&#125;finally &#123; if(a!=null)&#123; try &#123; a.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 字节流读数据（一次读一个字节数据） 需求：把文件的内容读出来打印到控制台 FileInputStream：从文件系统中的文件获取输入字节 FileInputStream(String name)：通过打开与实际文件的连接来创建一个FileInputStream，该文件由文件系统中的路径名name命名 步骤： 创建字节输入流对象 调用字节输入流对象的读数据方法 释放资源 读取数据：public int read() 12345678910111213141516171819202122232425262728293031public static void main(String[] args) throws IOException &#123; FileInputStream fs = new FileInputStream(&quot;a.txt&quot;); // public int read():读取一个字节的数据 int by = fs.read();//第一次读取 System.out.println((char)by);//a int by2 = fs.read();//第二次读取 System.out.println((char)by2);//9 int by3 = fs.read();//第三次读取 System.out.println(by3);//没有数据了返回-1 //循环读取 int by4 = fs.read(); while (by4!=-1)&#123; System.out.print((char)by4); by4 = fs.read(); &#125; //优化循环读取 //fs.read():读取数据 //by5=fs.read():赋值操作 //by5!=-1：判断数据是不是-1 int by5; while ((by5=fs.read())!=-1)&#123; System.out.println(by5); &#125; fs.close(); &#125; 案例：复制文本文件 12345678910111213分析：读取文件-&gt;写入新文件public static void main(String[] args) throws IOException &#123; FileInputStream fs = new FileInputStream(&quot;a.txt&quot;); FileOutputStream fo = new FileOutputStream(&quot;b.txt&quot;); int by; while ((by=fs.read())!=-1)&#123; fo.write(by); &#125; fs.close(); fo.close();&#125; 字节流读取数据（一次读一个字节数组）需求：把文件内容读取出来在控制台输出 public int read(byte b[]) 123456789101112131415161718192021222324252627public static void main(String[] args) throws IOException &#123; //文件中数据：12345678 FileInputStream fs = new FileInputStream(&quot;a.txt&quot;); //public int read(byte b[])：从输入流读取最多b.length个字节的数据到一个字节数组 byte[] bys = new byte[5]; //第一次读取数据：12345 //len表示实际读取的个数,-1表示末尾 int len = fs.read(bys); System.out.println(new String(bys,0,len)); //第二次读取：67845，只覆盖了前三个 len = fs.read(bys); System.out.println(new String(bys,0,len)); //第三次读取：67845，不变 len = fs.read(bys); //public String(char value[], int offset, int count) System.out.println(new String(bys,0,len)); //循环改进 byte[] bys2 = new byte[1024];//1024及其整数倍 int len1; while ((len1=fs.read(bys2))!=-1)&#123; System.out.print(new String(bys2,0,len1)); &#125; fs.close(); &#125; 字节缓冲流1、BufferOutputStream：该类实现缓冲输出流，通过设置这样的输出流，应用程序可以向底层输出流写入字节，而不必为写入的每个字节导致底层系统的调用 2、BufferInputStream：创建一个内部缓冲区数组，读取或者跳过字节时，内部缓冲区将根据需要从所包含的输入流中重新填充，一次很多字节 3、构造方法： 字节缓冲输出流：BufferOutputStream(OutputStream out) 字节缓冲输入流：BufferInputStream(InputStream in) 为什么构造方法需要的不是具体的文件？ 字节缓冲流只是提供缓冲区，真正的读写还得依靠字节流对象 就是构造方法和前面不一样，其他的应用方式一样 使用字节缓冲流进行复制文件，效率很高 字符流为什么会出现字符流？1、存储汉字： GBK编码：占用2个字节 UTF-8编码：占用3个字节 为什么复制文本文件有中文没有问题？ 123String s = &quot;中国&quot;;byte[] bys = s.getBytes(&quot;UTF-8&quot;);[-28,-72,-83,-27,-101,-67]byte[] bys2 = s.getBytes(&quot;GBK&quot;);[-42,-48,-71,-6] 因为中文字符编码存储后第一个字节永远是负的，拼接的时候就知道这个是汉字，再根据编码格式进行拼接。 2、由于字节流操作中文不方便，所以Java提供了字符流 字符流&#x3D;字节流+编码表 编码表计算机中存储的信息都是二进制数表示的 编码：按照某种规则，将字符存储到计算机中 解码：将存储在计算机中的二进制数按照某种规则解析 字符串中的编码解码问题1、编码： byte[] getBytes() byte[] getBytes(String charsetName) 2、解码： String(byte[] bytes)： String(byte[] bytes,String charsetName) 例子： 12345678String s = &quot;中国&quot;;byte[] bys = s.getBytes();// [-28, -72, -83, -27, -101, -67]byte[] bys1 = s.getBytes(&quot;UTF-8&quot;);// [-28, -72, -83, -27, -101, -67]byte[] bys2 = s.getBytes(&quot;GBK&quot;);// [-42, -48, -71, -6]String ss = new String(bys);//中国String ss1 = new String(bys1,&quot;UTF-8&quot;);//中国String ss2 = new String(bys1,&quot;GBK&quot;);//中国 字符流中的编码解码问题抽象基类： Reader Writer 相关的两个类： InputStreamReader：字节流到字符流的桥梁，读取字节并使用指定的字符集解码为字符 OuputStreamWriter：字符流到字节流的桥梁，使用指定的字符集将写入的字符编码为字节 例子： 12345678910111213141516171819public static void main(String[] args) throws IOException &#123; //public OutputStreamWriter(OutputStream out) //public OutputStreamWriter(OutputStream out, String charsetName) OutputStreamWriter os = new OutputStreamWriter(new FileOutputStream(&quot;a.txt&quot;),&quot;UTF-8&quot;); os.write(&quot;中国&quot;); os.close(); //public InputStreamReader(InputStream in) //public InputStreamReader(InputStream in, String charsetName) InputStreamReader isr = new InputStreamReader(new FileInputStream(&quot;a.txt&quot;)); //一次读取一个字符数据 int ch; while ((ch=isr.read())!=-1)&#123; System.out.println((char)ch); &#125; isr.close(); &#125; 字符流写数据的五种方式 12345678910111213OutputStreamWriter os = new OutputStreamWriter(new FileOutputStream(&quot;a.txt&quot;),&quot;UTF-8&quot;);//public void write(int c) os.write(97); //public void write(char cbuf[]) char[] chs=&#123;&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;&#125;; os.write(chs); //public void write(char cbuf[], int off, int len) os.write(chs,0,chs.length); //public void write(String str) os.write(&quot;中国&quot;); //public void write(String str, int off, int len) os.write(&quot;中国nb&quot;,1,2); os.close(); 字符流读数据的两种方式 123456789101112131415public static void main(String[] args) throws IOException &#123; InputStreamReader isr = new InputStreamReader(new FileInputStream(&quot;a.txt&quot;),&quot;UTF-8&quot;); //public int read() int ch; while ((ch=isr.read())!=-1)&#123; System.out.print((char)ch); &#125; //public int read(char cbuf[], int offset, int length) char[] chs = new char[1024]; int len; while ((len=isr.read(chs))!=-1)&#123; System.out.print(new String(chs,0,len)); &#125; isr.close(); &#125; FileReader和FileWriter当不涉及编码和解码时使用来简化操作 FileReader(String name)：读取字符文件的便捷类FileWriter(String name)：写入字符文件的便捷类 案例：复制文件 12345678910public static void main(String[] args) throws IOException &#123; FileReader isr = new FileReader(&quot;a.txt&quot;); FileWriter fw = new FileWriter(&quot;c.txt&quot;); int ch; while ((ch=isr.read())!=-1)&#123; fw.write(ch); &#125; isr.close(); fw.close(); &#125; 字符缓冲流用来提高读写数据的效率 BufferedReader(Reader in) BufferedWriter(Writer out)： 案例：复制文件 12345678910public static void main(String[] args) throws IOException &#123; BufferedReader isr = new BufferedReader(new FileReader(&quot;a.txt&quot;)); BufferedWriter fw = new BufferedWriter(new FileWriter(&quot;c.txt&quot;)); int ch; while ((ch=isr.read())!=-1)&#123; fw.write(ch); &#125; isr.close(); fw.close(); &#125; 字符缓冲流的特有功能1、BufferedReader public String readLine()：读一行文字，结果包含行的内容，不包括任何行终止字符，如果结尾到达，则为null 2、BufferedWriter void newLine()：写一行行分隔符，行分隔符字符串由系统定义（win、mac） 1234567891011121314151617181920public static void main(String[] args) throws IOException &#123; BufferedReader isr = new BufferedReader(new FileReader(&quot;a.txt&quot;)); BufferedWriter fw = new BufferedWriter(new FileWriter(&quot;a.txt&quot;)); //写数据 for(int i = 0;i&lt;10;i++)&#123; fw.write(&quot;hello&quot;+i); fw.newLine(); fw.flush(); &#125; //读取数据 String a; while((a =isr.readLine())!=null)&#123; System.out.print(a); &#125; isr.close(); fw.close(); &#125; 案例：复制文件 12345678910111213public static void main(String[] args) throws IOException &#123; BufferedReader isr = new BufferedReader(new FileReader(&quot;a.txt&quot;)); BufferedWriter fw = new BufferedWriter(new FileWriter(&quot;d.txt&quot;)); //读取数据 String a; while((a =isr.readLine())!=null)&#123; fw.write(a); fw.newLine(); fw.flush(); &#125; isr.close(); fw.close(); &#125; 复制文件的异常处理1、方法一：finally的做法 2、方法二：JDK7改进方案 格式： 123try(定义流对象)&#123;&#125;catch()&#123;&#125; 12345678910111213141516public static void main(String[] args) &#123; try(BufferedReader isr = new BufferedReader(new FileReader(&quot;a.txt&quot;)); BufferedWriter fw = new BufferedWriter(new FileWriter(&quot;d.txt&quot;)); )&#123; String a; while((a =isr.readLine())!=null)&#123; fw.write(a); fw.newLine(); fw.flush(); &#125; isr.close(); fw.close(); &#125;catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; 3、方法三：JDK9改进方案 1234定义输入流对象；定义输出流对象；try(输入流对象；输出流对象)&#123;&#125;catch()&#123;&#125; IO流小结1、字节流 2、字符流 特殊操作流标准输入输出流System类中有两个静态的成员变量： public static final InputStream in：标准输入流，对应于键盘输入或由主机环境或用户指定的另外一个输入源 public static final PrintStream out：标准输出流 自己实现键盘录入数据： BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); Java提供了一个类： Scanner sc = new Scanner(System.in) 输出数据： 1234567PrintStream is = System.out;is.println(&quot;hello&quot;);is.println(100);is.close();//System.out的本质是一个字节输出流System.out.println(&quot;hello&quot;); 打印流分类： 字节打印流：PrintStream 字符打印流：PrintWriter 打印流特点： 只负责输出数据 由自己的特有方法 1、字节打印流： PrintStream(String filename)：使用指定的文件名创建新的打印流 使用继承父类方法写数据（write）会转码，使用自己特有方法写数据会原样输出（print） 123PrintStream a = new PrintStream(&quot;a.txt&quot;);a.println(&quot;hello&quot;);a.close(); 2、字符打印流 PrintWriter(String Filename):不需要自动执行刷新 PrintWriter(Writer out,boolean autoFlush)：如果为true则print、printf或者format方法会刷新缓冲区 12345678PrintWriter a = new PrintWriter(&quot;a.txt&quot;);a.println(&quot;hello&quot;);a.flush()a.close();PrintWriter a = new PrintWriter(new FileWriter(&quot;a.txt&quot;),true);a.println(&quot;hello&quot;);a.close(); 对象序列化流1、对象序列化：将对象保存在磁盘中，或者在网络中传输对象 这种机制就是使用一个字节序列表示一个对象，该字节序列包含：对象的类型、对象的数据、对象中存储的属性等信息 字节序列写到文件中之后，相当于持久保存了一个对象的信息。 反之，字节序列可以从文件中读取回来，泛序列化 2、对象序列化流和反序列化流 对象序列化流：ObjectOutputStream 对象反序列化流：ObjectInputStream 对象序列化流ObjectOutputStream：将对象的原始数据类型和图形写入OutputStream，可以使用ObjectInputStream读取对象，提高使用流的文件来实现对象的持久存储 1、构造方法：-ObjectOutputStream(OutputStream out) 2、序列化对象的方法： void writeObject(Object obj)：将指定对象写入ObjectOutputStream 3、被序列化的对象需要实现Serializable接口，这个接口只是个标识接口，没有需要重写的方法 1234567import java.io.Serializable;public class b implements Serializable &#123; private int age; private String name; .....&#125; 123456public static void main(String[] args) throws IOException &#123; ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;a.txt&quot;)); b test= new b(30,&quot;zhang&quot;); oos.writeObject(test); oos.close(); &#125; 对象序列化流ObjectInputStream：可以使用ObjectInputStream反序列化对象 1、构造方法：-ObjectInputStream(InputStream in) 2、反序列化对象的方法： Object readObject()：读取一个对象 123456public static void main(String[] args) throws IOException, ClassNotFoundException &#123; ObjectInputStream oos = new ObjectInputStream(new FileInputStream(&quot;a.txt&quot;)); b test = (b)oos.readObject(); System.out.println(test.getAge()); oos.close(); &#125; 三个问题1、用对象序列化流序列化一个对象后，假如我们修改了对象所属的类文件，读取数据会不会出问题？ 答：出现了问题，报错java.io.InvalidClassException 1234报错：Exception in thread &quot;main&quot; java.io.InvalidClassException: b;stream classdesc serialVersionUID = -2649758102526158628,local class serialVersionUID = -2109106879062324476 1234当出现以下问题之一时抛出InvalidClassException：1、类的版本与读取的不一致2、类中包含未知的数据类型3、该类没有可访问的无参构造函数 12serialVersionUID序列化运行时与每个可序列化的类关联的一个版本号，序列化的类可以通过声明一个serialVersionUID来显式的声明它的serialVersionUID 2、如果出问题了，如何解决？ 显式声明一个serialVersionUID，就不会改变serialVersionUID了 12345public class b implements Serializable &#123; private static final long serialVersionUID = 42L; private int age; private String name;&#125; 3、如果一个对象中的某个成员值不想被序列化，如何实现 使用transient关键字或者static关键字修饰成员变量，就不参与序列化过程了 1234public class b implements Serializable &#123; private static final long serialVersionUID = 42L; private transient int age; private String name; Properties1public class Properties extends Hashtable&lt;Object,Object&gt; 是一个Map体系的集合类 Properties类表示一组持久的属性，可以保存到流中或者从流中加载 练习：作为Map集合使用 12345678910Properties prop = new Properties();prop.put(&quot;hello1&quot;,1);prop.put(&quot;hello2&quot;,1);prop.put(&quot;hello3&quot;,1);Set&lt;Object&gt; keySet = prop.keySet();for (Object key:keySet)&#123; Object value = prop.get(key); System.out.println(value);&#125; 作为集合的特有的方法 123456789Properties prop = new Properties();prop.setProperty(&quot;hello1&quot;,&quot;1&quot;);prop.setProperty(&quot;hello2&quot;,&quot;2&quot;);prop.setProperty(&quot;hello3&quot;,&quot;3&quot;);System.out.println(prop.getProperty(&quot;hello1&quot;));Set&lt;String&gt; keys = prop.stringPropertyNames();for(String key:keys)&#123; System.out.println(prop.getProperty(key));&#125; 与IO流结合 12345678910111213141516171819202122232425262728public static void main(String[] args) throws IOException, ClassNotFoundException &#123; //把集合中的数据保存到文件 myStore(); //文件的数据加载到集合 myLoad(); &#125; private static void myStore() throws IOException &#123; Properties prop = new Properties(); prop.setProperty(&quot;hello1&quot;,&quot;1&quot;); prop.setProperty(&quot;hello2&quot;,&quot;2&quot;); prop.setProperty(&quot;hello3&quot;,&quot;3&quot;); FileWriter fw = new FileWriter(&quot;a.txt&quot;); //writer 描述信息（可以为null） prop.store(fw,null); fw.close(); &#125; private static void myLoad() throws IOException &#123; Properties prop = new Properties(); FileReader fr =new FileReader(&quot;a.txt&quot;); prop.load(fr); fr.close(); System.out.println(prop); &#125; 多线程基础实现多线程进程和线程1、进程：正在运行的程序 是系统进行资源分配和调用的独立单位 每一个进程都有它自己的内存空间和系统资源 2、线程：进程中的单个顺序控制流，是一条执行路径 单线程：一个进程只有一条执行路径，则称为单线程程序 多线程：一个进程有多条执行路径，则称为多线程程序（扫雷程序） 3、核心概念： 线程是独立的执行路径 在程序运行时，没有创建线程后台也会有多个线程 main()称之为主线程，是系统的入口，用于执行整个程序 在一个进程中，如果开辟了多个线程，线程的运行由调度器安排调度，先后顺序不能人为干预 多个进程间并发执行，同一个进程内多个线程并发执行 进程拥有资源，线程不拥有资源 多线程的实现方式（一）1public class Thread implements Runnable 创建一个新的执行线程有两种方法： 1、将类继承Thread类： 定义一个类继承Thread类 在该类中重写run()方法 创建该类的对象 启动线程（调用start()方法，Java虚拟机调用run()方法） 12345678910111213141516public class c extends Thread&#123; @Override public void run() &#123; for(int i =0;i&lt;100;i++)&#123; System.out.println(i); &#125; &#125;&#125;public static void main(String[] args)&#123; c c1 = new c(); c c2 = new c(); c1.start(); c2.start(); &#125; 问题1：为什么要重写run方法？ 因为run方法是用来封装被线程执行的代码 问题2：run方法和start方法的区别？ run方法封装线程执行的代码，直接调用相当于普通方法的调用；start方法是用来启动线程，然后JVM来调用此线程的run方法 多线程的实现方式（二）实现Runnable接口 定义一个test类实现Runnable接口 在该类中重写run方法 创建test类的对象 创建Thread类的对象，把test对象作为构造方法的参数 启动线程 1234567891011public class c implements Runnable&#123; public c() &#123; &#125; @Override public void run() &#123; for(int i =0;i&lt;100;i++)&#123; System.out.println(Thread.currentThread().getName()+&quot;-&quot;+i); &#125; &#125;&#125; 1234567891011121314public static void main(String[] args)&#123; c c1 = new c(); c c2 = new c(); //public Thread(Runnable target) Thread t1 = new Thread(c1); Thread t2 = new Thread(c2); //public Thread(Runnable target, String name) Thread t3 = new Thread(c1,&quot;1&quot;); Thread t4 = new Thread(c2,&quot;2&quot;); t1.start(); t2.start();&#125; 使用这种方式的好处： 避免了Java单继承的局限性，方便一个对象被多个线程使用 适合多个相同程序的代码处理同一个资源的情况，把线程和程序的代码、数据有效分离，较好的体现了面向对象的设计思想 多线程的实现方式（三） 实现Callable接口，需要返回值类型 重写call方法，需要抛出异常 创建目标对象 创建执行服务 提交执行 获取结果 关闭服务 与 Runnable 相比，Callable 可以有返回值，返回值通过 FutureTask 进行封装 12345678//实现Callable接口，需要返回值类型public class MyCallable implements Callable&lt;Integer&gt; &#123; //重写call方法 @Override public Integer call() &#123; return 123; &#125;&#125; 1234567public static void main(String[] args) throws ExecutionException, InterruptedException &#123; MyCallable mc = new MyCallable(); FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(mc); Thread thread = new Thread(ft); thread.start(); System.out.println(ft.get());&#125; 设置和获取线程名称方法： void setName(String name)：将此线程的名称进行修改，默认名称Thread-0 String getName()：返回线程的名称 static Thread currentThread()：返回当前线程对象 1、线程的默认名称为Thread-0、Thread-1…….. 1234567891011121314151617private volatile String name;public Thread() &#123; init(null, null, &quot;Thread-&quot; + nextThreadNum(), 0);&#125;private static int threadInitNumber;private static synchronized int nextThreadNum() &#123; return threadInitNumber++;&#125;private void init(ThreadGroup g, Runnable target, String name,long stackSize) &#123; init(g, target, name, stackSize, null, true);&#125;private void init(ThreadGroup g, Runnable target, String name,long stackSize, AccessControlContext acc,boolean inheritThreadLocals) &#123; this.name = name;&#125; 2、获取名称 123public final String getName() &#123; return name;&#125; 3、更改名称 1234567891011public final synchronized void setName(String name) &#123; checkAccess(); if (name == null) &#123; throw new NullPointerException(&quot;name cannot be null&quot;); &#125; this.name = name; if (threadStatus != 0) &#123; setNativeName(name); &#125;&#125; 12345678public static void main(String[] args)&#123; c c1 = new c(); c c2 = new c(); c1.setName(&quot;1&quot;); c2.setName(&quot;2&quot;); c1.start(); c2.start();&#125; 4、使用Thread类带参构造更改名称 1234//父类public Thread(String name) &#123; init(null, null, name, 0);&#125; 1234567891011121314//子类public class c extends Thread&#123; public c() &#123; &#125; public c(String name) &#123; super(name); &#125; @Override public void run() &#123; for(int i =0;i&lt;100;i++)&#123; System.out.println(getName()+&quot;-&quot;+i); &#125; &#125;&#125; 123456public static void main(String[] args)&#123; c c1 = new c(&quot;1&quot;); c c2 = new c(&quot;2&quot;); c1.start(); c2.start(); &#125; 5、获取当前执行对象的线程对象引用 123public static void main(String[] args)&#123; System.out.println(Thread.currentThread().getName()); &#125; 线程调度(优先级)两种调度模型： 分时调度模型：所有线程轮流使用CPU的使用权，平均分配每个线程占用CPU的时间片 抢占式调度模型：优先让优先级高的线程使用CPU，如果线程的优先级相同，那么会随机选择一个，优先级高的线程获取CPU时间片相对多一些（Java使用） Thread类中设置和获取线程优先级的方法： public final int getPriority()：返回线程的优先级 public final void setPriority(int newPriority)：更改线程的优先级（最小1，最大10，默认5）,线程优先级高只是代表获取CPU时间片的几率比较高 12345678public static void main(String[] args)&#123; c c1 = new c(&quot;1&quot;); c c2 = new c(&quot;2&quot;); c1.setPriority(10); c2.setPriority(1); c1.start(); c2.start();&#125; 线程控制方法： static void sleep(long millis)：使当前正在执行的线程停留指定的毫秒数 void join()：等待这个线程死亡 void setDaemon(boolean on)：将此线程标记为守护线程，当运行的线程都是守护线程时，JVM退出 static void yield()：暂停当前正在执行的线程对象，并执行其他线程 停止线程1、不推荐使用JDK提供的stop()、destroy()方法 2、推荐线程自己停下来 3、建议使用一个标志位进行终止变量，当flag&#x3D;false，则终止线程 12345678910111213141516public class TestStop implements Runnable&#123; //1、设置一个标志位 private boolean flag=true; //2、重写run方法 @Override public void run() &#123; int i = 0; while(flag)&#123; System.out.println(getName()+&quot;-&quot;+i); &#125; &#125; //3、设置一个公开的方法停止线程，转换标识位 public void stop()&#123; this.flag=false; &#125;&#125; 线程休眠1、static void sleep(long millis)指定当前线程阻塞的毫秒数； 2、sleep存在异常InterruptedException 3、sleep时间达到后线程进入就绪状态 4、sleep可以模拟网络延时，倒计时等 5、每个对象都有一个锁，sleep不会释放锁 123456789101112@Overridepublic void run() &#123; for(int i =0;i&lt;100;i++)&#123; System.out.println(getName()+&quot;-&quot;+i); try &#123; //停止1秒 Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 线程礼让1、static void yield()：礼让线程，让当前执行的线程暂停，但不阻塞 2、将线程从运行状态转为就绪状态 3、让cpu重新调度，&#x3D;&#x3D;礼让不一定成功&#x3D;&#x3D;，看cpu心情 12345678910111213public class test&#123; main&#123; t a = new t(); new Thread(a,&quot;a&quot;).start(); new Thread(a,&quot;b&quot;).start(); &#125;&#125;class t implements Runnable&#123; @Override public void run() &#123; Thread.yield(); &#125;&#125; 线程强制执行1、void join()：等待这个线程死亡再执行其他线程，其他线程阻塞 例子： 123456789public static void main(String[] args) throws InterruptedException &#123; c t1 = new c(&quot;1&quot;); c t2 = new c(&quot;2&quot;); t1.start(); //t1结束后t2执行 t1.join(); t2.start(); &#125; 源代码： 123456789101112131415161718192021222324252627public final void join() throws InterruptedException &#123; join(0); //join()等同于join(0)&#125;public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException(&quot;timeout value is negative&quot;); &#125; if (millis == 0) &#123; while (isAlive()) &#123; wait(0); //join(0)等同于wait(0)，即wait无限时间直到被notify &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125; 可以看出，join()方法的底层是利用wait()方法实现的。可以看出，join方法是一个同步方法，当主线程调用t1.join()方法时，主线程先获得了t1对象的锁，随后进入方法，调用了t1对象的wait()方法，使主线程进入了t1对象的等待池，此时，A线程则还在执行，并且随后的t2.start()还没被执行，因此，B线程也还没开始。等到A线程执行完毕之后，主线程继续执行，走到了t2.start()，B线程才会开始执行。 此外，对于join()的位置和作用的关系，我们可以用下面的例子来分析: 123456789101112131415public class TestJoin &#123; public static void main(String[] args) throws InterruptedException &#123; System.out.println(Thread.currentThread().getName()+&quot; start&quot;); ThreadTest t1=new ThreadTest(&quot;A&quot;); ThreadTest t2=new ThreadTest(&quot;B&quot;); ThreadTest t3=new ThreadTest(&quot;C&quot;); System.out.println(&quot;t1start&quot;); t1.start(); System.out.println(&quot;t2start&quot;); t2.start(); System.out.println(&quot;t3start&quot;); t3.start(); System.out.println(Thread.currentThread().getName()+&quot; end&quot;); &#125;&#125; 结果： 1234567891011121314151617181920212223main startt1startt1endt2startt2endt3startt3endA-1A-2main endC-1C-2C-3C-4C-5A-3B-1B-2B-3B-4B-5A-4A-5 A、B、C和主线程交替运行,加入join()方法后： 12345678910111213141516171819public class TestJoin &#123; public static void main(String[] args) throws InterruptedException &#123; System.out.println(Thread.currentThread().getName()+&quot; start&quot;); ThreadTest t1=new ThreadTest(&quot;A&quot;); ThreadTest t2=new ThreadTest(&quot;B&quot;); ThreadTest t3=new ThreadTest(&quot;C&quot;); System.out.println(&quot;t1start&quot;); t1.start(); System.out.println(&quot;t1end&quot;); System.out.println(&quot;t2start&quot;); t2.start(); System.out.println(&quot;t2end&quot;); t1.join(); System.out.println(&quot;t3start&quot;); t3.start(); System.out.println(&quot;t3end&quot;); System.out.println(Thread.currentThread().getName()+&quot; end&quot;); &#125;&#125; 运行结果： 1234567891011121314151617181920212223main startt1startt1endt2startt2endA-1B-1A-2A-3A-4A-5B-2t3startt3endB-3main endB-4B-5C-1C-2C-3C-4C-5 可以看出，主线程在t1.join()方法处停止，并需要等待A线程执行完毕后才会执行t3.start()，然而，并不影响B线程的执行。因此，可以得出结论，t.join()方法只会使主线程进入等待池并等待t线程执行完毕后才会被唤醒。并不影响同一时刻处在运行状态的其他线程。 守护线程1、线程分为用户线程和守护线程 2、虚拟机必须确保用户线程执行完毕 3、虚拟机不用等待守护线程执行完毕 4、常见守护线程：后台记录操作日志、监控内存、垃圾回收…… 方法：void setDaemon(boolean on) 1234567891011121314151617public static void main(String[] args) throws InterruptedException &#123; c c1 = new c(&quot;1&quot;); c c2 = new c(&quot;2&quot;); //设置主线程为3 Thread.currentThread().setName(&quot;3&quot;); //设置3结束后1和2自杀,设置为守护线程,但不是立即杀掉 c1.setDaemon(true); c2.setDaemon(true); c1.start(); c2.start(); for(int i =0;i&lt;10;i++)&#123; System.out.println(Thread.currentThread().getName()+&quot;-&quot;+i); &#125;&#125; 线程生命周期线程状态： New（新建） Runnable（可运行） Blocked（阻塞） Wating（等待） Timed waiting（计时等待） Terminated（终止） 方法：Thread.State state1 = t1.getState(); 12345while (state1!=Thread.State.TERMINATED)&#123; Thread.sleep(1000); state1 = t1.getState(); System.out.println(state1);&#125; 线程同步卖票案例可能会出现的问题： 1、相同的票出现多次的情况 2、出现了负数票的情况 并发：同一个对象被多个线程同时操作 卖票数据安全问题1、为什么会出现问题？（判断多线程程序是否会有安全问题的标准） 是否有多线程环境（三个卖票窗口） 是否共享数据（共享票） 是否有多条语句操作共享数据（卖票） 2、如何解决线程安全问题？ 基本思想：让程序没有安全问题的环境（破坏上述三种环境中的一种环境） 线程同步：一种等待机制，多个需要同时访问此对象的线程进入对象的等待池形成队列 3、如何实现？ 队列+锁（每个对象都有锁） 同步代码块和同步方法同步代码块1、作用：锁多条语句操作共享数据 2、格式： 1234//相当于给代码加锁，任意对象可以看作一把锁synchronized(任意对象)&#123; 多条语句操作共享数据&#125; 例子： 123456789101112131415161718//定义同一把锁private Object obj = new Object();@Overridepublic void run() &#123; while (true)&#123; synchronized (obj)&#123; if(tickets&gt;0)&#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+&quot;正在出售第&quot;+tickets+&quot;张票&quot;); tickets--; &#125; &#125; &#125;&#125; 3、好处和弊端？ 好处：解决了多线程的数据安全问题 弊端：当线程很多时，每个线程都会去判断锁，很耗费资源，降低了程序的运行效率 同步方法1、同步方法：将synchronized关键字加到方法上 2、格式： 1修饰符 synchronized 返回值类型 方法名(方法参数)&#123;&#125; 同步方法的锁——this 4、同步静态方法：把synchronized关键字加到静态方法上 同步静态方法的锁——类.class 线程安全的类StringBuffer1234public final class StringBuffer extends AbstractStringBuilder implements java.io.Serializable, CharSequence&#123;&#125; 1、线程安全，可变的字符序列 2、从JDK5开始，被StringBuilder替代，通常使用StringBuilder类，因为它支持所有相同的操作，但是更快，因为它不执行同步 123//方法都是同步方法StringBuffer sb = new StringBuffer();StringBuilder sb2 = new StringBuilder(); Vector1234public class Vector&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123;&#125; 1、该类改进了list接口，使其成为Java Collections Framework的成员，与新的集合实现不同，Vector被同步，如果不需要线程安全的实现，建议使用ArrayList代替Vector 1234//方法都是同步方法Vector&lt;String&gt; v = new Vector&lt;&gt;();ArrayList&lt;String&gt; a = new ArrayList&lt;&gt;();List&lt;String&gt; aa = Collections.synchronizedList(new ArrayList&lt;&gt;()); Hashtable123public class Hashtable&lt;K,V&gt; extends Dictionary&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, java.io.Serializable &#123;&#125; 1、该类实现了一个哈希表，它将键映射到值，任何非null对象都可以作为键或者值 2、该类进行改进，实现了Map接口，使其成为Java Collections Framework的成员，与新的集合不同，Hashtable被同步，如果不需要线程安全的实现，建议使用HashMap代替 1234//方法都是同步方法Hashtable&lt;String, String&gt; ht = new Hashtable&lt;&gt;();HashMap&lt;String, String&gt; hm = new HashMap&lt;&gt;();Map&lt;String, String&gt; m = Collections.synchronizedMap(new HashMap&lt;&gt;()); 死锁多个线程各自占有一些资源，并且互相等待其他线程占有的资源才能运行，而导致两个或者多个线程都在等待对方释放资源，都停止执行的情形，某一个同步块同时拥有两个以上对象的锁时，可能发生死锁问题. 产生死锁的条件： 互斥条件：一个资源只能被一个进程使用 请求和保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放 不剥夺条件：进程已获得的资源，在没有使用完之前不能强行剥夺 循环等待条件：若干进程之间形成一种头尾相连的循环等待资源的关系 破坏其中一个条件即可破坏死锁～～ Lock锁为了更清晰表达如何加锁和师傅锁，JDK5之后提供了新的锁对象Lock 1public interface Lock &#123;&#125; 方法： void lock()：获得锁 void unlock()：释放锁 因为Lock是接口，所以采用它的实现类来实例化ReentrantLock（可重入锁）, Condition, ReadWriteLock 12345678910111213141516171819202122232425262728public class c implements Runnable&#123; private static int tickets = 100; //可重入锁 private Lock lock = new ReentrantLock(); @Override public void run() &#123; while (true)&#123; //加锁 lock.lock(); try&#123; if(tickets&gt;0)&#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+&quot;正在出售第&quot;+tickets+&quot;张票&quot;); tickets--; &#125; &#125;finally &#123; //解锁 lock.unlock(); &#125; &#125; &#125;&#125; synchronized与lock的对比1、Lock是显式锁（手动开启和关闭锁），synchronized是隐式锁，出了作用域自动释放 2、Lock只有代码锁，synchronized有代码锁和方法锁 3、使用Lock锁，JVM将话费少量的时间来调度线程，性能更好，具有更好的扩展性 4、优先使用的顺序：Lock &gt; 同步代码块 &gt; 同步方法 生产者消费者两类线程： 生产者 消费者 为了解耦，通常采用共享的数据区域，就像是仓库 为了体现生产和消费过程中的等待和唤醒，Java提供了几个方法： 包含的类： 奶箱类（Box）：定义一个成员变量表示第x瓶奶，提供存储牛奶和获取牛奶的操作 生产者类（Producer）：实现Runnable接口，重写run方法，调用存储牛奶操作 消费者（Customer）：实现Runnable接口，重写run方法，调用获取牛奶操作 测试类：main方法创建奶箱对象创建生产者对象创建消费者对象创建两个线程对象启动线程 1、奶箱类 123456789101112131415161718192021222324252627282930313233343536public class Box &#123; //第x瓶奶 private int milk; //奶箱的状态 private boolean state = false; public synchronized void put(int milk)&#123; if(state)&#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; this.milk = milk; System.out.println(&quot;生产者将第&quot;+this.milk+&quot;瓶奶放入奶箱&quot;); //生产完毕后修改状态 state=true; //唤醒其他等待的线程 notifyAll(); &#125; public synchronized void get()&#123; if (!state)&#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(&quot;消费者拿到第&quot;+this.milk+&quot;瓶奶&quot;); state=false; //唤醒其他等待的线程 notifyAll(); &#125;&#125; 2、生产者类 1234567891011121314public class Producer implements Runnable&#123; private Box b; public Producer(Box b) &#123; this.b = b; &#125; @Override public void run() &#123; for(int i =1;i&lt;=100;i++)&#123; b.put(i); &#125; &#125;&#125; 3、消费者类 1234567891011121314public class Consumer implements Runnable&#123; private Box box; public Consumer(Box b) &#123; this.box = b; &#125; @Override public void run() &#123; while (true)&#123; box.get(); &#125; &#125;&#125; 4、测试类 1234567891011public static void main(String[] args)&#123; Box box = new Box(); Producer p = new Producer(box); Consumer c = new Consumer(box); Thread t1 = new Thread(p,&quot;生产者&quot;); Thread t2 = new Thread(c,&quot;消费者&quot;); t1.start(); t2.start(); &#125; 线程池1、背景：经常创建和销毁、使用量特别大的资源，比如并发情况下的线程，对性能影响很大 2、思路：提前创建好多个线程，放入线程池中，使用时直接获取，使用完放回。可以避免频繁创建销毁、实现重复利用。 3、好处： 提高响应速度（减少了创建新线程的时间） 降低资源消耗（重复利用线程池中的线程，不需要每次都创建） 便于线程管理 corePoolSize：核心池的大小 maximumPoolSize：最大线程数 keepAliveTime：线程没有任务时最多保持多长时间会终止 4、JDK5起提供了线程池相关的相关API：ExecutorService和Executors 5、ExecutorService：真正的线程池接口，常见子类：ThreadPoolExecutor void execute(Runnable command)：执行任务&#x2F;命令，没有返回值，一般用来执行Runnable &lt;T&gt;Future&lt;T&gt;submit(Callable&lt;T&gt;task)：执行任务，又返回值，一般用来执行Callable void shutdown()：关闭连接池 6、Executors：工具类、线程池的工厂类，用于创建并返回不同类型的线程池 例子： 12345678910111213141516171819202122232425public class Test &#123; public static void main(String[] args) throws InterruptedException &#123; //1、创建服务，创建线程池 //newFixedThreadPool:参数为线程池大小 ExecutorService service = Executors.newFixedThreadPool(10); //执行 service.execute(new MyThread()); service.execute(new MyThread()); service.execute(new MyThread()); //2、关闭链接 service.shutdown(); &#125;&#125;class MyThread implements Runnable&#123; @Override public void run() &#123; for(int i=0;i&lt;100;i++)&#123; System.out.println(Thread.currentThread().getName()+i); &#125; &#125;&#125; Lambda函数式编程思想1、面向对象思想强调“必须通过对象的形式来做事情” 2、函数b式思想则尽量忽略面向对象的复杂语法，强调做什么，而不是以什么形式去做 体验Lambda表达式需求：启动一个线程，在控制台输出一句话 方法1: 1234567891011public class c implements Runnable&#123; @Override public void run() &#123; System.out.println(&quot;1&quot;); &#125;&#125;main&#123; c c1 = new c(); Thread t = new Thread(c1); t.start();&#125; 方法2：匿名内部类 1234567//匿名内部类new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;1&quot;); &#125;&#125;).start(); 方法3：Lambda表达式 1234//Lambda表达式new Thread(()-&gt;&#123; System.out.println(&quot;1&quot;);&#125;).start(); Lambda表达式的标准格式匿名内部类中重写run()方法的代码分析： 方法形式参数为空，说明调用方法时不需要传递参数 方法返回值类型为void，说明方法执行没有结果返回 方法体中的内容是我们要做的事情 Lambda表达式的代码分析： `()`：里面没有内容，看成形式参数为空 `-&gt;`：用剪头指向后面要做的事情 组成Lambda表达式的三要素：形式参数、箭头、代码块 Lambda表达式的标准格式： 格式：(形式参数)-&gt;&#123;代码块&#125; 形式参数：如果有多个参数，参数之间用逗号隔开，如果没有参数，留空即可 -&gt;：代表动作 代码块：代表具体要做的事情，方法体内容 Lambda表达式的练习1、使用前提： 有一个接口 接口中有且只有一个抽象方法 2、练习1： 定义一个接口，里面定义一个抽象方法 定义一个测试类，在测试类中提供两个方法 123456789101112131415161718192021public static void main(String[] args)&#123; //调用 useEatable c b1 = new b(); useEatable(b1); //匿名内部类 useEatable(new c() &#123; @Override public void eat() &#123; System.out.println(1); &#125; &#125;); //Lambda表达式 useEatable(()-&gt;&#123; System.out.println(1); &#125;); &#125;private static void useEatable(c e)&#123; e.eat(); &#125; 3、练习2 定义一个接口，里面定义一个抽象方法：void fly(String s); 定义一个测试类，在测试类中提供两个方法方法：useFlyable(Flyable f)一个方法是主方法，在主方法中调用useFlyable(Flyable f) 1234567891011121314151617181920public static void main(String[] args)&#123; //匿名内部类 Flyable(new c() &#123; @Override public void fly(String s) &#123; System.out.println(s); System.out.println(1); &#125; &#125;); //Lambda表达式 Flyable((String s)-&gt;&#123; System.out.println(s); System.out.println(2); &#125;); &#125; private static void Flyable(c e)&#123; e.fly(&quot;hello&quot;); &#125; 4、练习3 定义一个接口，里面定义一个抽象方法：void add(int x,int y); 定义一个测试类，在测试类中提供两个方法方法：useAdd(c c1)一个方法是主方法，在主方法中调用useAdd(c c1) 1234567891011public static void main(String[] args)&#123; //Lambda表达式 Flyable((int x,int y)-&gt;&#123; return x+y; &#125;);&#125;private static void Flyable(c e)&#123; int sum = e.add(1,2); System.out.println(sum);&#125; Lambda表达式的省略模式规则： 参数的类型可以省略，有多个参数的情况下不能只省略一个 如果参数只有一个，那么小括号可以省略 如果代码块只有一条语句，可以省略大括号和分号；如果有return，return省略掉 123456789101112131415161718public static void main(String[] args)&#123; //Lambda表达式 Flyable((int x,int y)-&gt;&#123; return x+y; &#125;); //参数的类型可以省略 //有多个参数的情况下不能只省略一个 Flyable((x,y)-&gt;&#123; return x+y; &#125;); //如果参数只有一个，那么小括号可以省略 //如果代码块只有一条语句，可以省略大括号和分号 //如果有return，return省略掉 Flyable((x,y)-&gt; x+y);&#125; 注意事项1、使用Lambda表达式时，必须要有接口，且要求接口中只能有一个抽象方法 2、必须有上下文环境，才能推导出Lambda对应的接口 根据局部变量的赋值得知对应的接口：Runnable r = ()-&gt;System.out.println(&quot;123&quot;) 根据调用方法的参数得知对应的接口：new Thread(()-&gt;System.out.println(&quot;123&quot;).start() Lambda表达式和匿名内部类的区别1、所需要的类型不同 匿名内部类：可以是接口、抽象类、具体类 Lambda表达式：接口 2、使用限制不同 如果接口中只有一个抽象方法，可以使用Lambda，也可以匿名内部类 如果接口多于一个抽象方法，只能使用匿名内部类 3、实现原理不同 匿名内部类：编译之后产生一个单独的.class字节码文件 Lambda表达式：没有单独的字节码文件，对应的字节码文件在运行的时候动态生成 注解和反射反射反射概述在运行状态中，对于任意一个类都能知道它的所有属性和方法，对于任意一个对象都能调用它的任意方法和属性，这种动态获取信息及调用对象方法的功能称为反射。 缺点：破坏了封装性以及泛型约束。 反射是框架的核心，Spring 大量使用反射。 获取反射对象1234567891011//方式一：通过对象teacher a1 = new teacher();student a2 = new student();Class c1 = a1.getClass();Class c2 = a2.getClass();//方式二：通过类名Class c3 = Class.forName(&quot;com.tao.teacher&quot;);//方式三：通过类的class属性Class c4 = teacher.class;//方式四Class c5 = Integer.TYPE; 所有类型的反射对象12345678910111213141516//类:class java.lang.ObjectClass c7 = Object.class;//接口:interface java.lang.ComparableClass c8 = Comparable.class;//一维数组:class [Ljava.lang.String;Class c9 = String[].class;//二维数组:class [[IClass c10 = int[][].class;//注解:interface java.lang.OverrideClass c11 = Override.class;//枚举:class java.lang.annotation.ElementTypeClass c12 = ElementType.class;//基本数据类型:class java.lang.IntegerClass c13 = Integer.class;//void:voidClass c14 = void.class; 类的方法Class1、加载功能 把字节码文件加载到内存 Class.forName(&quot;&quot;) 2、获取功能 获取成员变量 getField(String name)：根据属性名得到属性对象，如果属性是私有的返回null getFields()：得到当前class里面的所有非私有的属性 【重点】getDeclaredField(String name)：根据属性名得到属性对象[忽略修饰符] 【重点】getDeclaredFields()：得到当前class里面所有属性 获取构造方法 getConstructor(Class&lt;?&gt;... parameterTypes)：根据参数类型和个数得到对应公有的构造方法 getConstructor()：得到所有的公有的构造方法 【重点】getDeclaredConstructor(Class&lt;?&gt;... parameterTypes)：根据参数得到构造器 【重点】getDeclaredConstructors()：得到所有构造器 获取成员方法 getMethod(String name, Class&lt;?&gt;... parameterTypes) getMethods() 【重点】getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) 【重点】getDeclaredMethods() 获取类名 getName()：获取类的完全限定名（包+类型） getSimpleName：只得到类名 3、创建 newInstance()：使用class类创建一个当前的对象，真是的类里面必须要有空的构造方法 Constructor1、【重点】newInstance(Object ... initargs)：通过得到的构造器对象创建对象 12345678910//得到空的构造方法Constructor con1 = c1.getDeclaredConstructor();//调用构造方法Object o = con1.newInstance();System.out.println(o);//得到带参数的构造方法Constructor con2 = c1.getDeclaredConstructor(Integer.class,String.class);Object o1 = con2.newInstance(1,&quot;zhang&quot;);System.out.println(o1); 2、setAccessible：是否打破访问权限 123Constructor con1 = c1.getDeclaredConstructor();//打破访问权限con1.setAccessible(true); 3、getModifiers()：得到当前构造方法的访问权限 private：2 public：1 空：0 protected：4 4、getParameterCount()：获得参数个数 5、getParameterTypes()：获得参数类型 Field1、getName()：得到属性名 2、getModifiers()：得到属性访问权限 3、getType()：得到属性的类型 4、【重点】set(Object obj, Object value)：给对象的属性赋值 12345//得到属性Field f = c1.getDeclaredField(&quot;age&quot;);//赋值f.set(o1,2);System.out.println(o1); 5、setAccessible：是否打破访问权限 Method1、getModifiers()：得到属性访问权限 2、getName()：得到方法名 3、getParameterCount()：获得方法参数个数 4、getParameterTypes()：获得方法参数类型，返回数组 5、getReturnType()：得到返回值类型 6、setAccessible：是否打破访问权限 7、【重点】invoke(Object obj, Object... args)：执行obj这个对象里面的方法，参数为args 123456Method m = c1.getDeclaredMethod(&quot;hello&quot;,Integer.class);m.invoke(o1,1);public void hello(Integer age1)&#123; System.out.println(age1);&#125; 注解 注解就是对应用程序的某一个部分的特殊说明，这个说明只针对关注这个说明的程序，如果其他程序不关注，那么这个注解对其他程序无效 注解语法Java四大类型：类、接口、枚举、注解 1、格式：public @interface hello&#123;&#125; 2、用法： 123@hellopublic class hellotest &#123;&#125; 元注解作用在注解上面的注解，能够应用到其他的注解上面 元注解是一张标签，它的作用和目的就是给其他普通的标签进行解释说明 元标签包括： @Retention：解释说明注解的存活时间 RetentionPolicy.RUNTIME：可以保留到程序运行的时候，会被加载到JVM中 RetentionPolicy.CLASS：可以保留到编译运行的时候，不会被加载到JVM中 RetentionPolicy.SOURCE：只在源代码阶段保留，编译时丢弃 @Documented：能够将注解中的元素包含到Javadoc中 @Target ：标记这个注解作用的范围 123456789@Target(value = &#123;ElementType.TYPE,ElementType.METHOD&#125;)public @interface hello &#123;&#125;//ElementType.TYPE：可以加在类型上，比如类、接口、枚举//ElementType.METHOD：可以加在方法上（成员方法、静态方法）//ElementType.CONSTRUCTOR：可以加在构造函数上//ElementType.FIELD：可以加在属性上//ElementType.PARAMETER：可以加在方法的参数上 @Inherited：如果一个超类被它注解过的注解进行注解，那么如果它的子类没有被任何注解应用的话，这个子类就继承了超类的注解 @Repeatable 注解的属性注解的属性也叫做成员变量，注解只有成员变量，没有方法。 注解的成员变量在注解的定义中以“无形参的方法”形式来声明，其方法名定义了该成员变量的名字，其返回值定义了该成员变量的类型 12345678910@Inheritedpublic @interface hello &#123; //语法：类型 属性名() default 默认值 //不加default就必须给值 int age(); String name() default &quot;zhang&quot;;&#125;@hello(age = 1)public class hellotest &#123;&#125; 注：value属性可以省略 123456@Inheritedpublic @interface hello &#123; String value();&#125;@hello(&quot;aa&quot;)public class hellotest &#123;&#125; 预置的注解1、@Deprecated：当前类，方法，属性已经不推荐使用 2、@Override：提示子类要重写父类的方法 3、@SuppressWarnings：去除编辑器相关的警告 4、@FunctionalInterface：主要是标记这个类可以使用Lambda表达式，不加也可以使用Lambda 注解的解析离不开反射 1、得到类、属性、方法、参数等上面的注解，返回注解对象 &lt;A extends Annotation&gt; A getAnnotation(Class&lt;A&gt; annotationClass) &#123;&#125; Annotation[] getAnnotations() &#123;&#125; 2、判断注解 注解通过反射获取，首先可以通过Class对象的isAnnotationPresent()方法判断是否应用了某个注解 boolean isAnnotationPresent() &#123;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class hellotest &#123; public static void main(String[] args) throws Exception&#123; //1、解析helloclass Class&lt;Person&gt; personClass = Person.class; //判断是否有注解 System.out.println(personClass.isAnnotationPresent(helloclass.class)); //取出helloclass注解对象 helloclass a1 = personClass.getAnnotation(helloclass.class); System.out.println(a1.msg()+&quot;\\t&quot;+a1.value()); //2、解析hello Field[] declaredFields = personClass.getDeclaredFields(); for(Field field:declaredFields)&#123; //判断是否有注解 System.out.println(field.isAnnotationPresent(hello.class)); if(field.isAnnotationPresent(hello.class)==true)&#123; System.out.println(field.getAnnotation(hello.class).value()); &#125; &#125; //3、解析方法 Method[] declaredMethods = personClass.getDeclaredMethods(); for (Method m:declaredMethods)&#123; boolean a = m.isAnnotationPresent(hellomethod.class); System.out.println(a); if (a==true)&#123; System.out.println(m.getAnnotation(hellomethod.class).value()); &#125; //4、解析heloparam if(m.getParameterCount()&gt;0)&#123; //为什么是二维数组？因为一个方法可能有多个参数，一个参数可能有多个注解 Annotation[][] parameterAnnotations = m.getParameterAnnotations(); for (Annotation[] p:parameterAnnotations)&#123; for (Annotation p2:p)&#123; if(p2 instanceof helloParam)&#123; System.out.println(((helloParam) p2).value()); &#125; &#125; &#125; &#125; &#125; &#125;&#125;@helloclass(value = &quot;类上的注解value&quot;,msg=&quot;类上的注解msg&quot;)class Person&#123; @hello(&quot;属性上的注解value&quot;) private String name; @hellomethod(&quot;方法上的注解value&quot;) public void eat(@helloParam(&quot;参数上的注解value&quot;) String food)&#123; System.out.println(food); &#125;&#125; 类加载器类加载的三个阶段1、源代码：经过编译器编译后生成的.class字节码文件 2、类加载：class字节码文件经类加载器classloader加载到虚拟机内存，类加载器解析class文件生成Class类型的对象 3、运行时：newInstance()根据java类型生成对象 类加载器1、类加载器作用 用来加载字节码文件 java.lang.ClassLoader类的基本职责就是根据一个指定类的名称，找到或者生成其对应的字节代码，然后从这些字节代码定义出一个java类，即java.lang.Class的一个实例 2、类加载器的获得方法 Class：getClassLoader() ClassLoader类：ClassLoader.getSystemClassLoader() 3、类加载器重要方法 类加载的过程 装载：查找并加载二进制数据 链接 验证：确保被加载类信息符合JVM规范，没有安全问题 准备：为类的静态变量分配内存，并将其初始化为默认值 解析：把虚拟机常量池的符合引用转换为直接引用 初始化：为类的静态变量赋予正确的初始值 类初始化的步骤1、加载类信息 在实例化对象之前，类的装载器会找到需要加载的类class文件，进行类的加载（有父类的会先加载父类），一旦加载到最根上的基类，就会对基类的静态变量和静态初始化块进行初始化； 2、当所有类信息加载完毕，就会执行main（）主方法，然后执行new class（），对类进行实例化，首先对变量和、初始化块以及类的构造函数进行初始化（有父类的首先会对父类进行初始化，多个父类递归的方式） （静态变量、静态初始化块：决于它们在类中出现的先后顺序）&gt;（变量、初始化块：决于它们在类中出现的先后顺序）&gt; 构造器 有父类的加载顺序： 父类–静态变量 父类–静态初始化块 子类–静态变量 子类–静态初始化块 子类main方法 父类–变量 父类–初始化块 父类–构造器 子类–变量 子类–初始化块 子类–构造器 JVM中类加载器的层次结构1、根类加载器 用来加载Java的核心库（rt.jar），用原生C++代码实现，并不继承自java.lang.ClassLoader 加载扩展类和应用程序类加载器，并指定他们的父类加载器，在java中获取不到 2、扩展类加载器 用来加载java的扩展库（jre/.jar），java虚拟机的实现会提供一个扩展库目录，该类加载器在此目录里面查找并加载java类 3、系统类加载器 根据Java应用的类路径加载Java类，一般来说Java的类都是由它加载的 4、自定义加载器 除了系统提供的类加载器意外，开发人员继承java.lang.ClassLoader实现自己的类加载器 双亲委派机制如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。 好处：保护java核心库的安全 为什么叫双亲委派？ 双：有两个父模型 亲：因为java只支持单继承，所以亲指亲人","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"自动拆箱和自动装箱","slug":"自动装箱和拆箱","date":"2022-01-06T04:34:38.000Z","updated":"2022-02-07T12:38:15.818Z","comments":true,"path":"2022/01/06/自动装箱和拆箱/","link":"","permalink":"http://example.com/2022/01/06/%E8%87%AA%E5%8A%A8%E8%A3%85%E7%AE%B1%E5%92%8C%E6%8B%86%E7%AE%B1/","excerpt":"","text":"1、概念： 自动装箱：自动将基本数据类型转换为包装器类型 拆箱：自动将包装器类型转换为基本数据类型 123Integer i = 10;//装箱int n = i;//拆箱i += 200;//i=i+200; i+200是自动拆箱,i=i+200时自动装箱 2、如何实现？ 装箱：调用包装器的valueOf方法 拆箱：调用包装器的xxxValue方法 使用包装类类型时，如果做操作，最好先判断是否为null 面试题1、下面这个代码的输出结果 1234567891011public class Main &#123; public static void main(String[] args) &#123; Integer i1 = 100; Integer i2 = 100; Integer i3 = 200; Integer i4 = 200; System.out.println(i1==i2); System.out.println(i3==i4); &#125;&#125; 结果： 12truefalse 原因：查看Integer的ValueOf方法可以发现，在创建Integer对象时，如果数值在[-128,127]之间，便返回指向InetegrCache.cache中已经存在的对象的引用；否则创建新的对象。 2、下面这个代码的输出结果 1234567891011public class Main &#123; public static void main(String[] args) &#123; Double i1 = 100.0; Double i2 = 100.0; Double i3 = 200.0; Double i4 = 200.0; System.out.println(i1==i2); System.out.println(i3==i4); &#125;&#125; 结果： 12falsefalse 原因：查看Double的valueOf方法，可以发现，每次装箱都是创建一个不同的对象 3、下面这个代码的输出结果 1234567891011public class Main &#123; public static void main(String[] args) &#123; Boolean i1 = false; Boolean i2 = false; Boolean i3 = true; Boolean i4 = true; System.out.println(i1==i2); System.out.println(i3==i4); &#125;&#125; 结果： 12truetrue 原因：在Boolean类的valueOf方法中，会返回一个静态成员（TRUE和FALSE），因此结果都是ture 4、Integer i &#x3D; new Integer(xxx)和Integer i &#x3D;xxx;这两种方式的区别 答：1、 第一种方式不会触发自动装箱，第二张方式会触发2、第二种方式的执行效率和资源占用在一般情况下要优于第一种方式 5、下面这个代码的输出结果 1234567891011121314151617181920public class Main &#123; public static void main(String[] args) &#123; Integer a = 1; Integer b = 2; Integer c = 3; Integer d = 3; Integer e = 321; Integer f = 321; Long g = 3L; Long h = 2L; System.out.println(c==d); System.out.println(e==f); System.out.println(c==(a+b)); System.out.println(c.equals(a+b)); System.out.println(g==(a+b)); System.out.println(g.equals(a+b)); System.out.println(g.equals(a+h)); &#125;&#125; 结果： 1234567c==d truee==f false c==(a+b) true //触发自动拆箱，比较数值是否相等c.equals(a+b) true //先触发自动拆箱（a+b），再触发自动装箱（对a+b的数值进行装箱），再进行equals比较g==(a+b) true g.equals(a+b) falseg.equals(a+h) true 原因：==： 当==运算符的两个操作数都是包装器类型的引用时，则比较两边是不是同一个对象 当其中一个操作数为表达式（包含算术运算），则比较数值 equals： 并不会进行类型转换 源码IntegervalueOf 12345public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; 123456789101112private static class IntegerCache &#123; static final int low = -128; static final int high; static final Integer cache[]; static &#123; // high value may be configured by property int h = 127; ................ high = h; ................&#125; ShortvalueOf 12345678public static Short valueOf(short s) &#123; final int offset = 128; int sAsInt = s; if (sAsInt &gt;= -128 &amp;&amp; sAsInt &lt;= 127) &#123; // must cache return ShortCache.cache[sAsInt + offset]; &#125; return new Short(s);&#125; Byte1234public static Byte valueOf(byte b) &#123; final int offset = 128; return ByteCache.cache[(int)b + offset];&#125; 12345678910private static class ByteCache &#123; private ByteCache()&#123;&#125; static final Byte cache[] = new Byte[-(-128) + 127 + 1]; static &#123; for(int i = 0; i &lt; cache.length; i++) cache[i] = new Byte((byte)(i - 128)); &#125; &#125; Character123456public static Character valueOf(char c) &#123; if (c &lt;= 127) &#123; // must cache return CharacterCache.cache[(int)c]; &#125; return new Character(c);&#125; 12345678910private static class CharacterCache &#123; private CharacterCache()&#123;&#125; static final Character cache[] = new Character[127 + 1]; static &#123; for (int i = 0; i &lt; cache.length; i++) cache[i] = new Character((char)i); &#125;&#125; Long1234567public static Long valueOf(long l) &#123; final int offset = 128; if (l &gt;= -128 &amp;&amp; l &lt;= 127) &#123; // will cache return LongCache.cache[(int)l + offset]; &#125; return new Long(l);&#125; Double123public static Double valueOf(double d) &#123; return new Double(d);&#125; Float123public static Float valueOf(float f) &#123; return new Float(f); &#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"Java值传递","slug":"Java是按值传递的还是按引用传递的？","date":"2022-01-06T04:24:32.000Z","updated":"2022-02-07T12:39:09.852Z","comments":true,"path":"2022/01/06/Java是按值传递的还是按引用传递的？/","link":"","permalink":"http://example.com/2022/01/06/Java%E6%98%AF%E6%8C%89%E5%80%BC%E4%BC%A0%E9%80%92%E7%9A%84%E8%BF%98%E6%98%AF%E6%8C%89%E5%BC%95%E7%94%A8%E4%BC%A0%E9%80%92%E7%9A%84%EF%BC%9F/","excerpt":"","text":"Java：按值传递 方法的参数传递包括基本数据类型的传递和引用类型的传递 1、基本数据类型的传递举个例子： 1234567891011int a = 1;int b = 2;test(a,b);System.out.println(a);System.out.println(b);public static void test(int aa,int bb)&#123; aa=bb;&#125; 结果： 1212 分析： 进入test，aa初始化为a的一个副本，bb初始化为b的一个副本，在test方法里，aa被赋值为bb，那么aa就等于2，bb等于2；方法结束后，aa和bb作为参数变量也被一起丢弃了，因此最后a和b的值并不会发生改变 2、引用数据类型的传递举个例子： 1234567891011person a = new person(1);test(a);System.out.println(a.age);public class person&#123; int age;&#125;public static void test(person x)&#123; x.age = 10;&#125; 结果： 110 分析： 进入test方法后，x初始化为a的一个副本，a其实就是一个对象引用，真正的对象存储在堆内存中，在方法内，该对象的age被置为10，那么结束方法后这个x不再被使用，但是a还是指向那个堆内存中的对象，因此a的age为10 总结1、一个方法不能修改一个基本数据类型的参数（即数值型或布尔型）。 2、一个方法可以改变一个对象参数的状态。 3、一个方法不能让对象参数引用一个新的对象。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"==、equals、hashCode()","slug":"==、equals、hashCode() ","date":"2022-01-06T03:24:32.000Z","updated":"2022-02-07T12:33:07.734Z","comments":true,"path":"2022/01/06/==、equals、hashCode() /","link":"","permalink":"http://example.com/2022/01/06/==%E3%80%81equals%E3%80%81hashCode()%20/","excerpt":"","text":"equals()1、equals() 的作用是 用来判断两个对象是否相等。 2、equals() 定义在JDK的Object.java中。通过判断两个对象的地址是否相等(即，是否是同一个对象)来区分它们是否相等。 3、Java对equals（）的要求： 对称性：如果x.equals(y)为true，那么y.equals(x)也为true 反射性：x.equals(x)为true 类推性：x.equals(y)为true，y.equals(z)为true，则x.equals(z)为true 一致性：如果x.equals(y)为true，只要x和y的内容不变，不管重复多少次都是true 非空性：x.equals(null)为false，x.equals(不同类型的对象)为false &#x3D;&#x3D; 和 equals()面试官：请问 equals() 和 “&#x3D;&#x3D;” 有什么区别？ 应聘者： equals()方法用来比较的是两个对象的内容是否相等，由于所有的类都是继承自java.lang.Object类的，所以适用于所有对象，如果没有对该方法进行覆盖的话，调用的仍然是Object类中的方法，而Object中的equals方法返回的却是&#x3D;&#x3D;的判断； “&#x3D;&#x3D;” 比较的是变量(栈)内存中存放的对象的(堆)内存地址，用来判断两个对象的地址是否相同，即是否是指相同一个对象。 题目1234567891011121314151617181920String s1 = new String(&quot;zs&quot;);String s2 = new String(&quot;zs&quot;);System.out.println(s1 == s2); //falseString s3 = &quot;zs&quot;;String s4 = &quot;zs&quot;;System.out.println(s3 == s4); //true，常量池地址System.out.println(s3 == s1); //false，s1指向堆，s3指向常量池String s5 = &quot;zszs&quot;;String s6 = s3+s4;System.out.println(s5 == s6); //false，s3+s4构建新的对象final String s7 = &quot;zs&quot;;final String s8 = &quot;zs&quot;;String s9 = s7+s8;System.out.println(s5 == s9); //true，final关键字，表示是常量final String s10 = s3+s4;System.out.println(s5 == s10); //false hashCode()的作用1、hashCode() 的作用是获取哈希码，也称为散列码；它实际上是返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。 2、hashCode() 定义在JDK的Object.java中，这就意味着Java中的任何类都包含有hashCode() 函数。 虽然，每个Java类都包含hashCode() 函数。但是，仅仅当创建并某个“类的散列表”(关于“散列表”见下面说明)时，该类的hashCode() 才有用(作用：确定该类的每一个对象在散列表中的位置；其它情况下(例如，创建类的单个对象，或者创建类的对象数组等等)，类的hashCode() 没有作用。 上面的散列表，指的是：Java集合中本质是散列表的类，如HashMap，Hashtable，HashSet。 也就是说：hashCode() 在散列表中才有用，在其它情况下没用。在散列表中hashCode() 的作用是获取对象的散列码，进而确定该对象在散列表中的位置。 散列表散列码 我们都知道，散列表存储的是键值对(key-value)，它的特点是：能根据“键”快速的检索出对应的“值”。这其中就利用到了散列码！散列表的本质是通过数组实现的。当我们要获取散列表中的某个“值”时，实际上是要获取数组中的某个位置的元素。而数组的位置，就是通过“键”来获取的；更进一步说，数组的位置，是通过“键”对应的散列码计算得到的。 下面，我们以HashSet为例，来深入说明hashCode()的作用。 假设，HashSet中已经有1000个元素。当插入第1001个元素时，需要怎么处理？因为HashSet是Set集合，它允许有重复元素。 “将第1001个元素逐个的和前面1000个元素进行比较”？显然，这个效率是相等低下的。散列表很好的解决了这个问题，它根据元素的散列码计算出元素在散列表中的位置，然后将元素插入该位置即可。对于相同的元素，自然是只保存了一个。 由此可知，若两个元素相等，它们的散列码一定相等；但反过来确不一定。在散列表中， 如果两个对象相等，那么它们的hashCode()值一定要相同； 如果两个对象hashCode()相等，它们并不一定相等。注意：这是在散列表中的情况。在非散列表中一定如此！ hashCode()和equals()我们以“类的用途”来将“hashCode() 和 equals()的关系”分2种情况来说明。 不会创建“类对应的散列表”这里所说的“不会创建类对应的散列表”是说：我们不会在HashSet, Hashtable, HashMap等等这些本质是散列表的数据结构中，用到该类。例如，不会创建该类的HashSet集合。 在这种情况下，该类的“hashCode() 和 equals() ”没有半毛钱关系的！ 这种情况下，equals() 用来比较该类的两个对象是否相等。而hashCode() 则根本没有任何作用，所以，不用理会hashCode()。 下面，我们通过示例查看类的两个对象相等 以及 不等时hashCode()的取值。 12345678910111213141516171819202122232425262728293031323334public class NormalHashCodeTest&#123; public static void main(String[] args) &#123; // 新建2个相同内容的Person对象， // 再用equals比较它们是否相等 Person p1 = new Person(&quot;eee&quot;, 100); Person p2 = new Person(&quot;eee&quot;, 100); Person p3 = new Person(&quot;aaa&quot;, 200); System.out.printf(&quot;p1.equals(p2) : %s; p1(%d) p2(%d)\\n&quot;, p1.equals(p2), p1.hashCode(), p2.hashCode()); System.out.printf(&quot;p1.equals(p3) : %s; p1(%d) p3(%d)\\n&quot;, p1.equals(p3), p1.hashCode(), p3.hashCode()); &#125; private static class Person &#123; int age; String name; /** * @desc 覆盖equals方法 */ public boolean equals(Object obj)&#123; if(obj == null)&#123; return false; &#125; //如果是同一个对象返回true，反之返回false if(this == obj)&#123; return true; &#125; //判断是否类型相同 if(this.getClass() != obj.getClass())&#123; return false; &#125; Person person = (Person)obj; return name.equals(person.name) &amp;&amp; age==person.age; &#125; &#125;&#125; 结果： 12p1.equals(p2) : true; p1(1169863946) p2(1901116749)p1.equals(p3) : false; p1(1169863946) p3(2131949076) 从结果也可以看出：p1和p2相等的情况下，hashCode()也不一定相等。 会创建“类对应的散列表”这里所说的“会创建类对应的散列表”是说：我们会在HashSet, Hashtable, HashMap等等这些本质是散列表的数据结构中，用到该类。例如，会创建该类的HashSet集合。 在这种情况下，该类的“hashCode() 和 equals() ”是有关系的： 如果两个对象相等，那么它们的hashCode()值一定相同。 这里的相等是指，通过equals()比较两个对象时返回true。 如果两个对象hashCode()相等，它们并不一定相等。 因为在散列表中，hashCode()相等，即两个键值对的哈希值相等。然而哈希值相等，并不一定能得出键值对相等。补充说一句：“两个不同的键值对，哈希值相等”，这就是哈希冲突。 此外，在这种情况下。若要判断两个对象是否相等，除了要覆盖equals()之外，也要覆盖hashCode()函数。否则，equals()无效。 例如，创建Person类的HashSet集合，必须同时覆盖Person类的equals() 和 hashCode()方法。 Test1: 如果单单只是覆盖equals()方法，我们会发现，equals()方法没有达到我们想要的效果。 1234567891011121314151617181920212223242526272829303132333435363738394041public class ConflictHashCodeTest1&#123; public static void main(String[] args) &#123; // 新建Person对象， Person p1 = new Person(&quot;eee&quot;, 100); Person p2 = new Person(&quot;eee&quot;, 100); Person p3 = new Person(&quot;aaa&quot;, 200); // 新建HashSet对象 HashSet set = new HashSet(); set.add(p1); set.add(p2); set.add(p3); // 比较p1 和 p2， 并打印它们的hashCode() System.out.printf(&quot;p1.equals(p2) : %s; p1(%d) p2(%d)\\n&quot;, p1.equals(p2), p1.hashCode(), p2.hashCode()); // 打印set System.out.printf(&quot;set:%s\\n&quot;, set); &#125; private static class Person &#123; int age; String name; /** * @desc 覆盖equals方法 */ @Override public boolean equals(Object obj)&#123; if(obj == null)&#123; return false; &#125; //如果是同一个对象返回true，反之返回false if(this == obj)&#123; return true; &#125; //判断是否类型相同 if(this.getClass() != obj.getClass())&#123; return false; &#125; Person person = (Person)obj; return name.equals(person.name) &amp;&amp; age==person.age; &#125; &#125;&#125; 结果： 12p1.equals(p2) : true; p1(1169863946) p2(1690552137)set:[(eee, 100), (eee, 100), (aaa, 200)] 我们重写了Person的equals()。但是，很奇怪的发现：HashSet中仍然有重复元素：p1 和 p2。为什么会出现这种情况呢？ 这是因为虽然p1 和 p2的内容相等，但是它们的hashCode()不等；所以，HashSet在添加p1和p2的时候，认为它们不相等。 Test2:下面，我们同时覆盖equals() 和 hashCode()方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class ConflictHashCodeTest2&#123; public static void main(String[] args) &#123; // 新建Person对象， Person p1 = new Person(&quot;eee&quot;, 100); Person p2 = new Person(&quot;eee&quot;, 100); Person p3 = new Person(&quot;aaa&quot;, 200); Person p4 = new Person(&quot;EEE&quot;, 100); // 新建HashSet对象 HashSet set = new HashSet(); set.add(p1); set.add(p2); set.add(p3); // 比较p1 和 p2， 并打印它们的hashCode() System.out.printf(&quot;p1.equals(p2) : %s; p1(%d) p2(%d)\\n&quot;, p1.equals(p2), p1.hashCode(), p2.hashCode()); // 比较p1 和 p4， 并打印它们的hashCode() System.out.printf(&quot;p1.equals(p4) : %s; p1(%d) p4(%d)\\n&quot;, p1.equals(p4), p1.hashCode(), p4.hashCode()); // 打印set System.out.printf(&quot;set:%s\\n&quot;, set); &#125; private static class Person &#123; int age; String name; /** * @desc重写hashCode */ @Override public int hashCode()&#123; int nameHash = name.toUpperCase().hashCode(); return nameHash ^ age; &#125; /** * @desc 覆盖equals方法 */ @Override public boolean equals(Object obj)&#123; if(obj == null)&#123; return false; &#125; //如果是同一个对象返回true，反之返回false if(this == obj)&#123; return true; &#125; //判断是否类型相同 if(this.getClass() != obj.getClass())&#123; return false; &#125; Person person = (Person)obj; return name.equals(person.name) &amp;&amp; age==person.age; &#125; &#125;&#125; 结果： 123p1.equals(p2) : true; p1(68545) p2(68545)p1.equals(p4) : false; p1(68545) p4(68545)set:[aaa - 200, eee - 100] 这下，equals()生效了，HashSet中没有重复元素。 比较p1和p2，我们发现：它们的hashCode()相等，通过equals()比较它们也返回true。所以，p1和p2被视为相等。 比较p1和p4，我们发现：虽然它们的hashCode()相等；但是，通过equals()比较它们返回false。所以，p1和p4被视为不相等。 面试题1、为什么要有 hashCode？ 我们以“HashSet 如何检查重复”为例子来说明为什么要有 hashCode？ 当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashcode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用 equals() 方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。这样我们就大大减少了 equals 的次数，相应就大大提高了执行速度。 2、为什么重写 equals 时必须重写 hashCode 方法？ 通俗的讲，注释中第二点和第三点的含义就是equals（）和hashcode（）方法要保持相当程度的一致性，equals（）方法相等，hashcode（）必须相等；反之，equals方法不相等，hashcode可以相等，可以不相等。但是两者的一致有利于提高哈希表的性能。 equals（）相等的的两个等价对象因为hashCode不同，所以在hashmap中的table数组的下标不同，从而这两个对象就会同时存在于集合中，在调用hashmap集合中的方法时就会出现逻辑的错误，也就是，你的equals（）方法也“白白”重写了。 因此，对于“为什么重写equals()就一定要重写hashCode()方法？”这个问题应该是有个前提，就是你需要用到HashMap,HashSet等Java集合。用不到哈希表的话，其实仅仅重写equals()方法也可以吧。而工作中的场景是常常用到Java集合，所以Java官方建议重写equals()就一定要重写hashCode()方法。 3、为什么两个对象有相同的 hashcode 值，它们也不一定是相等的？ 因为 hashCode() 所使用的杂凑算法也许刚好会让多个对象传回相同的杂凑值。越糟糕的杂凑算法越容易碰撞，但这也与数据值域分布的特性有关（所谓碰撞也就是指的是不同的对象得到相同的 hashCode。 我们刚刚也提到了 HashSet,如果 HashSet 在对比的时候，同样的 hashcode 有多个对象，它会使用 equals() 来判断是否真的相同。也就是说 hashcode 只是用来缩小查找成本。 finalfinal修饰类，表示类不可变，不可继承，比如：String final修饰方法，表示方法不可以重写 final修饰变量，这个变量就是常量 注意： 修饰的是基本数据类型，这个值本身不可修改 修饰的引用类型，引用的指向不可以更改，内容可以更改下面这个代码是可以的： 12final Student student = new Student(1,&quot;Andy&quot;);student.setAge(18);","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"static关键字","slug":"static关键字","date":"2022-01-06T02:19:35.000Z","updated":"2022-02-07T12:39:49.282Z","comments":true,"path":"2022/01/06/static关键字/","link":"","permalink":"http://example.com/2022/01/06/static%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"","text":"静态字段如果将一个字段定义为static，那么每个类都只有一个这样的字段。而对于非静态的实例字段，每一个对象都有自己的一个副本。 例子： 12345class Employee&#123; private static int nextID = 1; private int id; ....&#125; 每一个Employee对象都有一个自己的ID字段，但这个类的所有实例将共享一个nextID字段。 如果有100个Employee对象，则有100个实例字段id，分别对应每一个对象；但是，只有一个nextID字段。即使没有Employee对象，静态字段nextID也存在。它属于类，不属于任何一个对象。 1Employee.nextID 静态常量例如： 12345public class Math&#123; ... public static final double PI = 3.1415926; ...&#125; 在程序中，可以使用Math.PI来访问这个常量 如果省略关键字static，PI就变成了一个实例字段，就需要通过类的一个对象来访问PI 咱们多次使用过System.out这个静态常量，它在System中的声明如下： 12345public class System&#123; ... public static final PrintStream out = ....; ...&#125; 静态方法1 、静态方法是不在对象上执行的方法 2、静态方法没有this参数的方法 3、静态方法不能访问实例字段，但是可以访问静态字段 123public static int getNextID()&#123; return nextID;&#125; 可以这样调用这个方法：Employee.getNextID(); 4、可以使用对象调用静态方法，但是不建议使用 5、下面两种状况可以使用静态方法： 方法不需要访问对象状态，因为它所需要的所有参数都通过显式参数提供 方法之需要访问类的静态字段 修饰类static修饰的类只能为内部类，普通类无法用static关键字修饰。static修饰的内部类相当于一个普通的类，访问方式为（new 外部类名.内部类的方法() ） 工厂方法静态方法还有一种常见的用途。类似LocalDate和NumberFormat的类使用静态工厂方法来构造对象。 为什么不使用构造器呢？ 无法命名，构造器的名字必须和类名相同 使用构造器时，无法改变所构造对象的类型。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"Java面对对象","slug":"Java面对对象","date":"2022-01-05T14:45:35.000Z","updated":"2022-02-07T14:38:36.296Z","comments":true,"path":"2022/01/05/Java面对对象/","link":"","permalink":"http://example.com/2022/01/05/Java%E9%9D%A2%E5%AF%B9%E5%AF%B9%E8%B1%A1/","excerpt":"","text":"面对对象基础类和对象1、什么是 面向对象 ？ 2、什么是 类 ？ 类是对现实生活中一类具有共同属性和行为的事物的抽象 类的特点 类是对象的数据类型 类是具有相同属性和行为的一组对象的集合 3、什么是 属性 ？ 属性：对象具有的各种特征，每个对象的每个属性都拥有特定的值 4、什么是 对象的行为 ？ 行为：对象能够执行的操作 5、 类和对象的关系 ： 类是对现实生活中一类具有共同属性和行为的事物的抽象 对象是能够看得到摸得着的真实存在的实体 类是对象的抽象，对象是类的实体 类的定义1、类的重要性：是Java程序的基本组成单位 2、类是什么：是对现实生活中一类具有共同属性和行为的事物的抽象 3、类的组成：属性和行为 4、格式：定义类+类的成员变量+类的成员方法 12345public class 类名&#123; //成员变量 //成员方法&#125; 对象的使用1、创建对象：类名 对象名 = new 类名() 2、使用对象： 对象.变量名() 对象.方法名() 对象内存图单个对象1、创建对象 2、取值 3、赋值 多个对象 多个对象指向相同 成员变量和局部变量1、成员变量：类中方法外的变量 2、局部变量：方法中的变量 3、区别： 位置不同：成员变量在类中方法外，局部变量在方法内或者方法声明上 内存中的位置不同：成员变量在堆内存，局部变量在栈内存 生命周期不同：成员变量随着对象，局部变量随着方法的调用 初始化值不同：成员变量有初始化值，局部变量没有初始化值，必须先定义后使用 封装private关键字 是一个权限修饰符 可以修饰成员（成员变量和成员方法） 作用是保护成员不被别的类使用，被private修饰的成员只能在本类中使用 1、针对被private修饰的成员变量，如果需要被其他类使用，提供相应的操作 提供get变量名()方法，用于获取成员变量的值，方法用public修饰 提供set变量名()方法，用于设置成员变量的值，方法用public修饰 2、private关键字的使用 把成员变量用private修饰 提供对应的get/set方法 this关键字 this修饰的变量用于指代成员变量在方法中，形参如果与成员变量同名，不带this修饰的变量指的是形参；如果形参没有与成员变量同名，那么就指的是成员变量 什么时候使用this？解决局部变量隐藏成员变量 this：代表所在类的对象引用记住：方法被哪个对象调用，this就代表哪个对象 this内存原理 方法被哪个对象调用，this代表的是哪个对象 封装1、封装：是面向对象三大特征之一（封装、继承、多态） 封装是面向对象编程语言对客观世界的模拟，客观世界里成员变量都是隐藏在对象内部的，外界无法直接操作 2、封装的原则：将类的某些信息隐藏在类内部，不允许外部程序直接访问，而是通过该类提供的方法来实现对隐藏信息的操作和访问，成员变量private，提供get/set方法 3、封装的好处： 提高了代码的安全性 把代码用方法进行封装，提高了代码的复用性 构造方法1、构造方法是一种特殊的方法 作用：创建对象 格式： 1234public class 类名&#123; 修饰符 类名(参数)&#123; &#125;&#125; 功能：主要是完成对象数据的初始化 2、注意事项 构造方法的创建如果没有定义构造方法，系统会给出一个默认的无参数构造方法如果定义了构造方法，系统不会给出默认的无参数构造方法 构造方法的重载如果自定义了带参构造方法，还要使用无参构造方法，就必须再写一个无参数构造方法 成员变量 使用private修饰 2、构造方法 提供一个无参构造方法 提供一个带多个参数的构造方法 3、成员方法 提供每一个成员变量对应的set/get() 提供一个显示对象信息的show() 4、创建对象并为成员变量赋值的两种方式 无参数构造方法创建对象后使用set()赋值 使用带参构造方法直接创建带有属性值的对象 字符串String1、String概述： String类在java.lang包下，所以使用的时候不需要导包 String类表示字符串，Java程序中所有的字符串文字（例如”abc”）都被实现为此类的实例，也就是说，Java程序中所有双引号字符串，都是String类的对象 字符串的特点 字符串不可变，它们的值在创建后不可以被更改 虽然String值不可变，但是可以被共享 字符串效果上相当于字符数组（char[]），但是底层原理是字节数组(byte[])，jdk8及以前是字符数组，jdk9及以后是字节数组 String构造方法 public String()：创建一个空白字符串对象，不含任何内容 public String(char[] chs)：根据字符数组的内容，来创建字符串对象 public String(byte[] bys)：根据字节数组的内容，来创建字符串对象 String s = &quot;abc&quot;：直接赋值的方式创建字符串对象（推荐） 例子：输出abc 123456789String s1 = new String();char[] chs = &#123;&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;&#125;;String s2 = new String(chs);byte[] bys = &#123;97,98,99&#125;;String s3 = new String(bys)String s4 = &quot;abc&quot;; String对象的特点 通过new创建的字符串对象，每一次new都会申请一个内存空间，但是地址不同 以&quot;&quot;的方式给出的字符串，只要字符序列相同，无论在程序中出现几次都只会建立一个String对象，并在字符池中维护 String对象的内存空间 字符串的比较 ==基本类型：比较的是数据值是否相同引用类型：比较的是地址值是否相同 equals字符串public boolean equals(Object anObject)：将此字符串与指定对象进行比较，由于比较的是字符串对象，所以参数直接传递字符串。 StringBuilder概述：StringBuilder是一个可变的字符串类，可以看作一个容器（可变是指StringBuilder对象中的内容是可变的） String的加法操作 String和StringBuilder的区别String内容不可变，StringBuilder内容可变 StringBuilder构造方法 public StringBuilder()：创建一个空白可变字符串对象，不含有任何内容 public StringBuilder(String str)：根据字符串的内容，来创建可变字符串对象 1234567// 创建一个空白可变字符串StingBuilder sb = new StringBuilder();System.out.println(sb);// 根据字符串内容创建一个可变字符串StingBuilder sb2 = new StringBuilder(&quot;hello&quot;);System.out.println(sb2); StringBuilder的添加和反转方法 public StringBuilder append(任意类型)：在对象本身上添加数据，并返回对象本身 public StringBuilder reverse()：对象本身进行相反的字符序列 12345StingBuilder sb = new StringBuilder();StingBuilder sb2 = sb.append(&quot;hello&quot;)System.out.println(sb);System.out.println(sb2);System.out.println(sb == sb2); 输出： 123hellohellotrue 注意：这两个方法都会改变对象本身～～ String和StringBuilder的相互转换StingBuilder转为Stringpublic String toString()：通过toString()就可以实现把StringBuilder转换为String 12StingBuilder sb = new StringBuilder(&quot;abc&quot;);String s = sb.toString(); Sting转为StringBuilderpublic StringBuilder(String s)：通过构造方法实现String转为StringBuilder 12String a = &quot;abc&quot;;StringBuilder b = new StringBuilder(a); 面试题1、String不可变的好处？ 可以缓存 hash 值因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。 String Pool 的需要如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用 String Pool。 安全性String 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 的那一方以为现在连接的是其它主机，而实际情况却不一定是。 线程安全String 不可变性天生具备线程安全，可以在多个线程中安全地使用。 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 2、浅谈一下String, StringBuffer，StringBuilder的区别？ String是不可变类，每当我们对String进行操作的时候，总是会创建新的字符串。操作String很耗资源,所以Java提供了两个工具类来操作String - StringBuffer和StringBuilder。 StringBuffer和StringBuilder是可变类，StringBuffer是线程安全的，StringBuilder则不是线程安全的。所以在多线程对同一个字符串操作的时候，我们应该选择用StringBuffer。由于不需要处理多线程的情况，StringBuilder的效率比StringBuffer高。 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 3、什么是字符串池？ 字符串常量池就是用来存储字符串的，它存在于Java 堆内存。 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 4、String是线程安全的吗？ String是不可变类，一旦创建了String对象，我们就无法改变它的值。因此，它是线程安全的，可以安全地用于多线程环境中。 &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 5、为什么我们在使用HashMap的时候总是用String做key？ 因为字符串是不可变的，当创建字符串时，它的它的hashcode被缓存下来，不需要再次计算。因为HashMap内部实现是通过key的hashcode来确定value的存储位置，所以相比于其他对象更快。这也是为什么我们平时都使用String作为HashMap对象。 集合基础集合基础 集合类的特点：提供一种存储空间可变的存储模型，存储的数据容量可以发生改变 ArrayList&lt;E&gt;：可调整大小的数组实现 ArrayList的构造方法和添加方法 `public ArrayList()`：创建一个空的集合对象 `public boolean add(E e)`：将指定的元素追加到此集合的末尾 `public void add(int index,E element)`：在此集合中的指定位置插入指定的元素 ArrayList常用方法 public boolean remove(Object o)：删除指定元素，返回是否删除成功 public E remove(int index)：删除指定索引的元素，返回被删除的元素 public E set(int index,E element)：修改指定索引的元素，返回被修改的元素 public E get(int index)：返回指定索引处的元素 public int size()：返回集合中元素的个数 继承继承概述继承是面向对象三大特征之一，可以使得子类具有父类的属性和方法，还可以在子类中重新定义，追加属性和方法 继承格式12345public class 子类名 extends 父类名&#123;&#125;public class Zi extends Fu&#123;&#125;Fu：是父类，也被称为基类、超类Zi：是子类，也被称为派生类 继承中子类的特点： 子类可以有父类的内容 子类还可以有自己的内容 继承的好处和弊端1、好处 提高了代码的复用性（多个类相同的成员可以放到同一个类中） 提高了代码的维护性（如果方法的代码需要修改，修改一处即可） 2、弊端 继承让类和类之间产生关系，类的耦合性增强了，削弱了子类的独立性 3、什么时候使用继承？ 继承体现的关系：is a，A是B的一种 继承中变量的访问特点在子类方法中访问一个变量：（优先级如下） 子类局部范围找 子类成员范围找 父类成员范围找 如果没有找到就报错（不考虑父亲的父亲） super关键字例子： 1234567891011121314public class Fu&#123; public int age = 10;&#125;public class Zi extends Fu&#123; public int age = 20; public void show()&#123; int age = 30; //如何访问Zi的成员变量age=20 this.age; //如何访问Fu的成员变量age=10 super.age; &#125;&#125; super和this的用法相似 this：代表本类对象的引用 super：代表父类存储空间的标识（可以理解为父类对象的引用） 继承中构造方法的访问特点子类中的所有构造方法默认都会访问父类中无参数的构造方法 为什么？ 因为子类会继承父类中的数据，可能还会使用父类的数据。所以子类初始化之前，一定要先完成父类数据的初始化 每一个子类构造方法的第一条语句默认都是super() 1234567891011121314151617181920212223public class Fu&#123; public int age = 10; public Fu()&#123; System.out.println(&quot;Fu-无参&quot;); &#125; public Fu(int age)&#123; System.out.println(&quot;Fu-有参&quot;); &#125;&#125;public class Zi extends Fu&#123; public int age = 20; public Zi()&#123; System.out.println(&quot;Zi-无参&quot;); &#125; public Zi(int age)&#123; System.out.println(&quot;Zi-有参&quot;); &#125;&#125;Zi z = new Zi();Zi z2 = new Zi(20); 结果： 12345Fu-无参Zi-无参Fu-无参Zi-有参 在子类的构造方法中的第一行都是super(),可以省略 如果父类中没有无参构造方法怎么办？ 通过使用super关键字去显示的调用父类的带参构造方法 在父类中提供一个无参构造方法 继承中成员方法的访问特点通过子类对象访问一个方法： 子类成员范围找 父类成员范围找 如果找不到就报错 super内存图123456789101112131415161718192021222324252627282930public class Fu&#123; public int age = 40; public Fu()&#123; System.out.println(&quot;Fu-无参&quot;); &#125; public void method()&#123; System.out.println(&quot;Fu-method&quot;); &#125;&#125;public class Zi extends Fu&#123; public int age = 20; public Zi()&#123; System.out.println(&quot;Zi-无参&quot;); &#125; public void show()&#123; int age = 30; System.out.println(age); System.out.println(this.age); System.out.println(super.age); &#125;&#125;public class Demo&#123; ...main...&#123; Zi z = new Zi(); z.show(); zi.method(); &#125;&#125; 结果： 12345678910// Zi z = new Zi();Fu-无参Zi-无参// zi.show();302040// zi.method(); // 调用FU类的method方法Fu-method 过程： 1zi.show(); 方法重写1、概述： 子类中出现了和父类中一模一样的方法声明 2、方法重写的应用： 当子类需要父类的功能，而功能主体子类有自己特有内容时，可以重写父类中的方法，这些，即沿袭了父类的功能，又定义了子类特有的内容 练习1234567891011121314151617181920212223242526272829303132/* 手机类*/public class Phone&#123; public void call(String name)&#123; System.out.println(name); &#125;&#125;/* 新手机类*/public class newPhone extends Phone&#123; @Override public void call(String name)&#123; System.out.println(&quot;new&quot;); super.call(name); &#125;&#125;/* 测试类*/public class test&#123; public static void main(String[] args)&#123; //创建对象，调用方法 Phone p = new Phone(); p.call(&quot;a&quot;); System.out.println(&quot;=========&quot;); newPhone p2 = new newPhone(); p2.call(&quot;a&quot;) &#125;&#125; @Override注解1、可以当注释用,方便阅读； 2、编译器可以给你验证@Override下面的方法名是否是你父类中所有的，如果没有则报错。例如，你如果没写@Override，而你下面的方法名又写错了，这时你的编译器是可以编译通过的，因为编译器以为这个方法是你的子类中自己增加的方法。 方法重写的注意事项1、子类不能重写父类中私有的方法 2、子类方法访问权限不能更低（public &gt; 默认 &gt; 私有） 重载和重写的区别 重载就是同样的一个方法能够根据输入数据的不同，做出不同的处理重写就是当子类继承自父类的相同方法，输入数据一样，但要做出有别于父类的响应时，你就要覆盖父类方法 1、重写： 返回值类型、方法名、参数列表必须相同，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类。 如果父类方法访问修饰符为 private&#x2F;final&#x2F;static 则子类就不能重写该方法，但是被 static 修饰的方法能够被再次声明。 构造方法无法被重写 重写就是子类对父类方法的重新改造，外部样子不能改变，内部逻辑可以改变 2、重载和重写的区别： 3、重写的返回值类型 如果方法的返回类型是void和基本数据类型，则返回值重写时不可修改。 但是如果方法的返回值是引用类型，重写时是可以返回该引用类型的子类的。 继承的注意事项1、类不能继承多个类（单继承） 2、类可以多层继承 权限修饰符、状态修饰符包1、其实就是文件夹 作用：对类进行分类管理 2、定义格式package 包名 3、带包的Java类编译和执行 手动建包：按照以前的格式编译java文件 Java HelloWorld.java手动创建包 在E盘建立文件夹com，在com下建立文件夹tao把class文件放到包的最里面 把HelloWorld.java文件放到com下的tao这个文件夹下带包执行 java com.tao.Helloworld 自动建包：Java -d .Helloworld.java java com.tao.HelloWorld 导包——import使用不同包下的类时，使用的时候要写类的全路径，写起来太麻烦了 为了简化带包的操作，Java就提供了导包的功能 格式：import 包名 权限修饰符四种：private、默认、protected、public 状态修饰符final关键字final关键字是最终的意思，可以修饰成员方法、成员变量、类 1、final修饰方法：最终方法，不可被重写 2、final修饰变量：常量，不能被再次赋值 3、final修饰类：最终类，不能被继承 final修饰局部变量1、final修饰基本类型变量：值不能变 2、final修饰引用类型变量：地址值不能变，地址里面的内容可以被修改 static关键字可以修饰成员方法、成员变量 特点： 被类的所有对象共享这是我们判断是否使用静态关键字的条件 可以通过类名调用，也可以通过对象名调用 static访问特点静态成员方法只能访问静态成员（静态成员变量、静态成员方法） 多态概述同一个对象，在不同时刻表现出来的不同形态 例子：我们可以说猫是猫：猫 cat = new 猫()也可以说猫是动物：动物 animal = new 猫()猫在不同时刻表现出不同的形态，这就是多态 多态的前提和体现 有继承&#x2F;实现关系 有方法重写 有父类引用指向子类对象 例子： 1234567891011121314151617public class animal&#123; public void eat()&#123; System.out.println(&quot;a&quot;); &#125;&#125;public class cat extends animal&#123; //重写 @Override public void eat()&#123; System.out.println(&quot;b&quot;); &#125;&#125;main&#123; //父类引用指向子类对象 animal a = new cat();&#125; 多态中成员的访问特点访问的是父类，方法和属性都是父类，但是如果子类重写了方法，就访问重写后的方法 成员变量：编译看左边，运行看左边 成员方法：编译看左边，运行看右边 多态的好处和弊端1、好处：提高了程序的扩展性 具体体现：定义方法时，使用父类作为参数，将来使用时，使用具体子类参与操作 2、弊端：不能使用子类的特有功能，只能使用重写的方法 多态中的转型分类： 向上转型子类到父类父类引用指向子类对象 向下转型从父到子父类引用转为子类对象 向上转型多态本身就是向上转型 1animal a = new cat(); 向下转型（强制类型转换）为了访问子类独特的方法 123456789101112131415例如：父类animal 有方法eat()子类cat，有重写方法eat()和独特的方法play()main&#123; //多态 animal a = new cat(); a.eat(); //强制类型转换 cat b = (cat)a; b.eat(); b.play();&#125; 转型的内存图前几条代码： 类型转换失败： 抽象类概述 在多态模块中，我们假定了父类animal，这个位于上层的类更具有一般性，更加抽象，因此可以看作抽象类 在Java中，一个没有方法体的方法应该被定义为抽象方法，而类中如果有抽象方法，应该被定义为抽象类。 例子： 12345//抽象类public abstract class animal&#123; //抽象方法 public abstract void eat();&#125; 抽象类的特点1234567891011121314151617181920212223//抽象类public abstract class animal&#123; //抽象方法 public abstract void eat(); //也可以有方法，抽象类里面可以没有抽象方法 public void sleep()&#123; System.out.println(&quot;sleep&quot;); &#125;&#125;//抽象类的子类public class cat&#123; @Override public void eat()&#123; System.out.println(&quot;cat&quot;); &#125;&#125;main&#123; animal a = new cat(); a.eat(); a.sleep();&#125; 因此，抽象类的特点如下： 抽象类和抽象方法必须使用abstract关键字修饰 抽象类可以没有抽象方法，有抽象方法的类一定是抽象类 抽象类不能直接实例化，可以参照多态的方式通过子类实例化 抽象类的子类要么也是抽象类，要么重写抽象类的所有的抽象方法 抽象类的成员特点1、成员变量：可以是变量，可以是常量 2、构造方法：有构造方法，但是不能实例化，他的作用是用于子类访问父类数据的初始化 3、成员方法：可以有抽象方法（限定子类必须完成的方法），可以有非抽象方法（提高代码复用性） 接口接口概述接口就是一种公共的规范标准，只要符合规范，大家都可以通用 Java中的接口更多的体现在对行为的抽象 接口特点1、接口用关键字interface修饰 格式：public interface 接口名() 2、类实现接口用implements标识 格式：public class implements 接口名&#123;&#125; 3、接口不能实例化 如何实例化呢？按照多态的方式，通过实现类对象实例化，这叫接口多态 多态的形式：具体类多态，抽象类多态、接口多态 多态的前提：有继承或者实现关系、有方法重写、有父类&#x2F;接口引用指向子类&#x2F;接口对象 4、接口的实现类 要么重写所有的抽象方法 要么是抽象类 接口的成员特点1、成员变量 只能是常量 默认修饰符public static final 2、构造方法 接口没有构造方法，因为接口主要是对行为进行抽象的，是没有具体存在 一个类如果没有父类，默认继承自Object类 3、成员方法 只能是抽象方法 默认修饰符public abstract 关于接口中的方法，JDK8和JDK9有一些新特性 类和接口的关系1、类和类的关系 继承关系，只能单继承，但是可以多层继承 2、类和接口的关系 实现关系，可以单实现，也可以多实现，还可以在继承一个类的同时实现多个接口 1public class test extends Object implements inter1,Inter2,Inter3&#123;&#125; 3、接口和接口的关系 继承关系，可以单继承，也可以多继承 1public interface Inter3 extends Inter1,Inter2&#123;&#125; 抽象类和接口的区别成员区别（语法层面）1、抽象类 变量、常量 有构造方法 有抽象方法也有非抽象方法 2、接口 常量 抽象方法 关系区别（语法层面）1、类与类 继承 单继承 2、类与接口 实现 单实现、多实现 3、接口与接口 继承 单继承、多继承 设计理念的区别1、抽象类 对类抽象 包括属性、行为 2、接口 对行为抽象 主要是行为 例子：门和警报 门：都有open()和close()两个动作，这个时候我们可以分别使用抽象类和接口来定义这个抽象概念 12345678910//抽象类public abstract class Door&#123; public abstract void open(); public abstract void close();&#125;//接口public interface Door&#123; void open(); void close();&#125; 随着时代的发展，门现在有了报警的功能，如果把这个功能放到抽象类中所有的门就都有了报警功能，如果放在接口中其他具有报警功能的也不一定有开关功能 123456789101112131415161718192021//抽象类public abstract class Door&#123; public abstract void open(); public abstract void close();&#125;//接口public interface Alram&#123; void alarm();&#125;//类public class AlarmDoor extends Door implements Alarm&#123; public void open()&#123; ... &#125; public void close()&#123; ... &#125; public void alarm()&#123; ... &#125;&#125; 再次强调，抽象类是对事物的抽象，接口是对行为的抽象 练习 需求：乒乓球运动员和篮球运动员，乒乓球教练和篮球教练。为了出国交流，跟乒乓球相关的人员都要学习英语。分析一下这个案例有哪些具体类，哪些抽象类，哪些接口，并用代码实现 分析：具体到抽象 实现：抽象到具体 使用：使用具体的类 代码实现思路： 定义说英语的接口 1成员方法：说英语()； 定义抽象人类 123成员变量：姓名、年龄构造方法：无参、带参成员方法：get()/set()、吃饭() 定义抽象的教练类，继承人类 12构造方法：无参、带参成员方法：教() 定义抽象的运动员类，继承人类 12构造方法：无参、带参成员方法：学习() 定义具体篮球教练类，继承教练类 12构造方法：无参、带参成员方法：重写吃饭()&#123;&#125;,重写教()&#123;&#125; 定义具体乒乓球教练类，继承教练类，实现说英语接口 12构造方法：无参、带参成员方法：重写吃饭()&#123;&#125;,重写教()&#123;&#125;,重写说英语()&#123;&#125; 定义具体篮球运动员类，继承运动员类 12构造方法：无参、带参成员方法：重写吃饭()&#123;&#125;,重写学习()&#123;&#125; 定义具体乒乓球运动员类，继承运动员类，实现说英语接口 12构造方法：无参、带参成员方法：重写吃饭()&#123;&#125;,重写学习()&#123;&#125;,重写说英语()&#123;&#125; 类名作为形参和返回值1、方法的形参是类名，其实需要的是该类的对象 2、方法的返回值是类名，其实返回的是该类的对象 抽象类名作为形参和返回值123456789101112131415161718192021222324252627282930public abstract class animal&#123; public abstract void eat();&#125;public class cat extends animal&#123; @Override public void eat()&#123; System.out.println(&quot;cat&quot;); &#125;&#125;public animalOperator&#123; public void useanimal(animal a)&#123; a.eat(); &#125; public animal getanimal()&#123; animal a = new cat(); return a; &#125;&#125;main&#123; //创建操作类对象并调用方法 animalOperator ao = new animalOperator(); animal a = new Cat(); ao.useanimal(a); animal a2 = ao.getanimal(); a2.eat();&#125; 1、方法的形参是抽象类名，其实需要的是该抽象类的子类对象 2、方法的返回值是抽象类名，其实返回的是抽象类的子类对象 接口名作为形参和返回值1、方法是形参是接口名，其实需要的是该接口的实现类对象 2、方法的返回值是接口名，其实返回的是接口的实现类对象 概述1、内部类：就是在一个类中定义一个类 2、定义格式： 1234public class 类名&#123; 修饰符 class 类名&#123; &#125;&#125; 3、内部类的访问格式 内部类可以直接访问外部类的成员，包括private 外部类要访问内部类的成员，必须创建对象 成员内部类1、内部类的分类： 在类的成员位置：成员内部类 在类的局部位置：局部内部类 2、成员内部类，外界如何创建对象使用？ 格式：外部类名.内部类名 对象名 = 外部类对象.内部类对象 例子：out.in i = new out().new in() 例子： 123456789101112131415public class out&#123; private int age = 10; //成员内部类 public class in&#123; public void show()&#123; System.out.println(age); &#125; &#125;&#125;main&#123; //创建内部类对象，并调用方法 out.in i = new out().new in(); i.show(); &#125; 3、内部类使用private修饰符怎么办？ 方法：创建一个成员方法调用内部类里面的方法 12345678910111213141516171819public class out&#123; private int age = 10; //成员内部类 private class in&#123; public void show()&#123; System.out.println(age); &#125; &#125; public void method()&#123; in i = new in(); i.show() &#125;&#125;main&#123; //创建内部类对象，并调用方法 out o = new out(); o.method()&#125; 局部内部类局部内部类是方法中定义的类，所以外界无法直接使用，需要在方法内部创建对象并使用，该类可以直接访问外部类的成员，也可以访问方法内部的局部变量 1234567891011121314151617181920212223public class out&#123; private int num = 10; public void method()&#123; int num2 = 20; class in&#123; public void show()&#123; System.out.println(num); System.out.println(num2); &#125; &#125; in i = new in(); i.show(); &#125;&#125;main&#123; out o = new out(); o.method()&#125; 输出： 121020 匿名内部类1、是局部内部类的特殊形式 2、前提：存在一个类或者接口，类可以是具体类或者抽象类 3、本质：是一个继承了该类或者实现了该接口的子类匿名对象 3、格式： 123new 类名/接口名()&#123; 重写方法&#125; 例子： 1234567891011121314151617181920public class out &#123; public void method()&#123; //匿名内部类 inter i = new inter()&#123; @Override public void show()&#123; System.out.println(&quot;abc&quot;) &#125; &#125; //调用方法 i.show(); &#125; &#125;public interface inter&#123; void show();&#125; 匿名内部类在开发中的使用1234//跳高接口public interface jumpping&#123; void jump();&#125; 123456//接口操作类，里面有一个方法，方法的参数是接口名public class jumpoperator&#123; public void method(jumpping j)&#123; j.jump(); &#125;&#125; 1234567891011121314//实现类public class cat implements jumpping&#123; @Override public void jump()&#123; System.out.println(&quot;cat&quot;); &#125;&#125;public class dog implements jumpping&#123; @Override public void jump()&#123; System.out.println(&quot;dog&quot;); &#125;&#125; 1234567891011121314151617181920212223242526//测试类main(String[] args)&#123; //需求：创建接口操作类的对象，调用method方法 jumpoperator jo = new jumpoperator(); jumpping j = new cat(); jo.method(j); jumpping j2 = new dog(); jo.method(j2); //改进 jp.method(new jumpping()&#123; @Override public void jump()&#123; System.out.println(&quot;cat&quot;); &#125; &#125;); jp.method(new jumpping()&#123; @Override public void jump()&#123; System.out.println(&quot;dog&quot;); &#125; &#125;); &#125; 综上：使用匿名内部类可以简化操作，如上例中需要构建实现类cat和dog才能够调用方法，经过改进，只需要创建两个匿名内部类即可。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"Java 基础","slug":"Java基础","date":"2022-01-04T13:25:35.000Z","updated":"2022-02-07T14:27:59.394Z","comments":true,"path":"2022/01/04/Java基础/","link":"","permalink":"http://example.com/2022/01/04/Java%E5%9F%BA%E7%A1%80/","excerpt":"","text":"Java语言发展史Java语言发展史1、Java语言 Java语言是美国 sun公司在1995年推出的 Java之父：詹姆斯.高斯林 2、Java语言发展历史 5.0：更新力度非常大，使得java发展进入快车道 8.0：公司使用最多 11.0：学习使用的版本 Java语言跨平台原理——JVM1、基本概念 平台：指的是操作系统平台（windows、macOS、Linux） 跨平台：Java程序可以在任意操作系统上运行 2、跨平台原理 针对不同的操作系统提供不同的JVM 方法：在需要运行Java应用程序的操作系统上安装一个与操作系统对应的Java虚拟机（JVM）即可完成跨平台 3、JVM：运行 Java 字节码的虚拟机。JVM 有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果。 什么是字节码?采用字节码的好处是什么? 含义：在 Java 中，JVM 可以理解的代码就叫做字节码（即扩展名为 .class 的文件），它不面向任何特定的处理器，只面向虚拟机。 好处：Java 语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以 Java 程序运行时比较高效，而且，由于字节码并不针对一种特定的机器，因此，Java 程序无须重新编译便可在多种不同操作系统的计算机上运行。 4、java程序运行过程 Java 程序从源代码到运行一般有下面 3 步： .class-&gt;机器码 JVM 类加载器首先加载字节码文件 然后通过解释器逐行解释执行，这种方式的执行速度会相对比较慢。而且，有些方法和代码块是经常需要被调用的(也就是所谓的热点代码)，所以后面引进了 JIT 编译器，而 JIT 属于运行时编译。当 JIT 编译器完成第一次编译后，其会将字节码对应的机器码保存下来，下次可以直接使用。而我们知道，机器码的运行效率肯定是高于 Java 解释器的。这也解释了我们为什么经常会说 Java 是编译与解释共存的语言。 HotSpot 采用了惰性评估(Lazy Evaluation)的做法，根据二八定律，消耗大部分系统资源的只有那一小部分的代码（热点代码），而这也就是 JIT 所需要编译的部分。JVM 会根据代码每次被执行的情况收集信息并相应地做出一些优化，因此执行的次数越多，它的速度就越快。JDK 9 引入了一种新的编译模式 AOT(Ahead of Time Compilation)，它是直接将字节码编译成机器码，这样就避免了 JIT 预热等各方面的开销。JDK 支持分层编译和 AOT 协作使用。但是 ，AOT 编译器的编译质量是肯定比不上 JIT 编译器的。 JRE和JDK1、JRE（Java Runtime Environment） 含义：java程序的运行时的环境，包含JVM和运行时所需要的核心类库 我们想要运行一个已有的java程序，只需要按照JRE即可 2、JDK（Java Development kit） 含义：java程序开发工具包，包含JRE和开发人员使用的工具 开发工具：编译工具（javac.exe）和运行工具（java.exe） 想要开发一个全新的Java程序，必须安装JDK 3、JDK、JRE、JVM的关系 Oracle JDK 和 OpenJDK1、Oracle JDK 大概每 6 个月发一次主要版本，而 OpenJDK 版本大概每三个月发布一次，但这不是固定的。 2、OpenJDK 是一个参考模型并且是完全开源的，而 Oracle JDK 是 OpenJDK 的一个实现，并不是完全开源的； 3、Oracle JDK 比 OpenJDK 更稳定。OpenJDK 和 Oracle JDK 的代码几乎相同，但 Oracle JDK 有更多的类和一些错误修复。因此，如果您想开发企业&#x2F;商业软件，我建议您选择 Oracle JDK，因为它经过了彻底的测试和稳定。 4、在响应性和 JVM 性能方面，Oracle JDK 与 OpenJDK 相比提供了更好的性能；Oracle JDK 不会为即将发布的版本提供长期支持，用户每次都必须通过更新到最新版本获得支持来获取最新版本； 5、Oracle JDK 根据二进制代码许可协议获得许可，而 OpenJDK 根据 GPL v2 许可获得许可。 Java 和 C++的区别 都是面向对象的语言，都支持封装、继承和多态 Java 不提供指针来直接访问内存，程序内存更加安全 Java 的类是单继承的，C++ 支持多重继承；虽然 Java 的类不可以多继承，但是接口可以多继承。 Java 有自动内存管理垃圾回收机制(GC)，不需要程序员手动释放无用内存 在 C 语言中，字符串或字符数组最后都会有一个额外的字符’\\0’来表示结束。但是，Java 语言中没有结束符这一概念。 Java——编译与解释并存Java 语言既具有编译型语言的特征，也具有解释型语言的特征，因为 Java 程序要经过先编译，后解释两个步骤，由 Java 编写的程序需要先经过编译步骤，生成字节码（*.class 文件），这种字节码必须由 Java 解释器来解释执行。因此，我们可以认为 Java 语言编译与解释并存。 Java语法注释1、注释：在指定位置添加的说明性信息（仅起到说明作用） 2、分类： 单行注释格式：// 注释信息 多行注释格式：/* 注释信息*/ 文档注释格式：/** 注释信息*/ 关键字1、关键字：被Java语言赋予了特定含义的单词 2、关键字的特点： 字母全部小写 常用的代码编辑器对关键字有特殊的颜色标记 常量1、常量：在程序运行过程中，值不会改变的量 2、常量的分类： 字符串常量说明：用双引号括起来的内容例子：&quot;HelloWorld&quot; 整数常量说明：不带小数的数字例子：520 小数常量说明：带小数的数字例子：13.14 字符常量说明：用单引号括起来的内容例子：&#39;A&#39; 布尔常量说明：布尔值例子：true false 空常量（不能直接输出）说明：一个特殊的值，空值例子：null 数据类型1、计算机存储单元 计算机存储设备（内存、硬盘）的最小信息单元——位（bit），又称为比特位，通常用小写字母b表示 计算机最小的存储单元——字节（byte），用大写字母B表示，由连续的8个位组成 1B &#x3D; 8 bit —— 1KB &#x3D; 1024B —— 1MB &#x3D; 1024KB —— 1GB &#x3D; 1024MB —— 1TB &#x3D; 1024GB 2、数据类型 Java语言时强类型语言，对于每一种数据都给出了明确的数据类型，不同的数据类型分配不同的存储空间，所以表示的数据大小也不同。 3、数据类型内存占用和取值范围 变量1、变量：在程序运行过程中，其值可以发生变化的量；从本质上讲，变量时内存中的一小块区域 2、变量的定义 组成：变量名+变量数据类型+变量值 例子：int a = 10; 3、变量的使用：取值、修改值 取值：变量名 a 修改值：变量名&#x3D;修改值 a = 20; 4、注意事项： 变量名不能重复 变量未赋值不能使用 long类型的变量定义时，为了防止整数过大，后面要加L float类型的变量定义时，为了防止类型不兼容，后面要加F 标识符1、标识符定义规则 由数字、字母、下划线、美元符组成 不能以数字开头 不能是关键字 区分大小写 2、常见命名约定： 小驼峰命名法：方法、变量标识符是一个单词时，首字母小写 标识符由多个单词组成的时候，第一个单词首字母小写，其他单词首字母大写 大驼峰命名法：类标识符是一个单词时，首字母大写 标识符由多个单词组成的时候，单词首字母大写 3、标识符和关键字的区别是什么？ 在我们编写程序的时候，需要大量地为程序、类、变量、方法等取名字，于是就有了标识符，简单来说，标识符就是一个名字。但是有一些标识符，Java 语言已经赋予了其特殊的含义，只能用于特定的地方，这种特殊的标识符就是关键字。 因此，关键字是被赋予特殊含义的标识符。比如，在我们的日常生活中 ，“警察局”这个名字已经被赋予了特殊的含义，所以如果你开一家店，店的名字不能叫“警察局”，“警察局”就是我们日常生活中的关键字。 类型转换1、分类： 自动类型转换：把一个数据范围小的数值或者变量赋值给另外一个大的变量例：double d = 10 强制类型转换：把一个数据范围大的数值或者变量赋值给另外一个小的变量格式：目标数据类型 变量名 &#x3D; （目标数据类型）值例子：int k = (int)88.8 基本概念： 运算符：对常量或者变量进行操作的符号 表达式：用运算符把常量或者变量连接起来符合Java语法的式子可以称为表达式，不同运算符连接的表达式体现的是不同类型的表达式 Java运算符算术运算符1、算数运算符：加号（+）、减号（-）、除号（&#x2F;）、乘号（*）以及取模操作符（%） 2、注意： 整数相除只能得到整数，若想得到小数，必须有浮点数参与运算 字符的+操作1234int i = 10;char c = &#x27;A&#x27; //65c = &#x27;a&#x27; //97c = &#x27;0&#x27; //48 字符参与加操作，拿字符在计算机底层的对应数值来计算 算术表达式中包含多个基本数据类型的值的时候，整个算术表达式的类型会进行自动提升 提升规则： byte类型、short类型、char类型将被提升到int类型 整个表达式的类型自动提升到表达式中最高等级的类型，顺序：byte、short、char -&gt; int -&gt; long -&gt; float -&gt; double 字符串的+操作1234&quot;zhang&quot;+&quot;tao&quot; //输出zhangtao&quot;zhang&quot;+666 //输出zhang666&quot;zhang&quot;+7+66 //输出zhang7661+99+&quot;zhang&quot; //输出100zhang 当“+”操作出现字符串时，这个+是字符串连接符，而不是算术运算 &quot;zhang&quot;+7+66：如果出现了字符串，就是连接运算符，否则是算术运算；当连续进行+操作时，从左到右逐个执行 1+99+&quot;zhang&quot;：从左到右逐个执行 赋值运算符 注意：隐含强制类型转换 自增自减运算符 前缀递增和前缀递减（如++a或–a），会先执行运算，再生成值 后缀递增和后缀递减（如a++或a–），会先生成值，再执行运算 ⚠️注意： ++和–可以放在变量的后边，也可以放在变量的前边 单独使用，放在前边和后边结果一样（最常见的用法&#x3D;&#x3D;） 参与操作时，如果放在变量后边，先拿变量进行操作，后拿变量做++或者–；如果放在变量前边，先拿变量做++或者–，后进行操作例如： 123int i =10int j = i++ // 结果：j = 10,i =11 关系运算符关系操作符：比较两个变量之间的关系，生成一个boolean值（true or false） 操作符 含义 &gt; 大于 &gt;&#x3D; 大于或等于 &lt; 小于 &lt;&#x3D; 小于或等于 &#x3D;&#x3D; 等于 !&#x3D; 不等 逻辑运算符逻辑运算符，是用来连接关系表达式的运算符，也可以直接连接布尔类型的常量或者变量 关键字 简介 具体含义 &amp;、 &amp;&amp; 长路与 、短路与 相同点：两边都为真时为真；任意一个为假结果为假； 不同点：长路与两侧都会被运算；短路与如果第一个为假则结果为假 ｜、｜｜ 长路或 、 短路或 相同点：两边都为假时为假；任意一个为真结果为真； 不同点：长路与两侧都会被运算；短路与如果第一个为真则结果为真 ！ 取反 真变假；假变真 ^ 异或 不同时返回真；相同时返回假 最常用的逻辑运算符：&amp;&amp; 、||、! 三元运算符格式：关系表达式？表达式1:表达式2 规则：首先计算关系表达式的值，如果为true，表达式1则为运算结果，反之表达式2为运算结果 案例：两只老虎 需求：动物园有两只老虎，分别是180kg和200kg，用程序实现判断两只老虎的体重是否相同 代码： 123int weight1 = 180;int weight2 = 200;System.out.println(weight1==weight2?true:false); 案例：三个和尚 需求：有三个和尚，身高分别为150cm、210cm、165cm，用程序获取三个和尚的最高身高 分析： 定义三个变量保存身高 用三元运算符获取前两个身高的较高身高，用临时变量保存 用三元运算符获得临时身高与第三个和尚的身高的较高身高 123456int height1 = 150;int height2 = 210;int height3 = 165;int temp = height1&gt;height2 ? height1:height2;int max = temp&gt;height3 ?temp:height3;System.out.println(max); 数据输入Scanner使用的基本步骤 导包 1import java.util.Scanner; 创建对象 1Scanner sc = new Scanner(System.in); 接受数据 1int i = sc.nextInt(); 案例：三个和尚 需求：一个寺庙住着三个和尚，他们的身高必须经过测量得出，用程序获取三个和尚最高身高 分析： 身高未知，通过键盘输入 录入身高 比较 输出结果 代码： 1234567Scanner sc = new Scanner(System.in);int height1 = sc.nextInt();int height2 = sc.nextInt();int height3 = sc.nextInt();int temp = height1 &gt; height2 ? height1:height2;int max = temp &gt; height3 ?temp:height3;System.out.println(max); 分支语句与循环语句分支语句流程控制流程控制语句分类： 顺序结构是程序中最简单最基本的流程控制，没有特定的语法结构，按照代码的先后顺序，依次执行，程序中大多数的代码都是这样执行的。 分支结构（if、switch） 循环结构（for、while、do…while） if语句12345678910111213141516171819202122格式1：if()&#123; 语句体;&#125;格式2:if()&#123; 语句体;&#125;else&#123; 语句体;&#125;格式3:if()&#123; 语句体;&#125;else if()&#123; 语句体;&#125; ......else&#123; 语句体;&#125; switch语句12345678910111213141516171819switch（表达式）&#123; case value1 : //语句 break; //可选 case value2 : //语句 break; //可选 //你可以有任意数量的case语句 default : //可选 //语句&#125; 循环语句组成部分： 初始化语句：循环开启的起始状态，一条或者多条语句 条件判断语句：反复执行的条件，使用一个结果为布尔值的表达式 循环体语句：反复执行的内容，任意语句 条件控制语句：循环执行中每次变化的内容，使用一条语句改变变量的值，例如i++ for循环语句123for(初始化语句；条件判断语句；条件控制语句)&#123; 循环体语句&#125; 执行过程：初始化语句-&gt;条件判断语句-&gt;循环体语句-&gt;条件控制语句-&gt;条件判断语句-&gt;循环体语句-&gt;………. while循环语句1234while（条件判断语句）&#123; 循环体语句 条件控制语句&#125; do-while循环语句1234do&#123; 循环体语句 条件控制语句&#125;while（条件判断语句） 三种循环的区别：1、for循环和while循环先判断条件是否成立，然后决定是否执行循环体（先判断后执行） 2、do-while循环先执行一次循环体，然后判断条件是否成立，是否继续执行循环体（先执行后判断） 3、for和while的区别： 条件控制语句所控制的自增变量，因为归属for循环的语法结构中，在for循环结束后，就不能再次被访问到了 条件控制语句所控制的自增变量，对于while循环来说不归属其语法结构中，在while循环结束后，该变量还可以继续使用 4、死循环： for(;;)&#123;&#125; while(true)&#123;&#125; do&#123;&#125;while(true) 跳转控制语句1、continue：用在循环中，基于条件控制，跳过某次循环体内容的执行，继续下一次的执行 2、break：用在循环中，终止循环体内容的执行，也就是说结束当前的整个循环 3、return ：用于跳出所在方法，结束该方法的运行。 return 一般有两种用法：return; ：直接使用 return 结束方法执行，用于没有返回值函数的方法return value; ：return 一个特定值，用于有返回值函数的方法 循环嵌套语句结构： 顺序语句：以分号结尾，表示一句话的结束 分支语句：一对大括号表示if&#x2F;switch的整体结构，整体描述一个完整的if语句 循环语句：for包for ；do-while以分号结尾，整体描述一个完整的do-while语句 Random1、作用：用于产生一个随机数 2、使用步骤： 导包 1import java.util.Random 创建对象 1Random r = new Random(); 获取随机数 1int number = r.nextInt(10);//[0,10) 数组数组定义格式1、数组：用于存储多个相同类型数据的存储模型 2、定义格式： 1234格式一：数据类型[]变量名例如：int[] arr格式二：数据类型 变量名[]例如：int arr [] 数组初始化之动态初始化1、数组初始化：Java中的数组必须先初始化，然后才能使用 初始化：为数组中的数组元素分配内存空间，并为每个数组元素赋值 2、初始化方式： 动态初始化：初始化时只制定数组长度，由系统分配初始值格式：数据类型[] 变量名 = new(为数组申请内存空间) 数据类型[数组长度]例子：int[] arr = new int[3]; 静态初始化 数组元素访问1、数组变量的访问方式 格式：数组名 2、数组内部保存数据的访问方式 格式：数组名[索引] 3、索引是数组中数据的编号方式 作用：索引用于访问数组中的数据使用，数组名[索引]等同于变量名，是一种特殊的变量名 索引从0开始，连续的，逐一增加的 内存分配1、java中的内存分配：Java程序在运行时，需要在内存中分配空间，为了提高运算效率，就对空间进行了不同区域的划分，因为每一片区域都有特定的处理数据方式和内存管理方式 栈内存：存储局部变量 定义在方法中的变量，例如arr 使用完毕，立即消失 堆内存：存储new出来的内容（实体，对象） 数组在初始化时，会为存储空间添加默认值 每一个new出来的东西都有一个地址值 使用完毕，会在垃圾回收器空闲时被回收 2、数组的内存分配 123456789int[] arr = new int[3];//数组在初始化时，会为存储空间添加默认值//整数：0，浮点数：0.0，布尔值：false，字符：空字符，引用数据类型：null//输出数组名及元素System.out.println(arr); //输出内存地址System.out.println(arr[0]); //输出元素System.out.println(arr[1]); //输出元素System.out.println(arr[2]); //输出元素 数组内存图（单个数组）1234567891011121314int[] arr = new int[3];//输出数组名及元素System.out.println(arr); //输出内存地址System.out.println(arr[0]); //输出元素System.out.println(arr[1]); //输出元素System.out.println(arr[2]); //输出元素//给数组中的元素赋值arr[0] = 100;arr[2] = 200;//再次输出数组名及元素System.out.println(arr); //输出内存地址System.out.println(arr[0]); //输出元素System.out.println(arr[1]); //输出元素System.out.println(arr[2]); //输出元素 内存图： 1int[] arr = new int[3]; 1System.out.println(arr); 1System.out.println(arr[1]); 1arr[0] = 100; 输出结果： 12345600100001100200 数组内存图（多个数组）1234567891011121314151617181920int[] arr = new int[2];int[] arr2 = new int[3];//输出数组名及元素System.out.println(arr); //输出内存地址System.out.println(arr[0]); //输出元素System.out.println(arr[1]); //输出元素System.out.println(arr2); //输出内存地址System.out.println(arr2[0]); //输出元素System.out.println(arr2[2]); //输出元素//给数组中的元素赋值arr[0] = 100;arr2[0] = 200;arr2[2] = 300;//再次输出数组名及元素System.out.println(arr); //输出内存地址System.out.println(arr[0]); //输出元素System.out.println(arr[1]); //输出元素System.out.println(arr2); //输出内存地址System.out.println(arr2[0]); //输出元素System.out.println(arr2[2]); //输出元素 内存图： 12int[] arr = new int[2];int[] arr2 = new int[3]; 输出： 1234567891011121300100002000011000002200300 数组内存图（多个数组指向相同）1234567891011121314151617181920int[] arr = new int[3];//给数组中的元素赋值arr[0] = 100;arr[1] = 200;arr[2] = 300;//输出数组名及元素System.out.println(arr); //输出内存地址System.out.println(arr[0]); //输出元素System.out.println(arr[1]); //输出元素System.out.println(arr[2]); //输出元素//定义第二个数组指向第一个数组int[] arr2 = arr;arr2[0] = 111;arr2[1] = 222;arr2[2] = 333;//再次输出数组名及元素System.out.println(arr); //输出内存地址System.out.println(arr[0]); //输出元素System.out.println(arr2); //输出内存地址System.out.println(arr2[0]); //输出元素 内存图： 1int[] arr2 = arr; 123arr2[0] = 111;arr2[1] = 222;arr2[2] = 333; 输出结果： 123456789001100200300001111002111 数组初始化之静态初始化1、静态初始化：初始化时指定每个数组元素的初始值，由系统决定数组长度 格式：数据类型[]变量名 = new 数据类型[]&#123;数据1，数据2，数据3........&#125; 简化格式：数据类型[] 变量名 = &#123;数据1，数据2，数据3........&#125; 数组操作的两个问题索引越界访问了数组中不存在的索引对应的元素，造成该问题 12int[] arr = new int[3];System.out.println(arr[3]); 空指针异常访问的数组已经不再指向堆内存的数据，造成空指针异常 1234int[] arr = new int[3];System.out.println(arr[2]);arr=null;System.out.println(arr[0]) 1arr=null; 数组常见操作遍历12345int[] arr = &#123;11,22,33,44,55&#125;for(int i = 0 ; i&lt;arr.length ; i++)&#123; System.out.println(arr[i]);&#125; 获取最值12345678int[] arr = &#123;11,22,33,44,55&#125;int max = arr[0];for(int i=0;i&lt;arr.length;i++)&#123; if(arr[i]&gt;max)&#123; max =arr[i]; &#125;&#125; 方法方法概述1、方法：将具有独立功能的代码块组织成一个整体，使其具有特殊功能的代码集 2、注意： 方法必须先创建才可以使用，该过程称为 方法定义 方法创建后并不是直接运行的，需要手动使用后才执行，该过程称为 方法调用 方法的定义和调用1、方法定义： 格式： 123public static void 方法名()&#123; //方法体&#125; 2、方法调用： 格式：方法名() 带参数方法的定义和调用1、定义格式：public static void 方法名(参数)&#123;......&#125; 格式（单个参数）:public static void 方法名(数据类型 变量名)&#123;.....&#125; 格式（多个参数）:public static void 方法名(数据类型1 变量名1,数据类型2 变量名2....)&#123;.....&#125; 2、调用格式：方法名(参数) 3、形参和实参 形参：方法定义中的参数，等同于变量定义格式，例如：int number 实参：方法调用中的参数，等同于使用变量或常量，例如：10 number 带返回值方法的定义和调用1、定义格式： 123public static 数据类型 方法名（参数）&#123; return 数据;&#125; 2、调用格式： 格式1：方法名(参数) 格式2：数据类型 变量名 = 方法名(参数) 3、返回值：是指我们获取到的某个方法体中的代码执行后产生的结果！（前提是该方法可能产生结果）。返回值的作用是接收出结果，使得它可以用于其他的操作。 方法的注意事项1、注意事项： 方法不能嵌套定义（平级关系） void表示没有返回值，可以省略return，也可以单独写return，后面不加数据 2、方法的通用格式： 格式： 1234public static 返回值类型 方法名（参数）&#123; 方法体; return 数据;&#125; 定义方法要做到两个明确：返回值类型、参数 调用方法时，void类型的方法直接调用即可，非void方法用变量接受 方法重载1、方法重载：同一个类中定义的多个方法之间的关系，满足下列条件的多个方法相互构成重载： 多个方法在同一个类中 多个方法具有相同的方法名 多个方法参数不同、类型不同或者数量不同 判定重载只看同一个类、相同方法名、不同参数！！！ 2、特点： 重载只对应方法的定义，与方法的调用无关，调用方式按照标准格式 重载只针对同一个类中方法的名称与参数进行识别，与返回值无关，换句话说不能通过返回值来判定两个方法是否相互重载 方法的参数传递（按值传递的）1、方法参数传递（基本数据类型） 结论：对于基本数据类型的参数，形式参数的改变不影响实际参数的值 例子： 输出结果： 12100100 2、方法参数传递（引用类型） 结论：对于引用类型的参数，形式参数的改变，影响实际参数的值 例子： 结果： 1220200","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}]},{"title":"docker命令","slug":"docker","date":"2021-07-10T01:29:14.000Z","updated":"2022-02-15T15:29:33.294Z","comments":true,"path":"2021/07/10/docker/","link":"","permalink":"http://example.com/2021/07/10/docker/","excerpt":"","text":"docker版本 docker -v docker镜像列表 docker images 启动docker服务 sudo systemctl start docker docker下载镜像 sudo docker pull mysql:5.7 创建mysql docker run –name hsk-mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD&#x3D;123456 -d mysql:5.6 运行mysql容器 docker start hsk-mysql 查看正在运行的容器 docker ps 查看所有容器 docker ps -a docker停止正在运行的容器 docker stop hsk-mysql 删除一个容器 docker rm hsk-mysql 查看日志信息 docker logs hsk-mysql 重启某个docker服务 docker restart redis","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}]},{"title":"git命令","slug":"git","date":"2021-07-08T03:13:14.000Z","updated":"2022-02-15T15:29:57.021Z","comments":true,"path":"2021/07/08/git/","link":"","permalink":"http://example.com/2021/07/08/git/","excerpt":"","text":"提交到本地库 git commit -m “日志信息” 文件名 查看历史记录 git refloggit log 从暂存区删除文件 git rm –cached 文件名 设置用户签名 git config –global user.name “Stitch” 设置用户邮箱 git config –global user.email “&#120;&#x78;&#104;&#115;&#x6b;&#48;&#54;&#x31;&#x38;&#64;&#x31;&#x36;&#x33;&#46;&#99;&#111;&#x6d;“ 初始化本地仓库 git init 查看本地仓库状态 git status 添加远程库 git remote add origin ‘你的远程仓库地址’ 添加到暂存区 git add 文件名 版本穿梭 git reset –hard 版本号 查看分支 git branch -v 创建分支 git branch 分支名 切换分支 git checkout 分支名 合并分支 git merge 分支名 删除分支 git branch –delete hsk 查看远程地址别名 git remote -v 修改远程连接别名 a-&gt;b git remote rename a b 推送本地库到远程库 git push test master:abc —-test 为设置的远程仓库别名，master为本地分支名，abc为远程分支名 拉取远程库到本地库 git pull e-shop master 码云私人令牌 ce9823f401265d 2999693af00351ce0c","categories":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"keywords":[{"name":"开发笔记","slug":"开发笔记","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/"}]}]}